\newpage
\section{Methodik} \label{sec:Methodik}

\fixme{Vertiefung relevanter Themenbereiche basierend auf den Erkenntnissen aus der Artefakt-Entwicklung erfolgt unsystematisch...}

Abgrenzung Herleitung des Themas und Relevanz systematisch vs. DSR unsystematische Literaturrecherche bedarfsspezifisch?

\subsection{Systematische Literaturrecherche} \label{sec:Systematische Literaturrecherche}

Die systematische Literaturrecherche für diese Seminararbeit folgt einer Anzahl ausgewählter Methoden der PRISMA 2020 Richtlinien, dessen aktualisierte Leitlinien Transparenz und Vollständigkeit bei der Darstellung von Vorgehen und Ergebnissen systematischer Reviews fördern. Ziel ist es, den Erkenntnisstand zu einem spezifischen Forschungsproblem durch eine strukturierte Identifikation, Selektion, Bewertung und Synthese einschlägiger Studien methodisch nachvollziehbar zu dokumentieren, wodurch eine belastbare Grundlage für die Analyse der Forschungslücke und die Ableitung von Forschungsfragen geschaffen wird \parencite[S. 1--3]{page_PRISMA2020Statementupdatedguidelinereportingsystematicreviews_2021}. Die PRISMA 2020 Richtlinien fordern u.a. die offene Darlegung der Suchstrategien, der Auswahlkriterien sowie der Bewertungs- und Syntheseverfahren, um die Nachvollziehbarkeit und Replizierbarkeit des Forschungsprozesses sicherzustellen \parencite[S. 1--6]{page_PRISMA2020Explanationelaborationupdatedguidanceexemplarsreportingsystematicreviews_2021}.

Die systematische Literaturrecherche wurde in zwei zeitlich getrennten Iterationen durchgeführt, um den evolving Charakter des Forschungsfeldes zu adressieren und die Aktualität der Wissensbasis sicherzustellen. Beide Iterationen dienen ausschließlich der initialen Problemidentifikation, der Ergründung des Forschungsstands sowie der Ableitung der Forschungslücke und initialen Forschungsfragen.

\subsubsection{Erste Iteration (30. Mai 2025)}

Die erste Iteration fand im Rahmen des Exposés statt und etablierte die methodische Grundlage für das gesamte Forschungsprojekt. Diese initiale Recherche identifizierte 61 relevante Quellen mit differenzierter Relevanzklassifizierung (hoch/mittel/niedrig) und ermöglichte die Formulierung der Forschungsfragen sowie die Identifikation der Forschungslücke im Bereich Post-Quantum-Kryptografie für Self-Sovereign-Identity-Systeme in kritischen Infrastrukturen. Die detaillierte Dokumentation dieser ersten Iteration \fixme{aus dem Exposé} wurde in \ref{sec:Anhang_Dokumentation der ersten Iteration der systematischen Literaturrecherche (Exposé)} dieser Masterarbeit integriert, um Transparenz und Reproduzierbarkeit zu gewährleisten.

\subsubsection{Zweite Iteration (02. November 2025)}

Die zweite Iteration erfolgt im Rahmen der Masterarbeit unter Berücksichtigung der in der ersten Iteration definierten ausgewählten Methoden der PRISMA 2020 Richtlinien (\autoref{tab:Ausgewählte Methoden der PRISMA 2020 Richtlinien}).

Angepasst wurde der Suchzeitraum (Zeitrahmen: 30. Mai 2025 bis 02. November 2025) innerhalb der Ein- und Ausschlusskriterien, um die Wissensbasis zu aktualisieren und neu erschienene Publikationen im dynamischen Forschungsfeld der Post-Quantum-Kryptografie und blockchain-basierten SSI-Systeme zu erfassen (\autoref{tab:einausschlusskriterien_iteration2}).

\begin{longtable}{L{3cm}L{4cm}L{4cm}L{3cm}}
    \caption{Ein- und Ausschlusskriterien für die systematische Literaturrecherche}
    \label{tab:einausschlusskriterien_iteration2} \\
    \toprule
    \textbf{Kategorie} & \textbf{Einschluss} & \textbf{Ausschluss} & \textbf{Begründung} \\
    \midrule
    \endfirsthead
    \multicolumn{4}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Kategorie} & \textbf{Einschluss} & \textbf{Ausschluss} & \textbf{Begründung} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{4}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{4}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung.} \\
    \endlastfoot
    Thematischer Fokus &
    \ac{SSI} und dezentrale Identitätslösungen;
    Blockchain-basierte Identitätsmanagementsysteme;
    \ac{PQC} und quantensichere Algorithmen;
    Sicherheit und Compliance in \ac{KRITIS};
    \ac{DSR}-Methodik in IT/Informationssystemen;
    Kryptoagilität und kryptografische Migration & 
    Identitätsmanagement ohne Bezug zu \ac{SSI} oder Blockchain;
    Klassische \ac{PKI} ohne \ac{PQC}-Bezug;
    Kryptografie ohne Post-Quantum-Relevanz;
    Arbeiten ohne Bezug zu \ac{KRITIS} oder ohne sicherheitskritischen Kontext;
    Nicht-\ac{DSR}-basierte Entwicklungsansätze & 
    Fokussierung auf die Forschungsfragen und relevante technologische, methodische und regulatorische Aspekte. \\
    \midrule
    Zeitrahmen & 30. Mai 2025 bis 02. November 2025 & Alles davor oder danach & Berücksichtigung aktueller technologischer Entwicklungen (Blockchain, \ac{PQC}, \ac{SSI}) und regulatorischer Anforderungen. \\
    \midrule
    Publikationstypen & 
    Peer-reviewed Journalartikel;
    Konferenzbeiträge anerkannter Fachgesellschaften (z. B. IEEE, ACM, IFIP); Preprints;
    Offizielle Standards und Empfehlungen (z. B. \ac{NIST}, W3C, \ac{BSI});
    Whitepaper etablierter Organisationen;
    Dissertationen und anerkannte Fachbücher & 
    Blogposts, Forenbeiträge, Marketingmaterial;
    Populärwissenschaftliche Artikel ohne wissenschaftliche Fundierung;
    Unveröffentlichte Manuskripte ohne Peer-Review;
    Seminar- und Abschlussarbeiten ohne wissenschaftliche Begutachtung & 
    Sicherstellung wissenschaftlicher Qualität, Nachvollziehbarkeit und Relevanz der Quellen für die Masterarbeit; Da das Forschungsthema aktuell noch sehr neu ist und die einschlägige Fachliteratur teilweise noch nicht den Peer-Review-Prozess durchlaufen hat, werden auch Preprints in die Analyse einbezogen. Preprints ermöglichen eine zeitnahe Verfügbarkeit aktueller Forschungsergebnisse, was insbesondere bei diesem innovativen von großer Bedeutung ist. \\
    \midrule
    Sprache & Deutsch; Englisch & Andere Sprachen als Deutsch und Englisch & Gewährleistung der Verständlichkeit und Zugänglichkeit für den deutsch- und englischsprachigen Forschungskontext. \\
    \midrule
    Zugänglichkeit & Verfügbare Volltexte & Nicht verfügbare Volltexte & Ermöglichung einer gründlichen Analyse und Bewertung der Inhalte. \\
\end{longtable}

Um die Konsistenz und Vergleichbarkeit der Ergebnisse zu gewährleisten wurde die zweite Iteration mit identischer Suchstrategie durchgeführt.
Dazu zählen alle in \autoref{tab:suchstrategie} dargestellten Schritte, von der Identifikation relevanter Schlüsselkonzepte bis zur Übersetzung der Suchanfrage für die EBSCO Datenbank.

\paragraph*{Übersetzung der Suchanfrage für EBSCO}

Das Ergebnis der EBSCO Suchanfrage ist in \autoref{fig:EBSCO Ergebnis_11} dargestellt. Insgesamt wurden mit dieser Abfrage 34 Quellen identifiziert.

\begin{figure}[H]
    \centering
    \includegraphics[width=\paperwidth, height=\paperheight, keepaspectratio, angle=90]{EBSCO_11.png}
    \caption{Ergebnis der EBSCO Suchanfrage}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:EBSCO Ergebnis_11}
\end{figure}

\paragraph*{Selektionsprozess}

Der Selektionsprozess in Iteartion 2 wurde gegenüber dem iteration 1 Expose erweitert um die Relevanzbewertung der neu identifizierten Quellen zu verfeinern und ist in \fixme{Abb. XY} dargestellt.
Dafür wurde ein zweistufiger Screening-Prozess implementiert, bestehend aus einem Title-Abstract-Screening gefolgt von einem Full-Text-Screening.

Für das Title-Abstract-Screening wurden alle in Iteration 2 identifizierten Quellen anhand ihrer Titel und Abstracts wie auch schon im Expose in Bezug auf den thematischen Fokus der Arbeit. Hohe Relevanz erhalten Quellen mit klaren Beiträgen zu SSI, PQC, KRITIS oder dezentralen Identitätsarchitekturen. Mittlere Relevanz wird Arbeiten zugeordnet, die angrenzende Technologien wie Blockchain-Sicherheit im IoT oder digitale Forensik behandeln. Niedrige Relevanz erhalten Quellen zu allgemeinen Technologietrends ohne direkten Bezug zum Thema.

\begin{figure}[H]
    \centering
    \includegraphics[width=\paperwidth-3.75cm]{PRISMA_2020_flow_diagram_updated_SRs_v1_ITERATION_2.png}
    \caption{PRISMA 2020 Flussdiagramm - zweite Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} In Anlehnung an \textcite[S. 5]{page_PRISMA2020Statementupdatedguidelinereportingsystematicreviews_2021}.
    \end{flushleft}
    \label{fig:PRISMA_Flussdiagramm_Iteration2}
\end{figure}

\autoref{fig:PRISMA_Flussdiagramm_Iteration2} visualisiert den gesamten Auswahlprozess der systematischen Literaturrecherche nach anerkannten wissenschaftlichen Standards. Im Diagramm werden alle Schritte der Literatursuche und -auswahl strukturiert und nachvollziehbar dokumentiert, beginnend mit der Identifikation relevanter Quellen aus Datenbanken, über das Screening der Titel und Abstracts sowie die Bewertung der Volltexte bis hin zur finalen Bestimmung der eingeschlossenen Studien.

\autoref{tab:quellenuebersicht_iteration2} stellt eine Übersicht der Bewertung der 34 identifizierten Quellen dar, welche vollständig in in \autoref{tab:quellenbewertung_iteration2} dokumentiert wurde.

\begin{longtable}{L{1.5cm}L{11cm}L{1cm}}
    \caption[]{Übersicht der Bewertung der identifizierten Quellen hinsichtlich ihrer Relevanz}
    \label{tab:quellenuebersicht_iteration2} \\
    \toprule
    \textbf{Nr.} & \textbf{Quelle} & \textbf{Relevanz} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Nr.} & \textbf{Quelle} & \textbf{Relevanz} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Basierend auf \autoref{tab:quellenbewertung_iteration2} und Titel und Abstracts von \textcite{barrett-danes_QuantumComputingCybersecurityrigoroussystematicreviewemergingthreatspostquantumsolutionsresearchdirections_2025,feng_IdentityManagementSystemsComprehensiveReview_2025}.} \\
    \endlastfoot
    1 & Barrett-danes, F., \& Ahmad, F. (2025). Quantum computing and cybersecurity: a rigorous systematic review of emerging threats, post-quantum solutions, and research directions (2019-2024). Discover Applied Sciences, 7(10). \url{https://doi.org/10.1007/s42452-025-07322-5} & Hoch \\
    \midrule
    2 & Feng, Z., Li, Z., Cui, H., \& Whitty, M. T. (2025). Identity management systems: A comprehensive review. Information (Basel), 16(9), 778. \url{https://doi.org/10.3390/info16090778} & Hoch \\
    \midrule
    3--10 & Diverse & Mittel  \\
    \midrule
    11--34 & Diverse & Niedrig \\
\end{longtable}


Die im Title-Abstract-Screening als potenziell relevant eingestuften Publikationen der ersten und zweiten Iteration wurden im nächsten Schritt, dem Full-Text-Screening vollständig gesichtet und einer detaillierten Bewertung unterzogen. Dabei wurden die Ausschlussgründe dokumentiert, um Transparenz im Selektionsprozess zu gewährleisten.

---


\subparagraph*{Ergebnisse der zweiten Iteration (02. November 2025)}

Die zweite Iteration, durchgeführt mit identischer Suchstrategie und angepasstem Zeitrahmen (30. Mai 2025 bis 02. November 2025), identifizierte insgesamt 34 neue Quellen aus der EBSCO-Datenbank (\autoref{fig:EBSCO Ergebnis_11}).

\textbf{Title-Abstract-Screening:} Im ersten Screening-Schritt wurden alle 34 identifizierten Quellen anhand ihrer Titel und Abstracts gegen die definierten Einschlusskriterien (\autoref{tab:einausschlusskriterien_iteration2}) bewertet. Dabei wurden [X] Publikationen ausgeschlossen, die offensichtlich nicht den thematischen Anforderungen entsprachen. [Y] Publikationen wurden für das Full-Text-Screening vorgemerkt.

\textbf{Full-Text-Screening:} Die [Y] verbliebenen Publikationen wurden vollständig gesichtet und einer detaillierten Bewertung gegen alle Ein- und Ausschlusskriterien unterzogen. Dabei wurden weitere [Z] Publikationen ausgeschlossen. Die Ausschlussgründe verteilten sich wie folgt:
\begin{itemize}
    \item Thematisch nicht relevant (kein direkter Bezug zu mindestens einer Kerndomäne): [A] Publikationen
    \item Methodisch ungeeignet (z.B. reine Meinungsbeiträge ohne empirische oder konzeptionelle Fundierung): [B] Publikationen
    \item Volltext nicht verfügbar trotz Document Delivery Anfrage: [C] Publikationen
\end{itemize}

Nach Abschluss des zweistufigen Screening-Prozesses verblieben [W] Publikationen für die finale Relevanzklassifikation:
\begin{itemize}
    \item \textbf{Hohe Relevanz}: [W1] Publikationen mit substanziellen Beiträgen zu mindestens zwei Kerndomänen
    \item \textbf{Mittlere Relevanz}: [W2] Publikationen mit Bezug zu einer Kerndomäne
    \item \textbf{Niedrige Relevanz}: [W3] Publikationen mit angrenzenden Themen
\end{itemize}

\subparagraph*{Konsolidierte Ergebnisse beider Iterationen}

Die erste Iteration (Exposé, 30. Mai 2025) identifizierte 61 Quellen, die anhand von Titel und Abstract nach Relevanz klassifiziert wurden (\autoref{tab:A-1}). Diese Klassifikation wurde für die Masterarbeit beibehalten, da sie dem methodischen Standard eines Exposés entspricht und zur Identifikation der Forschungslücke sowie zur Formulierung der Forschungsfragen ausreichend war.

Die zweite Iteration ergänzte diese Wissensbasis um [W] neue Quellen, die einem vollständigen zweistufigen Screening-Prozess nach PRISMA 2020 unterzogen wurden. Dies gewährleistet, dass alle für die Masterarbeit neu hinzugefügten Quellen den höheren wissenschaftlichen Standards systematischer Reviews genügen.

Über beide Iterationen hinweg stehen somit insgesamt [61 + W] Quellen für die Analyse des Forschungsstands, die Ableitung der theoretischen Grundlagen und die Entwicklung des SSI-Prototyps zur Verfügung. Die detaillierte Bewertung aller Quellen ist in \autoref{tab:A-1} (Iteration 1) und \autoref{tab:bewertung_iteration2} (Iteration 2) dokumentiert.




---







\autoref{tab:quellenuebersicht} stellt eine Übersicht der Bewertung der 61 \fixme{72} identifizierten Quellen dar, welche vollständig in \ref{sec:Anhang_Systematische Literaturrecherche} aufzufinden ist.

Die Einstufung basiert auf Titel und Abstract in Bezug auf den thematischen Fokus der Arbeit. Hohe Relevanz erhalten Quellen mit klaren Beiträgen zu \ac{SSI}, \ac{PQC}, \ac{KRITIS} oder dezentralen Identitätsarchitekturen. Mittlere Relevanz wird Arbeiten zugeordnet, die angrenzende Technologien wie Blockchain-Sicherheit im \ac{IoT} oder digitale Forensik behandeln. Niedrige Relevanz erhalten Quellen zu allgemeinen Technologietrends ohne direkten Bezug zum Thema.

\begin{longtable}{L{1.5cm}L{11cm}L{1cm}}
    \caption[]{Übersicht der Bewertung der identifizierten Quellen hinsichtlich ihrer Relevanz}
    \label{tab:quellenuebersicht} \\
    \toprule
    \textbf{Nr.} & \textbf{Quelle} & \textbf{Relevanz} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Nr.} & \textbf{Quelle} & \textbf{Relevanz} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Basierend auf \autoref{tab:quellenbewertung} und Titel und Abstracts von \textcite{szymanski_QuantumSafeSoftwareDefinedDeterministicInternetThingsIoTHardwareEnforcedCyberSecurityCriticalInfrastructures_2024,nouma_TrustworthyEfficientDigitalTwinsPostQuantumEraHybridHardwareAssistedSignatures_2024,sharif_EIDASRegulationSurveyTechnologicalTrendsEuropeanElectronicIdentitySchemes_2022,alam_PrivatelyGeneratedKeyPairsPostQuantumCryptographyDistributedNetwork_2024,radanliev_ReviewComparisonUSEUUKRegulationsCyberRiskSecurityCurrentBlockchainTechnologies_2023}.} \\
    \endlastfoot
    1 & Szymanski, T. H. (2024). A Quantum-Safe Software-Defined Deterministic Internet of Things (IoT) with Hardware-Enforced Cyber-Security for Critical Infrastructures. Information (2078-2489), 15(4), 173. \url{https://doi.org/10.3390/info15040173} & Hoch \\
    \midrule
    2 & Nouma, S. E., \& Yavuz, A. A. (2024). Trustworthy and Efficient Digital Twins in Post-Quantum Era with Hybrid Hardware-Assisted Signatures. ACM Transactions on Multimedia Computing, Communications \& Applications, 20(6), 1–30. \url{https://doi.org/10.1145/3638250} & Hoch \\
    \midrule
    3 & Sharif, A., Ranzi, M., Carbone, R., Sciarretta, G., Marino, F. A., \& Ranise, S. (2022). The eIDAS Regulation: A Survey of Technological Trends for European Electronic Identity Schemes. Applied Sciences (2076-3417), 12(24), 12679. \url{https://doi.org/10.3390/app122412679} & Hoch \\
    \midrule
    4 & Alam, M., Hoffstein, J., \& Cambou, B. (2024). Privately Generated Key Pairs for Post Quantum Cryptography in a Distributed Network. Applied Sciences (2076-3417), 14(19), 8863. \url{https://doi.org/10.3390/app14198863} & Hoch \\
    \midrule
    5 & Radanliev, P. (2023). Review and Comparison of US, EU, and UK Regulations on Cyber Risk/Security of the Current Blockchain Technologies: Viewpoint from 2023. Review of Socionetwork Strategies, 17(2), 105–129. \url{https://doi.org/10.1007/s12626-023-00139-x} & Hoch \\
    \midrule
    6--38 & Diverse & Mittel  \\
    \midrule
    39--61 & Diverse & Niedrig \\
\end{longtable}

\subsection{Design Science Research} \label{Design Science Research}

Die systematische Entwicklung und Evaluation eines blockchain-basierten Self-Sovereign-Identity-Prototyps mit Post-Quantum-Kryptografie für kritische Infrastrukturen erfordert einen Forschungsansatz, der sowohl die wissenschaftliche Fundierung als auch die praktische Anwendbarkeit der entwickelten Lösung gewährleistet.
\ac{DSR} erweist sich als besonders geeigneter methodischer Rahmen für dieses Vorhaben, da dieser Ansatz explizit darauf abzielt, innovative IT-Artefakte zu schaffen, die zur Erweiterung menschlicher und organisationaler Fähigkeiten beitragen \parencite[S. 75]{hevner_DesignScienceInformationsystemsresearch_2004}. 

Im Kern verfolgt \ac{DSR} einen problemlösungsorientierten Ansatz, der in den Ingenieurwissenschaften und den Wissenschaften des \fixme{Künstlichen (SIMON 1996)} verwurzelt ist. Das zentrale Ziel besteht darin, Innovationen zu schaffen, die Ideen, Praktiken, technische Fähigkeiten und Produkte definieren, durch welche die Analyse, das Design, die Implementierung, das Management und die Nutzung von Informationssystemen effektiv und effizient erreicht werden können \parencite[S. 76]{hevner_DesignScienceInformationsystemsresearch_2004}.

Die besondere Eignung von DSR für das vorliegende Forschungsvorhaben begründet sich durch mehrere zentrale Aspekte:

Erstens adressiert diese Arbeit ein hochrelevantes, praxisorientiertes Problem: die drohende Verwundbarkeit bestehender SSI-Systeme durch leistungsfähige Quantencomputer sowie die spezifischen Sicherheits- und Compliance-Anforderungen kritischer Infrastrukturen. Das primäre Forschungsziel liegt in der Entwicklung technologiebasierter Lösungen für bedeutende und relevante Geschäftsprobleme \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Zweitens erfordert die Integration von Post-Quantum-Kryptografie in blockchain-basierte SSI-Systeme die Schaffung eines neuartigen IT-Artefakts. DSR fordert explizit, dass Forschungsprojekte ein praktikables Artefakt in Form eines Konstrukts, Modells, einer Methode oder einer Instanziierung hervorbringen müssen \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Drittens ermöglicht DSR die systematische Evaluation des entwickelten Artefakts. Der Nutzen, die Qualität und die Wirksamkeit eines Design-Artefakts müssen durch gut durchgeführte Evaluationsmethoden rigoros nachgewiesen werden \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Viertens unterstützt DSR den wissenschaftlichen Erkenntnisgewinn durch die systematische Dokumentation von Forschungsbeiträgen. Effektive Design-Science-Forschung muss klare und verifizierbare Beiträge in den Bereichen Design-Artefakt, Design-Grundlagen und/oder Design-Methodologien liefern \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Fünftens gewährleistet DSR wissenschaftliche Strenge durch die Anwendung rigoroser Methoden sowohl bei der Konstruktion als auch bei der Evaluation des Design-Artefakts \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Die Methodenwahl DSR ist somit nicht nur durch die Passung zur Forschungsfrage begründet, sondern auch durch die inhärenten Anforderungen des Forschungsvorhabens: die Notwendigkeit, ein funktionsfähiges Artefakt zu entwickeln, dessen Nutzen für die Praxis nachzuweisen und gleichzeitig einen wissenschaftlichen Beitrag zur Wissensbasis zu leisten. DSR schafft hierfür den methodischen Rahmen, der Relevanz und Rigorosität gleichermaßen adressiert und die Brücke zwischen theoretischer Fundierung und praktischer Anwendbarkeit bildet.

\subsubsection{Drei-Zyklen-Modell} \label{Drei-Zyklen-Modell}

Das Drei-Zyklen-Modell von \textcite[S. 87]{hevner_ThreeCycleViewDesignScienceResearch_2007}, dargestellt in \autoref{fig:Design Science Research Cycles}, stellt die enge Verbindung der drei Aktivitätszyklen, dem Relevance Cycle, dem Rigor Cycle und dem Design Cycle, in der Design-Science-Forschung dar.
 
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{3-cycle.png}
    \caption{Design Science Research Cycles}
    \begin{flushleft}
    \textit{Anmerkung.} Aus \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007}.
    \end{flushleft}
    \label{fig:Design Science Research Cycles}
\end{figure}

Diese drei Zyklen stellen sicher, dass Design-Science-Forschung sowohl relevante Probleme aus der Anwendungsdomäne adressiert als auch auf einer soliden wissenschaftlichen Grundlage aufbaut, während gleichzeitig ein iterativer Entwicklungs- und Evaluationsprozess ermöglicht wird.

\paragraph*{Relevance Cycle: Integration von KRITIS-Anforderungen und Praxisanforderungen} \label{Relevance Cycle: Integration von KRITIS-Anforderungen und Praxisanforderungen}

Der Relevance Cycle initiiert die Design-Science-Forschung mit einem Anwendungskontext, der nicht nur die Anforderungen an die Forschung liefert, sondern auch die Akzeptanzkriterien für die letztendliche Evaluation der Forschungsergebnisse definiert \parencite[S. 89]{hevner_ThreeCycleViewDesignScienceResearch_2007}.

Im Kontext dieser Arbeit manifestiert sich der Relevance Cycle durch die Integration mehrschichtiger Anforderungen aus dem KRITIS-Umfeld:

\textbf{KRITIS-spezifische Sicherheitsanforderungen:} Die Zuverlässigkeit, Leistungsfähigkeit und Sicherheit kritischer Infrastrukturen stellen elementare nationale Prioritäten dar, da sie für die moderne Gesellschaft essenziell sind \parencite[S. 1]{alcaraz_CriticalInfrastructureProtectionRequirementschallenges21stcentury_2015}. Der Relevance Cycle adressiert konkret die besonderen Schutzbedarfe von Sektoren wie Energie, Gesundheit, Wasser oder Telekommunikation, deren Ausfall oder Beeinträchtigung erhebliche Versorgungsengpässe, Gefährdungen der öffentlichen Sicherheit oder andere dramatische Folgen nach sich ziehen würde.

\textbf{Regulatorische Vorgaben:} Die Anforderungen aus dem Relevance Cycle umfassen insbesondere die Einhaltung des IT-Sicherheitsgesetzes 2.0, der NIS2-Richtlinie sowie der Vorgaben des Bundesamts für Sicherheit in der Informationstechnik (BSI). Diese regulatorischen Rahmenbedingungen definieren Mindeststandards für Informationssicherheit, Meldepflichten bei Sicherheitsvorfällen und organisatorische Maßnahmen, die in das Design des Artefakts einfließen müssen.

\textbf{Datenschutz- und Compliance-Anforderungen:} Der Relevance Cycle integriert die Anforderungen der Datenschutz-Grundverordnung (DSGVO), insbesondere die Prinzipien Privacy by Design und Privacy by Default. Diese Anforderungen stellen sicher, dass der entwickelte Prototyp nicht nur technisch funktionsfähig ist, sondern auch die Grundrechte auf informationelle Selbstbestimmung und Datenschutz wahrt \fixme{QUELLE}.

\textbf{Quantenbedrohung und kryptografische Agilität:} Der Relevance Cycle adressiert die praktische Herausforderung, dass bestehende kryptografische Verfahren durch die Entwicklung leistungsfähiger Quantencomputer gefährdet sind. Dies erfordert die Integration von Post-Quantum-Algorithmen sowie die Implementierung kryptoagiler Mechanismen, die zukünftige Algorithmus-Updates ohne Systemunterbrechung ermöglichen.

\textbf{Feldtest und Evaluation:} Der Relevance Cycle schließt sich durch die Evaluation des entwickelten Prototyps anhand definierter Use Cases aus dem KRITIS-Umfeld. Die Bewertung erfolgt anhand von Akzeptanzkriterien, die sich aus den identifizierten Anforderungen ableiten: Funktionalität, Sicherheit, Performance, Compliance-Konformität und Zukunftsfähigkeit durch kryptografische Agilität.

Die kontinuierliche Rückkopplung zwischen Anwendungsumfeld und Forschungsaktivitäten stellt sicher, dass das entwickelte Artefakt nicht nur theoretisch fundiert, sondern auch praktisch relevant und anwendbar ist.

\paragraph*{Rigor Cycle: Einbindung wissenschaftlicher Erkenntnisse und systematischer Literaturrecherche} \label{Rigor Cycle: Einbindung wissenschaftlicher Erkenntnisse und systematischer Literaturrecherche}

Der Rigor Cycle liefert vergangenes Wissen an das Forschungsprojekt, um dessen Innovation sicherzustellen. Es obliegt den Forschenden, die Wissensbasis gründlich zu recherchieren und zu referenzieren, um zu gewährleisten, dass die entwickelten Designs Forschungsbeiträge darstellen und nicht Routinedesigns auf Basis wohlbekannter Prozesse sind \parencite[S. 90]{hevner_ThreeCycleViewDesignScienceResearch_2007}.

Im Rahmen dieser Arbeit manifestiert sich der Rigor Cycle durch mehrere zentrale Komponenten:

\textbf{Systematische Literaturrecherche nach PRISMA 2020 und unsystematische Recherche im DSR-Kontext:} 
Die Arbeit folgt einem hybriden Review-Ansatz, der zeitlich und funktional klar differenziert ist.

Die initiale, systematische Literaturrecherche nach ausgewählten Methoden der PRISMA 2020-Richtlinien (Kapitel 3.1) dient ausschließlich der \textbf{initialen Problemidentifikation, Ergrundung des Forschungsstands und Ableitung der Forschungslücke}. Diese systematische Vorgehensweise gewährleistet einen transparenten reproduzierbaren Prozess und verbessert die Berichtqualität \fixme{PRISMA-Quelle}.

\textbf{Davon abzugrenzen} ist die \textbf{bedarfsorientierte, unsystematische Literaturrecherche} während der iterativen Artefaktentwicklung im Design Cycle (Kapitel 4). Diese orientiert sich am iterativen Review-Ansatz nach vom \textcite[S. 208--209]{brocke_StandingShouldersGiantsChallengesRecommendationsLiteratureSearchInformationSystemsResearch_2015} und erfolgt \textbf{ad-hoc und problemspezifisch} zur Lösung konkreter technischer und methodischer Fragestellungen, die sich iterativ aus den Entwicklungs- und Evaluationszyklen ergeben. Diese unsystematische Recherche umfasst:

\begin{itemize}
  \item Technische Dokumentationen zu PQC-Algorithmen (NIST FIPS 203, 204, 205)
  \item Framework-spezifische Ressourcen (Hyperledger Aries/ACA-Py, liboqs, OpenSSL)
  \item BSI-Standards und Compliance-Vorgaben
  \item Ad-hoc-Literatur zu identifizierten Implementierungsherausforderungen
\end{itemize}

Im Gegensatz zur initialen systematischen Recherche ist diese bedarfsgesteuerte Suche \textbf{nicht vollständig dokumentiert nach PRISMA-Standards}, sondern erfolgt iterativ und problemspezifisch zur Lösung konkreter Designherausforderungen während der Prototypentwicklung. Dies entspricht dem explorativen Charakter des Design Science Research, bei dem das Artefakt iterativ entwickelt und evaluiert wird \fixme{DSR-Quelle}.



\textbf{Wissenschaftliche Grundlagen aus Referenzdisziplinen:} Der Rigor Cycle integriert theoretische und methodische Grundlagen aus mehreren Disziplinen:

    Kryptografie: Insbesondere die standardisierten Post-Quantum-Algorithmen des NIST (ML-KEM, ML-DSA, SLH-DSA) sowie Prinzipien der kryptografischen Agilität

    Blockchain-Technologie: Distributed-Ledger-Architekturen, Konsensmechanismen, Smart Contracts und deren Anwendung im Identitätsmanagement

    Self-Sovereign Identity: Konzeptionelle Grundlagen, Standards (DID, Verifiable Credentials) und bestehende Framework-Implementierungen

    Informationssicherheit für KRITIS: BSI-Vorgaben, Sicherheitsstandards, Compliance-Anforderungen und Best Practices

\textbf{Evaluation bestehender Artefakte und Frameworks:} Der Rigor Cycle umfasst die systematische Analyse und Bewertung existierender SSI-Frameworks (z.B. Hyperledger Indy/Aries, Walt.ID, Veramo, Cheqd) hinsichtlich ihrer PQC-Kompatibilität, Erweiterbarkeit und Eignung für KRITIS-Anwendungen.

\textbf{Methodische Strenge in Konstruktion und Evaluation:} Die Anwendung rigoroser Methoden erfolgt sowohl bei der Entwicklung des Prototyps als auch bei dessen Evaluation. Hierzu zählen formale Sicherheitsanalysen der kryptografischen Verfahren, Performance-Messungen, Funktionalitätstests sowie die Anwendung des Framework for Evaluation in Design Science (FEDS).

\textbf{Beitrag zur Wissensbasis:} Der Rigor Cycle schließt sich durch die Rückführung neuer Erkenntnisse in die wissenschaftliche Wissensbasis. Dies umfasst:

    Gestaltungsprinzipien für quantenresistente SSI-Systeme in KRITIS

    Evaluationsergebnisse zur Performance und Skalierbarkeit PQC-basierter Implementierungen

    Methodische Erkenntnisse zur Integration von Post-Quantum-Kryptografie in bestehende SSI-Frameworks

    Praktische Handlungsempfehlungen für die Umsetzung kryptoagiler Architekturen

Die enge Verzahnung des Rigor Cycle mit dem Design Cycle stellt sicher, dass die Entwicklung des Artefakts auf einer soliden wissenschaftlichen Grundlage erfolgt und gleichzeitig neue, über den Stand der Technik hinausgehende Erkenntnisse generiert werden.

\paragraph*{Design Cycle: Iterativer Entwicklungs- und Evaluationsprozess des Prototyps} \label{Design Cycle: Iterativer Entwicklungs- und Evaluationsprozess des Prototyps}

Der interne Design Cycle bildet das Herzstück jedes Design-Science-Forschungsprojekts. Dieser Zyklus iteriert zwischen dem Aufbau eines Artefakts, dessen Evaluation und dem anschließenden Feedback zur weiteren Verfeinerung des Designs \parencite[S. 90-91]{hevner_ThreeCycleViewDesignScienceResearch_2007}.

Im Kontext dieser Arbeit manifestiert sich der Design Cycle durch einen systematischen, mehrstufigen Entwicklungs- und Evaluationsprozess:

\textbf{Phase 1: Architekturdesign und Technologieauswahl}

Der Design Cycle beginnt mit der konzeptionellen Gestaltung der Systemarchitektur. Basierend auf den Anforderungen aus dem Relevance Cycle und den wissenschaftlichen Grundlagen aus dem Rigor Cycle werden fundamentale Designentscheidungen getroffen:

    Auswahl eines geeigneten SSI-Frameworks (z.B. Hyperledger Indy/Aries)

    Festlegung der Blockchain-Plattform (permissioned Ledger)

    Definition der PQC-Algorithmen für verschiedene Anwendungsfälle (Signaturen, Schlüsselaustausch, Hashing)

    Konzeption der kryptoagilen Architektur zur Ermöglichung zukünftiger Algorithmus-Updates

Evaluation: Bewertung der Architekturentscheidungen anhand definierter Kriterien (PQC-Kompatibilität, Erweiterbarkeit, Compliance-Konformität, Performance-Potenzial)

\textbf{Phase 2: Implementierung der Kernkomponenten}

Die Entwicklung des Prototyps erfolgt modular in einer containerisierten Laborumgebung (Docker, Ubuntu 24.04 LTS). Zentrale Komponenten umfassen:

    Kryptografische Schlüsselverwaltung: Integration von PQC-Algorithmen (ML-DSA, ML-KEM) für Schlüsselgenerierung, -speicherung und -verwaltung

    DID-Management: Implementierung dezentraler Identifikatoren mit PQC-basierten Signaturen

    Verifiable Credentials: Erstellung, Signierung und Verifikation von Credentials mit quantenresistenten Verfahren

    Wallet-Funktionalität: Agenten-Software für Holder, Issuer und Verifier

    Blockchain-Integration: Anbindung an permissioned Ledger mit PQC-gesicherten Transaktionen

Evaluation: Funktionalitätstests der einzelnen Komponenten, Unit-Tests, Integrationstests

\textbf{Phase 3: Systemintegration und Interoperabilität}

Nach erfolgreicher Implementierung der Kernkomponenten erfolgt die Integration zum Gesamtsystem. Dabei werden die Schnittstellen zwischen SSI-Komponenten und Blockchain-Backend sowie die End-to-End-Workflows getestet.

Evaluation: Systemtests, Use-Case-Validierung anhand definierter KRITIS-Szenarien

\textbf{Phase 4: Performance- und Sicherheitsanalyse}

Die Evaluation des integrierten Systems umfasst:

    Performance-Messungen: Durchsatz, Latenz, Speicher- und Rechenaufwand der PQC-Operationen

    Skalierbarkeitsanalyse: Bewertung des Systemverhaltens unter Last

    Sicherheitsbewertung: Kryptografische Stärke, Analyse potenzieller Angriffsvektoren, Resilience-Tests

    Compliance-Validierung: Überprüfung der Einhaltung regulatorischer Anforderungen

\textbf{Phase 5: Refinement und Iteration}

Basierend auf den Evaluationsergebnissen erfolgt eine iterative Verfeinerung des Designs. Identifizierte Schwachstellen, Performance-Engpässe oder Funktionsdefizite führen zu Designanpassungen, die wiederum evaluiert werden. Dieser iterative Prozess wird solange durchlaufen, bis ein zufriedenstellendes Design erreicht ist, das die definierten Anforderungen erfüllt.

Die Such- und Optimierungsstrategie des Design Cycle folgt dem Prinzip, verfügbare Mittel zu nutzen, um gewünschte Ziele zu erreichen, während gleichzeitig die Gesetzmäßigkeiten der Problemumgebung berücksichtigt werden \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Die enge Verzahnung von Konstruktion und Evaluation im Design Cycle stellt sicher, dass das entwickelte Artefakt nicht nur technisch realisierbar ist, sondern auch die definierten Qualitäts- und Nutzenanforderungen erfüllt. Die Erkenntnisse aus jeder Iteration fließen sowohl in die weitere Verfeinerung des Prototyps als auch in die Wissensbasis (Rigor Cycle) und die Bewertung der praktischen Anwendbarkeit (Relevance Cycle) ein.

\subsubsection{DSR-Leitlinien} \label{DSR-Leitlinien}

Die sieben DSR-Leitlinien nach \textcite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}, dargestellt in \autoref{tab:DSR_Guidelines} bilden einen strukturierten Rahmen zur Durchführung und Bewertung von Design-Science-Forschung. Im Folgenden wird dargelegt, wie diese Arbeit die einzelnen Leitlinien erfüllt.

\begin{longtable}{L{4cm}L{7cm}}
    \caption[]{Design Science Research Guidelines}
    \label{tab:DSR_Guidelines} \\
    \toprule
    \textbf{Guideline} & \textbf{Description} \\
    \midrule
    \endfirsthead
    \multicolumn{2}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Guideline} & \textbf{Description} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{2}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{2}{p{\linewidth}}{\textit{Anmerkung.} In Anlehnung an \textcite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.} \\
    \endlastfoot
    Guideline 1: Design as an Artifact & Design-science research must produce a viable artifact in the form of a construct, a model, a method, or an instantiation. \\
    \midrule
    Guideline 2: Problem Relevance & The objective of design-science research is to develop technology-based solutions to important and relevant business problems. \\
    \midrule
    Guideline 3: Design Evaluation & The utility, quality, and efficacy of a design artifact must be rigorously demonstrated via well-executed evaluation methods. \\
    \midrule
    Guideline 4: Research Contributions & Effective design-science research must provide clear and verifiable contributions in the areas of the design artifact, design foundations, and/or design methodologies. \\
    \midrule
    Guideline 5: Research Rigor & Design-science research relies upon the application of rigorous methods in both the construction and evaluation of the design artifact. \\
    \midrule
    Guideline 6: Design as a Search Process & The search for an effective artifact requires utilizing available means to reach desired ends while satisfying laws in the problem environment. \\
    \midrule
    Guideline 7: Communication of Research & Design-science research must be presented effectively both to technology-oriented as well as management-oriented audiences. \\
\end{longtable}

\paragraph*{Guideline 1: Design als Artefakt} \label{Guideline 1: Design als Artefakt}

Design-Science-Forschung muss ein praktikables Artefakt in Form eines Konstrukts, Modells, einer Methode oder einer Instanziierung hervorbringen \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Erfüllung: Diese Arbeit entwickelt mehrere miteinander verknüpfte Artefakte:

    Instanziierung: Ein funktionsfähiger Prototyp eines blockchain-basierten SSI-Systems mit integrierten PQC-Algorithmen, implementiert in einer Laborumgebung

    Konstrukte: Kryptografische Abstraktionsschichten für kryptoagile Systemarchitekturen, PQC-kompatible DID-Methoden

    Modelle: Systemarchitektur für quantenresistente SSI in KRITIS, Integration von PQC in SSI-Workflows

    Methoden: Vorgehensmodell zur Integration von PQC in bestehende SSI-Frameworks, Evaluationsmethodik für quantenresistente Identitätssysteme

\paragraph*{Guideline 2: Problemrelevanz} \label{Guideline 2: Problemrelevanz}

Das Ziel von Design-Science-Forschung besteht darin, technologiebasierte Lösungen für wichtige und relevante Geschäftsprobleme zu entwickeln \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Erfüllung: Die Arbeit adressiert ein hochrelevantes Problem von nationaler und internationaler Bedeutung:

    Quantenbedrohung: Bestehende kryptografische Verfahren in SSI-Systemen sind durch leistungsfähige Quantencomputer bedroht

    KRITIS-Sicherheit: Kritische Infrastrukturen stellen besondere Anforderungen an Verfügbarkeit, Integrität und Vertraulichkeit digitaler Identitäten

    Regulatorische Compliance: IT-Sicherheitsgesetz 2.0, NIS2-Richtlinie und BSI-Vorgaben erfordern nachweislich sichere Lösungen

    Zukunftsfähigkeit: Die Notwendigkeit kryptoagiler Systeme zur Anpassung an zukünftige kryptografische Entwicklungen

Die Problemstellung ist sowohl wissenschaftlich als auch praktisch hochrelevant und tangiert unmittelbar die Sicherheit und Funktionsfähigkeit essenzieller gesellschaftlicher Infrastrukturen.

\paragraph*{Guideline 3: Design-Evaluation} \label{Guideline 3: Design-Evaluation}

Nutzen, Qualität und Wirksamkeit eines Design-Artefakts müssen durch gut durchgeführte Evaluationsmethoden rigoros nachgewiesen werden \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Erfüllung: Die Evaluation erfolgt multidimensional und systematisch:

    Funktionalitätstests: Validierung der Kernfunktionen (DID-Erstellung, Credential-Issuance, Verification) anhand definierter Use Cases aus dem KRITIS-Umfeld

    Performance-Analyse: Quantitative Messungen von Durchsatz, Latenz, Speicher- und Rechenaufwand der PQC-Operationen

    Skalierbarkeitsanalyse: Bewertung des Systemverhaltens unter verschiedenen Lastszenarien

    Sicherheitsbewertung: Analyse der kryptografischen Stärke, Identifikation von Angriffsvektoren, Resilience-Tests

    Compliance-Validierung: Überprüfung der Einhaltung regulatorischer Anforderungen (BSI, DSGVO, IT-SiG 2.0)

    FEDS-Framework: Systematische Anwendung formativer und summativer Evaluationsstrategien

Die Evaluationsmethodik orientiert sich am Framework for Evaluation in Design Science (FEDS) und kombiniert künstliche Evaluationsparadigmen (Labor) mit naturalistischen Aspekten (realitätsnahe Use Cases).

\paragraph*{Guideline 4: Forschungsbeiträge} \label{Guideline 4: Forschungsbeiträge}

Effektive Design-Science-Forschung muss klare und verifizierbare Beiträge in den Bereichen Design-Artefakt, Design-Grundlagen und/oder Design-Methodologien liefern \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Erfüllung: Die Arbeit leistet Beiträge auf mehreren Ebenen:

Design-Artefakt:

    Erster funktionsfähiger Prototyp eines SSI-Systems mit vollständiger PQC-Integration für KRITIS

    Nachweis der technischen Machbarkeit quantenresistenter SSI-Architekturen

    Kryptoagile Systemarchitektur zur Unterstützung zukünftiger Algorithmus-Updates

Design-Grundlagen:

    Gestaltungsprinzipien für die Integration von PQC in SSI-Systeme

    Systematische Bewertung der Eignung verschiedener PQC-Algorithmen für unterschiedliche SSI-Komponenten

    Erkenntnisse zu Trade-offs zwischen Sicherheit, Performance und Praktikabilität

Design-Methodologien:

    Vorgehensmodell zur PQC-Migration in bestehenden SSI-Frameworks

    Evaluationsmethodik für quantenresistente Identitätssysteme

    Best Practices für die Implementierung kryptoagiler Architekturen in KRITIS

Diese Beiträge erweitern die Wissensbasis sowohl für die wissenschaftliche Community als auch für Praktiker in KRITIS-Organisationen.


\paragraph*{Guideline 5: Forschungsstrenge} \label{Guideline 5: Forschungsstrenge}

Design-Science-Forschung beruht auf der Anwendung rigoroser Methoden sowohl bei der Konstruktion als auch bei der Evaluation des Design-Artefakts \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Erfüllung: Die Forschungsstrenge wird durch mehrere Aspekte gewährleistet:

Konstruktion:

    Systematische Anforderungsanalyse basierend auf wissenschaftlicher Literatur und regulatorischen Vorgaben

    Fundierte Technologieauswahl durch kriterienbasierte Evaluation bestehender Frameworks

    Implementierung nach etablierten Software-Engineering-Prinzipien (Modularität, Testbarkeit, Dokumentation)

    Einsatz standardisierter PQC-Algorithmen (NIST FIPS 203, 204, 205)

Evaluation:

    Systematische Literaturrecherche nach PRISMA 2020-Richtlinien

    Anwendung etablierter Evaluationsframeworks (FEDS)

    Reproduzierbare Performance-Messungen in kontrollierter Laborumgebung

    Formale Sicherheitsanalysen der kryptografischen Verfahren

    Systematische Dokumentation aller Designentscheidungen und Evaluationsergebnisse

Wissenschaftliche Fundierung:

    Rückgriff auf etablierte Theorien und Methoden aus Kryptografie, Distributed Systems und Informationssicherheit

    Bezugnahme auf aktuelle wissenschaftliche Literatur und Standards

    Kritische Reflexion von Limitationen und Annahmen

\paragraph*{Guideline 6: Design als Suchprozess} \label{Guideline 6: Design als Suchprozess}

Die Suche nach einem effektiven Artefakt erfordert die Nutzung verfügbarer Mittel, um gewünschte Ziele zu erreichen, während gleichzeitig die Gesetzmäßigkeiten der Problemumgebung berücksichtigt werden \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Erfüllung: Der Suchprozess manifestiert sich durch:

Verfügbare Mittel:

    Bestehende SSI-Frameworks (Hyperledger Indy/Aries) als Ausgangsbasis

    Standardisierte PQC-Algorithmen (ML-KEM, ML-DSA, SLH-DSA)

    Open-Source-Bibliotheken (liboqs, OpenSSL 3.x)

    Containerisierte Entwicklungsumgebung (Docker)

    Blockchain-Plattformen (Indy-Besu, Hedera)

Gewünschte Ziele:

    Quantenresistente SSI-Architektur

    KRITIS-konforme Sicherheit und Compliance

    Praktikable Performance und Skalierbarkeit

    Kryptografische Agilität

Gesetzmäßigkeiten der Problemumgebung:

    Physikalische Grenzen der PQC-Performance (größere Schlüssel, langsamere Operationen)

    Blockchain-Charakteristika (Unveränderlichkeit, begrenzte Transaktionsgröße)

    Regulatorische Constraints (Datenschutz, Nachweispflichten)

    Bestehende Standards und Interoperabilitätsanforderungen

Der iterative Design Cycle ermöglicht die systematische Exploration des Lösungsraums und die schrittweise Annäherung an ein optimales Design unter Berücksichtigung konkurrierender Anforderungen und Randbedingungen.

\paragraph*{Guideline 7: Kommunikation der Forschung} \label{Guideline 7: Kommunikation der Forschung}

Design-Science-Forschung muss sowohl für technologieorientierte als auch für managementorientierte Zielgruppen effektiv präsentiert werden \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}.

Erfüllung: Die Kommunikation der Forschungsergebnisse erfolgt zielgruppenspezifisch:

Für technologieorientierte Zielgruppen (Forscher, Entwickler):

    Detaillierte Beschreibung der Systemarchitektur und Implementierung

    Technische Spezifikation der PQC-Integration

    Performance-Metriken und Benchmark-Ergebnisse

    Quellcode-Dokumentation und Deployment-Anleitungen

    Reproduzierbare Evaluationsergebnisse

Für managementorientierte Zielgruppen (KRITIS-Betreiber, Entscheidungsträger):

    Zusammenfassung der Problemstellung und Lösungsansätze

    Business Case für quantenresistente SSI-Systeme

    Compliance-Konformität und regulatorische Erfüllung

    Implementierungsrichtlinien und Migrationsstrategien

    Risiko-Nutzen-Bewertung und Handlungsempfehlungen

    Gestaltungsprinzipien und Best Practices

Publikationsformen:

    Diese Masterarbeit als umfassende wissenschaftliche Dokumentation

    Potenzielle Publikation in wissenschaftlichen Journals und Konferenzen

    Präsentation der Ergebnisse im Rahmen des Kolloquiums

    Technische Dokumentation und Whitepapers für Praktiker

    Mögliche Beiträge zu Open-Source-Communities

Die strukturierte Darstellung entlang der DSR-Leitlinien gewährleistet, dass sowohl der wissenschaftliche Beitrag als auch die praktische Relevanz der Forschung klar kommuniziert werden.

---





% Die besondere Eignung von DSR für das vorliegende Forschungsvorhaben begründet sich durch die systematische Ausrichtung an sieben fundierenden Leitlinien (\autoref{tab:DSR_Guidelines}), die \textcite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004} als konzeptionellen Rahmen für effektive Design-Science-Forschung etabliert haben. Diese Leitlinien stellen sicher, dass das Forschungsprojekt gleichzeitig wissenschaftlich rigoros und praktisch relevant durchgeführt wird.

% Design als Artefakt (Guideline 1). Design-Science-Forschung muss ein praktikables Artefakt in Form eines Konstrukts, Modells, einer Methode oder einer Instanziierung hervorbringen \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}. Die Integration von Post-Quantum-Kryptografie in blockchain-basierte SSI-Systeme erfordert die Schaffung eines neuartigen, funktionsfähigen IT-Artefakts. Dieser Arbeitsschritt ist elementar für das vorliegende Forschungsvorhaben. Der entwickelte Prototyp verkörpert sowohl die Instanziierung (funktionierendes Laborumfeld mit ACA-Py-Agenten, Hyperledger-Komponenten und PQC-Integration) als auch designierte Konstrukte und Methoden (kryptoagile Architekturmuster, PQC-kompatible DID-Schemata).

% Problemrelevanz (Guideline 2). Das Ziel von Design-Science-Forschung besteht darin, technologiebasierte Lösungen für bedeutende und relevante Geschäftsprobleme zu entwickeln \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}. Das vorliegende Forschungsvorhaben adressiert das \fixme{in Kapitel XY vorgestellte} hochrelevante, multi-dimensionale Problem: die drohende Verwundbarkeit bestehender SSI-Systeme durch die Entwicklung leistungsfähiger Quantencomputer, die exponentielle Sicherheitsrisiken für kritische Infrastrukturen darstellen. Zudem existiert ein regulatorisches Compliance-Problem, da IT-Sicherheitsgesetz 2.0, NIS2-Richtlinie und BSI-Vorgaben nachweislich sichere, zukunftsfähige Lösungen fordern. Dies ist nicht nur ein technisches, sondern auch ein kritisches Geschäftsproblem für Betreiber kritischer Infrastrukturen. \fixme{QUELLE}

% Design-Evaluation (Guideline 3). Der Nutzen, die Qualität und die Wirksamkeit eines Design-Artefakts müssen durch gut durchgeführte Evaluationsmethoden rigoros nachgewiesen werden \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}. Dieses Projekt schreibt eine systematische, mehrstufige Evaluationsstrategie vor: Funktionalitätstests der PQC-Komponenten, Performance-Analysen (Latenz, Durchsatz, Speicheraufwand), Sicherheitsbewertungen der kryptografischen Verfahren, Skalierungsstudien unter Lasten sowie Compliance-Validierung anhand realistischer KRITIS-Use-Cases. Diese rigorose Evaluation stellt sicher, dass die Designentscheidungen nicht nur konzeptionell, sondern auch praktisch-funktional gerechtfertigt sind. \fixme{abspecken}

% Forschungsbeiträge (Guideline 4). Effektive Design-Science-Forschung muss klare und verifizierbare Beiträge in den Bereichen Design-Artefakt, Design-Grundlagen und/oder Design-Methodologien liefern \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}. Das Projekt generiert Forschungsbeiträge auf drei Ebenen: (a) das innovative Artefakt selbst (erster Prototyp quantenresistenter SSI für KRITIS), (b) Gestaltungsprinzipien und Erkenntnisse zur PQC-Integration in SSI-Systeme (Design-Grundlagen) sowie (c) ein reproduzierbares Vorgehensmodell zur PQC-Migration in bestehenden Frameworks (Design-Methodologie). Damit trägt die Arbeit zur Wissensbasis bei, die Forschenden und Praktikern hilft, zukünftige quantenresistente Identitätssysteme zu entwickeln.

% Forschungsstrenge (Guideline 5). Design-Science-Forschung beruht auf der Anwendung rigoroser Methoden sowohl bei der Konstruktion als auch bei der Evaluation des Design-Artefakts \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}. Forschungsstrenge wird in diesem Projekt gewährleistet durch: (a) systematische Anforderungsanalyse basierend auf PRISMA-geleiteter Literaturrecherche, (b) Verwendung standardisierter, durch NIST validierter PQC-Algorithmen, (c) Implementierung nach etablierten Software-Engineering-Standards (Modularität, Testbarkeit, Versionskontrolle), (d) Anwendung formaler Sicherheitsanalysemethoden sowie (e) transparente Dokumentation aller Designentscheidungen. Diese methodische Strenge unterscheidet design-orientiertes Forschungsprojekt von bloßer Systemimplementierung.

% Design als Suchprozess (Guideline 6). Die Suche nach einem effektiven Artefakt erfordert die Nutzung verfügbarer Mittel, um gewünschte Ziele zu erreichen, während gleichzeitig die Gesetzmäßigkeiten der Problemumgebung berücksichtigt werden \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}. Das Projekt nutzt verfügbare Mittel systematisch: existierende SSI-Frameworks (Hyperledger Indy/Aries), standardisierte PQC-Algorithmen (ML-KEM, ML-DSA, Falcon), Open-Source-Bibliotheken (liboqs, OpenSSL 3.x) sowie Containerisierungstechnologien. Die Suchstrategie berücksichtigt aber auch die Gesetzmäßigkeiten der Problemumgebung: physikalische PQC-Performance-Grenzen, Blockchain-Charakteristiken (begrenzte Transaktionsgröße, Immutabilität), regulatorische Constraints und Interoperabilitätsstandards. Der iterative Design Cycle ermöglicht die systematische Exploration des Lösungsraums und schrittweise Verbesserung des Designs innerhalb dieser Rahmenbedingungen.

% Kommunikation der Forschung (Guideline 7). Design-Science-Forschung muss sowohl für technologieorientierte als auch für managementorientierte Zielgruppen effektiv präsentiert werden \parencite[S. 83]{hevner_DesignScienceInformationsystemsresearch_2004}. Die Arbeit adressiert mehrere Zielgruppen gezielt: Forschende und Entwickler erhalten detaillierte technische Spezifikationen, Implementierungsrichtlinien und reproduzierbare Evaluationsergebnisse; KRITIS-Betreiber und Entscheidungsträger erhalten Management Summaries, Compliance-Analysen, Geschäftsfallbewertungen und praktische Handlungsempfehlungen. Diese mehrschichtige Kommunikationsstrategie stellt sicher, dass die Forschungsergebnisse sowohl in die akademische Wissensbasis als auch in die Praxis diffundieren.

\subsection{DSRM Prozessmodell} \label{DSRM Prozessmodell}

Für die Umsetzung des \ac{DSR} wird das sechsstufige Prozessmodell nach \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} (\autoref{fig:DSRM Process Model}) adaptiert und sichert eine systematische Strukturierung des Forschungsvorhabens.

Durch iterative Rückkopplung insbesondere zu Zieldefinition und Design/Entwicklung kann das Artefakt laufend anhand von Evaluationen und neuen Anforderungen optimiert werden. Die Praxisnähe ist durch die Orientierung an realen Use Cases und \ac{KRITIS}-Anforderungen gewährleistet.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{DSRM Process Model.png}
    \caption{DSRM Process Model}
    \begin{flushleft}
    \textit{Anmerkung.} Aus \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.
    \end{flushleft}
    \label{fig:DSRM Process Model}
\end{figure}

\pagebreak

Die konkrete Umsetzung der sechs \ac{DSR}-Phasen zeigt \autoref{tab:dsr_phasen}.

\begin{longtable}{L{3.5cm}L{11cm}}
    \caption{Konkrete Anwendung des DSRM Process Modells}
    \label{tab:dsr_phasen} \\
    \toprule
    \textbf{Phase} & \textbf{Beschreibung} \\
    \midrule
    \endfirsthead
    \multicolumn{2}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Phase} & \textbf{Beschreibung} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{2}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{2}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung auf Basis von \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} mit Inhalten des vorliegenden Exposes und \textcite[S. 1]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.} \\
    \endlastfoot
    Phase 1: \newline Problemidentifikation und Motivation &
    Identifikation der drohenden Quantenbedrohung für bestehende \ac{SSI}-Systeme für \ac{KRITIS} als zentrale Herausforderung. \\
    \midrule
    Phase 2: \newline Zieldefinition &
    Konkretisierung der vier Forschungsfragen zu Systemarchitektur, Algorithmenauswahl, Performance und kryptografischer Agilität als Rahmengebung des Lösungsansatzes. \\
    \midrule
    Phase 3: \newline Design und Entwicklung &
    Festlegung des Technologie-Stacks, Architekturentscheidungen, die Auswahl und Integration der \ac{PQC}-Algorithmen sowie die Definition geeigneter Schnittstellen und Datenflüsse. Darüber hinaus werden die spezifischen Compliance-Anforderungen für \ac{KRITIS} in das Systemdesign integriert. Die Implementierung innerhalb der Laborumgebung erfolgt modular, um kryptografische Agilität zu gewährleisten und zukünftige Algorithmus-Updates ohne Systemunterbrechung zu ermöglichen. Sie umfasst die (Weiter-)Entwicklung zentraler Systemkomponenten und Mechanismen für zentrale Aktivitäten des Identity Management Lifecycles. \\
    \midrule
    Phase 4: \newline Demonstration &
    Verifizierung der grundsätzlichen Funktionsfähigkeit des entwickelten Prototyps innerhalb der Laborumgebung anhand voridentifizierter Use Cases, die auf dem Identity Management Lifecycle aufbauen und ausgewählte Szenarien des \ac{KRITIS}-Bereichs darstellen. \\
    \midrule
    Phase 5: \newline Evaluation &
    Multidimensionale Anwendung des von \textcite{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} entwickelten \ac{FEDS}-Frameworks, welches eine systematische Bewertungsstrategie für \ac{DSR}-Artefakte bereitstellt. Die Evaluation gliedert sich nach \textcite[S. 1]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} in formative und summative Komponenten, wobei sowohl künstliche als auch naturalistische Evaluationsparadigmen zum Einsatz kommen. \\
    \midrule
    Phase 6: \newline Kommunikation &
    Weitergabe der Forschungsergebnisse. Im Rahmen dieser Masterarbeit erfolgt dies in einem ausgewählten Rahmen, wobei sowohl wissenschaftliche als auch praxisorientierte Zielgruppen berücksichtigt werden. Die Ergebnisse zur Integration von \ac{PQC} in \ac{SSI}-Systeme werden in Form von Gestaltungsprinzipien zusammengefasst, um Anhaltspunkte für zukünftige Entwicklungen in diesem Bereich zu bieten. \\
\end{longtable}

==>

DSRM-Phase	Kapitel in der Arbeit
Phase 1: Problem Identification	1.1
Phase 2: Objectives	1.4, 4.1.1
Phase 3: Design \& Development	4.1-4.4 (Iterationen 0-3)
Phase 4: Demonstration	4.3.3, 4.4.3 (innerhalb Iterationen) + 5.2
Phase 5: Evaluation	4.2.3, 4.3.3, 4.4.3 (formativ) + 5 (summativ)
Phase 6: Communication	8, 9

\subsection{FEDS-Framework} \label{FEDS-Framework}

Die Evaluation des entwickelten SSI-Prototyps folgt dem Framework for Evaluation in Design Science (FEDS) nach \textcite[S. 1]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}, welches eine systematische Evaluationsstrategie für Design-Science-Artefakte bereitstellt. Evaluation ist eine zentrale und kritische Komponente von Design-Science-Forschung, da sie Feedback für die weitere Entwicklung liefert und bei korrekter Durchführung die Rigorosität der Forschung sicherstellt \parencite[S. 1]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

Evaluation in DSR ist essenziell, da Forschende rigorös die Nützlichkeit, Qualität und Wirksamkeit eines Design-Artefakts mittels gut durchgeführter Evaluationsmethoden nachweisen müssen \parencite[S. 1]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

Das FEDS-Framework adressiert die Forschungsfrage, wie eine geeignete Strategie für die Durchführung verschiedener Evaluationsaktivitäten in einem DSR-Projekt zu gestalten ist \parencite[S. 2]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Es charakterisiert DSR-Evaluationsepisoden (spezifische Evaluationen) anhand zweier Dimensionen: der funktionalen Zielsetzung der Evaluation (formativ oder summativ) und dem Paradigma der Evaluation (künstlich oder naturalistisch) \parencite[S. 1]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

\subsubsection{Dimension 1: Funktionale Zielsetzung}

Die funktionale Zielsetzung unterscheidet zwischen formativer und summativer Evaluation. Diese Unterscheidung liegt nicht in der inhaltlichen Natur der Evaluation, sondern in deren funktionalem Zweck \parencite[S. 2]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

\textbf{Formative Evaluationen} werden verwendet, um empirisch fundierte Interpretationen zu erzeugen, die als Grundlage für erfolgreiches Handeln zur Verbesserung der Eigenschaften oder Performance des Evaluationsobjekts dienen. Formative Evaluationen fokussieren auf Konsequenzen und unterstützen Entscheidungen zur Verbesserung des Evaluationsobjekts \parencite[S. 2]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

\textbf{Summative Evaluationen} werden verwendet, um empirisch fundierte Interpretationen zu erzeugen, die als Grundlage für die Schaffung geteilter Bedeutungen über das Evaluationsobjekt in verschiedenen Kontexten dienen. Summative Evaluationen fokussieren auf Bedeutungen und unterstützen Entscheidungen zur Auswahl des Evaluationsobjekts für eine Anwendung \parencite[S. 2-3]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

Im Kontext dieser Arbeit werden beide Evaluationsformen eingesetzt: Formative Evaluationen erfolgen iterativ während der drei Entwicklungszyklen (\fixme{Kapitel 4}), um Designschwächen frühzeitig zu identifizieren und zu beheben. Summative Evaluationen werden nach Abschluss der Prototyp-Entwicklung durchgeführt, um die Gesamtperformance, Sicherheit und KRITIS-Tauglichkeit des finalen Artefakts zu bewerten (\fixme{Kapitel 7}).

\subsubsection{Dimension 2: Evaluationsparadigma}

Das FEDS-Framework unterscheidet zwischen künstlicher (artificial) und naturalistischer (naturalistic) Evaluation \parencite[S. 3-4]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

\textbf{Künstliche Evaluation} kann empirisch oder nicht-empirisch sein und ist nahezu immer positivistisch und reduktionistisch. Sie wird zur Prüfung von Design-Hypothesen verwendet und umfasst Laborexperimente, Simulationen, kriterienbasierte Analysen, theoretische Argumente und mathematische Beweise. Das dominante wissenschaftlich-rationale Paradigma bringt künstlicher Evaluation den Vorteil stärkerer wissenschaftlicher Reliabilität in Form besserer Wiederholbarkeit und Falsifizierbarkeit \parencite[S. 4]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

\textbf{Naturalistische Evaluation} erforscht die Performance einer Lösungstechnologie in ihrer realen Umgebung, typischerweise innerhalb einer Organisation. Durch Evaluation in einer realen Umgebung (reale Menschen, reale Systeme, reale Settings) umfasst naturalistische Evaluation alle Komplexitäten menschlicher Praxis in realen Organisationen. Sie ist immer empirisch und tendiert zum Interpretivismus, kann aber auch positivistisch oder kritisch sein. Das dominante interpretivistische Paradigma bringt naturalistischer DSR-Evaluation den Vorteil stärkerer interner Validität \parencite[S. 4]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

Einerseits ist künstliche Evaluation oft die einfachste, direkteste und kostengünstigste Form der Evaluation mit präziser Sprache in den Ergebnissen. Andererseits beinhaltet künstliche Evaluation eine reduktionistische Abstraktion von der natürlichen Umgebung und ist notwendigerweise unrealistisch, da sie in einem oder mehreren von drei Realitäten (unreale Nutzer, unreale Systeme oder unreale Probleme) nicht der Realität entspricht \parencite[S. 4]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Im Gegensatz dazu bietet naturalistische Evaluation kritische Gesichtsvalidität und sichert eine rigorosere Bewertung der Effektivität des Artefakts \parencite[S. 4]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Die beiden Dimensionen sind vollständig orthogonal zueinander: Sowohl naturalistische als auch künstliche Evaluationsmethoden können für formative und/oder summative Evaluationen verwendet werden \parencite[S. 4]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

Für diese Arbeit werden beide Paradigmen kombiniert: Künstliche Evaluationen erfolgen in einer kontrollierten Laborumgebung (Docker-Container, definierte Test-Use-Cases) zur Messung von Performance-Metriken und kryptografischer Stärke. Naturalistische Elemente werden durch KRITIS-spezifische Szenarien integriert, die reale Anforderungen und Workflows abbilden.

\subsubsection{FEDS-Evaluationsstrategien}

Das FEDS-Framework identifiziert vier prototypische Evaluationsstrategien, die jeweils unterschiedliche Trajektorien vom Ursprung (keine Evaluation) zur umfassenden und rigorosen Evaluation (formativ-summativ, künstlich-naturalistisch) verfolgen \parencite[S. 4-5]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}:

\begin{enumerate}
    \item \textbf{Quick \& Simple Strategy:} Wenig formative Evaluation, schneller Übergang zu summativen und naturalistischeren Evaluationen. Geeignet bei kleinen, einfachen Designs mit niedrigem sozialen und technischen Risiko.
    
    \item \textbf{Human Risk \& Effectiveness Strategy:} Betont formative Evaluationen früh im Prozess, progrediert schnell zu naturalistischen formativen Evaluationen. Gegen Ende werden summative Evaluationen durchgeführt, die auf rigorose Evaluation der Effektivität des Artefakts fokussieren.
    
    \item \textbf{Technical Risk \& Efficacy Strategy:} Betont künstliche formative Evaluationen iterativ früh im Prozess, progrediert zu summativen künstlichen Evaluationen zur rigorosen Bestimmung der Wirksamkeit. Gegen Ende werden naturalistische Evaluationen eingebunden.
    
    \item \textbf{Purely Technical Strategy:} Wird verwendet, wenn ein Artefakt rein technisch ist ohne menschliche Nutzer, oder wenn geplante Deployment mit Nutzern so weit in der Zukunft liegt, dass naturalistische Evaluation irrelevant ist.
\end{enumerate}

Für diese Arbeit wird eine Kombination aus \textbf{Technical Risk \& Efficacy} und \textbf{Human Risk \& Effectiveness} Strategy gewählt. Die Entwicklung beginnt mit künstlichen formativen Evaluationen (Unit-Tests, Performance-Messungen in Laborumgebung), progrediert zu naturalistischeren Evaluationen (KRITIS-Use-Cases) und schließt mit summativen Evaluationen ab (Gesamtbewertung gegen definierte Erfolgskriterien).

\subsubsection{FEDS-Evaluationsdesign-Prozess}

Das FEDS-Framework bietet einen vierstufigen Prozess zur Gestaltung der Evaluationsstrategie \parencite[S. 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}:

\textbf{Schritt 1: Explizierung der Evaluationsziele}  
Es existieren mindestens vier möglicherweise konkurrierende Ziele bei der Gestaltung der Evaluationskomponente von DSR: Rigorosität (Wirksamkeit und Effektivität), Unsicherheits- und Risikoreduktion, Ethik und Effizienz \parencite[S. 6-7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

Für diese Arbeit sind die Evaluationsziele:
\begin{itemize}
    \item \textbf{Rigorosität:} Nachweis, dass der Prototyp funktionsfähig ist (Wirksamkeit) und in realistischen KRITIS-Szenarien einsetzbar ist (Effektivität)
    \item \textbf{Risikoreduktion:} Frühzeitige Identifikation technischer Risiken (PQC-Integrationsprobleme, Performance-Engpässe) durch formative Evaluationen
    \item \textbf{Effizienz:} Begrenzung des Evaluationsaufwands auf für eine Masterarbeit realisierbare Laborumgebungen
\end{itemize}

\textbf{Schritt 2: Auswahl der Evaluationsstrategie(n)}  
Basierend auf den Zielen wird eine oder mehrere Strategien gewählt. Tabelle \ref{tab:feds_strategy} fasst die Auswahlkriterien zusammen \parencite[S. 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.

\begin{table}[h]
\centering
\caption{Auswahlkriterien für FEDS-Evaluationsstrategien}
\label{tab:feds_strategy}
\begin{tabular}{|l|p{10cm}|}
\hline
\textbf{Strategie} & \textbf{Auswahlkriterien} \\
\hline
Quick \& Simple & Kleines und einfaches Design mit niedrigem sozialen und technischen Risiko \\
\hline
Human Risk \& Effectiveness & Hauptrisiko sozial oder nutzerorientiert; günstiger Zugang zu echten Nutzern; kritisches Ziel ist rigorose Etablierung langfristiger Nützlichkeit in realen Situationen \\
\hline
Technical Risk \& Efficacy & Hauptrisiko technisch orientiert; Evaluation mit echten Nutzern prohibitiv teuer; kritisches Ziel ist rigorose Etablierung, dass Nutzen dem Artefakt zuzuschreiben ist \\
\hline
Purely Technical & Artefakt rein technisch ohne soziale Aspekte oder Deployment liegt weit in der Zukunft \\
\hline
\end{tabular}
\end{table}

Für diese Arbeit wird \textbf{Technical Risk \& Efficacy} gewählt, da:
\begin{itemize}
    \item Das Hauptrisiko technischer Natur ist (PQC-Integration, Performance)
    \item Die Evaluation in realen KRITIS-Umgebungen nicht realisierbar ist (Zugang, Sicherheitsrisiken, regulatorische Hürden)
    \item Nachweis erforderlich ist, dass PQC-Algorithmen die erwartete Sicherheit bieten
\end{itemize}

\textbf{Schritt 3: Bestimmung der zu evaluierenden Eigenschaften}  
Die Auswahl der Artefakteigenschaften für die Evaluation ist notwendigerweise einzigartig für das Artefakt, seinen Zweck und seine Situation \parencite[S. 7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für diese Arbeit werden folgende Eigenschaftskategorien evaluiert:

\begin{itemize}
    \item \textbf{Funktionalität:} Vollständigkeit der Implementierung (UC1--UC7), Korrektheit der kryptografischen Operationen
    \item \textbf{Performance:} Latenz (Credential-Verification < 1s), Durchsatz, Speicheraufwand (Schlüssel-, Signaturgröße)
    \item \textbf{Sicherheit:} Kryptografische Stärke (NIST Security Level), Resilience gegen Angriffe
    \item \textbf{Compliance:} Erfüllung von BSI-Anforderungen (IDM, KRY), DSGVO, NIS2
    \item \textbf{Kryptoagilität:} Fähigkeit zum Algorithmus-Update ohne Systemunterbrechung
\end{itemize}

\textbf{Schritt 4: Gestaltung der individuellen Evaluationsepisoden}  
Unter Berücksichtigung von Umgebungsfaktoren (verfügbare Zeit, Budget, Ressourcen) werden die konkreten Evaluationsepisoden geplant \parencite[S. 8]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für diese Arbeit umfasst dies:

\begin{enumerate}
    \item \textbf{Formative Evaluationen (Iteration 1--3):} Unit-Tests, Integrationstests, Performance-Benchmarks
    \item \textbf{Summative Evaluation (nach Iteration 3):}
    \begin{itemize}
        \item Funktionalitätstests anhand KRITIS-Use-Cases (Kapitel 7.2)
        \item Performance-Analyse (Latenz, Durchsatz, Ressourcenverbrauch) (Kapitel 7.3)
        \item Sicherheitsbewertung (kryptografische Analyse, Threat-Modeling) (Kapitel 7.4)
        \item Compliance-Validierung (Abgleich mit BSI-Anforderungen) (Kapitel 7.4)
    \end{itemize}
\end{enumerate}

Die Evaluation erfolgt in einer kontrollierten Laborumgebung (Ubuntu 24.04 LTS, Docker, Hyper-V), um Wiederholbarkeit und wissenschaftliche Rigorosität zu gewährleisten. KRITIS-Realitätsnähe wird durch realistische Use Cases und Szenarien sichergestellt (Kapitel 6).

Das FEDS-Framework sichert somit eine systematische, rigorose und effiziente Evaluation des entwickelten PQC-basierten SSI-Prototyps, die sowohl wissenschaftlichen Standards als auch praktischen Anforderungen gerecht wird.

\newpage
\section{Iterative Artefaktentwicklung}
Überblick über den iterativen Entwicklungsprozess: \\
       - Zuordnung zu DSRM-Phasen und Hevner-Zyklen \\
       - Iterationsplanung und Forschungsfragen-Triangulation


\subsection{Iteration 1: Basisarchitektur mit Transport-Layer PQC-Integration}
\label{sec:Iteration 1: Basisarchitektur mit Transport-Layer PQC-Integration}

\subsubsection{Designziele dieser Iteration}
%           ALLE FF, mit SCHWERPUNKT auf FF1 (Architektur), FF2 (Algorithmen) \\
%           → FF1 (Architektur): Modulare Layer-Architektur implementieren \\
%           → FF2 (Algorithmen): Erste PQC-Algorithmen auswählen (ML-DSA-65) \\
%           → FF3 (Performance): Baseline-Performance ohne PQC messen \\
%           → FF4 (Kryptoagilität): Crypto Abstraction Layer konzipieren

%Initiales Design und Implementierung der Kernkomponenten

% - DZ1.1: Evaluation von SSI-Frameworks und Technologiestack \\
%   → adressiert FF1 (Systemarchitektur - initial) \\
% - DZ1.2: Design der vier-schichtigen Architektur mit PQC-Integration \\
%   → adressiert FF1 (Systemarchitektur) \\
% - DZ1.3: Implementierung und Baseline-Test der Kernkomponenten (DID, VC, Signaturen) \\
%   → adressiert FF2 (Algorithmenauswahl - initial) \\
% ------------------------------------------------ \\
% - DZ1.4: Erste Performance-Baseline ohne PQC \\
%   → adressiert FF3 (Performance - Baseline)

Die erste Iteration der Artefaktentwicklung korrespondiert mit der DSRM-Phase 2 \textit{Objectives} nach \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} und fokussiert auf die Etablierung einer funktionsfähigen Basisarchitektur für das blockchain-basierte SSI-System mit initialer PQC-Integration auf Transport-Layer-Ebene. Im Kontext des Drei-Zyklen-Modells nach \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007} adressiert diese Iteration primär den \textit{Design Cycle}, wobei die Anforderungen aus dem \textit{Relevance Cycle} systematisch in konkrete Designentscheidungen überführt werden.


Die erste Iteration der Artefaktentwicklung korrespondiert mit der DSRM-Phase 2 \textit{Objectives} nach \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} und adressiert die systematische Ableitung von Designzielen aus den in Kapitel~\ref{sec:Zielsetzung und Forschungsfragen} definierten Forschungsfragen. Im Kontext des Drei-Zyklen-Modells nach \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007} erfolgt eine primäre Aktivierung des \textit{Design Cycle}, in welchem die aus dem \textit{Relevance Cycle} stammenden Anforderungen zu operativen Designprinzipien und Evaluationskriterien systematisiert werden. Diese Systematisierung bildet das Fundament für die in den Kapitel~\ref{sec:Anforderungsanalyse} bis \ref{sec:Implementierung} durchgeführte Anforderungsanalyse, Technologieauswahl, Architekturentwurf und Implementierung.

Die Designziele dieser Iteration leiten sich aus den in Kapitel~\ref{sec:Zielsetzung und Forschungsfragen} definierten Forschungsfragen ab, wobei der Schwerpunkt auf FF1 (Systemarchitektur \& Compliance) liegt. Bezüglich FF1 wird das Ziel verfolgt, eine modulare Schichtenarchitektur zu etablieren, die eine klare Separation zwischen SSI-Agenten, DLT-Infrastruktur und kryptografischer Transportschicht realisiert. Das Design soll dabei das Potenzial demonstrieren, Post-Quantum-Kryptografie systemisch zu integrieren, ohne dabei klassische blockchainbasierte SSI-Architekturen grundsätzlich umgestalten zu müssen.

Bezüglich FF2 (Algorithmenauswahl und Sicherheitsbewertung) liegt das Designziel auf der systematischen Identifikation und Erprobung quantenresistenter kryptografischer Primitive für die Sicherung von Zertifikatssignaturen auf der Transport-Layer-Ebene. Die empirische Evaluierung soll dabei Erkenntnisse zur praktischen Eignung und Interoperabilität dieser Algorithmen in einer integrierten Systemumgebung generieren, um eine evidenzbasierte Grundlage für die Algorithmenauswahl in SSI-Architekturen zu schaffen.

Für FF3 (Kryptografische Agilität) zielt die Iteration auf die architektonische Vorbereitung für Austauschbarkeit kryptografischer Algorithmen ab. Das Design soll dabei Mechanismen vorsehen, die zukunftige Algorithmenupdates ermöglichen, ohne das System grundlegend umgestalten zu müssen.

\subsubsection{Anforderungsanalyse}
            %  - Funktionale Anforderungen (FR1-FR7) \\
            %  - Nicht-funktionale Anforderungen (NFR1-NFR22) \\
            %  - KRITIS-spezifische Compliance-Anforderungen

\paragraph{Funktionale Anforderungen} \label{sec:Funktionale Anforderungen}

Die funktionalen Anforderungen für das zu entwickelnde SSI-System orientieren sich am Operational Reference Model (ORM) und umfassen sieben Kernfunktionalitäten, die von \textcite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021} als essenziell für blockchain-basierte Self-Sovereign-Identity-Systeme identifiziert wurden. Diese Funktionalitäten bilden die Grundlage für die iterative Artefaktentwicklung und definieren die zu implementierenden Use Cases.

\textbf{FR1: Issuer Discovery}

Das System muss die Identifikation und Auffindbarkeit von vertrauenswürdigen Ausstellern (Issuers) digitaler Identitätsnachweise ermöglichen \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Identity Holder müssen in der Lage sein, geeignete Aussteller für gewünschte Credentials zu entdecken und deren Vertrauenswürdigkeit zu validieren. Im KRITIS-Kontext ist dies besonders relevant für die Identifikation autorisierter Zertifizierungsstellen und regulierter Identitätsanbieter.

\textbf{FR2: Connection Creation}

Das System muss sichere, authentifizierte Verbindungen zwischen den drei Hauptakteuren des SSI-Ökosystems -- Identity Holder, Issuer und Verifier -- etablieren können \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Diese Verbindungen bilden die Grundlage für alle nachfolgenden Interaktionen und müssen kryptografisch gesichert sowie persistent verwaltbar sein. Die Implementierung erfolgt typischerweise über DIDComm-Protokolle mit gegenseitiger Authentifizierung.

\textbf{FR3: Credential Creation}

Das System muss die vollständige Funktionalität zur Erstellung, Ausstellung und Verwaltung digitaler Credentials (Verifiable Credentials) bereitstellen \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Dies umfasst sowohl issuer-initiierte als auch verifier-vorgeschlagene Credential-Ausstellungen sowie die Unterstützung hierarchischer Identitätsstrukturen (z.B. nationale, regionale und lokale Identitätsnachweise). Die Credentials müssen den W3C-Standards entsprechen und kryptografisch signiert sein.

\textbf{FR4: Verification with Credentials}

Das System muss die Verifikation digitaler Identitätsnachweise durch Verifier ermöglichen und dabei das Prinzip der minimalen Offenlegung (Minimal Disclosure) unterstützen \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Identity Holder müssen in der Lage sein, Identitätsattribute selektiv offenzulegen -- entweder vollständig (value revealed), durch Zero-Knowledge-Proofs (value not revealed) oder gar nicht (value not required). Die Verifikation muss ohne direkte Einbindung des Issuers erfolgen können, um Skalierbarkeit und Privacy zu gewährleisten.

\textbf{FR5: Backup/Recovery}

Das System muss Mechanismen zur Sicherung und Wiederherstellung von Credentials und kryptografischem Material bereitstellen \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Dies umfasst sowohl die Wiederherstellung nach permanentem Verlust des Wallets (z.B. bei Gerätewechsel) als auch nach temporärem Verlust. Im KRITIS-Kontext ist eine sichere, auditierbare Recovery-Strategie unter Einhaltung von Compliance-Anforderungen essenziell, um Verfügbarkeit und Kontinuität zu gewährleisten.

\textbf{FR6: Derive/Share Credentials}

Das System muss die Ableitung neuer Credentials aus bestehenden Nachweisen sowie das plattformübergreifende, nutzerkontrollierte Teilen persönlicher Daten unterstützen \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Dies schließt die Authentifizierung durch Drittanbieter-Applikationen über das SSI-Wallet ein. Die Funktionalität ermöglicht granulare Zugriffskontrolle und unterstützt das Prinzip der Datenminimierung.

\textbf{FR7: Sunset/Delete/Revoke Credentials}

Das System muss vollständige Lebenszyklusverwaltung für Credentials bieten, einschließlich Ablaufdaten (Sunset), nutzerseitiger Löschung, temporärer Deaktivierung und issuer-seitiger Widerrufung (Revocation) \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Revocation-Mechanismen müssen auf der Blockchain nachvollziehbar, jedoch unter Wahrung der Privacy implementiert werden. Im KRITIS-Kontext ist die Echtzeit-Prüfung des Revocation-Status für sicherheitskritische Zugriffsentscheidungen unerlässlich.

\paragraph{Nicht-funktionale Anforderungen} \label{sec:Nicht-Funktionale Anforderungen}

Die nicht-funktionalen Anforderungen (Non-Functional Requirements, NFR) definieren die Qualitätsattribute und systemübergreifenden Eigenschaften des zu entwickelnden SSI-Prototyps. \textcite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021} identifizieren in ihrer umfassenden Vergleichsstudie 22 NFR für blockchain-basierte Self-Sovereign-Identity-Systeme, die in zwei Kategorien unterteilt werden können: acht prominente Kern-NFR (NFR 1--8), die in der akademischen Literatur sowie in kommerziellen und Open-Source-Lösungen weitverbreitet sind, sowie 14 erweiterte NFR (NFR 9--22), die spezifischere Qualitätsaspekte adressieren.

Die folgenden acht Kern-NFR bilden das qualitative Fundament für blockchain-basierte SSI-Systeme und sind in der Fachliteratur sowie in Standardisierungsinitiativen (W3C, DIF, RWoT) prominent vertreten \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}:

\textbf{NFR1: Provability (Nachweisbarkeit)}

Das System muss Identity Holder die Fähigkeit bieten, ihre Identität kryptografisch nachzuweisen \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Im KRITIS-Kontext ist dies besonders relevant für Zugriffsentscheidungen auf kritische Infrastruktursysteme, bei denen Non-Repudiation (Nicht-Abstreitbarkeit) und forensische Nachvollziehbarkeit essenziell sind.

\textbf{NFR2: Interoperability (Interoperabilität)}

Das System muss plattform-, blockchain- und jurisdiktionsübergreifende Kompatibilität gewährleisten und über Programmiersprachen, Anbieter, Netzwerke, rechtliche Rahmen, Kryptografie-Algorithmen sowie Hardware hinweg funktionieren \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Dies schließt zeitliche Interoperabilität ein (langfristige Lesbarkeit von Credentials trotz technologischer Evolution). Für KRITIS ist die Interoperabilität mit bestehenden IAM-Systemen (z.B. Active Directory, LDAP) und Compliance-Frameworks (BSI-Grundschutz, ISO 27001) unabdingbar.

\textbf{NFR3: Portability (Portabilität)}

Identity Holder müssen ihre digitalen Identitätsnachweise und Credentials geräte-, plattform- und anbieterübergreifend mitnehmen können \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Dies impliziert standardisierte Export-/Import-Mechanismen (z.B. W3C Verifiable Credentials) sowie Vendor-Lock-In-Vermeidung. Im KRITIS-Kontext unterstützt dies die Anforderung der Unabhängigkeit von einzelnen Dienstleistern gemäß NIS-2-Richtlinie.

\textbf{NFR4: Pseudonymity (Pseudonymität)}

Das System muss Identity Holder die Möglichkeit bieten, zu interagieren, ohne ihre reale Identität offenlegen zu müssen \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Dies wird typischerweise durch paarweise pseudonyme DIDs (Decentralized Identifiers) erreicht, bei denen für jede Beziehung ein eindeutiger Identifier generiert wird. Pseudonymität ist komplementär zu selektiver Offenlegung und Zero-Knowledge-Proofs.

\textbf{NFR5: Recovery (Wiederherstellbarkeit)}

Das System muss sichere und benutzerfreundliche Mechanismen zur Wiederherstellung von kryptografischen Schlüsseln und Credentials bereitstellen \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. \textcite[S. 133]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021} identifizieren Recovery als eine der am wenigsten unterstützten NFR in existierenden SSI-Lösungen, obwohl die Absicherung und Wiederherstellung in Wallet-basierten Systemen vital ist. Im KRITIS-Kontext ist eine auditierbare, compliant Recovery-Strategie (z.B. mittels Social Recovery, Hardware-Security-Modules oder Threshold-Kryptografie) unerlässlich.

\textbf{NFR6: Scalability (Skalierbarkeit)}

Das System muss für breite Adoption und Replikation geeignet sein \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Dies umfasst sowohl technische Skalierbarkeit (Transaktionsdurchsatz, Latenz bei Credential-Verifikation) als auch organisatorische Skalierbarkeit (Onboarding von Issuern und Verifiern). Für KRITIS-Anwendungen müssen hohe Transaktionsvolumina (z.B. Authentifizierung von Millionen IoT-Geräten) bewältigt werden.

\textbf{NFR7: Security (Sicherheit)}

Das System muss umfassenden Schutz von Daten, kryptografischen Schlüsseln und Credentials gewährleisten \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Im Kontext der Post-Quantum-Kryptografie bedeutet dies konkret die Resistenz gegen Angriffe durch Quantencomputer. Die Implementierung muss NIST-FIPS-203/204/205-konforme PQC-Algorithmen (ML-DSA, ML-KEM, SLH-DSA) integrieren und dabei gängige Bedrohungsmodelle (Impersonation, Replay-Attacken, Man-in-the-Middle) adressieren.

\textbf{NFR8: Usability (Benutzerfreundlichkeit)}

Das System muss eine menschenzentrierte, verständliche User Experience bieten \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Dies schließt intuitive Wallet-Interfaces, verständliche Consent-Dialoge und niedrige Eintrittsbarrieren ein. Für KRITIS-Umgebungen ist die Balance zwischen Sicherheit (z.B. Multi-Faktor-Authentifizierung) und Usability (z.B. Single-Sign-On-Erlebnis) kritisch, um sowohl IT-Security-Experten als auch End-User zu unterstützen.

% \paragraph*{Erweiterte NFR für KRITIS-spezifische Compliance}

% Zusätzlich zu den Kern-NFR definieren \textcite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021} 14 erweiterte Anforderungen, von denen folgende im KRITIS-Kontext besonders relevant sind:

% \textbf{NFR9--NFR16: Privacy- und Datenhoheits-Anforderungen}

% Das System muss \textit{Protection} (sichere Datenspeicherung), \textit{Persistence} (Verfügbarkeit bis zur nutzerseitigen Löschung), \textit{Minimization} (Datenminimierung gemäß DSGVO Art. 5 Abs. 1 lit. c), \textit{Existence} (Dateneinsichtnahme), \textit{Control} (Zugriffskontrolle durch Identity Holder), \textit{Consent} (explizite Einwilligung für jeden Zugriff), \textit{Transparency} (Nachvollziehbarkeit der Datenverarbeitung) und \textit{Access} (jederzeitiger Datenzugriff) gewährleisten \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Diese Anforderungen adressieren direkt die DSGVO-Compliance sowie die Prinzipien der Selbstbestimmung und Datenhoheit.

% \textbf{NFR17--NFR19: Systemvertrauen und Inklusion}

% Das System muss \textit{Convenience} (einfacher Datenzugriff), \textit{Inclusion} (Unterstützung verschiedener Nutzergruppen unabhängig von Nationalität, technischer Affinität etc.) und \textit{Trust} (Vertrauenswürdigkeit der Plattform) bieten \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Für KRITIS ist insbesondere das Vertrauen in die Governance-Struktur der SSI-Infrastruktur relevant (z.B. Transparenz des Ledger-Betriebs, Auditierbarkeit von Revocation-Entscheidungen).

% \textbf{NFR20--NFR22: Technologie-Integration und Wirtschaftlichkeit}

% Das System sollte \textit{Biometrics support} (biometrische Authentifizierung), \textit{Support for IoT} (Identity Management für IoT-Geräte in Industrial Control Systems) sowie vertretbare \textit{Cost}-Strukturen für Identity Holder, Issuer und Verifier aufweisen \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Die IoT-Unterstützung ist für KRITIS-Umgebungen mit massiven Sensor- und Aktor-Netzwerken besonders kritisch.

% Für die iterative Artefaktentwicklung werden die NFR nach Kritikalität priorisiert. \textbf{Iteration 1} fokussiert auf NFR1, NFR7 und NFR13 (Provability, Security, Control). \textbf{Iteration 2} adressiert NFR2, NFR5 und NFR11 (Interoperability, Recovery, Minimization). \textbf{Iteration 3} implementiert NFR4, NFR6 und NFR15 (Pseudonymity, Scalability, Transparency). Die verbleibenden NFR werden im Rahmen der summativen Evaluation bewertet und als Grundlage für zukünftige Iterationen dokumentiert.

\paragraph{KRITIS-spezifische Compliance-Anforderungen} \label{sec:KRITIS-spezifische Compliance-Anforderungen}

% 2.5 Technische Informationssicherheit:
% IDM-07 + IDM-08 bis IDM-13 + KRY-01 bis KRY-04

% 2.6 Personelle und organisatorische Sicherheit
% IDM-01 bis IDM-06 + IDM-09


% Tabelle auf Basis von \textcite[S. 12-19]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024}


Die KRITIS-spezifische Compliance für SSI-Systeme erfordert eine Verschneidung von vier Compliance-Ebenen:

1. \textbf{Technische Sicherheit} (BSI TR-02102-1): Kryptographische Algorithmen, Schlüssellängen, Verschlüsselungsprotokolle.

2. \textbf{Organisatorische Sicherheit} (ORP.4, KRITIS-Anforderungskatalog): IAM, Funktionstrennung, Audit-Trails.

3. \textbf{Datenschutz} (DSGVO): Pseudonymität, Datensparsamkeit, Betroffenenrechte.

4. \textbf{Kontinuitätsmanagement} (BSIG § 8a): Recovery, Backup, Incident Response.

Die Implementierung dieser Anforderungen in der SSI-Prototyp-Entwicklung wird in Kapitel 4.2 adressiert, wobei Compliance-Checks in den Design Science Research-Zyklus integriert werden.


Die Umsetzung der KRITIS-Anforderungen in SSI-Systemen erfordert eine ganzheitliche Integration von Compliance-Anforderungen, die aus der deutschen und europäischen Regulierung abgeleitet sind. \textcite[S. 4]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024} präzisieren die Anforderungen des § 8a Absatz 1 und Absatz 1a BSIG für Betreiber Kritischer Infrastrukturen und definieren damit den verbindlichen Rahmen für die Informationssicherheit bei KRITIS-Systemen.

\paragraph*{Identitäts- und Berechtigungsmanagement (IAM)}

Das Identitäts- und Berechtigungsmanagement bildet das Fundament für sichere SSI-Systeme im KRITIS-Kontext. \textcite[S. 1--2]{bsi_ITGrundschutzKompendiumORP4IdentitaetsundBerechtigungsmanagementEdition2023_2023} definieren, dass der Zugang zu schtzenswerten Ressourcen auf berechtigte Benutzende und IT-Komponenten einzuschränken ist und dass Benutzende sowie IT-Komponenten zweifelsfrei identifiziert und authentisiert werden müssen. Im Kontext von SSI bedeutet dies konkret, dass DIDs (Decentralized Identifiers) eindeutig einer Person oder IoT-Komponente zugeordnet werden müssen und dass eine nicht-abstreitbare Authentifizierung durch kryptografische Verfahren erfolgen muss.

\textcite[S. 12]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024} fordern die Implementierung von Multi-Faktor-Authentifizierung für Administratoren: „Automatischer Ablauf Multi-Faktor-Authentifizierung für Administratoren des KRITIS-Betreibers z.B. durch Smart Card oder biometrische Merkmale ist zwingend erforderlich, sofern ein Zugriff über öffentliche Netze erfolgt." Für SSI-Systeme bedeutet dies, dass die Ausweisung von administrativen Credentials und deren Delegation zur Verifizierung neuer Credentials durch hybride Authentifizierungsmechanismen (z.B. Kombination aus DID-basierten Signaturen und Hardware-Token) erfolgen muss.

Die Prinzipien \textit{Least Privilege} und \textit{Need-to-Know} müssen in SSI-Umgebungen durch eine strikte Implementierung granularer Zugriffsrechte auf Basis von Verifiable Credentials und selektiven Offenlegungsmechanismen realisiert werden. \textcite[S. 2]{bsi_ITGrundschutzKompendiumORP4IdentitaetsundBerechtigungsmanagementEdition2023_2023} weisen auf die Gefahr des „Wildwuchses" bei der Rechtevergabe hin: „Sind Prozesse beim Identitäts- und Berechtigungsmanagement unzureichend definiert oder implementiert, ist nicht gewährleistet, dass Zugriffe auf das erforderliche Maß eingeschränkt sind." Im SSI-Kontext ist dies besonders kritisch, da fehlerhaft ausgestellte Credentials mit unbegrenzter Gültigkeitsdauer zu permanenten Sicherheitslücken führen können.

\paragraph*{Authentifizierung und Verschlüsselung}

Das \textcite[S. 12--14]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024} verlangt für KRITIS-Systeme umfassende Anforderungen zur Transportverschlüsselung und zur Schlüsselverwaltung: „Das Nutzen von starken Verschlüsselungsverfahren z.B. AES und die Verwendung von sicheren Netzwerkprotokollen, die dem Stand der Technik entsprechen z.B. TLS, IPsec, SSH" sind anzuwenden. Im Kontext von SSI-Ledgern (z.B. Hyperledger Indy) bedeutet dies, dass sämtliche Transaktionen, Credentials und DIDs durch starke Verschlüsselung geschützt werden müssen. Die Schlüsselverwaltung muss dabei kritischen Anforderungen genügen: „Anforderungen für das sichere Erzeugen, Speichern, Archivieren, Abrufen, Verteilen, Entziehen und Löschen der Schlüssel" müssen dokumentiert und implementiert sein.

Die Post-Quantum-Kryptographie-Standards (FIPS 203/204/205) sind gemäß \textcite[S. 30--41]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025} zu integrieren. Die Technische Richtlinie BSI TR-02102-1 empfiehlt konkrete PQC-Algorithmen: ML-KEM für Schlüsselvereinbarung, ML-DSA für Signaturen und SLH-DSA für zustandslose Signaturverfahren. Im SSI-Kontext ist die Hybridisierung dieser Verfahren mit klassischen Algorithmen (z.B. ECDSA) notwendig, um eine „Crop and Paste"-Resistenz zu erreichen: Eine Signatur ist nur gültig, wenn \textit{beide} klassische und quantensichere Signaturen valide sind.

\paragraph*{Datenschutz und DSGVO-Compliance}

Die Europäische Datenschutz-Grundverordnung (DSGVO) bildet eine zusätzliche Compliance-Schicht. \textcite[Art. 5, Art. 6]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016} definieren die Grundprinzipien der Datenverarbeitung: Rechtmäßigkeit, Transparenz, Zweckbindung, Datensparsamkeit, Richtigkeit, Speicherbegrenzung, Integrität und Vertraulichkeit. Für SSI-Systeme bedeutet dies, dass:

\begin{enumerate}
\item \textbf{DIDs müssen pseudonym sein:} Die Verknüpfung einer Person zu ihrer DID darf nicht ohne explizite Einwilligung erfolgen.

\item \textbf{Selektive Offenlegung (Selective Disclosure):} Nur minimale Informationen aus Verifiable Credentials dürfen preisgegeben werden (z.B. Bestätigung eines Altersanspruchs ohne Geburtsdatum).

\item \textbf{Datenlöschung:} Es müssen technische und organisatorische Mechanismen existieren, um Credentials (z.B. durch Revocation auf dem Ledger) zu annullieren und damit das Löschen von Attributen zu ermöglichen.

\item \textbf{Betroffenenrechte:} Wallets und SSI-Agents müssen Funktionen zur Einsichtnahme (Art. 15 DSGVO), Berichtigung (Art. 16) und Vergessenwerden (Art. 17) unterstützen.
\end{enumerate}

\paragraph*{Kryptografische Anforderungen und Schlüssellängen}

\textcite[S. 20]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025} legen fest, dass ein Sicherheitsniveau von mindestens 120 Bits zu erreichen ist. Konkrete Empfehlungen für SSI-Systeme:

\begin{itemize}
\item \textbf{Symmetrische Verschlüsselung:} AES-256 ist verpflichtend für Daten mit KRITIS-Relevanz.

\item \textbf{Asymmetrische Schlüssellängen:} RSA-Schlüssel müssen mindestens 3000 Bits betragen; %EC-Systeme müssen eine Ordnung q ≥ 2\textsuperscript{250} verwenden.

\item \textbf{Digitale Signaturen:} ML-DSA-65 oder ML-DSA-87 (quantensicher) sowie klassische %ECDSA (mit Ordnung q ≥ 2\textsuperscript{250}) müssen hybrid kombiniert werden.

\item \textbf{Hashfunktionen:} SHA-256, SHA-384 und SHA-512 sind akzeptabel; SHA-1 ist obsolet und unzulässig.
\end{itemize}

\paragraph*{Versionierung und Deprecation von Verfahren}

Eine Besonderheit der KRITIS-Compliance ist die Notwendigkeit von Deprecation-Roadmaps. \textcite[S. 56]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025} empfehlen beispielsweise, die Verwendung von DSA (Digital Signature Algorithm) bis 2029 auslaufen zu lassen. Im SSI-Kontext bedeutet dies, dass:

\begin{enumerate}
\item Protokolle zur \textit{Credential Migration} implementiert werden müssen, um alte Credentials mit veralteten Algorithmen durch neue mit aktuellen Algorithmen zu ersetzen.

\item Die Vertrauenskette (Trust Chain) von Vertrauenswurzeln (Root DIDs, Ledger Validators) muss regelmäßig überprüft und aktualisiert werden.

\item Audit-Logs müssen dokumentieren, wann und wie kryptographische Verfahren aktualisiert wurden.
\end{enumerate}

\paragraph*{Governance und Audit-Trail}

\textcite[S. 7--27]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024} fordert ein umfassendes Information Security Management System (ISMS) mit definierten Rollen, Verantwortlichkeiten und regelmäßigen Audits. Im SSI-Kontext bedeutet dies: Die Betreiber der Vertrauensinfrastruktur (Ledger Betreiber, Issuer, Verifier) müssen:

\begin{enumerate}
\item Rollen und Verantwortlichkeiten dokumentieren (z.B. DID Registry Steward, Credential Issuer Manager).

\item Eine Revocation- und Recovery-Strategie für Credentials implementieren, die dokumentiert und regelmäßig getestet wird.

\item Mindestens jährlich Penetrationstests durchführen, insbesondere auf SSI-spezifische Angriffsmuster (z.B. illegitime Credential-Ausstellung, DID-Hijacking).

\item Meldepflichten erfüllen: \textcite[S. 22--23]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024} verlangen, dass Strungen der Verfügbarkeit, Integrität, Authentizität und Vertraulichkeit, die zu einem Ausfall oder erheblicher Beeinträchtigung der kritischen Dienstleistung führen, unverzüglich an das BSI gemeldet werden müssen.
\end{enumerate}







\subsubsection{Framework- und Technologie-Auswahl}

Die in Abschnitt 4.1.1 spezifizierten funktionalen, nicht-funktionalen und KRITIS-Compliance-Anforderungen bilden die Grundlage für eine systematische Auswahl der technologischen Komponenten. Die akademische Literatur bietet umfassende Vergleichsstudien zur Bewertung von SSI-Frameworks. Nokhbeh Zaeem et al. führten eine der detailliertesten Analysen durch, in der 31 blockchain-basierte SSI-Lösungen anhand von 22 nicht-funktionalen und sieben funktionalen Anforderungsgruppen untersucht wurden \parencite[S. 128--129]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Die Autoren kommen zu dem Ergebnis, dass Sovrin, das auf Hyperledger Indy basiert, zu den besten derzeit verfügbaren SSI-Lösungen zählt und dass blockchain-basierte SSI-Ansätze ihren nicht-blockchain-basierten Pendants überlegen sind \parencite[S. 133]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}.

\paragraph{DLT-Plattform}

Für die blockchain-basierte Speicherung von DIDs, Schemas und Credential Definitions wird Hyperledger Indy als DLT-Plattform gewählt. Hyperledger Indy wurde als spezialisierte DLT-Plattform für dezentrale Identitätsverwaltung konzipiert und ist ein öffentlich eingesehenes, aber permissioned blockchain-basiertes Ledger, bei dem nur autorisierte Stewards Transaktionen validieren dürfen. Dies erfüllt die KRITIS-Governance-Anforderungen aus 4.1.1.3, insbesondere die Notwendigkeit einer auditier- und kontrollierbaren Validierungsinfrastruktur.

Dixit et al. analysieren ein dezentrales IIoT-Identitätsframework mit identischen SSI-Komponenten sowohl auf Ethereum als auch auf Hyperledger Indy und weisen Hyperledger Indy als public permissioned und Ethereum als permissionless aus \parencite[S. 2]{dixit_DecentralizedIIoTIdentityFrameworkbasedSelfSovereignIdentityusingBlockchain_2022}. In ihren Experimenten zeigen sich signifikante Unterschiede hinsichtlich Transaktionskosten und Performance: Während Identitätsoperationen und Credential-Prozesse auf Indy ressourceneffizient und mit geringeren Gebühren abgewickelt werden können, sind diese bei Ethereum mit höherem Overhead und längeren Ablaufzeiten verbunden \parencite[S. 3]{dixit_DecentralizedIIoTIdentityFrameworkbasedSelfSovereignIdentityusingBlockchain_2022}.

Su und Hsu betonen, dass Hyperledger Indy es Identitätsinhabern ermöglicht, ihre Daten und Beziehungen unabhängig zu kontrollieren, und dass die Plattform auf offenen Standards und sicheren Mechanismen der Public-Key-Kryptographie basiert, die mit anderen distributed ledgers interoperabel ist \parencite[S. 548]{su_HyperledgerIndybasedRoamingIdentityManagementSystem_2023}. Ein besonderes Merkmal ist die Integration von Zero-Knowledge-Proof-Verfahren (AnonCreds), die die Privacy-Anforderung NFR4 aus 4.1.1.2 adressieren. Die Produktionsreife ist durch mehrjährigen Betrieb des Sovrin-Netzwerks nachgewiesen, das auf Indy basiert und seit 2020 kontinuierlich verfügbar ist.

Nokhbeh Zaeem et al. identifizieren Connect.me als eine der besten SSI-Lösungen für Einzelpersonen, die von Evernym entwickelt wurde und auf dem Sovrin-Netzwerk basiert, welches wiederum auf Hyperledger Indy aufbaut \parencite[S. 133]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Alternative SSI-Frameworks wie uPort und Jolocom basieren auf der Ethereum-Blockchain. Diese public permissionless Architektur führt zu höheren Transaktionskosten und bietet weniger inhärente Privacy-Preserving-Mechanismen im Vergleich zu Indys permissioned Modell. ShoCard repräsentiert eine kommerzielle Lösung mit geringerer akademischer Dokumentation und eingeschränkter Community-getriebener Entwicklung \parencite[S. 133]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}.

\fixme{VON-Network ergänzen}

\paragraph{SSI-Framework}

Während Indy die Ledger-Ebene bereitstellt, ist eine separate Protokoll- und Implementierungsebene notwendig, um SSI-Workflows (Credential Issuance, Verification, Holder-Management) zu orchestrieren. Hyperledger Aries erfüllt diese Rolle als protokollbasiertes Framework. Ferdous et al. zeigen anhand eines Praxisbeispiels der SSI-Integration für Web-Services, dass Hyperledger Indy aktuell eine der zunehmend genutzten Blockchain-Plattformen im Bereich SSI darstellt \parencite[S. 7]{ferdous_SSI4WebSelfsovereignIdentitySSIFrameworkWeb_2022}. In ihrer Implementierung kombinieren sie Hyperledger Aries und Indy als technische Grundlage und veranschaulichen so die praktische Umsetzbarkeit dieser Framework-Kombination \parencite[S. 6--7]{ferdous_SSI4WebSelfsovereignIdentitySSIFrameworkWeb_2022}.

Aries Cloud Agent Python (ACA-Py) ist die offizielle Referenzimplementierung und eine vollständige Realisierung des Aries Interop Profile (AIP) 2.0. Ferdous et al. erklären, dass Hyperledger Aries Bibliotheken zur Entwicklung von SSI-Applikationen in verschiedenen Programmiersprachen bereitstellt, und beschreiben, dass der SSI-Agent unter Verwendung von NodeJS entwickelt wurde, der auf die ACA-Py-Bibliothek angewiesen ist, um verschiedene SSI-Funktionalitäten bereitzustellen \parencite[S. 5]{ferdous_SSI4WebSelfsovereignIdentitySSIFrameworkWeb_2022}. Die Architektur implementiert DIDComm-Messaging zur sicheren Kommunikation zwischen Identity Holder, Issuer und Verifier und unterstützt mehrere Verifiable Credential Formate, insbesondere W3C VCs und Indy AnonCreds. Diese Standardisierung erfüllt die NFR1 (Nachweisbarkeit) und adressiert die Interoperabilitätsanforderungen aus 4.1.1.2.

ACA-Py implementiert alle sieben funktionalen Anforderungen aus 4.1.1.1: Issuer Discovery (FR1) über DID-Registry-Queries, Connection Creation (FR2) via DIDComm-Protokolle, Credential Creation (FR3) mit W3C VCs und AnonCreds, Verification (FR4) mit ZKP-basierten Presentations, Backup/Recovery (FR5) über Wallet-Export-Mechanismen, Derive/Share (FR6) durch granulare Zugriffskontrolle und Revocation (FR7) via Revocation Registry auf dem Indy-Ledger.

Ein zentrales Merkmal von ACA-Py ist die Separation von Agent und Business Logic: Der Agent kommuniziert über HTTP mit einer externen Controller-Anwendung, die in beliebigen Programmiersprachen implementiert werden kann. Dies ermöglicht Flexibilität und Modularität, adressiert die NFR2 (Interoperabilität) durch Unterstützung von W3C-Standards und ermöglicht pluginbare Integrationspunkte für spezifische Anforderungen wie die Post-Quantum-Kryptografie. Die Architektur trennt den Agent von der Business-Logic-Komponente (Controller), wodurch eine sprachunabhängige Integration über HTTP-APIs möglich wird \parencite[S. 5]{ferdous_SSI4WebSelfsovereignIdentitySSIFrameworkWeb_2022}.

\paragraph{Kryptografiebibliothek}

Für die Integration von Post-Quantum-Kryptografie wird die Open Quantum Safe (OQS) Bibliothek in Verbindung mit OpenSSL 3.x gewählt. Die Anforderungen der Post-Quantum-Kryptografie (Forschungsfrage FF2, Abschnitt 1.4) erfordern eine Kryptografiebibliothek, die NIST-standardisierte PQC-Algorithmen (FIPS 203, 204, 205) implementiert und gleichzeitig klassische Algorithmen hybridisieren kann (Crop-and-Paste-Resistenz aus 4.1.1.3).

Open Quantum Safe (OQS) ist ein Linux-Foundation-Projekt, das die Transition zu quantenresistenter Kryptografie unterstützt. OQS besteht aus zwei Hauptkomponenten: liboqs, eine C-Bibliothek, die quantum-resistente Algorithmen implementiert, sowie Prototyp-Integrationen in verbreitete Protokolle und Anwendungen, einschließlich OpenSSL. Diese Designentscheidung ermöglicht eine kryptoagile Architektur, die zukünftige Standards leicht integrieren kann.

Der oqs-provider für OpenSSL 3.x ermöglicht die nahtlose Integration quantensicherer Algorithmen in bestehende OpenSSL-basierte Systeme durch Bereitstellung einer shared library. Diese Integration ist entscheidend, da sowohl Hyperledger Indy-Nodes als auch ACA-Py-Instanzen OpenSSL für kryptografische Operationen verwenden. Durch die Verwendung von oqs-provider werden alle kryptografischen Operationen auf PQC-Algorithmen erweitert, ohne dass Änderungen an der OpenSSL-API notwendig sind. Dies hat den Vorteil, dass bestehende Systeme mit minimalen Änderungen quantensicher gestaltet werden können.

OQS unterstützt Hybrid-Schemes, bei denen klassische und quantensichere Algorithmen kombiniert werden: Beispielsweise können ML-KEM (NIST FIPS 203, Schlüsselvereinbarung) mit ECDH und ML-DSA (NIST FIPS 204, digitale Signaturen) mit ECDSA hybridisiert werden. Dies erfüllt die Crop-and-Paste-Resistenz-Anforderung aus 4.1.1.3: Eine Signatur ist nur dann gültig, wenn sowohl die klassische als auch die quantum-sichere Variante verifizieren.

Die Wahl von OQS erfüllt die kryptografische Agilitätsanforderung (Forschungsfrage FF4, Tabelle 1): Die modulare Architektur erlaubt den Austausch von Algorithmen über Konfigurationsänderungen ohne Code-Anpassungen. Su und Hsu beschreiben, dass Hyperledger Ursa eine sichere, gemeinsame kryptographische Bibliothek darstellt, die modular und erweiterbar konzipiert ist \parencite[S. 548]{su_HyperledgerIndybasedRoamingIdentityManagementSystem_2023}.

\paragraph{Revocation-Infrastruktur}

Für die Revocation-Anforderung FR7 wird das Revocation-Schema von Hyperledger Indy gewählt. Indy implementiert Privacy-Preserving-Revocation durch kryptografische Akkumulatoren, wodurch Holder Nicht-Widerrufung via Zero-Knowledge-Proofs nachweisen können, ohne ihre Credential-IDs oder Indizes preiszugeben \parencite{hardman_0011CredentialRevocationHyperledgerIndyHIPEdocumentation_2018}. Dieses Verfahren erfüllt gleichzeitig NFR4 (Pseudonymität) und adressiert DSGVO-Compliance durch Unlinkability - ein kritisches Merkmal für SSI-Systeme in kritischen Infrastrukturen.

Verglichen mit Alternativen wie Revocation-Listen oder Bitmap-basierten Ansätzen bietet das Akkumulator-Verfahren Auditierbarkeit (Akkumulator-Werte sind auf dem öffentlichen Ledger transparent) bei gleichzeitigem Datenschutz, da keine PII in Revocation-Proofs enthalten ist \parencite{hardman_0011CredentialRevocationHyperledgerIndyHIPEdocumentation_2018}. Die Entkopplung von Issuance und Revocation (Issuer-Autonomie ohne direkten Kontakt zu Holdern) bietet zudem Skalierungsvorteile für KRITIS-Szenarien mit hohem Durchsatz.

Der **Indy Tails Server** wird als Infrastrukturkomponente gewählt, um die erforderlichen Faktoren für das Akkumulator-Verfahren bereitzustellen \parencite{bcgov_GitHubBcgovIndytailsserverThissoftwarestoresmakesavailabletailsfilesuseHyperledger_}. Die BC-Government-Referenzimplementierung bietet native Integration mit ACA-Py und stellt sicher, dass Holder und Verifier die notwendigen kryptografischen Daten abrufen können, ohne auf zentrale Issuer-Services angewiesen zu sein. Diese dezentralisierte Architektur mit öffentlichem Ledger und verteiltem Fileserver erfüllt die Governance- und Auditierbarkeitsanforderungen von KRITIS (4.1.1).

\paragraph{Sidecar Proxy}

Für die transparente Integration von Post-Quantum-Kryptografie in die Agent-zu-Agent-Kommunikation wird NGINX als Sidecar Proxy gewählt. Diese Designentscheidung adressiert eine zentrale Herausforderung: ACA-Py unterstützt nativ keine PQC-Algorithmen, und substantielle Modifikationen der Codebasis würden kryptografische Agilität und Wartbarkeit beeinträchtigen.

Das Sidecar-Proxy-Pattern ermöglicht die automatische Injektion privilegierter Proxy-Container, die sämtliche ein- und ausgehende Kommunikation eines Pods abfangen und kryptografisch schützen, ohne die zugrundeliegende Anwendungslogik zu modifizieren \parencite[S. 1--2]{berlato_WorkinProgressSidecarProxyUsablePerformanceAdaptableEndtoEndProtectionCommunications_2024}. \textcite[S. 2, 5]{berlato_WorkinProgressSidecarProxyUsablePerformanceAdaptableEndtoEndProtectionCommunications_2024} demonstrieren dieses Pattern für Cryptographic Access Control in Cloud-Native-Anwendungen und identifizieren Transparenz, Automatisierung und Modularität als zentrale Eigenschaften. Diese Arbeit adaptiert das Pattern von CAC auf PQC-Integration für SSI-Systeme.

NGINX wird gewählt, da es mit OpenSSL 3.5+ kompiliert werden kann, das über den OQS-Provider NIST-standardisierte PQC-Algorithmen (ML-KEM-768, ML-DSA-65/87) unterstützt \parencite{nginx_GitHubNginxNginxofficialNGINXOpenSourcerepository_}. Die TLS-Termination erfolgt auf NGINX-Ebene mit hybriden Key Exchange Mechanisms (X25519MLKEM768), bevor die entschlüsselte Kommunikation über HTTP an den Backend-ACA-Py-Agent weitergeleitet wird. Im Vergleich zu vollständigen Service-Mesh-Lösungen (Istio, Linkerd, Consul) bietet NGINX höhere kryptografische Flexibilität: Während Service Meshes primär auf klassisches mTLS setzen und keine native PQC-Unterstützung bieten \parencite[S. 6, Tab. 3]{berlato_WorkinProgressSidecarProxyUsablePerformanceAdaptableEndtoEndProtectionCommunications_2024}, erlaubt die NGINX+OQS-Integration beliebige NIST-standardisierte Algorithmen ohne zusätzliche Control-Plane-Komplexität.

Die Wahl erfüllt mehrere nicht-funktionale Anforderungen: **Transparenz (NFR14)** durch vollständige Entkopplung von ACA-Py, sodass keine Anwendungsmodifikationen erforderlich sind \parencite[S. 2]{berlato_WorkinProgressSidecarProxyUsablePerformanceAdaptableEndtoEndProtectionCommunications_2024}; **Kryptoagilität (NFR15)** durch konfigurationsbasierte Algorithmus-Austauschbarkeit über OpenSSL-Provider-Architektur; **Security (NFR7)** durch PQC-hybride TLS 1.3-Termination mit Crop-and-Paste-Resistenz. Die Docker-Sidecar-Architektur gewährleistet zudem automatisches Scaling und nahtlose Integration in Orchestrierungsumgebungen.

\paragraph{Anforderungsmapping}

Die gewählte Technologiekombination Hyperledger Indy + ACA-Py + NGINX + OQS + OpenSSL 3.x erfüllt systematisch alle Anforderungskategorien aus 4.1.1:

\textbf{Funktionale Anforderungen (4.1.1.1):} Indy stellt die dezentralisierte Ledger-Infrastruktur für DIDs und Schemas bereit (FR1, FR2, FR7), ACA-Py implementiert die Credential-Lebenszyklusverwaltung und SSI-Workflows (FR3, FR4, FR5, FR6). OQS integriert quantensichere Signaturen und Verschlüsselung über NGINX-Reverseproxy in die Agent-zu-Agent-Kommunikation, ohne ACA-Py zu modifizieren.

\textbf{Nicht-funktionale Anforderungen (4.1.1.2):} Nachweisbarkeit und Interoperabilität werden durch W3C-Standards und standardisierte Aries-Protokolle erreicht (NFR1, NFR2). Portabilität ermöglicht W3C VC-Export/Import (NFR3). Pseudonymität ergibt sich aus der paarweisen DID-Struktur (NFR4). Recovery wird durch Wallet-Backup und Social Recovery-Mechanismen unterstützt (NFR5). Skalierbarkeit ist durch optimierte Konsens-Mechanismen gegeben (NFR6). Security wird durch PQC-Hybridisierung (ML-KEM-768, ML-DSA-65/87) über NGINX-TLS-Termination und klassische Kryptografie erreicht (NFR7). Usability wird durch ACA-Py's HTTP-API und Wallet-Schnittstellen bereitgestellt (NFR8). Transparenz wird durch das Sidecar-Proxy-Pattern gewährleistet, bei dem ACA-Py keine Modifikationen erfordert (NFR14) \parencite[S. 2]{berlato_WorkinProgressSidecarProxyUsablePerformanceAdaptableEndtoEndProtectionCommunications_2024}. Kryptoagilität ermöglicht der modulare NGINX+OQS-Aufbau, der Algorithmus-Austausch ohne Anwendungsänderungen erlaubt (NFR15).

\textbf{KRITIS-Compliance (4.1.1.3):} Die permissioned Architektur von Indy gewährleistet Governance (4.1.1.3.1) und Auditierbarkeit (4.1.1.3.2) durch Ledger-Transparenz. Das IAM-Framework wird durch DID-basierte Authentifizierung und granulare Credential-basierte Zugriffskontrolle (Least Privilege) realisiert (4.1.1.3.4). Authentifizierung und Verschlüsselung werden durch PQC-hybride Schemas nach BSI-Richtlinien implementiert: NGINX terminiert TLS 1.3 mit hybriden KEMs (X25519MLKEM768) und ML-DSA-signierten Zertifikaten (4.1.1.3.3). Datenschutz wird durch Zero-Knowledge-Proofs und selektive Offenlegung unterstützt (4.1.1.3.5).

\textbf{Post-Quantum-Kryptografie:} OQS integriert NIST-standardisierte Algorithmen (ML-KEM-768, ML-DSA-65/87, SLH-DSA) über den OpenSSL-3-Provider \parencite{openquantumsafe_TLS_2025}. Die Implementierung als NGINX-Reverseproxy ermöglicht transparente PQC-Integration ohne Modifikation von ACA-Py und gewährleistet Crop-and-Paste-Resistenz durch Hybrid-Schemes. Die kryptografische Agilität wird durch die OpenSSL-Provider-Architektur gewährleistet, die Algorithmus-Aktualisierungen durch Konfigurationsänderungen statt Code-Anpassungen erlaubt.

Die Eignung von Hyperledger Indy und Aries für diese Arbeit lässt sich zusammenfassend anhand folgender Kriterien begründen: Hyperledger Indy ist als spezialisierte DLT-Plattform konzipiert, die nativ DIDs und VCs unterstützt \parencite[S. 548]{su_HyperledgerIndybasedRoamingIdentityManagementSystem_2023}. Der production-ready Status beider Projekte mit nachgewiesener Stabilität in Produktivumgebungen erfüllt Anforderungen an technologische Reife. Nokhbeh Zaeem et al. fassen zusammen, dass ihre vergleichende Analyse den allgemeinen Konsens über die besten SSI-Lösungen bestätigt: Sovrin, Connect.me, uPort und ShoCard decken die meisten Anforderungen ab \parencite[S. 133]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}. Aries RFCs definieren standardisierte Protokolle, die Interoperabilität zwischen verschiedenen Implementierungen gewährleisten. Das permissioned blockchain-Modell, production-grade Stabilität und dokumentierte Enterprise-Deployments demonstrieren die Eignung für kritische Infrastrukturen. Die PQC-Integration via NGINX-Reverseproxy erweitert diese Eignung um Quantum-Resistenz, ohne die bewährte Architektur zu kompromittieren.


% ----------


acapy ist das beste ==> \parencite{bahce_CaseStudyMobileWalletImplementationSelfSovereignIdentityInfrastructure_2023}


\subsubsection{Architekturentwurf}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Architektur_Iteration1.png}
    \caption{Architekturentwurf Iteration 1}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Architektur_Iteration1}
\end{figure}


Die in \autoref{fig:Architektur_Iteration1} dargestellte Systemarchitektur konkretisiert den in den vorangegangenen Kapiteln definierten Technologie-Stack durch eine Drei-Akteur-Topologie: \textit{Issuer}, \textit{Holder} und \textit{Verifier}. Diese Topologie veranschaulicht das operative Zusammenspiel der Komponenten sowie die Integrationsstrategie für Post-Quantum-Kryptografie.

Die zentrale Designentscheidung ist die vertikale Schichtung jedes Akteurs: Jeder verfügt über einen ACA-Py Agent als Protokoll-Implementierung und einen NGINX PQC Sidecar Proxy als Transportschicht. Diese Architektur realisiert das \emph{Encryption Proxy Pattern}, bei dem die Agenten unverschlüsselt auf HTTP-Ebene mit ihren lokalen Proxies kommunizieren und diese alle Verschlüsselungsoperationen durchführen. Eine Credential-Issuance-Nachricht wird vom Issuer-Agent im Klartext an seinen NGINX Proxy gesendet, dort mit X25519+ML-KEM-768 sowie ML-DSA-65/87 verschlüsselt, über das Netzwerk transportiert und beim Holder-Proxy ankommen, wo sie dechiffriert wird.

Dieses Pattern adressiert die zentrale Herausforderung, dass ACA-Py nativ keine Post-Quantum-Kryptografie unterstützt. Durch die Sidecar-Architektur wird die komplette Netzwerkebene quantenresistent, ohne den Agent-Code zu modifizieren. Die horizontalen Pfeile zwischen den Proxy-Schichten zeigen die DIDComm-Protokoll-Kommunikation mit vollständiger PQC-Transportverschlüsselung.

Unterhalb dieser Agent-Ebene ist die Ledger-Schicht dargestellt mit vier Validator-Knoten (Indy Nodes 1-4), die das permissioned Distributed Ledger replizieren. Der \emph{Indy Webserver Node} stellt die HTTP-API für DID- und Credential-Definition-Queries bereit, auch diese durch einen NGINX PQC Sidecar Proxy geschützt. Die \emph{Revocation Registry} mit integriertem \emph{Indy Tails Server} implementiert Privacy-Preserving-Revocation mittels kryptografischer Akkumulatoren, was Holder ermöglicht, Nicht-Widerrufung via Zero-Knowledge-Proofs nachzuweisen, ohne ihre Identität preiszugeben.

Ein kritischer Aspekt ist die \textbf{duale PQC-Protection}: Nicht nur inter-Agenten-Kommunikation, sondern auch Ledger-Zugriffsoperationen (DID-Registry-Queries, Credential-Abrufe, Revocation-Status-Checks) durchlaufen die NGINX-Proxies. Dies gewährleistet, dass selbst Infrastruktur-Abfragen quantenresistent sind.

Die Architektur verkörpert mehrere Designprinzipien: \textbf{Kryptografische Transparenz} ermöglicht Algorithmus-Updates (z.\,B. ML-KEM-768 zu ML-KEM-1024) durch OpenSSL-Provider-Konfiguration, nicht durch Code-Änderungen. \textbf{Separation of Concerns} trennt Geschäftslogik (Agent) von Kryptographie (Proxy), wodurch Zukunftssicherheit entsteht. Die \textbf{modulare Komponentenstruktur} ermöglicht Skalierbarkeit: Mehrere ACA-Py-Instanzen nutzen den gleichen Proxy-Pool; Ledger-Knoten und Tails-Server skalieren unabhängig.

% \paragraph{High Level}

% Der Architekturentwurf der prototypischen PQC-SSI-Integration basiert auf dem vierschichtigen Framework von Naghmouchi und Laurent (2025), das SSI-Systeme in Infrastructure, Identifiers \& Cryptographic Material, Credentials \& Presentations sowie Wallet Application untergliedert. \fixme{KAP 2 ???} Diese Architekturschichten bilden die konzeptionelle Grundlage für die systematische Integration post-quantensicherer Kryptographie in bestehende SSI-Komponenten.

% \textbf{Infrastructure Layer (Layer 1).} Die Infrastrukturschicht wird durch von-network realisiert, eine portable Hyperledger-Indy-Node-Implementierung für Entwicklungs- und Testzwecke, welches ein dezentrales Ledger bereit stellt, das als Verifiable Data Registry (VDR) und Decentralized Public Key Infrastructure (DPKI) fungiert \parencite{bcgov_GitHubBcgovVonnetworkportabledevelopmentlevelIndyNodenetwork_}. Die Implementierung umfasst vier Indy-Nodes in Docker-Containern, einen Ledger Browser mit API-Schnittstelle sowie drei distinkte Ledger für Domain-, Pool- und Config-Transaktionen. Als VDR ermöglicht von-network die Publikation von DIDs, öffentlichen Schlüsseln, Credential Definitions und Revocation Registries.

% \textbf{Identifiers \& Cryptographic Material Layer (Layer 2).} Diese Schicht integriert post-quantensichere kryptographische Primitive durch die Kombination von liboqs und OpenSSL 3.5. Liboqs ist eine C-Bibliothek des Open Quantum Safe-Projekts, die NIST-standardisierte PQC-Algorithmen bereitstellt, insbesondere ML-KEM (FIPS-203) für Schlüsselaustausch sowie ML-DSA (FIPS-204) und SLH-DSA (FIPS-205) für digitale Signaturen \parencite{open-quantum-safe_GitHubOpenquantumsafeLiboqslibraryprototypingexperimentingquantumresistantcryptography_}. OpenSSL 3.5 als erste Long-Term-Support-Version mit integrierter PQC-Unterstützung ermöglicht hybride Kryptosysteme, die klassische und post-quantensichere Verfahren kombinieren. Die Integration erfolgt über den OQS-Provider, der PQC-Algorithmen in die OpenSSL-Provider-Architektur einbindet \parencite{openssl_GitHubOpensslOpensslTLSSSLcryptolibrary_}.

% \textbf{Credentials \& Presentations Layer (Layer 3).} Der Indy Tails Server bildet die Revocation-Infrastruktur für AnonCreds-Credentials \parencite{bcgov_GitHubBcgovIndytailsserverThissoftwarestoresmakesavailabletailsfilesuseHyperledger_}. Tails-Dateien enthalten kryptographische Akkumulator-Werte für Zero-Knowledge-Proofs der Nicht-Widerrufbarkeit. Der Server stellt eine HTTP/HTTPS-API für Upload und Download der Tails-Dateien bereit und integriert sich nahtlos mit ACA-Py. Die URL des Tails-Servers wird in der Revocation Registry Definition auf dem Ledger persistiert, wodurch Holder die Dateien für Non-Revocation-Proofs abrufen können \parencite{bcgov_GitHubBcgovIndytailsserverThissoftwarestoresmakesavailabletailsfilesuseHyperledger_}.

% \textbf{Wallet Application Layer (Layer 4).} Aries Cloud Agent Python (ACA-Py) implementiert die Wallet-Funktionalität als Open-Source-Framework für dezentrale Identitätsagenten. Die Architektur trennt den Agent (Core-Funktionalität für Aries-Protokolle, DIDComm, Secure Storage) vom Controller (Business-Logik, Anwendungsschnittstelle) \parencite{openwallet-foundation_GitHubOpenwalletfoundationAcapyACAPyfoundationbuildingdecentralizedidentityapplicationsservicesrunningnonmobile_}. Die Kommunikation erfolgt bidirektional: Der Agent sendet Webhook-Notifications an den Controller, welcher über eine REST-API administrative Anweisungen zurückgibt. ACA-Py unterstützt Multi-Tenancy, pluggable Storage-Backends sowie Transport-Mechanismen und operiert in den Schichten 2 und 3 des Trust-Over-IP-Frameworks \parencite{openwallet-foundation_GitHubOpenwalletfoundationAcapyACAPyfoundationbuildingdecentralizedidentityapplicationsservicesrunningnonmobile_}.

% \textbf{Komponenteninteraktionen.} Die Architektur weist ausgeprägte Interdependenzen zwischen den Schichten auf. ACA-Py (Layer 4) schreibt DIDs, Schemas und Credential Definitions auf von-network (Layer 1) und liest Genesis-Transaktionen für die Pool-Initialisierung. Der Tails-Server (Layer 3) wird von ACA-Py für Speicherung und Abruf von Revocation-Tails-Dateien genutzt. Die PQC-Integration über OpenSSL 3.5 und liboqs (Layer 2) ermöglicht zukünftig quantum-resistente TLS-Verbindungen zwischen Indy-Nodes sowie hybride Signaturverfahren in ACA-Py.

% \paragraph{Low Level}

% Die Low-Level-Architektur spezifiziert die internen Komponenten und Datenflüsse innerhalb der vier Schichten.

\subsubsection{Setup der Entwicklungsumgebung}

\fixme{ABBILDUNG?}

Die Entwicklungsumgebung für diese Arbeit folgt einer geschichteten Architektur, die Ressourceneffizienz, Isolierung und Reproduzierbarkeit kombiniert. Das System nutzt Hyper-V als Type-1-Hypervisor unter Windows 10, der direkt auf der Hardware-Ebene arbeitet und eine stabile Grundlage für die virtualisierte Umgebung bietet.

Auf der Hyper-V-Infrastruktur wird eine Ubuntu 24.04 LTS Virtual Machine betrieben, die als Gastbetriebssystem für die Entwicklungsarbeit dient. Ubuntu 24.04 LTS erfüllt die notwendigen Systemanforderungen und bietet als Long-Term-Support-Version langfristige Stabilität und Sicherheitsupdates - entscheidend für reproduzierbare akademische Forschung.

Die eigentliche Entwicklungsumgebung wird durch Docker-Container bereitgestellt, die auf der Ubuntu-VM ausgeführt werden. Docker ermöglicht die Definition isolierter, vorkonfigurierter Entwicklungsumgebungen über Dockerfiles, wodurch Abhängigkeiten und Toolketten konsistent verwaltet werden. Dies minimiert Konfigurationsfehler und gewährleistet, dass alle Iterationen der Forschungsarbeit unter identischen Bedingungen reproduzierbar sind.

Die Quellcodeverwaltung erfolgt über Git und GitHub, wodurch Versionskontrolle, Kollaborationsmöglichkeiten und vollständige Nachverfolgbarkeit aller Entwicklungsschritte realisiert werden. Diese Kombination aus Hyper-V, Ubuntu, Docker und Git/GitHub schafft eine isolierte, versionskontrollierte und hochgradig reproduzierbare Forschungsinfrastruktur, die akademische Standards erfüllt und gleichzeitig moderne DevOps-Praktiken umsetzt.


% SSI Layers \parencite[S. 7]{naghmouchi_SystematicReviewLayeredFrameworkPrivacybyDesignSelfSovereignIdentitySystems_2025}

% Infrastructure ==> indy on besu \\
% Identifier + Cryptographic material ==> Indy DID \\
% Credential \& Presentations ==> AnonCreds W3C VCs \\
% Agent ==> ACA-Py




% Layer Sicht:

% Agent ==> ACA-Py (als Edge Agent aufgesetzt)
% Credential \& Presentations ==> AnonCreds W3C VCs \\
% Identifier + Cryptographic material ==> Indy DID \\
% Infrastructure ==> indy on besu \\



% indy besu ==> \parencite{shcherbakov_HyperledgerIndyBesupermissionedledgerSelfsovereignIdentity_2024}



\subsubsection{Implementierung}

\paragraph{Zertifikatsstruktur}

Die Zertifikatsinfrastruktur für die PQC-Sidecar-Proxies basiert auf einer selbstsignierten Root Certificate Authority (Root CA), die mit dem Post-Quantum-Signaturalgorithmus ML-DSA-87 (NIST FIPS-204) mit maximaler Schlüsselgröße (4880 Bit) erstellt wurde. Die Root CA dient als Trust Anchor für alle in der Architektur verwendeten TLS-Zertifikate und gewährleistet, dass sämtliche Zertifikatssignaturen quantenresistent sind.

Das Zertifikatserstellungsverfahren folgt einem fünfschrittigen Workflow, wie in \autoref{fig:Zertifikatserstellungsworkflow} dargestellt: Zunächst wird der Root-CA-Schlüssel generiert (\textit{Step 1}), gefolgt von der Erstellung des selbstsignierten Root-CA-Zertifikats mit einer Gültigkeit von zehn Jahren (\textit{Step 2}). Anschließend werden für jeden Sidecar-Proxy dedizierte Schlüssel mit ML-DSA-65 generiert (\textit{Step 3}), die ein besseres Verhältnis zwischen Sicherheit und Performance bieten (3044 Bit). Für jeden Proxy wird ein Certificate Signing Request (CSR) erstellt, der die erforderlichen Subject Alternative Names (SANs) enthält (\textit{Step 4}), bevor die Zertifikate abschließend von der Root CA mit ML-DSA-65 und SHA3-256 signiert werden (\textit{Step 5}). Die detaillierte Implementierung dieses Workflows ist in Listing \autoref{lst:Zertifikatserstellungsworkflow} dokumentiert.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Zertifikatserstellungsworkflow.png}
    \caption{Zertifikatserstellungsworkflow für PQC-basierte Sidecar-Proxies}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Zertifikatserstellungsworkflow}
\end{figure}

Das Root-CA-Zertifikat besitzt eine Gültigkeit von zehn Jahren und wird in den System-Trust-Store aller Container importiert, sodass Python-Bibliotheken wie \texttt{requests} und Kommandozeilen-Tools wie \texttt{curl} die ML-DSA-65-signierten Zertifikate automatisch als vertrauenswürdig erkennen.

Für jeden der fünf Sidecar-Proxies wurde ein dediziertes Server-Zertifikat generiert: \texttt{issuer.crt}, \texttt{holder.crt}, \texttt{verifier.crt}, \texttt{von-webserver.crt} und \texttt{tails-server.crt}. Jedes dieser Zertifikate wird mittels Certificate Signing Request (CSR) erstellt und von der Root CA mit ML-DSA-65 signiert. Die Zertifikate enthalten Subject Alternative Names (SAN), die sowohl den DNS-Namen \texttt{localhost} als auch die IP-Adresse \texttt{127.0.0.1} umfassen, um flexible Zugriffsmöglichkeiten während der Entwicklung zu ermöglichen. Die Zertifikatsgröße liegt bei durchschnittlich 9.500 Bytes pro Agent-Zertifikat, während die Root CA mit 10.312 Bytes aufgrund zusätzlicher Metadaten geringfügig größer ausfällt. Diese Größenordnung ist charakteristisch für ML-DSA-65-Signaturen, deren Signaturlänge 3.293 Bytes beträgt und damit signifikant über klassischen ECDSA-Signaturen (ca.\ 64--72 Bytes) liegt.

Die Integration der Zertifikate erfolgt über Docker-Volume-Mounts: Das Verzeichnis \texttt{hopE/pqc\_sidecarproxy\_nginx/certs/} wird als Read-Only-Volume in jeden Nginx-Container unter \texttt{/opt/nginx/certs/} eingebunden. In der Nginx-Konfiguration werden die Zertifikate durch die Direktiven \texttt{ssl\_certificate /opt/nginx/certs/<agent>.crt} und \texttt{ssl\_certificate\_key /opt/nginx/certs/<agent>.key} referenziert. Parallel dazu wird das Root-CA-Zertifikat in allen ACA-Py-Agent-Containern nach \texttt{/usr/local/share/ca-certificates/pqc-root-ca.crt} kopiert und mittels \texttt{update-ca-certificates} in den System-Trust-Store importiert. Zusätzlich werden die Umgebungsvariablen \texttt{SSL\_CERT\_FILE}, \texttt{REQUESTS\_CA\_BUNDLE} und \texttt{CURL\_CA\_BUNDLE} auf \texttt{/etc/ssl/certs/ca-certificates.crt} gesetzt, um sicherzustellen, dass Python-Anwendungen und HTTP-Clients die importierte Root CA verwenden und TLS-Verbindungen zu den PQC-Proxies erfolgreich validieren können.

\paragraph{Sidecar Proxy nginx}

Die Implementierung der post-quanten-kryptographischen Absicherung auf Transport-Layer-Ebene basiert zum einen auf einer modifizierten Version des NGINX-Dockerfiles von \textcite{open-quantum-safe_OpenquantumsafeOqsdemosNginxDockerfile_2025}, zum anderen auf spezifischen NGINX-Konfigurationsdateien für jeden Sidecar-Proxy.

\textbf{Dockerfile}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{2 Stage Sidecarproxy Dockerfile.png}
    \caption{Sidecar Proxy NGINX Dockerfile Multi-Stage Build}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Sidecar_Proxy_nginx_Dockerfile}
\end{figure}

\fixme{CHANGES IN ROT MARKIEREN INNERHALB DER GRAFIK}

Die \autoref{fig:Sidecar_Proxy_nginx_Dockerfile} visualisiert anschaulich den zweistufigen Aufbau des modifizierten Dockerfiles (Listing \ref{lst:Dockerfile-Sidecar-Proxy-nginx}) für eine post-quantenfähige NGINX-Sidecar-Proxy-Lösung, die auf die Integration von OpenSSL 3.5.4 und dem OQS Provider ausgerichtet ist. Das modifizierte Dockerfile folgt dabei dem Multi-Stage-Build-Prinzip, einer Optimierungsstrategie nach \textcite[S. 1]{rosa_MiningMeasuringImpactchangepatternsimprovingsizebuildtimedockerimages_2025}, und gliedert sich in die zwei zentrale Phasen \textbf{Build-Stage (Stage 1)} und \textbf{Runtime-Stage (Stage 2)}.

In der Build-Phase findet die gesamte Kompilierung und Zusammenführung der für den Betrieb erforderlichen Abhängigkeiten statt. Zunächst werden Versionsangaben für Bibliotheken, Algorithmen, TLS-Gruppen und Installationsverzeichnisse als Build-Parameter definiert. Anschließend werden die projektrelevanten Quellen wie \texttt{liboqs}, \texttt{oqs-provider}, \texttt{openssl}, \texttt{nginx} und \texttt{curl} gezielt und versioniert aus ihren jeweiligen Repositories geladen. Die Kompilierung erfolgt dabei in einer spezifischen Reihenfolge: OpenSSL und liboqs werden mit definierten Einstellungen gebaut, NGINX wird unter Einbindung des OQS Providers und einer hybrid gelinkten OpenSSL-Version kompiliert, und curl wird dynamisch mit OpenSSL gebaut, um HTTPS-Unterstützung sicherzustellen. Abschließend werden die generierten Binaries optimiert und nicht benötigte Dateien entfernt, um das finale Image so schlank wie möglich zu gestalten.

Die Runtime-Stage bildet daraufhin das minimalistische Endprodukt, das zum produktiven Einsatz bestimmt ist. Die in der Build-Phase erzeugten Binaries und Konfigurationen werden hier in das neue Runtime-Image übernommen. Die notwendigen Einstellungen für Post-Quantum-TLS-Gruppen und Logging werden über Umgebungsvariablen und angepasste Konfigurationen gesetzt. Das Image läuft nach dem Least-Privilege-Prinzip \parencite[S. 1]{khattar_DockerProEssentialPracticesSecureScalableContainers_2025} mit einem dedizierten Non-Root User (\texttt{oqs}), und der Container-Entrypoint ist klar über den Aufruf von nginx definiert.

Gegenüber dem Original-Dockerfile \parencite{open-quantum-safe_OpenquantumsafeOqsdemosNginxDockerfile_2025} wurden mehrere zielgerichtete Modifikationen vorgenommen. Die OpenSSL-Version wurde von variablen Tags auf die explizite Versionsnummer \texttt{3.5.4} festgelegt, da dieses Release als LTS mit aktuellen Sicherheitsfixes gilt. Die für den Key-Encapsulation-Mechanism zentralen TLS-Gruppen wurden auf \texttt{X25519MLKEM768}, \texttt{mlkem768}, \texttt{x25519} und \texttt{mlkem1024} reduziert, um gezielt ML-KEM-768 zu forcieren. Im Originalskript werden Zertifikate direkt während des Builds generiert; die modifizierte Version hingegen verzichtet darauf und sieht vor, dass Zertifikate via Volume von außen eingebracht werden, was dem Produktionsszenario entspricht. Die Build-Reihenfolge wurde neu strukturiert: OpenSSL wird zuerst als Shared Library kompiliert, um eine dynamische Verlinkung von curl und nginx zu ermöglichen. Dies umgeht auch Inkompatibilitäten zwischen Alpine Linux und statisch gelinkten OpenSSL-Versionen. Die Optimierung und Entfernung nicht benötigter Artefakte erfolgt granularer, wobei dynamische Binaries und Modul-Dateien wie \texttt{oqsprovider.so} gezielt gestreift werden. Das finale Runtime-Image wurde zusätzlich verschlankt: Es werden \texttt{ca-certificates} als Runtime-Abhängigkeit hinzugefügt, Ports werden explizit nicht mehr im Dockerfile exponiert (dies erfolgt stattdessen via Docker Compose oder Kubernetes), und der ENTRYPOINT ist strikt auf den Sidecar-Proxy-Einsatz ausgerichtet.


% Die primäre Modifikation betrifft den Wechsel von OpenSSL 3.4.0 auf OpenSSL 3.5.4 LTS, welche zum Zeitpunkt der Implementierung die aktuelle Long-Term-Support-Version mit essenziellen Sicherheitspatches darstellte und somit eine produktionsnahe Testumgebung ermöglichte. Diese Version gewährleistet Kompatibilität mit dem OQS-Provider 0.9.0 und liboqs 0.13.0, während gleichzeitig kritische CVE-Fixes berücksichtigt werden, die in früheren Versionen nicht verfügbar waren.

% Eine wesentliche Anpassung erfolgte in der Konfiguration der unterstützten Schlüsselaustausch-Mechanismen über die \texttt{DEFAULT\_GROUPS}-Variable. Während die OQS-Referenzimplementierung eine breite Palette klassischer und post-quanten-Algorithmen vorsieht (\texttt{x25519:x448:prime256v1:secp384r1:secp521r1:mlkem512:mlkem768:mlkem1024}), fokussiert die angepasste Implementierung auf die hybriden NIST-standardisierten Varianten mit der Priorisierung \texttt{X25519MLKEM768:mlkem768:x25519:mlkem1024}. Diese Auswahl basiert auf der Empfehlung des BSI für den Einsatz hybrider Verfahren im Übergangszeitraum zur post-quanten-Kryptographie sowie der NIST-Standardisierung von ML-KEM (ehemals CRYSTALS-Kyber) als primären Key Encapsulation Mechanism. Die hybride Variante X25519MLKEM768 kombiniert dabei die bewährte Elliptic-Curve-Diffie-Hellman-Variante X25519 mit ML-KEM-768 und bietet somit Schutz sowohl gegen klassische als auch gegen quantencomputerbasierte Angriffe.

% Die dritte substantielle Modifikation betrifft das Certificate-Management. Während die OQS-Referenzimplementierung zur Build-Zeit selbstsignierte Zertifikate mit ML-DSA-65-Signaturen generiert und diese im Image einbettet, wurde in der angepassten Version die Zertifikatsgenerierung vollständig entfernt und durch ein Volume-basiertes Mount-Verfahren ersetzt. Diese architektonische Entscheidung ermöglicht die Verwendung einer zentralen Public-Key-Infrastruktur (PKI) mit dedizierten Certificate Authorities sowie die Rotation von Zertifikaten ohne Neubildung des Container-Images. Die Zertifikate werden zur Laufzeit über Docker-Volumes unter dem Pfad \texttt{/opt/nginx/certs} bereitgestellt und durch die NGINX-Konfiguration referenziert. Dies gewährleistet Flexibilität in Multi-Agent-Deployments, bei denen unterschiedliche Agents individuelle Zertifikate mit spezifischen Subject Alternative Names (SANs) benötigen.

% Zusätzlich wurde die Build-Pipeline um cURL 8.11.1 erweitert, welches ebenfalls gegen die kompilierte OpenSSL-3.5.4-Instanz gelinkt wird. Diese Integration ermöglicht administrative Operationen und Debugging-Prozesse mit post-quanten-kryptographischen TLS-Verbindungen direkt aus dem Container heraus, ohne auf externe Tools mit potentiell inkompatiblen OpenSSL-Versionen angewiesen zu sein. Die Shared-Library-Verlinkung über RPATH-Einträge stellt sicher, dass sowohl NGINX als auch cURL zur Laufzeit die korrekte OpenSSL-Version mit aktiviertem OQS-Provider referenzieren, unabhängig von systemweiten OpenSSL-Installationen auf dem Host-System.


\textbf{nginx.conf}

Die NGINX-Konfigurationsdateien implementieren ein standardisiertes Sidecar-Proxy-Pattern für die post-quantensichere Verschlüsselung von Datenverkehr mittels TLS~1.3 mit Hybrid-Key-Exchange (\textit{X25519MLKEM768}). Eine Beispielkonfiguration für den Holder-Agenten-Sidecarproxy ist in Listing \ref{lst:nginx_holder.conf} dargestellt.

Strukturell folgen alle Konfigurationen einem konsistenten Schichtenmodell. Die globale Konfigurationsebene definiert Worker-Prozesse, Logging-Parameter sowie HTTP-Grundeinstellungen. Die mittlere Ebene besteht aus \textbf{Upstream-Blöcken}, die interne Services abstrahieren (\texttt{holder:8030}, \texttt{holder:8031}). Die oberste Ebene enthält \textbf{Server-Blöcke}, die für jeden öffentlich erreichbaren Endpoint eine HTTPS-Schnittstelle exponieren.

Das zentrale Sicherheitsmerkmal aller Konfigurationen ist die Direktive \texttt{ssl\_ecdh\_curve X25519MLKEM768}, die den Hybrid-Key-Exchange zwischen klassischer Elliptischen-Kurven-Kryptografie und dem post-quantensicheren ML-KEM-768-Algorithmus aktiviert. Die konkrete Gruppenauswahl wird extern über die Umgebungsvariable \texttt{DEFAULT\_GROUPS} gesteuert, was eine Trennung von Konfiguration und Deploymentslogik ermöglicht. Komplementär hierzu werden SSL-Zertifikate mit \textit{ML-DSA-65}-Signaturalgorithmus verwendet, die als Volume-Mounts unter \texttt{/opt/nginx/certs/} eingebunden werden. Dieser Ansatz gewährleistet, dass sowohl der Schlüsselaustausch als auch die Server-Authentifikation post-quantensicher erfolgen, während die Zertifikate unabhängig von der Container-Runtime verwaltet und rotiert werden können.

Die Reverse-Proxy-Funktionalität wird durch \texttt{location /}-Blöcke realisiert, die Anfragen an Upstream-Services weiterleiten. Alle Konfigurationen exponieren einen \texttt{/health}-Endpoint für Orchestrierungs-Health-Checks.

\paragraph{DLT-Infrastruktur}

Die Implementierung der Distributed-Ledger-Infrastruktur basiert auf dem \textit{von-network}-Repository \parencite{bcgov_GitHubBcgovVonnetworkportabledevelopmentlevelIndyNodenetwork_}, das eine portable, docker-basierte Hyperledger-Indy-Entwicklungsumgebung bereitstellt. Das von-network-Projekt wurde ursprünglich entwickelt, um Entwicklern und Organisationen eine sofort einsatzbereite Indy-Blockchain-Umgebung zur Verfügung zu stellen, ohne die Komplexität eines produktiven Sovrin-Netzwerks bewältigen zu müssen. Die Entscheidung für von-network als Basis-Infrastruktur begründet sich durch die vollständige Kapselung aller erforderlichen Komponenten -- Genesis-File-Generierung, Validator-Node-Orchestrierung und Ledger-Browser-Interface -- in einer konsistenten Docker-Compose-Konfiguration.

Die unmodifizierte von-network-Implementierung stellt vier Indy-Validator-Nodes bereit, die über das Practical Byzantine Fault Tolerance (PBFT) Konsensprotokoll synchronisiert werden. Jeder Node exponiert zwei Ports für die Indy-Protokollkommunikation (9701--9708) und verfügt über ein dediziertes Docker-Volume zur Persistierung des Ledger-Zustands. Zusätzlich zu den Validator-Nodes wird ein Webserver-Container deployt, der ein Web-Interface zur Ledger-Visualisierung sowie einen HTTP-Endpoint zur Genesis-File-Distribution bereitstellt. Diese Architektur ermöglicht es ACA-Py-Agents, beim Start die Genesis-Transaktionsdatei über eine konfigurierbare URL abzurufen und sich automatisch mit dem Indy-Netzwerk zu verbinden.

Für die Integration der Post-Quantum-Kryptografie auf Transport-Layer-Ebene wurde die von-network-Architektur um einen PQC Nginx Sidecar Proxy erweitert.
Diese Modifikation stellt die zentrale Anpassung gegenüber dem Original-Quellcode dar und betrifft primär die \texttt{docker-compose.yml}-Konfigurationsdatei (Listing \ref{lst:docker-compose.yml-DLT-Infrastruktur}) sowie die Hinzufügung eines neuen Verzeichnisses \texttt{pqc\_sidecarproxy\_nginx/}, das die \fixme{in Kapitel XY vorgestellten} Dockerfile- und Nginx-Konfigurationsdateien für den quantensicheren Reverse Proxy enthält. Der Webserver-Container, der im Original-Setup direkt auf Port 9000 exponiert wurde, verbleibt in der modifizierten Architektur ausschließlich im internen Docker-Netzwerk \texttt{von}. Stattdessen terminiert der neu hinzugefügte \texttt{pqc-sidecarproxy-webserver}-Container alle eingehenden TLS-1.3-Verbindungen auf Port 8000 und leitet die Anfragen nach erfolgreicher ML-KEM-768-basierter Schlüsselvereinbarung und ML-DSA-65-Zertifikatsverifikation als unverschlüsseltes HTTP an den internen Webserver-Container weiter.

Die Integration des Sidecar Proxies erforderte die Definition eines zusätzlichen, extern zugänglichen Docker-Netzwerks \texttt{von\_sidecarproxy}, das als gemeinsame Kommunikationsebene für alle PQC-Proxies der Gesamtarchitektur dient. Dieses Netzwerk wird in der \texttt{docker-compose.yml} als \texttt{external: true} deklariert. Der \texttt{pqc-sidecarproxy-webserver}-Container ist sowohl mit dem internen \texttt{von}-Netzwerk (für Backend-Kommunikation) als auch mit dem externen \texttt{von\_sidecarproxy}-Netzwerk (für Client-Zugriffe) verbunden, wodurch eine strikte Netzwerksegmentierung zwischen interner und externer Kommunikation gewährleistet wird.

Neben der Proxy-Integration wurden die Indy-Validator-Nodes und der Webserver-Container vollständig unverändert aus dem Original-Repository übernommen. Dies umfasst das Base-Image \texttt{ghcr.io/bcgov/von-image:node-1.12-6}, die Genesis-Generierungslogik in \texttt{scripts/init\_genesis.sh} sowie die Node-Startup-Scripts \texttt{scripts/start\_node.sh}. Die Beibehaltung des ursprünglichen Indy-Node-Codes gewährleistet, dass die blockchain-interne Validierung, Konsens-Mechanismen und Ledger-Operationen identisch mit etablierten Indy-Deployments funktionieren und ausschließlich die externe Kommunikationsschicht durch Post-Quantum-Kryptografie abgesichert wird.

Die Ledger-Struktur von Hyperledger Indy bleibt ebenfalls unverändert und umfasst drei logische Ledger-Typen: Der \textit{Domain Ledger} speichert DIDs, Schemas und Credential Definitions; der \textit{Pool Ledger} verwaltet die Validator-Node-Registry; der \textit{Config Ledger} enthält Netzwerk-Konfigurationen wie Transaction Author Agreements (TAA) und Acceptable Mechanism Lists (AML). Die Persistierung dieser Ledger erfolgt über Docker-Volumes (\texttt{node1-data} bis \texttt{node4-data}), die bei einem Neustart der Container den Ledger-Zustand wiederherstellen und somit eine konsistente Datenbasis über mehrere Entwicklungs- und Testzyklen hinweg gewährleisten.

% Zusammenfassend beschränkt sich die Modifikation des von-network-Projekts auf die Hinzufügung einer PQC-Transport-Layer-Sicherheitsebene, während die Core-Funktionalität der Indy-Blockchain-Infrastruktur vollständig erhalten bleibt. Diese minimalinvasive Anpassungsstrategie entspricht dem Sidecar-Pattern-Prinzip, das eine klare Separation zwischen kryptografischen Sicherheitsmechanismen (Proxy-Ebene) und Geschäftslogik (Blockchain-Ebene) etabliert. Die Wiederverwendbarkeit des etablierten von-network-Codes reduziert die Implementierungskomplexität und gewährleistet, dass die DLT-Infrastruktur auf bewährten, produktionserprobten Komponenten basiert, während die quantensichere Absicherung als modulare Erweiterungsschicht implementiert wird.

\paragraph{Revocation Registry}

Die Implementierung der Revocation-Registry-Infrastruktur basiert auf dem offiziellen \textit{indy-tails-server}-Repository \parencite{bcgov_GitHubBcgovIndytailsserverThissoftwarestoresmakesavailabletailsfilesuseHyperledger_}, das einen dedizierten File-Server für die Speicherung und Distribution von Revocation-Registry-Tails-Dateien bereitstellt. Im Kontext von AnonCreds -- dem Privacy-Preserving-Credential-Format von Hyperledger Indy -- werden Tails-Dateien benötigt, um Non-Revocation-Proofs zu generieren und zu verifizieren, ohne dabei die gesamte Revocation-Registry-Datenstruktur im Ledger zu speichern. Der Tails-Server fungiert als zentraler Storage-Service, auf den sowohl Credential-Issuer (zum Upload der Tails-Dateien) als auch Verifier (zum Download für Proof-Verifikation) zugreifen.

Die unmodifizierte indy-tails-server-Implementierung stellt eine Python-basierte REST-API bereit, die zwei primäre Operationen unterstützt: Das Hochladen von Tails-Dateien über HTTP-PUT-Requests auf die Endpoints \texttt{/hash/\{tails-hash\}} oder \texttt{/\{revoc\_reg\_id\}} sowie das Abrufen von Tails-Dateien über HTTP-GET-Requests. Die Server-Architektur implementiert eine Hash-basierte Integritätsvalidierung, bei der der SHA-256-Hash der hochgeladenen Datei mit dem in der URL spezifizierten Hash verglichen wird, um Dateikorruption oder Manipulation zu detektieren. Die Tails-Dateien werden im Dateisystem des Containers persistiert, wobei der Speicherpfad über die Umgebungsvariable \texttt{STORAGE\_PATH} konfigurierbar ist.

Für die Integration in die Post-Quantum-gesicherte Gesamtarchitektur wurde der indy-tails-server analog zur DLT-Infrastruktur um einen PQC Nginx Sidecar Proxy erweitert. Diese Modifikation betrifft primär die Docker-Compose-Konfigurationsdatei (Listing \ref{lst:docker-compose.yml-Revocation-Registry}), in der ein zusätzlicher Service \texttt{pqc-sidecarproxy-tails-server} definiert wurde, sowie die Hin-
zufügung eines neuen Verzeichnisses pqc\_sidecarproxy\_nginx/, das die \fixme{in Kapitel XY vorgestellten} Dockerfile- und Nginx-Konfigurationsdateien für den
quantensicheren Reverse Proxy enthält. Der ursprüngliche Tails-Server-Container verbleibt im internen Docker-Netzwerk \texttt{tails-server} und exponiert Port 6543 ausschließlich innerhalb dieses Netzwerks. Der neu hinzugefügte PQC-Proxy-Container terminiert alle externen TLS-1.3-Verbindungen auf Port 6543 und leitet die Anfragen nach erfolgreicher quantensicherer Authentifizierung (ML-DSA-65-Zertifikatsverifikation) und Schlüsselvereinbarung (ML-KEM-768) als unverschlüsseltes HTTP an den internen Tails-Server weiter.

Die Netzwerk-Integration folgt dem etablierten Sidecar-Pattern: Der \texttt{pqc-sidecarproxy-tails-server}-Container ist sowohl mit dem internen \texttt{tails-server}-Netzwerk (für Backend-Kommunikation) als auch mit dem externen, manuell erstellten \texttt{von\_sidecarproxy}-Netzwerk (für Client-Zugriffe) verbunden. Diese Dual-Network-Architektur erzwingt, dass alle externen Zugriffe auf den Tails-Server -- sowohl von ACA-Py-Issuer-Agents beim Upload als auch von Verifier-Agents beim Download -- über den quantensicheren Reverse Proxy geleitet werden.

Die funktionale Logik des Tails-Servers -- einschließlich File-Upload-Validierung, Hash-Verifikation und Storage-Management -- bleibt vollständig unverändert. Dies umfasst die Python-basierte REST-API-Implementierung, die Multi-Part-File-Upload-Handler sowie die Fehlerbehandlung für invalide Hashes oder fehlende Dateien. Die Beibehaltung des Original-Codes gewährleistet, dass die Revocation-Mechanismen kompatibel mit Standard-AnonCreds-Implementierungen bleiben und ausschließlich die Transport-Layer-Sicherheit durch Post-Quantum-Kryptografie erweitert wird.

% Ein wesentlicher Aspekt der Tails-Server-Integration ist die Performance-Charakteristik in Abhängigkeit von der Revocation-Registry-Größe. Bei der Erstellung einer Credential Definition mit aktivierter Revocation wird ein Parameter \texttt{revocation\_registry\_size} spezifiziert, der die maximale Anzahl widerrufbarer Credentials festlegt. Die Größe der resultierenden Tails-Datei korreliert linear mit der Registry-Größe: Eine Registry mit 3\,000 Einträgen erzeugt eine 768\,KB-Datei, während 32\,768 Einträge eine 8,4\,MB-Datei generieren. Diese Dateien müssen von Verifier-Agents während der Proof-Verifikation heruntergeladen werden, wobei der PQC-Proxy-Overhead durch ML-KEM-768-Schlüsselaustausch die Transfer-Latenz geringfügig erhöht. Empirische Tests zeigten, dass die zusätzliche TLS-1.3-Handshake-Latenz mit ML-KEM-768 im Vergleich zu klassischem X25519 durchschnittlich 15--25\,ms beträgt, was bei typischen Tails-File-Transfer-Zeiten von mehreren Sekunden vernachlässigbar ist.

Die Docker-Compose-Orchestrierung des Tails-Servers definiert ein persistentes Volume \texttt{tails-files}, das den \texttt{STORAGE\_PATH}-Verzeichnis-Mount bereitstellt. Dieses Volume gewährleistet, dass hochgeladene Tails-Dateien über Container-Neustarts hinweg erhalten bleiben, was insbesondere in Entwicklungsumgebungen relevant ist, in denen Credential Definitions mit Revocation Registry wiederverwendet werden sollen. Die Health-Check-Konfiguration des Proxy-Containers überwacht die Verfügbarkeit des HTTPS-Endpoints und stellt sicher, dass nachgelagerte Services (ACA-Py-Agents) erst starten, wenn die Tails-Server-Infrastruktur vollständig einsatzbereit ist.

% Zusammenfassend beschränkt sich die Modifikation des indy-tails-server-Projekts auf die Integration einer quantensicheren Transport-Layer-Sicherheitsebene, während die Core-Funktionalität des Revocation-Registry-File-Servers vollständig erhalten bleibt. Diese Anpassungsstrategie entspricht dem übergeordneten Architekturprinzip, bestehende, produktionserprobte Hyperledger-Komponenten mit minimalen Eingriffen zu erweitern und die Post-Quantum-Kryptografie als modulare, nicht-invasive Sicherheitsschicht zu implementieren. Die resultierende Architektur gewährleistet, dass alle Tails-File-Transfers -- sowohl Upload durch Issuer als auch Download durch Verifier -- über ML-KEM-768-gesicherte TLS-1.3-Verbindungen erfolgen und somit resistent gegen zukünftige Angriffe durch Quantencomputer sind.

\paragraph{SSI-Agenten} \label{SSI-Agenten}

Die Implementierung der Self-Sovereign-Identity-Agenten basiert auf Hyperledger Aries Cloud Agent Python (ACA-Py) \parencite{openwallet-foundation_GitHubOpenwalletfoundationAcapyACAPyfoundationbuildingdecentralizedidentityapplicationsservicesrunningnonmobile_}, der offiziellen Referenzimplementierung des Aries Interop Profile (AIP) 2.0. ACA-Py stellt eine vollständige SSI-Agent-Infrastruktur bereit, die alle erforderlichen Protokolle für DID-basierte Verbindungen, Credential Issuance, Presentation Exchange und Revocation Management implementiert. Die Architektur folgt dem Controller-Pattern, bei dem der Agent als eigenständiger Service agiert und über eine REST-API (Admin API) von externen Controller-Anwendungen gesteuert wird.

In der vorliegenden Iteration-1-Implementierung wurden drei ACA-Py-Agent-Instanzen deployt, die die klassischen SSI-Rollen abbilden: Ein \textit{Issuer Agent}, der Credentials ausstellt; ein \textit{Holder Agent}, der Credentials empfängt und speichert; sowie ein \textit{Verifier Agent}, der Proof-Requests erstellt und Presentations verifiziert \fixme{folgt theorie kapitel XY}. Alle drei Agents verwenden das unmodifizierte ACA-Py-Base-Image (Listing \ref{lst:Dockerfile-acapy-base}) aus dem offiziellen Hyperledger-Repository und werden ausschließlich über Kommandozeilen-Parameter konfiguriert, ohne Änderungen am ACA-Py-Quellcode vorzunehmen.

Listing \ref{lst:docker-compose.yml-SSI-Agenten} zeigt die Docker-Compose-Konfiguration der drei ACA-Py-Agenten innerhalb der Gesamtarchitektur. Die Agent-Konfiguration erfolgt hierbei vollständig deklarativ über Docker-Compose-Service-Definitionen, die jeweils den \texttt{start}-Befehl von ACA-Py mit rollenspezifischen Parametern aufrufen. Zentrale Konfigurationsparameter umfassen \texttt{--label} (zur Identifikation des Agents), \texttt{--inbound-transport http 0.0.0.0 <port>} (zur Definition des DIDComm-Message-Endpoints), \texttt{--outbound-transport http} (für ausgehende Verbindungen), \texttt{--admin 0.0.0.0 <port>} (zur Aktivierung der Admin-API) sowie \texttt{--wallet-type askar} (zur Spezifikation des Wallet-Backends). Alle Agents verwenden Aries Askar als Wallet-Implementierung, das eine moderne, in Rust implementierte Wallet-Architektur mit ChaCha20-Poly1305-Verschlüsselung und Argon2id-Key-Derivation bereitstellt.

Ein kritischer Konfigurationsparameter ist \texttt{--endpoint https://host.docker.internal:<port>}, der spezifiziert, unter welcher URL der Agent für eingehende DIDComm-Verbindungen erreichbar ist. Dieser Parameter wird in Out-of-Band-Invitations und DID-Exchange-Nachrichten eingebettet und muss auf den externen PQC-Proxy-Endpoint zeigen, nicht auf den internen Agent-Container. Beispielsweise konfiguriert der Issuer-Agent \texttt{--endpoint https://host.docker.internal:8020}, wodurch andere Agents ihre DIDComm-Nachrichten an den PQC-Proxy auf Port 8020 senden, der diese nach TLS-Terminierung an den internen Issuer-Container weiterleitet. Diese Indirektion ist essentiell, um sicherzustellen, dass alle Agent-zu-Agent-Verbindungen die Post-Quantum-gesicherte Transport-Layer-Sicherheit nutzen.

Die Wallet-Konfiguration erfolgt über die Parameter \texttt{--wallet-name <name>}, \texttt{--wallet-key <key>} und \texttt{--auto-provision}, wobei letzterer sicherstellt, dass das Wallet automatisch beim ersten Start initialisiert wird. Jedes Wallet wird in einem dedizierten Docker-Volume persistiert (\texttt{issuer-data}, \texttt{holder-data}, \texttt{verifier-data}), sodass DID-Keypairs, Credentials und Connections über Container-Neustarts hinweg erhalten bleiben. Die Wallet-Verschlüsselung mittels ChaCha20-Poly1305 gewährleistet, dass gespeicherte kryptografische Schlüssel selbst bei Kompromittierung des Host-Filesystems nicht ohne den Wallet-Key extrahiert werden können.

Ein wesentlicher Aspekt der Agent-Konfiguration ist die Anbindung an die DLT-Infrastruktur über den Parameter \texttt{--genesis-url https://host.docker.internal:8000/genesis}. Diese URL referenziert den PQC-gesicherten Webserver der DLT-Infrastruktur und ermöglicht es den Agents, beim Start die Genesis-Transaktionsdatei über eine quantensichere TLS-1.3-Verbindung abzurufen. Analog dazu wird die Verbindung zur Revocation Registry über \texttt{--tails-server-base-url https://host.docker.internal:6543} konfiguriert, wobei ebenfalls der PQC Nginx Sidecar Proxy als Endpoint fungiert. Die Verwendung von \texttt{host.docker.internal} ermöglicht dabei die Adressierung des Docker-Hosts aus Container-Perspektive und abstrahiert plattformspezifische Netzwerk-Unterschiede zwischen Linux, macOS und Windows.

Zusätzlich zu den grundlegenden Konfigurations-Parametern aktivieren die Agents mehrere Auto-Response-Features, die für Entwicklungs- und Testzwecke die manuelle Interaktion reduzieren: \texttt{--auto-accept-invites} (automatisches Akzeptieren von Connection-Invitations), \texttt{--auto-respond-credential-proposal}, \texttt{--auto-respond-credential-offer} und \texttt{--auto-respond-credential-request} (automatische Credential-Exchange-Antworten beim Issuer), \texttt{--auto-store-credential} (automatisches Speichern empfangener Credentials beim Holder) sowie \texttt{--auto-verify-presentation} (automatische Presentation-Verifikation beim Verifier). Diese Automatisierungen ermöglichen vollständig scriptgesteuerte SSI-Workflows über die Admin-API, wie sie in Jupyter-Notebook-basierten Demonstrationen implementiert sind.

Für die Post-Quantum-Absicherung der Agent-Kommunikation wurde analog zur DLT-Infrastruktur und Revocation Registry ein dedizierter PQC Nginx Sidecar Proxy pro Agent implementiert. Die Docker-Compose-Konfiguration definiert drei zusätzliche Services -- \texttt{pqc-sidecarproxy-issuer}, \texttt{pqc-sidecarproxy-holder} und \texttt{pqc-sidecarproxy-verifier} --, die jeweils als Reverse Proxy vor dem zugehörigen Agent platziert werden. Jeder Agent-Container exponiert zwei interne HTTP-Ports: einen für Inbound-Transport (8020, 8030, 8040) und einen für die Admin-API (8021, 8031, 8041). Diese Ports sind ausschließlich im agent-spezifischen internen Docker-Netzwerk (\texttt{hope-issuer}, \texttt{hope-holder}, \texttt{hope-verifier}) zugänglich.

Die Sidecar Proxies terminieren alle eingehenden TLS-1.3-Verbindungen und leiten die Anfragen nach erfolgreicher quantensicherer Authentifizierung und Schlüsselvereinbarung als unverschlüsseltes HTTP an die internen Agent-Ports weiter. Jeder Proxy ist mit zwei Docker-Netzwerken verbunden: dem agent-spezifischen internen Netzwerk für Backend-Kommunikation sowie dem gemeinsamen externen \texttt{von\_sidecarproxy}-Netzwerk für Client-Zugriffe. Diese Dual-Network-Architektur erzwingt, dass sämtliche externe Kommunikation -- einschließlich DIDComm-Nachrichten zwischen Agents, Admin-API-Zugriffe durch Controller-Anwendungen sowie Ledger- und Tails-Server-Requests -- über quantensichere TLS-Verbindungen erfolgt.

Die Netzwerk-Architektur folgt einem strikten Isolation-Prinzip: Jeder Agent residiert in einem dedizierten internen Docker-Netzwerk, das ausschließlich den Agent-Container und den zugehörigen PQC-Proxy umfasst. Die Agents können untereinander nicht direkt kommunizieren, sondern ausschließlich über das externe \texttt{von\_sidecarproxy}-Netzwerk, das die PQC-Proxies verbindet. Diese Segmentierung erzeugt eine Defense-in-Depth-Architektur, bei der selbst bei einer Kompromittierung eines Agent-Containers der Zugriff auf andere Agents durch Netzwerk-Isolation verhindert wird.

Die Health-Check-Konfiguration der Agent-Container überwacht die Verfügbarkeit der Admin-API mittels periodischer HTTP-Requests an \texttt{http://localhost:<admin-port>/status/ready}. Zusätzlich definieren die Service-Dependencies (\texttt{depends\_on}) eine Startup-Reihenfolge, die sicherstellt, dass die PQC-Proxies vor den Agents starten und dass die Infrastruktur-Services (von-network, Tails-Server) vollständig initialisiert sind, bevor die Agents ihre Genesis-Datei abrufen. Diese Orchestrierung eliminiert Race-Conditions während des Deployment-Prozesses und gewährleistet eine deterministische Startup-Sequenz.

%Zusammenfassend basiert die SSI-Agent-Implementierung auf vollständig unmodifizierten ACA-Py-Komponenten, wobei die Post-Quantum-Kryptografie ausschließlich über externe Nginx-Sidecar-Proxies integriert wird. Diese nicht-invasive Architektur gewährleistet, dass die Agents mit Standard-Aries-Protokollen und -Workflows kompatibel bleiben, während alle externen Kommunikationskanäle durch ML-KEM-768-basierte Schlüsselvereinbarung und ML-DSA-65-Zertifikatsauthentifizierung quantensicher abgesichert sind. Die strikte Netzwerk-Segmentierung und das Sidecar-Pattern etablieren eine klare Separation zwischen kryptografischer Transport-Sicherheit und SSI-Geschäftslogik, was die Grundlage für nachfolgende Iterationen bildet, in denen PQC schrittweise auf die Application-Layer-Ebene erweitert wird.

\paragraph{Docker Orchestrierung der Gesamtarchitektur} \label{Docker Orchestrierung der Gesamtarchitektur}

\fixme{manage scripts im Anhang hinterlegen?}

Die in den vorangegangenen Abschnitten beschriebenen Einzelkomponenten -- Zertifikatsinfrastruktur, PQC-Sidecar-Proxies, DLT-Infrastruktur, Revocation Registry und SSI-Agenten -- werden mittels einer mehrstufigen Docker-Compose-Orchestrierung zu einem funktionsfähigen Gesamtsystem integriert. Der Startprozess der Gesamtarchitektur folgt einer deterministischen Sequenz, die in Listing~\ref{lst:Docker-Compose-Start-der-Gesamtarchitektur} dokumentiert ist und die korrekten Abhängigkeiten zwischen den Infrastrukturschichten gewährleistet.

Die Orchestrierung gliedert sich in drei sequenzielle Phasen, die jeweils durch separate Docker-Compose-Konfigurationen gesteuert werden. In der ersten Phase wird die DLT-Infrastruktur über das \texttt{von-network}-Management-Skript initialisiert, wodurch die vier Indy-Validator-Nodes, der Genesis-Webserver sowie der zugehörige PQC-Sidecar-Proxy gestartet werden. Diese Phase erzeugt das gemeinsame externe Docker-Netzwerk \texttt{von\_sidecarproxy}, das als zentrale Kommunikationsschicht für alle quantensicheren Verbindungen dient. Die zweite Phase umfasst die Initialisierung der Revocation Registry mittels des \texttt{indy-tails-server}-Management-Skripts, wodurch der Tails-Server-Container sowie dessen PQC-Proxy-Frontend bereitgestellt werden. In der dritten Phase werden schließlich die SSI-Agenten -- Issuer, Holder und Verifier -- gemeinsam mit ihren jeweiligen PQC-Sidecar-Proxies über die projektspezifische Docker-Compose-Konfiguration gestartet.

\refstepcounter{manualListingCounter}
\label{lst:Docker-Compose-Start-der-Gesamtarchitektur}
\begin{lstlisting}[language=bash, caption={Listing \arabic{lstlisting}: Docker Compose Start der Gesamtarchitektur}, numbers=left, frame=single]
(.venv) ferris@blockchain-ssi-pqc:~/github/MSc-blockchain-ssi-pqc$ ./von-network/manage start && ./indy-tails-server/docker/manage start && docker compose -f ./hopE/docker-compose.yml up -d
[+] Running 15/15
Network von_von                                 Created     0.0s 
Network von_sidecarproxy                        Created     0.0s 
Volume "von_webserver-ledger"                   Created     0.0s 
Volume "von_node1-data"                         Created     0.0s 
Volume "von_node3-data"                         Created     0.0s 
Volume "von_node2-data"                         Created     0.0s 
Volume "von_node4-data"                         Created     0.0s 
Volume "von_nginx-logs"                         Created     0.0s 
Volume "von_webserver-cli"                      Created     0.0s 
Container von-node4                             Started     0.6s 
Container von-webserver                         Started     0.4s 
Container von-node3                             Started     0.4s 
Container von-node2                             Started     0.5s 
Container von-node1                             Started     0.5s 
Container von-pqc-sidecarproxy-webserver        Started     0.6s 
Want to see the scrolling container logs? Run "./manage logs"
[+] Running 4/4
Network docker_tails-server                     Created     0.0s 
Volume "docker_nginx-logs"                      Created     0.0s 
Container docker-tails-server-1                 Started     0.3s 
Container pqc-sidecarproxy-tails-server         Started     0.5s 
Run './manage logs' for logs
WARN[0000] /home/ferris/github/MSc-blockchain-ssi-pqc/hopE/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion 
[+] Running 13/13
Network hope_hope-issuer                        Created     0.0s 
Network hope_hope-holder                        Created     0.0s 
Network hope_hope-verifier                      Created     0.0s 
Volume "hope_issuer-data"                       Created     0.0s 
Volume "hope_holder-data"                       Created     0.0s 
Volume "hope_verifier-data"                     Created     0.0s 
Volume "hope_nginx-logs"                        Created     0.0s 
Container issuer-agent                          Started     0.6s 
Container holder-agent                          Started     0.5s 
Container verifier-agent                        Started     0.5s 
Container pqc-sidecarproxy-holder               Started     1.3s 
Container pqc-sidecarproxy-issuer               Started     1.0s 
Container pqc-sidecarproxy-verifier             Started     1.2s
\end{lstlisting}


Die in \autoref{fig:Docker-Compose-Übersicht-Iteration-1} visualisierte Containerarchitektur verdeutlicht die resultierende Systemtopologie. Die Gesamtarchitektur umfasst insgesamt 14 Container, die sich auf die drei funktionalen Schichten verteilen: Die DLT-Schicht besteht aus sechs Containern -- vier Validator-Nodes, einem Webserver und einem PQC-Proxy. Die Revocation-Schicht umfasst zwei Container für den Tails-Server und dessen PQC-Proxy. Die Agent-Schicht besteht aus sechs Containern für die drei SSI-Agenten und ihre jeweiligen PQC-Proxies.

% Die Netzwerksegmentierung folgt einem strikten Isolation-Prinzip. Jede funktionale Einheit -- DLT-Infrastruktur, Revocation Registry sowie jeder einzelne SSI-Agent -- residiert in einem dedizierten internen Docker-Netzwerk, das ausschließlich den jeweiligen Service-Container und den zugehörigen PQC-Proxy umfasst. Die einzige Verbindung zwischen diesen isolierten Netzwerken erfolgt über das externe \texttt{von\_sidecarproxy}-Netzwerk, an das alle PQC-Proxies angebunden sind. Diese Architektur erzwingt, dass sämtliche inter-service Kommunikation -- einschließlich DIDComm-Nachrichten zwischen Agenten, Admin-API-Zugriffe, Genesis-File-Abrufe und Tails-Server-Requests -- ausschließlich über die quantensicheren TLS-1.3-Verbindungen mit ML-KEM-768-Schlüsselvereinbarung und ML-DSA-65-Zertifikatsauthentifizierung erfolgt.

Die \texttt{depends\_on}-Direktiven in den Docker-Compose-Konfigurationen definieren explizite Startup-Abhängigkeiten, die Race-Conditions während des Deployment-Prozesses eliminieren. Die PQC-Proxies werden vor den ihnen zugeordneten Backend-Services gestartet, und die SSI-Agenten warten auf die vollständige Initialisierung der Infrastruktur-Services, bevor sie ihre Genesis-Transaktionsdatei abrufen. Diese Orchestrierung gewährleistet eine deterministische Startup-Sequenz und stellt sicher, dass alle Komponenten beim Erreichen ihres operativen Zustands auf vollständig verfügbare Abhängigkeiten zugreifen können.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{docker_compose_übersicht.png}
    \caption{Docker-Compose-Übersicht der Iteration 1 Architektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Docker-Compose-Übersicht-Iteration-1}
\end{figure}

\subsubsection{Formative Evaluation}

Die formative Evaluation dieser Iteration orientiert sich an der \textit{Technical Risk \& Efficacy Strategy} des FEDS-Frameworks nach \textcite[S. 4--5]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} und erfolgt unter einem künstlichen Evaluationsparadigma in der Laborumgebung. Ziel ist die Validierung der technischen Funktionsfähigkeit der implementierten Komponenten als Voraussetzung für die nachfolgende Iteration, nicht jedoch die vollständige Prüfung gegen die in Kapitel~\ref{sec:Anforderungsanalyse} definierten Anforderungen -- diese erfolgt im Rahmen der summativen Evaluation in Kapitel~\ref{sec:Summative Evaluation}.

Für die formative Evaluation während der ersten Iteration war die Bereitstellung eines PQC-fähigen Browsers zwingend erforderlich, da aktuelle Produktivbrowser keine Post-Quanten-Kryptographie in ihren TLS-Implementierungen unterstützen. Diese Limitation führt bei Verbindungsversuchen zu PQC-fähigen Servern zu einem Cipher-Mismatch, wie in \autoref{fig:Cipher-Mismatch-Blockchain-Webserver} veranschaulicht. Um diese Inkompatibilität zu überwinden, wurde ein Chromium-basierter Browser mit integrierter PQC-Unterstützung kompiliert (\ref{Eigenkompilation eines Chromium-Browsers mit PQC-Unterstützung}). Dieser selbstkompilierte Browser ermöglicht die Durchführung von TLS-Handshakes mit hybriden und rein PQ-basierten Algorithmen und dient als fundamentale Testplattform für die experimentelle Analyse von PQC-Verfahren im Kontext realer Webanwendungen.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_blockchain_webserver_CIPHER_MISMATCH.png}
    \caption{Cipher Mismatch bei Validierung der TLS-1.3-Verbindung des Blockchain-Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Cipher-Mismatch-Blockchain-Webserver}
\end{figure}

\paragraph{Validierung der Zertifikatskette und ML-DSA-Signaturen}

Zur Verifikation der kryptographischen Integrität der implementierten Public-Key-Infrastruktur wurde die Zertifikatskette der Sidecar-Proxies mittels \texttt{openssl}-Diagnosewerkzeugen analysiert. Ziel war der Nachweis, dass die ausgelieferten X.509-Zertifikate korrekt auf den spezifizierten Post-Quanten-Signaturalgorithmen basieren. Die Inspektion des vom Issuer-Agenten-Proxy bereitgestellten Zertifikats (\autoref{fig:Successful-Validation-Issuer-MLDSA-Cert}) bestätigt, dass der öffentliche Schlüssel des Leaf-Zertifikats (\textit{pqc reverseproxy issuer agent}) den Algorithmus \texttt{ML-DSA-65} verwendet. Des Weiteren belegt der Signaturalgorithmus \texttt{ML-DSA-87}, dass die Zertifikatskette valide durch die \textit{Master Thesis PQC Root CA} signiert wurde, was die erfolgreiche Generierung und Einbindung der Dilithium-basierten Zertifikate in den TLS-Handshake beweist.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_issuer_mldsa_cert.png}
    \caption{Erfolgreiche Validierung des ML-DSA-Zertifikats des Issuer-Agenten}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-MLDSA-Cert}
\end{figure}

\paragraph{Validierung der TLS 1.3 Algorithmen-Aushandlung}

Die erfolgreiche Integration der PQC-Algorithmen in das Transportprotokoll wurde durch einen Verbindungsaufbau mittels \texttt{openssl s\_client} verifiziert. Wie in \autoref{fig:Successful-Validation-Issuer-TLS1.3} dargestellt, konnte erfolgreich eine TLS-1.3-Sitzung etabliert werden. Die Analyse der Handshake-Parameter bestätigt die Verwendung der hybrid-post-quanten Schlüsselaustauschgruppe \texttt{X25519MLKEM768}, welche den klassischen elliptischen Kurvenalgorithmus X25519 mit dem KEM-Verfahren ML-KEM-768 kombiniert. Zudem wird für die Authentifizierung des Peer-Zertifikats der Signaturalgorithmus \texttt{mldsa65} (Dilithium) ausgewiesen. Diese Ergebnisse validieren die korrekte Konfiguration der OQS-Provider-Bibliothek innerhalb der Proxy-Komponenten und belegen die praktische Funktionsfähigkeit des hybriden Schlüsselaustauschs im Zusammenspiel mit PQC-Signaturen.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_issuer_TLS1.3.png}
    \caption{Erfolgreiche Validierung der TLS-1.3-Verbindung des Issuer-Agenten}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-TLS1.3}
\end{figure}

\paragraph{Validierung der Ledger-Initialisierung}

Die operative Funktionsfähigkeit des Hyperledger Indy Netzwerks wurde primär über das Web-Interface des Blockchain-Servers validiert. Wie in \autoref{fig:Successful-Validation-Blockchain-Webserver} dargestellt, zeigen die Statusindikatoren aller vier Validator-Nodes eine aktive Beteiligung am Konsensus-Protokoll (Status \textit{Node1--4}), womit der Distributed Ledger erfolgreich initialisiert ist. Simultan belegt diese Abbildung die korrekte PQC-Absicherung der Webserver-Komponente: Der Zugriff erfolgt über den eigens kompilierten PQC-Chromium-Browser, dessen Security-Panel explizit eine authentifizierte TLS-1.3-Verbindung unter Verwendung der hybriden Schlüsselaustauschgruppe \texttt{X25519MLKEM768} ausweist.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_blockchain_webserver.png}
    \caption{Erfolgreiche Validierung der TLS-1.3-Verbindung des Blockchain-Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Blockchain-Webserver}
\end{figure}

Als zweite notwendige Bedingung für die spätere Anbindung der SSI-Agenten (ACA-Py) wurde die Verfügbarkeit der Genesis-Datei verifiziert. \autoref{fig:Successful-Validation-Genesis-File-Blockchain-Webserver} dokumentiert den Abruf des \texttt{/genesis}-Endpunkts mittels \texttt{curl}. Die erfolgreiche Rückgabe der JSON-formatierten Genesis-Transaktionen bestätigt, dass die für das Bootstrapping externer Clients erforderlichen Netzwerkinformationen korrekt publiziert werden.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_genesis.png}
    \caption{Erfolgreiche Validierung der Genesis-Datei des Blockchain-Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Genesis-File-Blockchain-Webserver}
\end{figure}

\paragraph{Validierung der ACA-Py API-Verfügbarkeit}

Die funktionale Erreichbarkeit der SSI-Agenten wurde durch eine systematische Analyse der Initialisierungsphase und der anschließenden API-Verfügbarkeit validiert. Die Logging-Ausgabe des Issuer-Agenten (Listing~\ref{lst:Issuer-Agent-Boot-Logs}) dokumentiert die erfolgreiche Genesis-Datei-Abrufung über \texttt{https://host.docker.internal:8000/genesis} (Zeile 3) und die vollständige Ledger-Konfiguration (Zeile 8). Die Erstellung eines neuen Wallet-Profils mit Askar-Backend (Zeile 5) und die erfolgreiche Initialisierung der Inbound- und Outbound-Transports (Zeile 10--26) demonstrieren die korrekte Konfiguration des ACA-Py-Agents. Die durchgeführten Health-Checks über den \texttt{/status/ready}-Endpunkt (Zeile 51--52) bestätigen die vollständige Initialisierung und Bereitschaft des Agenten.

Die Visualisierung der Swagger-basierten Admin-Oberfläche (\autoref{fig:Successful-Validation-Issuer-Agent-ACA-Py-Swagger-API}) ergänzt diese technischen Log-Daten durch den Nachweis, dass die Admin-API über den PQC-Reverse-Proxy fehlerfrei erreichbar ist und alle administrativen Endpunkte zur Steuerung der Agenten-Komponente bereitstellt. Die Tatsache, dass die Swagger-Oberfläche unter dem PQC-gesicherten HTTPS-Endpoint vollständig funktionsfähig ist, belegt die korrekte TLS-Terminierung am Proxy sowie die fehlerfreie Weiterleitung der HTTP-Anfragen an den ACA-Py-Container.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_Issuer_Agent_Swagger_API.png}
    \caption{Erfolgreiche Validierung der Issuer Agent ACA-Py Swagger Admin API}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-Agent-ACA-Py-Swagger-API}
\end{figure}

\paragraph{Validierung der Netzwerkisolation}

Die integrale Sicherheitseigenschaft der Netzwerksegmentierung wurde durch eine Inspektion der Docker-Netzwerktopologie und systematische Erreichbarkeitstests validiert. Die Architektur implementiert ein striktes Micro-Segmentation-Konzept, bei dem jeder SSI-Akteur in einem dedizierten, isolierten Subnetz operiert. \autoref{fig:Darstellung-Network-Isolation} belegt diese Topologie anhand des \texttt{docker network inspect}-Outputs: Der Issuer-Agent befindet sich exklusiv im Netzwerksegment \texttt{hope\_hope-issuer}, während der Holder-Agent im Segment \texttt{hope\_hope-holder} isoliert ist. In jedem dieser Segmente fungiert der zugehörige PQC-Sidecar-Proxy als einziger Ingress-Punkt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_network_isolation.png}
    \caption{Darstellung der Netzwerkisolation innerhalb der Gesamtarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Darstellung-Network-Isolation}
\end{figure}

\autoref{fig:Successful-Validation-Network-Isolation-Through-Tests} demonstriert die Wirksamkeit dieser Isolation auf zwei Ebenen. Erstens zeigt die Prozessliste (\texttt{docker ps}), dass lediglich die Sidecar-Proxies externe Ports (z.\,B. 8020, 8030, 8040) an das Host-System binden, während die Ports der ACA-Py-Container (z.\,B. \texttt{issuer-agent}) nicht exponiert sind. Zweitens beweisen die Inter-Container-Verbindungstests die logische Trennung: Ein direkter Zugriffsversuch aus dem \texttt{issuer-agent}-Container auf den \texttt{holder-agent} schlägt mit einem DNS-Auflösungsfehler (\textit{Could not resolve host}) fehl, da keine Routing-Route zwischen den isolierten Netzwerkbrücken existiert. Im Gegensatz dazu ist der lokale Zugriff des \texttt{pqc-sidecarproxy-holder} auf seinen zugehörigen Agenten erfolgreich möglich. Diese Konfiguration erzwingt, dass jegliche Kommunikation zwischen den Akteuren das Host-Netzwerk passieren muss, wo sie durch die in den Proxies terminierte Post-Quanten-Kryptographie (TLS 1.3 mit ML-KEM) abgesichert wird.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_network_isolation_through_tests.png}
    \caption{Erfolgreiche Validierung der Netzwerkisolation innerhalb der Gesamtarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Network-Isolation-Through-Tests}
\end{figure}

\subsubsection{Erkenntnisse und Anpassungsbedarfe}

Die erste Iteration bildet das fundamentale technologische Fundament der Forschungsarbeit. Die formative Evaluation (Kapitel \ref{sec:Formative-Evaluation-I1}) validierte die operative Integrität der entwickelten Architektur: Die verteilten Micro-Services, der Hyperledger Indy Ledger und die PQC-Sidecar-Proxies interagieren funktional korrekt. Diese Initialphase generierte jedoch spezifische Erkenntnisse, die eine gezielte Weiterentwicklung in der zweiten Iteration motivieren. Diese werden nachfolgend in Bezug auf die Designziele und die Funktionsmerkmale (FF) analysiert.

\paragraph{Abgleich mit den Designzielen der Iteration 1}

Das primäre Designziel, die Absicherung der Transportebene in einem SSI-Ökosystem mittels Post-Quanten-Kryptographie, wurde vollständig erreicht. Die erfolgreiche Validierung des Sidecar-Musters belegt die Machbarkeit einer transparenten PQC-Migration für Legacy-Systeme (ACA-Py, Indy Node) ohne Eingriffe in deren Kerncode. Die implementierte Micro-Segmentation erfüllt zudem die architektonischen Anforderungen an Netzwerkisolation und Angriffsflächenminimierung in KRITIS-Umgebungen.

\paragraph{FF1: Funktionale SSI-Kernprozesse \& Systemarchitektur}

Die implementierte Sidecar-Proxy-Architektur erwies sich als effektives Design-Pattern zur Realisierung einer \emph{Separation of Concerns} im KRITIS-Kontext. Durch die strikte Entkopplung der kryptographischen Terminierung (Proxy) von der Business-Logik (SSI-Agent) konnte eine PQC-Integration realisiert werden, die die Kernprozesse der Identitätsverwaltung funktional nicht beeinträchtigt. Diese architektonische Entscheidung ermöglicht es, sicherheitskritische Updates an der Krypto-Komponente vorzunehmen, ohne die Integrität der komplexen SSI-Logik zu gefährden.

\paragraph{FF2: Sicherheit, Compliance \& Algorithmenwahl}

Die Implementierung von ML-KEM-768 und ML-DSA-65 bestätigte die technische Reife dieser Algorithmen für den produktiven Einsatz. Die durchgeführten Tests validierten die Interoperabilität von hybriden Zertifikatsketten. Eine zentrale Erkenntnis ist jedoch, dass Sicherheit im KRITIS-Kontext über die Transportebene hinausgehen muss. Die aktuelle Transportverschlüsselung schützt zwar Daten "in Transit", bietet aber keine Ende-zu-Ende-Integrität auf Anwendungsebene (z.B. für VCs im Ruhezustand). Eine Erweiterung des Sicherheitsmodells auf die Applikationsschicht ist daher für Defense-in-Depth unerlässlich.

\paragraph{FF3: Kryptografische Agilität}

Entgegen der Annahme, dass statische Proxy-Konfigurationen starr sind, offenbarten die Tests, dass die gewählte Container-Architektur in Kombination mit TLS 1.3 ein hohes Maß an \textit{operativer Krypto-Agilität} bietet.
Erstens ermöglicht die Containerisierung (Docker) den Austausch kryptografischer Bibliotheken durch einfache Image-Updates. Ein Algorithmenwechsel erfordert lediglich den Austausch des Proxy-Containers ("Rolling Update"), ohne dass der SSI-Agent (Business-Logik) gestoppt oder rekompiliert werden muss \textcite{docker2017rolling}. Dies realisiert eine Agilität auf Infrastrukturebene.
Zweitens erlaubt das TLS 1.3-Protokoll eine dynamische Aushandlung (Negotiation) der Cipher Suites \textcite{keyfactor2023tls}. Die Sidecar-Proxies können so konfiguriert werden, dass sie mehrere PQC-Algorithmen parallel unterstützen und je nach Client-Fähigkeit den stärksten gemeinsamen Standard wählen. Dies stellt eine Protokoll-basierte Agilität dar.
Drittens begünstigt die Micro-Segmentation granulare Migrationspfade: Einzelne Netzwerksegmente (z.B. nur der Issuer) können isoliert auf neuere Algorithmen umgestellt werden, ohne das Gesamtsystem zu gefährden \textcite{colortokens2025microsegmentation}.

\paragraph{Design-Refinement für Iteration 2}

Basierend auf diesen Erkenntnissen wird das Design für Iteration 2 gezielt erweitert, um PQC zusätzlich auf der Applikationsebene zu verankern:

\begin{itemize}
\item \textbf{Application-Layer-PQC:} Integration der \emph{liboqs} direkt in die SSI-Agenten. Dies ermöglicht PQC-Signaturen für VCs und DIDComm-Nachrichten, wodurch eine Ende-zu-Ende-Integrität unabhängig vom Transportkanal gewährleistet wird (Adressierung FF2).
\item \textbf{Hybride Sicherheitsarchitektur:} Beibehaltung der Sidecar-Proxies als erste Verteidigungslinie (Transport Security) bei gleichzeitiger Härtung der Datenobjekte selbst (Application Security). Dies schafft Redundanz und Tiefenverteidigung.
\end{itemize}

\subsection{Iteration 2: Application-Layer PQC-Integration}

\subsubsection{Designziele dieser Iteration}
%   ALLE FF, mit SCHWERPUNKT auf FF2 (PQC), FF3 (Performance) \\
%   → FF1 (Architektur): Blockchain-Integration finalisieren \\
%   → FF1 (Architektur): Compliance-Layer finalisieren (BSI, DSGVO) \
%   → FF2 (Algorithmen): Vollständige PQC-Suite (ML-DSA, ML-KEM) \\
%   → FF2 (Algorithmen): Hybride Schemata implementieren \
%   → FF3 (Kryptoagilität): Plugin-System für Algorithmen implementieren
%   → FF3 (Kryptoagilität): Key-Rotation-Mechanismus validieren

Die zweite Iteration der Artefaktentwicklung baut auf der in Iteration 1 erfolgreich validierten Basisarchitektur auf und korrespondiert erneut mit der DSRM-Phase 2 \textit{Objectives} nach \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}. Der Fokus dieser Iteration liegt auf der Erweiterung des Prototyps um eine tiefgreifende PQC-Integration auf der Anwendungsebene (Application Layer). Im Kontext des Drei-Zyklen-Modells nach \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007} wird der Design Cycle intensiviert, um die kryptografische Sicherheit von der reinen Transportsicherung (TLS) auf die tatsächlichen Nutzdaten (Verifiable Credentials und DID-Dokumente) auszuweiten und somit eine Ende-zu-Ende-Sicherheit zu gewährleisten.

Die Designziele dieser Iteration leiten sich konsistent aus den in Kapitel~\ref{sec:Zielsetzung und Forschungsfragen} definierten Forschungsfragen ab, wobei eine inhaltliche Vertiefung der technischen Anforderungen erfolgt:

Bezüglich \textbf{FF1 (Systemarchitektur \& Compliance)} wird das Ziel verfolgt, die SSI-Kernprozesse - insbesondere Issuance und Verification - so zu modifizieren, dass sie quantenresistente Signaturen und Schlüsselformate nativ unterstützen. Das Design muss sicherstellen, dass die Unveränderlichkeit und Authentizität von Identitätsnachweisen unabhängig vom Transportkanal auch langfristig gegenüber Quantencomputer-Angriffen gewährleistet bleibt, was eine zentrale Anforderung für den Einsatz in KRITIS-Umgebungen darstellt.

Hinsichtlich \textbf{FF2 (Algorithmenauswahl \& Sicherheitsbewertung)} liegt der Fokus auf der Integration und Evaluierung des NIST-standardisierten Signaturalgorithmus ML-DSA (Dilithium) innerhalb der Credential-Strukturen. Das Designziel besteht darin, die praktische Machbarkeit von PQC-Signaturen in Verifiable Credentials (VCs) und Decentralized Identifiers (DIDs) nachzuweisen.

Für \textbf{FF3 (Kryptografische Agilität)} zielt diese Iteration auf die Implementierung von Agilitätsmechanismen direkt in den Datenstrukturen ab. Das System soll so gestaltet werden, dass es hybride Szenarien unterstützt und eine Koexistenz sowie den nahtlosen Wechsel zwischen klassischen (z.\,B. Ed25519) und post-quanten Kryptografieverfahren innerhalb der DID-Methoden und Credential-Definitionen ermöglicht, ohne die Interoperabilität grundlegend zu gefährden.

\subsubsection{Architekturentwurf}
%   - Application-Layer-PQC-Integration (liboqs in ACA-Py) \\
%   - Kryptoagiles Design (Plugin-Architektur) \\

\paragraph{Gesamtarchitektur}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Gesamtarchitektur_Iteration2.png}
    \caption{Gesamtarchitekturentwurf Iteration 2}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Gesamtarchitektur_Iteration2}
\end{figure}

\paragraph{ACA-Py Applikationsarchitektur}

\fixme{Überflüssig?}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{ACAPY Application Architecture_Iteration 2.png}
    \caption{ACA-Py High Level Applikationsarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:ACAPY_Application_Architecture_Iteration2}
\end{figure}

Die Architektur von Hyperledger Aries Cloud Agent Python (ACA-Py) folgt einem fünfschichtigen Design mit klarer Verantwortlichkeitstrennung.

\textit{Layer 1} bildet eine zustandslose HTTP-REST-API (Admin API), die es Controller-Anwendungen ermöglicht, den Agent über standardisierte Endpoints wie \texttt{/out-of-band/create-invitation}, \texttt{/issue-credential-2.0/send} oder \texttt{/present-proof-2.0/send-request} zu steuern, ohne direkt mit der Python-Codebasis zu interagieren.

\textit{Layer 2} implementiert die SSI-Geschäftslogik als Protocol Handler, die Aries RFCs (Request for Comments) in Form zustandsbasierter State Machines umsetzen: Das Out-of-Band Protocol (RFC 0434) generiert Invitation-Nachrichten mit \texttt{did:peer:4}-DIDs, das DID Exchange Protocol (RFC 0023) authentifiziert Agent-Verbindungen mittels ED25519-Signaturen, das Issue Credential Protocol (RFC 0453) erstellt AnonCreds-CL-signierte Credentials, und das Present Proof Protocol (RFC 0454) orchestriert Zero-Knowledge-Proof-basierte Presentations.

\textit{Layer 3} abstrahiert die Schlüsselverwaltung durch das Aries-Askar-Wallet, das ED25519-Schlüsselpaare (32 Bytes, für Signaturen) und X25519-Schlüsselpaare (32 Bytes, für Key Agreement) generiert, diese mit Multicodec-Präfixen (\texttt{0xed}, \texttt{0xec}) kodiert und verschlüsselt in einer SQLite-Datenbank ablegt, wobei ChaCha20-Poly1305-Authenticated-Encryption nach Argon2id-basierter Schlüsselableitung verwendet wird.

\textit{Layer 4} realisiert DIDComm-Messaging über \texttt{pack\_message()} und \texttt{unpack\_message()}: Nachrichten werden mittels X25519-ECDH-Key-Agreement, HKDF-SHA256-Schlüsselableitung und XChaCha20-Poly1305-Verschlüsselung in JWE-Strukturen transformiert, die Vertraulichkeit und Integrität zwischen Agents gewährleisten.

\textit{Layer 5} implementiert HTTP- und WebSocket-basierte Transport-Mechanismen für Inbound- (\texttt{--inbound-transport http 0.0.0.0 8020}) und Outbound-Kommunikation, wobei in der klassischen Architektur kein quantensicheres TLS verwendet wird. Die gesamte kryptografische Basis -- ED25519 für DID-Authentifizierung, X25519 für DIDComm-Encryption und AnonCreds-CL-Signaturen für Credentials -- ist nicht quantenresistent, da elliptische Kurven durch Shor's Algorithmus auf Quantencomputern kompromittiert werden können, was die Notwendigkeit einer systematischen Post-Quantum-Kryptografie-Integration begründet.


\paragraph{ACA-Py Applikationsarchitektur mit PQC-Integration}

Die Integration von Post-Quantum-Kryptografie in Hyperledger Aries Cloud Agent Python erfolgt über eine plugin-basierte Architektur, die sechs zentrale Design-Prinzipien verfolgt: Transparenz, Erweiterbarkeit, Interoperabilität, Defense-in-Depth, Standards-Konformität und Separierung von Belangen.
Abbildung~\ref{fig:ACAPY_Application_Architecture_Iteration2_PQC} visualisiert die erweiterte Architektur und hebt die Unterschiede zur klassischen Implementierung hervor.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{ACA-Py Applikationsarchitektur mit PQC-Integration.png}
    \caption{ACA-Py High Level Applikationsarchitektur mit PQC-Integration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:ACAPY_Application_Architecture_Iteration2_PQC}
\end{figure}

Das fundamentale Design-Prinzip der \textit{Transparenz} manifestiert sich in der vollständigen Beibehaltung der Controller-Application-Schnittstelle und der ACA-Py Admin API. Beide Schichten bleiben unverändert, wodurch bestehende Controller-Anwendungen -- beispielsweise Web-Applikationen, Jupyter-Notebooks oder CLI-Tools -- ohne Modifikationen weiterhin funktionieren. Die HTTP-REST-API exponiert identische Endpoints (\texttt{/out-of-band/create-invitation}, \texttt{/issue-credential-2.0/send}, etc.) mit strukturell unveränderten Request- und Response-Schemata. Diese Architekturentscheidung eliminiert Breaking Changes und ermöglicht eine schrittweise Migration: Controller-Code bleibt kompatibel, während die kryptografischen Primitive unterhalb der API-Ebene ausgetauscht werden. Das Diagramm markiert diese Schichten explizit mit \texttt{NO CHANGE}, um die Nicht-Invasivität der PQC-Integration zu verdeutlichen.

Die \textit{Erweiterbarkeit} der Architektur wird durch das Key-Type-Registry-Pattern gewährleistet. Das PQC-Plugin erweitert die Wallet-Schnittstelle um neue Schlüsseltypen (ML-DSA-65 für digitale Signaturen, ML-KEM-768 für Key Encapsulation), ohne die bestehende Registry zu modifizieren. Diese Erweiterung erfolgt zur Laufzeit durch Registrierung zusätzlicher \texttt{KeyType}-Objekte, die Multicodec-Präfixe (\texttt{0xd065} für ML-DSA-65, \texttt{0xe018} für ML-KEM-768), Multicodec-Namen und JWS-Algorithmus-Identifier definieren. Die Architektur nutzt pluggable Crypto Backends: Das PQC-Plugin bindet \texttt{liboqs-python} als kryptografische Engine ein, während klassische Operationen weiterhin über \texttt{libsodium} abgewickelt werden. Dieses Backend-Abstraktionsmodell erlaubt die Integration zukünftiger Post-Quantum-Algorithmen -- beispielsweise SLH-DSA (NIST FIPS-205) oder zukünftige NIST-Standardisierungsrunden -- durch Addition weiterer Backend-Module ohne Änderungen an der Core-Architektur.

Das Design gewährleistet \textit{Interoperabilität} durch explizite Fallback-Mechanismen zu klassischen Algorithmen. Die Wallet-Operation-Wrapper im Plugin implementieren Key-Type-Erkennung: Wenn eine Operation einen klassischen Schlüssel (ED25519, X25519) detektiert, delegiert sie an die ursprüngliche Implementierung; bei PQC-Schlüsseln erfolgt die Delegation an die \texttt{liboqs}-Integration. Diese Dual-Mode-Architektur ermöglicht hybride Deployments, in denen Agents sowohl mit PQC-fähigen als auch mit Legacy-Agents kommunizieren können. Zusätzlich unterstützt das Design explizit Hybrid-Kryptografie (X25519MLKEM768), bei der klassische und quantensichere Algorithmen kombiniert werden, um Crop-and-Paste-Resistenz gemäß BSI-Richtlinien zu erreichen. Die strukturelle JWE-Kompatibilität bleibt erhalten: DIDComm-Nachrichten verwenden weiterhin die JSON-Web-Encryption-Struktur mit \texttt{protected}, \texttt{recipients}, \texttt{iv}, \texttt{ciphertext} und \texttt{tag}-Feldern, wobei lediglich das \texttt{encrypted\_key}-Feld größere Ciphertexte aufnimmt (1088 Bytes für ML-KEM-768 statt circa 32 Bytes für X25519-ECDH) und der \texttt{alg}-Header den verwendeten Algorithmus spezifiziert.

Das Prinzip \textit{Defense-in-Depth} wird durch zweischichtige Quantenresistenz realisiert. Auf Transport-Layer-Ebene (Iteration 1, bereits implementiert) terminieren Nginx-Reverse-Proxies TLS-1.3-Verbindungen mit ML-KEM-768-Schlüsselaustausch und ML-DSA-65-Zertifikaten, wodurch alle HTTP-basierten Kommunikationskanäle quantensicher werden. Auf Application-Layer-Ebene (Iteration 2, Plugin-Integration) verschlüsselt das DIDComm-Messaging-Protokoll Nachrichten mittels ML-KEM-768-basierter Key Encapsulation, unabhängig vom zugrundeliegenden Transport-Protokoll. Diese doppelte Absicherung gewährleistet, dass selbst bei Kompromittierung der Transport-Layer-Infrastruktur (z.\,B.\ Proxy-Penetration) die End-to-End-verschlüsselten DIDComm-Nachrichten quantenresistent bleiben. Das Architekturdiagramm visualisiert diese Schichtung durch separate Markierungen für \texttt{Iteration 2: PQC within DIDComm} (Transport Layer) und die PQC-spezifischen Wallet-Operationen (\texttt{PQC Pack/Unpack}).

Die \textit{Standards-Konformität} manifestiert sich in der strukturellen Beibehaltung aller Aries RFCs. Das Out-of-Band Protocol (RFC 0434), DID Exchange Protocol (RFC 0023), Issue Credential Protocol (RFC 0453) und Present Proof Protocol (RFC 0454) bleiben als Python-Module unverändert; lediglich die von ihnen aufgerufenen Wallet-Operationen werden durch das Plugin abgefangen und an PQC-Implementierungen delegiert. Diese Interception-Architektur (im Diagramm als \texttt{PQC-Interception} und \texttt{Delegation to PQC-Plugin} markiert) gewährleistet, dass die State-Machine-Logik der Protokoll-Handler intakt bleibt. Die Multicodec-Spezifikation für ML-DSA-65 und ML-KEM-768 ist derzeit provisorisch (W3C-Standardisierung ausstehend), jedoch strukturell kompatibel mit dem bestehenden Multicodec-Framework. Die DIDComm-v1-JWE-Kompatibilität bleibt vollständig erhalten, sodass Messages zwischen PQC-fähigen und klassischen Agents ausgetauscht werden können, sofern beide Seiten die entsprechenden Algorithmen unterstützen.

Das Prinzip der \textit{Separierung von Belangen} reflektiert die schrittweise Migrationsstrategie. AnonCreds-Credentials verwenden weiterhin CL-Signaturen (Camenisch-Lysyanskaya), da der AnonCreds-Standard keine Post-Quantum-Signaturen spezifiziert und eine Änderung Inkompatibilität mit bestehenden Indy-Ledger-Deployments erzeugen würde. Diese Entscheidung isoliert die PQC-Integration auf die DID-Ebene (did:peer:4-Generierung mit ML-DSA-65/ML-KEM-768) und die Transport-Ebene (TLS 1.3 und DIDComm), während die Credential-Signatur-Ebene klassisch bleibt. Zukünftige Migrationen könnten W3C Verifiable Credentials mit PQC-Signaturen nutzen, ohne die bestehende AnonCreds-Infrastruktur zu beeinflussen. Diese Architektur vermeidet einen Big-Bang-Ansatz, bei dem alle kryptografischen Schichten simultan migriert werden müssten, zugunsten einer inkrementellen, risikominimierten Transition.

Die zentrale architektonische Innovation ist das \texttt{PQC Plugin}-Modul, das als Vermittlungsschicht zwischen Protocol Handlers, Wallet Interface und den kryptografischen Backends fungiert. Das Plugin umfasst vier Kernkomponenten: Den \texttt{liboqs Integration Layer}, der Python-Bindings zu den NIST-standardisierten Algorithmen bereitstellt; den \texttt{PQC did:peer:4 Generator}, der Dual-Key-DIDs (Signing Key: ML-DSA-65, Agreement Key: ML-KEM-768) mit korrekter Multicodec-Kodierung erzeugt; die \texttt{Protocol Interceptors}, die Aufrufe von Protocol Handlers abfangen und an PQC-Implementierungen delegieren; sowie die \texttt{Wallet Operation Wrappers}, die \texttt{create\_key()}, \texttt{sign\_message()}, \texttt{verify\_message()}, \texttt{pack\_message()} und \texttt{unpack\_message()} durch PQC-Varianten erweitern. Diese Komponenten werden beim Agent-Start durch die Plugin-Setup-Funktion registriert und installiert, wodurch die Interception-Logik zur Laufzeit aktiviert wird.

Die Wallet-Implementierung (Aries Askar mit SQLite-Backend) erfährt zwei wesentliche Erweiterungen: Die \texttt{Expanded Key-Type-Registry} speichert Metadaten für ML-DSA-65- und ML-KEM-768-Schlüssel, einschließlich Schlüsselgrößen (Public Key: 1952 Bytes bzw.\ 1184 Bytes, Private Key: 4000 Bytes bzw.\ 2400 Bytes) und Algorithmus-Identifiern. Die \texttt{PQC-Key-Storage}-Erweiterung persistiert diese Schlüssel verschlüsselt in der SQLite-Datenbank, wobei die bestehende ChaCha20-Poly1305-AEAD-Verschlüsselung nach Argon2id-Key-Derivation unverändert bleibt. Die Wallet-Schnittstelle exponiert neue Operationen (\texttt{PQC Key Operations}, \texttt{PQC Sign/Verify}, \texttt{PQC Pack/Unpack}), die transparent von den Protocol Handlers aufgerufen werden, ohne dass diese Kenntnis über die zugrundeliegenden Algorithmen besitzen müssen.

Die Architektur gewährleistet, dass alle Schichten oberhalb der Wallet-Schnittstelle -- insbesondere Protocol Handlers und Admin API -- keine Änderungen erfahren. Dies reduziert die Testoberfläche, da ausschließlich die Plugin-Komponenten und Wallet-Erweiterungen validiert werden müssen, während die etablierte Aries-Protokoll-Logik unverändert bleibt. Die resultierende Architektur kombiniert die Produktionsreife von Hyperledger Aries mit der Quantenresistenz von NIST-standardisierten Post-Quantum-Algorithmen, ohne die Interoperabilität mit bestehenden SSI-Deployments zu kompromittieren.


%  - PQC-Algorithmen-Integration (ML-DSA, ML-KEM) \\
%  - Kryptoagiles Design (Plugin-Architektur) \\
\subsubsection{Implementierung}

% Die Implementierung der PQC-Unterstützung auf Application-Ebene erfolgt durch das \texttt{pqc\_didpeer4\_fm}-Plugin, das über den ACA-Py Plugin-Mechanismus transparent in die Agent-Architektur integriert wird. ACA-Py definiert ein Plugin als Python-Paket mit einem \texttt{setup(context)}-Entrypoint, der beim Agent-Start aufgerufen wird und Zugriff auf zentrale Agent-Komponenten (Wallet, DIDComm, Protocol Registry) über einen \texttt{PluginContext} erhält. Plugins können entweder neue Protokolle registrieren oder bestehende Funktionen durch Monkey-Patching erweitern.

Die Implementierung der PQC-Unterstützung auf Application-Ebene folgt einem zweistufigen Ansatz. In der ersten Stufe wird das \texttt{pqc\_didpeer4\_fm}-Plugin entwickelt, das sich in den ACA-Py Plugin-Mechanismus einfügt. Das Plugin ist als Python-Paket strukturiert und definiert einen \texttt{setup(context)}-Entrypoint, der beim Agent-Start aufgerufen wird. Über den \texttt{PluginContext} erhält das Plugin unmittelbaren Zugriff auf zentrale Agent-Komponenten wie die Wallet, das DIDComm-System und die Protocol Registry. Diese Architektur ermöglicht es Plugins, neue Protokolle zu registrieren oder bestehende Funktionen durch Monkey-Patching zu erweitern, ohne den ACA-Py Kern zu modifizieren.

Die zweite Stufe integriert das entwickelte Plugin in die containerisierte Deployment-Infrastruktur. Dabei wird das Plugin als Abhängigkeit in der \texttt{Dockerfile} definiert, sodass es während des Container-Builds installiert wird. Anschließend erfolgt die Konfiguration über \texttt{docker-compose}, indem der ACA-Py Service mit den erforderlichen Umgebungsvariablen und Plugin-Parametern initialisiert wird. Diese Trennung von Plugin-Entwicklung und Deployment-Integration gewährleistet Modularität und Wartbarkeit.

\begin{figure}[h]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 liboqs\_wrapper.py.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

% Das \texttt{pqc\_didpeer4\_fm}-Plugin nutzt beide Erweiterungsmechanismen: Es registriert neue PQC-Schlüsseltypen über \texttt{key\_types.py} und \texttt{key\_type\_patches.py} in der globalen \texttt{KeyType}-Registry und erweitert durch Monkey-Patching bestehende ACA-Py-Funktionen. Die Plugin-Initialisierung in \texttt{\_\_init\_\_.py} orchestriert die schrittweise Integration aller Module beim Agent-Start.

Die Implementierung des PQC-Plugins gliedert sich in drei funktionale Schichten, in die die in \autoref{fig:pqc_didpeer4_fm_directory_structure} dargestellten 15 Module eingeteilt sind: 

Die \textit{Kryptografie-Abstraktionsschicht} (\texttt{liboqs\_wrapper.py}) kapselt ML-DSA-65- und ML-KEM-768-Operationen, 

die \textit{DID-Verarbeitungsschicht} umfasst \texttt{pqc\_peer4\_creator.py} (did:peer:4-Generierung), \texttt{pqc\_peer4\_resolver.py} (DID-Auflösung), \texttt{pqc\_multicodec.py} und \texttt{pqc\_multikey.py} (Multiformat-Kodierung) sowie \texttt{pqc\_didcomm\_v1.py} (DIDComm-Verschlüsselung), 

und die \textit{Integration-Patching-Schicht} mit \texttt{monkey\_patches.py} (zentrale Funktion-Interceptors), \texttt{askar\_pqc\_patch.py} und \texttt{wallet\_patch.py} (Wallet-Operationen), \texttt{base\_manager\_patch.py} und \texttt{connection\_target\_patch.py} (Connection-Management), \texttt{validator\_patch.py} (Input-Validierung) sowie \texttt{multicodec\_patch.py} (Multicodec-Registry-Erweiterung). Diese modulare Architektur ermöglicht eine vollständig transparente PQC-Integration ohne Modifikation des ACA-Py-Kerncodes.

% \paragraph{Kryptografie-Abstraktionsschicht (liboqs Integration Layer)}
% - Einbindung der liboqs-python-Bibliothek \\
% - ML-DSA-65 Signatur-Operationen \\
% - ML-KEM-768 Key Encapsulation

%  - liboqs-Wrapper-Implementierung (liboqs\_wrapper.py) \\
%   - ML-DSA-65 Signatur-Operationen \\
%   - ML-KEM-768 Key Encapsulation \\
%   - Fehlerbehandlung und Validierung

% \paragraph{PQC did:peer:4 Generator}
% - Multicodec und Multikey-Kodierung \\
% - did:peer:4 Struktur mit Dual-Keys

%   - DID-Generierung mit PQC-Schlüsseln (pqc\_peer4\_creator.py) \\
%   - DID-Auflösung (pqc\_peer4\_resolver.py) \\
%   - Multicodec-Kodierung (pqc\_multicodec.py, multicodec\_patch.py) \\
%   - Multikey-Transformation (pqc\_multikey.py) \\
%   - did:peer:4 Struktur mit Dual-Keys (ML-DSA-65 + ML-KEM-768)

% \paragraph{Protocol Interceptors (Monkey-Patching)}
% - Interception-Mechanismus \\
% - Connection Manager Interception \\
% - DID Exchange Signatur-Interception \\
% - Installation der Patches

%   - Interception-Mechanismus (\_\_init\_\_.py, monkey\_patches.py) \\
%   - Connection Manager Interception (base\_manager\_patch.py) \\
%   - DID Exchange und Connection Target (connection\_target\_patch.py) \\
%   - JWS-Validierung (validator\_patch.py) \\
%   - Installation der Patches (Reihenfolge und Abhängigkeiten)

% \paragraph{Wallet Operation Wrappers}
% - Key-Creation-Wrapper \\
% - Signatur-Wrapper (sign\_message / verify\_message) \\
% - DIDComm Pack/Unpack-Wrapper \\

%   - Askar-Integration (askar\_pqc\_patch.py)
%   - Key-Creation-Wrapper und Verkey-Lookup (wallet\_patch.py)
%   - Signatur-Wrapper (sign\_message / verify\_message)
%   - DIDComm Pack/Unpack-Wrapper (pqc\_didcomm\_v1.py)

% \paragraph{Key-Type-Registry-Erweiterung}
% - KeyType-Datenstruktur \\
% - Registrierung im Wallet \\
% - Fallback-Mechanismus \\

%   - KeyType-Definitionen (key\_types.py)
%   - Registry-Integration (key\_type\_patches.py)
%   - API-Schema-Anpassungen
%   - Fallback-Mechanismus

% \paragraph{Wallet-Speicherung und Persistierung}
% - SQLite-Schema (Aries Askar) \\

% \paragraph{Deployment und Konfiguration}
% - Plugin-Installation (Dockerfile.acapy-base-pqc)\\
% - Agent-Konfiguration \\
% - Umgebungsvariablen \\
% - Verifikation der Installation

%   - Plugin-Installation (Dockerfile.acapy-base-pqc, setup.py) \\
%   - Agent-Konfiguration (--plugin pqc\_didpeer4\_fm) \\
%   - Umgebungsvariablen (OQS\_DISABLE=0) \\
%   - Verifikation der Installation

\paragraph{Pluginentwicklung: Kryptografie-Abstraktionsschicht}

Die Kryptografie-Abstraktionsschicht bildet die unterste Ebene der PQC-Integration und wird durch das Modul \texttt{liboqs\_wrapper.py} (Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_Kryptografie-Abstraktionsschicht}) realisiert. Dieses Modul kapselt die nativen Operationen der C-basierten liboqs-Bibliothek und stellt eine Python-API für die NIST-standardisierten PQC-Algorithmen ML-DSA-65 (Dilithium3, FIPS-204) und ML-KEM-768 (Kyber768, FIPS-203) bereit.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_Kryptografie-Abstraktionsschicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 \textbf{liboqs\_wrapper.py}.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Die Implementierung (Listing~\ref{lst:liboqs_wrapper.py}) definiert eine \texttt{LibOQSWrapper}-Klasse mit sechs Kern\-methoden: \texttt{generate\_ml\_dsa\_65\_keypair()} und \texttt{generate\_ml\_kem\_768\_keypair()} erzeugen kryptografische Schlüsselpaare, \texttt{sign\_ml\_dsa\_65()} und \texttt{verify\_ml\_dsa\_65()} implementieren digitale Signaturen, während \texttt{encapsulate\_ml\_kem\_768()} und \texttt{decapsulate\_ml\_kem\_768()} die Key Encapsulation für sichere Schlüsselvereinbarung realisieren.

Die Wrapper-Architektur abstrahiert die komplexen Foreign-Function-Interface-Aufrufe (FFI) an die liboqs-C-Bibliothek und stellt sicher, dass Schlüsselmaterial ausschließlich als Byte-Arrays (\texttt{bytes}) serialisiert wird - eine Voraussetzung für die Persistierung in der Aries-Askar-Wallet und die Kodierung in Multicodec-Formate. Das Singleton-Pattern (\texttt{get\_liboqs()}) gewährleistet eine einzige globale Instanz zur Vermeidung redundanter Initialisierungen. Diese Abstraktionsschicht ermöglicht es den höheren Modulen (DID-Generierung, DIDComm-Verschlüsselung), PQC-Operationen durchzuführen, ohne direkte Abhängigkeiten zur liboqs-C-API zu haben.

\paragraph{Pluginentwicklung: DID-Verarbeitungsschicht}

Die DID-Verarbeitungsschicht (siehe Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_DID-Verarbeitungsschicht}) orchestriert die Erzeugung, Auflösung und Kodierung von PQC-fähigen did:peer:4-Identifikatoren sowie die DIDComm-Nachrichtenverschlüsselung. Diese Schicht umfasst sechs funktional gekoppelte Module, die gemeinsam eine standardkonforme Integration von Post-Quantum-Kryptografie in das did:peer:4-Ökosystem realisieren.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_DID-Verarbeitungsschicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 liboqs\_wrapper.py.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 \textbf{pqc\_didcomm\_v1.py}.
.4 \textbf{pqc\_multicodec.py}.
.4 \textbf{pqc\_multikey.py}.
.4 \textbf{pqc\_peer4\_creator.py}.
.4 \textbf{pqc\_peer4\_resolver.py}.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Das Modul \texttt{pqc\_peer4\_creator.py} (Listing~\ref{lst:pqc_peer4_creator.py}) implementiert die Funktion \texttt{create\_pqc\_peer4\_did()}, die aus zwei PQC-Schlüsselpaaren (ML-DSA-65 für \texttt{authentication}/\texttt{assertionMethod}, ML-KEM-768 für \texttt{keyAgreement}) einen did:peer:4-Long-Form-Identifier generiert. Die Schlüssel werden über die Wallet-API erzeugt, in Multikey-Format transformiert und als \texttt{KeySpec}-Objekte in einem did:peer:4-Input-Dokument strukturiert, wobei die Reihenfolge der Schlüssel deren Fragment-IDs determiniert (\texttt{\#key-0} für Signaturen, \texttt{\#key-1} für Verschlüsselung in \texttt{recipientKeys}). Das Gegenstück \texttt{pqc\_peer4\_resolver.py} (Listing~\ref{lst:pqc_peer4_resolver.py}) registriert einen DID-Resolver für die \texttt{peer}-Methode, der did:peer:4-Long-Form-DIDs in DID-Dokumente
  auflöst und dabei PQC-Multicodec-Präfixe korrekt dekodiert.

Die Multiformat-Kodierung wird durch drei Module realisiert: \texttt{pqc\_multicodec.py} (Listing~\ref{lst:pqc_multicodec.py}) definiert eine Multicodec-Registry mit provisorischen Präfixen gemäß W3C-Draft (ML-DSA-65: \texttt{0xd065}, ML-KEM-768: \texttt{0xe018}) und stellt Wrapper-Funktionen (\texttt{wrap\_pqc()}, \texttt{unwrap\_pqc()}) für Präfix-Operationen bereit. \texttt{pqc\_multikey.py} (Listing~\ref{lst:pqc_multikey.py}) transformiert Schlüsselinformationen in das Multikey-Format durch Verkettung von Multicodec-Präfix und Schlüsselmaterial sowie Base58-Kodierung mit Multibase-Präfix \texttt{z} (Base58btc), wodurch Multikeys wie \texttt{z6MNxxx...} (ML-DSA-65) oder \texttt{z6MK768xxx...} (ML-KEM-768) entstehen.

Das Modul \texttt{pqc\_didcomm\_v1.py} (Listing~\ref{lst:pqc_didcomm_v1.py}) erweitert die DIDComm-v1-Envelope-Verarbeitung um PQC-Unterstützung: \texttt{pack\_message\_pqc()} und \texttt{unpack\_message\_pqc()} detektieren automatisch anhand der Schlüssellänge (ML-KEM-768: 1184~Bytes $\approx$ 1615~Base58-Zeichen vs. X25519: 32~Bytes $\approx$ 44~Zeichen), ob PQC- oder klassische Kryptografie verwendet werden muss, und generieren JWE-Envelopes mit angepassten Algorithmus-Headern (\texttt{alg: "PQC-Authcrypt"} bzw. \texttt{"PQC-Anoncrypt"}). Die Content Encryption erfolgt weiterhin mit XChaCha20-Poly1305 (quantum-sicher für symmetrische Verschlüsselung), während der Content Encryption Key (CEK) mittels ML-KEM-768 Key Encapsulation für jeden Empfänger verschlüsselt wird - im Gegensatz zur klassischen ECDH-ES-basierten CEK-Vereinbarung. Diese Schicht ermöglicht eine hybride Betriebsweise, bei der PQC- und klassische Agenten koexistieren können, solange jeweils homogene Verschlüsselungsmodi verwendet werden.

\paragraph{Pluginentwicklung: Integration-Patching-Schicht}

Die Integration-Patching-Schicht (siehe Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_Integration-Patching-Schicht}) implementiert die transparente Einbettung der PQC-Funktionalität in den ACA-Py-Kern durch gezieltes Monkey-Patching kritischer Funktionen und Erweiterung globaler Registries. Diese Schicht umfasst neun Module, die gemeinsam eine vollständig transparente PQC-Integration ohne Modifikation des ACA-Py-Quellcodes ermöglichen - existierende Workflows und API-Aufrufe bleiben unverändert funktionsfähig.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_Integration-Patching-Schicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 \textbf{askar\_pqc\_patch.py}.
.4 \textbf{base\_manager\_patch.py}.
.4 \textbf{connection\_target\_patch.py}.
.4 \textbf{key\_type\_patches.py}.
.4 \textbf{key\_types.py}.
.4 liboqs\_wrapper.py.
.4 \textbf{monkey\_patches.py}.
.4 \textbf{multicodec\_patch.py}.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 \textbf{validator\_patch.py}.
.4 \textbf{wallet\_patch.py}.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Das zentrale Orchestrierungsmodul \texttt{monkey\_patches.py} (Listing~\ref{lst:monkey_patches.py}) koordiniert die Installation aller Patches durch die Funktion \texttt{apply\_all\_patches()}, die beim Plugin-Setup aufgerufen wird. Dieses Modul überschreibt Methoden der Klasse \texttt{BaseConnectionManager} (z.\,B. \texttt{create\_did\_peer\_4()}, \texttt{\_extract\_key\_material\_in\_base58\_format()}, \texttt{long\_did\_peer\_4\_to\_short()}) und delegiert deren Implementierung an spezialisierte Patch-Module, wobei die ursprünglichen Methoden als Fallback-Referenzen gespeichert werden. Das Modul \texttt{base\_manager\_patch.py} (Listing~\ref{lst:base_manager_patch.py}) stellt die PQC-Implementierungen dieser \texttt{BaseConnectionManager}-Methoden bereit: \texttt{create\_did\_peer\_4\_pqc\_complete()} generiert did:peer:4-DIDs mit ML-DSA-65- und ML-KEM-768-Schlüsseln anstelle klassischer ED25519/X25519-Schlüssel, \texttt{\_extract\_key\_material\_in\_base58\_format\_pqc()} extrahiert PQC-Schlüsselmaterial aus DID-Dokumenten unter Berücksichtigung der größeren Schlüssellängen, und \texttt{record\_keys\_for\_resolvable\_did\_pqc()} persistiert beide PQC-Schlüssel (Signatur- und Verschlüsselungsschlüssel) in der Wallet-Datenbank.

Die Wallet-Integration erfolgt durch drei Module: \texttt{askar\_pqc\_patch.py} (Listing~\ref{lst:askar_pqc_patch.py}) patcht die Aries-Askar-Funktionen \texttt{create\_keypair()} zur Unterstützung von PQC-Schlüsselgenerierung mittels liboqs sowie \texttt{pack\_message()} und \texttt{unpack\_message()} zur Integration der PQC-DIDComm-v1-Implementierung aus \texttt{pqc\_didcomm\_v1.py}. \texttt{wallet\_patch.py} (Listing~\ref{lst:wallet_patch.py}) erweitert die Methode \texttt{get\_local\_did\_for\_verkey()} der \texttt{AskarWallet}-Klasse, um ML-KEM-768-Verkeys (1184~Bytes Länge) korrekt in der Datenbank zu lokalisieren – eine kritische Anpassung, da klassische Verkey-Lookups nur für 32-Byte-ED25519-Schlüssel ausgelegt sind. \texttt{connection\_target\_patch.py} (Listing~\ref{lst:connection_target_patch.py}) passt das Marshmallow-Schema der \texttt{ConnectionTarget}-Klasse an, indem die Validierungsregeln für \texttt{recipient\_keys} PQC-konforme Schlüssellängen akzeptieren (bisherige Validierung: exakt 44~Base58-Zeichen für ED25519).

Die Erweiterung der Schlüsseltyp-Infrastruktur erfolgt durch zwei Module: \texttt{key\_types.py} (Listing~\ref{lst:key_types.py}) definiert neue \texttt{KeyType}-Konstanten (\texttt{ML\_DSA\_65}, \texttt{ML\_KEM\_768}) mit Metadaten wie NIST-FIPS-Referenzen, Schlüssellängen und Multicodec-Präfixen. \texttt{key\_type\_patches.py} (Listing~\ref{lst:key_type_patches.py}) registriert diese KeyTypes in der globalen ACA-Py-Registry durch \texttt{register\_pqc\_key\_types()}, erweitert die Admin-API-Schemata (\texttt{patch\_api\_key\_type\_schemas()}) zur Akzeptanz von PQC-KeyType-Strings in JSON-Requests, und patcht Algorithmus-Mappings (\texttt{patch\_alg\_mappings\_for\_pqc()}) für JWS/JWE-Header-Generierung. \texttt{multicodec\_patch.py} (Listing~\ref{lst:multicodec_patch.py}) erweitert die globale \texttt{SupportedCodecs}-Enumeration durch dynamisches Hinzufügen von ML-DSA-65- und ML-KEM-768-Multicodec-Einträgen, sodass Multicodec-Dekodierungsfunktionen aus \texttt{multiformats}-Bibliotheken PQC-Präfixe verarbeiten können.

Das Modul \texttt{validator\_patch.py} (Listing~\ref{lst:validator_patch.py}) patcht die \texttt{JWSHeaderKid}-Validierungsklasse, die standardmäßig nur klassische DID-Formate (did:key, did:sov) in JWS-Header-\texttt{kid}-Feldern akzeptiert, um did:peer:4-Identifier zu unterstützen – eine Voraussetzung für ML-DSA-65-signierte DID-Exchange-AttachDecorators. Diese neun Module bilden gemeinsam eine Patch-Architektur, die durch sequenzielle Installation beim Plugin-Setup (orchestriert in \texttt{\_\_init\_\_.py}) eine vollständige PQC-Funktionalität in ACA-Py injiziert, ohne dass Änderungen an Controllern, Admin-API-Endpunkten oder externen Business-Logic-Schichten erforderlich sind.

% \paragraph{Deployment und Konfiguration}'
% - Plugin-Installation (Dockerfile.acapy-base-pqc) \\
% - Agent-Konfiguration \\
% - Umgebungsvariablen \\
% - Verifikation der Installation

%   - Umgebungsvariablen (OQS\_DISABLE=0) \\
%   - Verifikation der Installation

% Das Deployment des PQC-Plugins erfolgt über die Python-Package-Infrastruktur (siehe Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_Deployment}). Das Modul \texttt{setup.py} (Listing~\ref{lst:setup.py}) definiert das Plugin als installierbare Python-Distribution mit Entry-Point-Registration (\texttt{aries\_cloudagent.plugins = pqc\_didpeer4\_fm}), sodass ACA-Py das Plugin beim Start automatisch über setuptools-Discovery erkennt und die \texttt{setup()}-Funktion aus \texttt{\_\_init\_\_.py} aufruft. Die Plugin-Aktivierung erfolgt durch den Kommandozeilenparameter \texttt{--plugin pqc\_didpeer4\_fm} beim Agent-Start oder durch entsprechende Konfiguration in docker-compose.yml-Dateien. Das \texttt{README.md} (Listing~\ref{lst:README.md}) dokumentiert die Installation (\texttt{pip install -e .}), Konfigurationsparameter und den transparenten Integrationsmechanismus, der keine API-Änderungen erfordert - existierende Workflows wie \texttt{POST /out-of-band/create-invitation} mit Parameter \texttt{use\_did\_method: "did:peer:4"} erzeugen automatisch PQC-fähige DIDs anstelle klassischer ED25519-basierter Identifikatoren. Die Verifikation erfolgt über die Admin-API-Endpoint \texttt{GET /wallet/did}, die für PQC-DIDs erweiterte Metadaten (\texttt{pqc\_enabled: true}, \texttt{signature\_algorithm: "ml-dsa-65"}, \texttt{key\_agreement\_algorithm: "ml-kem-768"}) zurückgibt.

% \begin{figure}[H]
%   \flushleft
%   \caption{Verzeichnisstruktur des Projekts}
%   \label{fig:pqc_didpeer4_fm_directory_structure_Deployment}
% \dirtree{%
% .1 pqc\_didpeer4\_fm/.
% .2 pqc\_didpeer4\_fm/.
% .3 v1\_0/.
% .4 askar\_pqc\_patch.py.
% .4 base\_manager\_patch.py.
% .4 connection\_target\_patch.py.
% .4 key\_type\_patches.py.
% .4 key\_types.py.
% .4 liboqs\_wrapper.py.
% .4 monkey\_patches.py.
% .4 multicodec\_patch.py.
% .4 pqc\_didcomm\_v1.py.
% .4 pqc\_multicodec.py.
% .4 pqc\_multikey.py.
% .4 pqc\_peer4\_creator.py.
% .4 pqc\_peer4\_resolver.py.
% .4 validator\_patch.py.
% .4 wallet\_patch.py.
% .3 \_\_init\_\_.py.
% .2 \textbf{README.md}.
% .2 \textbf{setup.py}.
% }
% \begin{flushleft}
%     \textit{Anmerkung.} Eigene Darstellung.
% \end{flushleft}
% \end{figure}

% \textbf{Plugin-Installation}
%   - Weiterentwicklung vom Dockerfile.acapy-base zum Dockerfile.acapy-base-pqc + setup.py \\

\paragraph{Dockerfile-Modifikation}

Für die Integration des Plugins wurde das ACA-Py Docker-Base-Image (Listing~\ref{lst:Dockerfile-acapy-base}) aus Iteration~1 Kapitel~\ref{SSI-Agenten} modifiziert. Die Baseline-Architektur von Iteration~1 verwendet einen 2-stufigen Build-Prozess (Poetry-Wheel-Building + Runtime-Installation) mit System-OpenSSL und unterstützt ausschließlich klassische Kryptografie (ED25519, X25519, RSA).

Iteration~2 (Listing~\ref{lst:Dockerfile-acapy-base-pqc}, siehe Abbildung~\ref{fig:Iteration2_Acapy_Multi_Stage_Build}) erweitert die Architektur auf einen 4-stufigen Multi-Stage-Build: Stage~1 kompiliert OpenSSL~3.5.4 mit FIPS-Modul und nativer ML-KEM/ML-DSA-Unterstützung, Stage~2 baut liboqs~0.14.0 als Shared Library, Stage~3 bleibt identisch zu Iteration~1 (Poetry-basiertes ACA-Py-Wheel), und Stage~4 integriert alle Artefakte durch \texttt{COPY --from}-Direktiven aus den Builder-Stages. Die Runtime-Stage überschreibt System-OpenSSL-Symlinks mittels \texttt{ln -sf}, aktualisiert Shared-Library-Pfade via \texttt{ldconfig}, importiert das PQC-Root-CA-Zertifikat in den System-Trust-Store (\texttt{update-ca-certificates}), und installiert das \texttt{pqc\_didpeer4\_fm}-Plugin mithilfe von pip direkt in das Container-Image.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Iteration2_Acapy_Multi_Stage Build.png}
    \caption{ACA-Py Multi-Stage Build Dockerfile mit PQC-Integration (Iteration 2)}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Iteration2_Acapy_Multi_Stage_Build}
\end{figure}

\paragraph{Deployment in docker-compose.yml}

Das Deployment der PQC-fähigen SSI-Agenten erfolgt innerhalb der in Iteration 1 (Kapitel~\ref{Docker Orchestrierung der Gesamtarchitektur}) entwickelten docker-compose.yml-Orchestrierung, deren Evolution vom klassischen Setup (Iteration~1, Listing~\ref{lst:docker-compose.yml-SSI-Agenten}) zur PQC-Integration (Iteration~2, Listing~\ref{lst:docker-compose.yml-SSI-Agenten-mit-acapy-base-pqc-und-plugin}) zwei zentrale Anpassungen umfasst. Während die Iteration~1-Konfiguration noch das klassische ACA-Py-Base-Image ohne PQC-Unterstützung und Plugin-Aktivierung verwendet, wurde in Iteration~2 im Rahmen der ersten Anpassung die docker-compose.yml so modifiziert, dass alle drei Agent-Services (issuer, holder, verifier) das neue \texttt{acapy-base-pqc}-Image nutzen in welchem das \texttt{pqc\_didpeer4\_fm}-Plugin enthalten ist. Diese Änderung kann durch den Vergleich von \autoref{fig:Docker-Compose-Übersicht-Iteration-2} mit \autoref{fig:Docker-Compose-Übersicht-Iteration-1} nachvollzogen werden.

Die zweite Anpassung erweitert die \texttt{command}-Direktive aller drei Agenten um den Parameter \texttt{--plugin pqc\_didpeer4\_fm}, der beim Agent start das \texttt{pqc\_didpeer4\_fm}-Plugin lädt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{docker_compose_übersicht_pqc_plugin.png}
    \caption{Docker-Compose-Übersicht der Iteration 2 Architektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Docker-Compose-Übersicht-Iteration-2}
\end{figure}

\subsubsection{Formative Evaluation}

\paragraph{Validierung des Plugin-Ladevorgangs bei Agent-Start}
% - Issuer Agent Boot Log Iteration 1 vs Iteration 2 \\

% Listing~\ref{lst:Issuer-Agent-Boot-Logs} vs. Listing~\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}

Die erste formative Evaluationsmaßnahme bestand in der Validierung des korrekten Plugin-Ladevorgangs beim Start eines ACA-Py-Agenten. Dieser Test diente der Sicherstellung, dass die PQC-Integration transparent und ohne Beeinträchtigung der Standard-ACA-Py-Funktionalität erfolgt.

Listing~\ref{lst:Issuer-Agent-Boot-Logs} zeigt den Boot-Prozess eines Standard-ACA-Py-Agenten (Version 1.3.2) ohne PQC-Plugin. Nach der Registrierung der Default- und Askar-Plugins wird direkt mit der Ledger-Konfiguration und Wallet-Initialisierung fortgefahren.

Im Vergleich dazu zeigt Listing~\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin} den erweiterten Boot-Prozess mit geladenem \texttt{pqc\_didpeer4\_fm}-Plugin. Zwischen der Askar-Plugin-Registrierung und der Ledger-Konfiguration erfolgt nun die Plugin-Initialisierung mit mehreren charakteristischen Schritten:

\begin{enumerate}
\item \textbf{Askar-Patching:} Die \texttt{\_create\_keypair}-Funktion wird durch eine PQC-fähige Variante ersetzt, die ML-DSA-65 und ML-KEM-768 unterstützt. Zusätzlich werden \texttt{Session}-Methoden (\texttt{insert\_key}, \texttt{fetch\_key}, \texttt{update\_key}) und \texttt{AskarWallet.assign\_kid\_to\_key()} gepatcht.
\item \textbf{KeyType-Registry-Erweiterung:} Die neuen Schlüsseltypen \texttt{ml-dsa-65} und \texttt{ml-kem-768} werden in der ACA-Py KeyTypes-Registry registriert und die API-Schemas zur Laufzeit erweitert.
\item \textbf{did:peer:4-Erweiterung:} Die unterstützten Schlüsseltypen für did:peer:4 werden von \texttt{['ed25519', 'x25519']} auf \texttt{['ed25519', 'x25519', 'ml-dsa-65', 'ml-kem-768']} erweitert.
\item \textbf{Multicodec-Patching:} Die \texttt{SupportedCodecs}-Klasse wird für PQC-Multicodec-Präfixe erweitert (ML-DSA-65: \texttt{0xd065}, ML-KEM-768: \texttt{0xe018}).
\item \textbf{DIDComm-Patching:} \texttt{AskarWallet.pack\_message()} und \texttt{unpack\_message()} werden für ML-KEM-768-basierte Verschlüsselung angepasst. Die \texttt{AttachDecorator}-Klasse wird für ML-DSA-65-JWS-Signaturen erweitert.
\item \textbf{Monkey-Patches:} Die \texttt{BaseConnectionManager}-Methoden (\texttt{create\_did\_peer\_4}, \texttt{record\_keys\_for\_resolvable\_did}, etc.) werden durch PQC-fähige Varianten ersetzt.
\end{enumerate}



\paragraph{Validierung der Pluginfunktionalität: Out-of-Band Invitation mit did:peer:4}

% did:peer:4 ==> /out-of-band/create-invitation
% - Admin-API Aufruf: \texttt{POST /out-of-band/create-invitation} mit Parameter \texttt{use\_did\_method: "did:peer:4"} \\

Die zweite formative Evaluationsmaßnahme validierte die Kernfunktionalität des Plugins: die transparente Erstellung von PQC-fähigen did:peer:4-DIDs während des Out-of-Band-Invitation-Prozesses.

Listing~\ref{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-vor-OOB-Invitation} zeigt die initiale Wallet-Abfrage eines frisch gestarteten Issuer-Agenten. Das leere \texttt{results}-Array bestätigt, dass noch keine DIDs im Wallet vorhanden sind.

\refstepcounter{manualListingCounter}
\label{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-vor-OOB-Invitation}
\begin{lstlisting}[language=bash, caption={Listing \arabic{lstlisting}: Iteration 2 - Validierung der Pluginfunktionalität - Wallet DID Abfrage vor Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X GET https://host.docker.internal:8021/wallet/did | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    15  100    15    0     0   1083      0 --:--:-- --:--:-- --:--:--  1153
{
  "results": []
}
\end{lstlisting}

Anschließend wurde mittels \texttt{POST /out-of-band/create-invitation} mit dem Parameter \texttt{use\_did\_method: "did:peer:4"} eine Einladung erstellt (Listing~\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}). Die API-Response enthält eine vollständige did:peer:4-Langform-DID im \texttt{services}-Array der Invitation, erkennbar am charakteristischen Format \texttt{did:peer:4zQm...:z25g...}.

\refstepcounter{manualListingCounter}
\label{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}
\begin{lstlisting}[language=bash, caption={Listing \arabic{lstlisting}: Iteration 2 - Validierung der Pluginfunktionalität - Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X POST https://host.docker.internal:8021/out-of-band/create-invitation     -H "Content-Type: application/json"     -d '{
      "handshake_protocols": ["https://didcomm.org/didexchange/1.1"],
      "use_did_method": "did:peer:4",
      "my_label": "Issuer Test"
    }' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 16198  100 16051  100   147  91160    834 --:--:-- --:--:-- --:--:-- 91514
{
  "state": "initial",
  "trace": false,
  "invi_msg_id": "89e9cc87-318f-49aa-a61a-fc805706cd8d",
  "oob_id": "70998122-5a5b-4020-8b5f-ae5884af20b3",
  "invitation": {
    "@type": "https://didcomm.org/out-of-band/1.1/invitation",
    "@id": "89e9cc87-318f-49aa-a61a-fc805706cd8d",
    "label": "Issuer Test",
    "handshake_protocols": [
      "https://didcomm.org/didexchange/1.1"
    ],
    "services": [
      "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc..."
    ]
  },
  "invitation_url": "https://host.docker.internal:8020?oob=eyJAdHlwZSI6ICJodHR..."
}
\end{lstlisting}

Die entscheidende Validierung erfolgt in Listing~\ref{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-nach-OOB-Invitation} durch eine erneute Wallet-Abfrage nach der Invitation-Erstellung. Die Response zeigt nun die automatisch generierte PQC-DID mit folgenden charakteristischen Merkmalen:

\begin{itemize}
\item \textbf{Dual-Key-Struktur:} Das \texttt{key\_type}-Feld weist den Wert \texttt{ml-dsa-65} auf, während die Metadata zusätzlich \texttt{kem\_verkey} (ML-KEM-768) enthält. Dies bestätigt die erfolgreiche Implementierung der Hybrid-Kryptografie mit getrennten Schlüsseln für digitale Signaturen und Schlüsselvereinbarung.
\item \textbf{PQC-Metadata:} Die Metadaten enthalten explizite Marker (\texttt{pqc\_enabled: true}, \texttt{signature\_algorithm: "ml-dsa-65"}, \texttt{key\_agreement\_algorithm: "ml-kem-768"}), die eine eindeutige Identifikation PQC-fähiger DIDs zur Laufzeit ermöglichen.
\item \textbf{Key Identifier:} Das \texttt{kem\_key\_kid}-Feld referenziert den KEM-Schlüssel über den DID-URL-Fragment-Identifier \texttt{\#key-1}, was der did:peer:4-Spezifikation entspricht, bei der Verification-Methods sequenziell nummeriert werden (\texttt{\#key-0} für Authentication, \texttt{\#key-1} für Key Agreement).
\end{itemize}

\refstepcounter{manualListingCounter}
\label{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-nach-OOB-Invitation}
\begin{lstlisting}[language=bash, caption={Listing \arabic{lstlisting}: Iteration 2 - Validierung der Pluginfunktionalität - Wallet DID Abfrage nach Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X GET https://host.docker.internal:8021/wallet/did | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 17778  100 17778    0     0  1655k      0 --:--:-- --:--:-- --:--:-- 1736k
{
  "results": [
    {
      "did": "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc...",
      "verkey": "2BvJSsMeLjejWKygFBC1qFPLqUvvTzfed7y2Btp...",
      "posture": "wallet_only",
      "key_type": "ml-dsa-65",
      "method": "did:peer:4",
      "metadata": {
        "invitation_reuse": "true",
        "pqc_enabled": true,
        "signature_algorithm": "ml-dsa-65",
        "key_agreement_algorithm": "ml-kem-768",
        "kem_key_kid": "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc...D6SUGP43VJWg#key-1",
        "kem_verkey": "h6ngVfG9n2qF1SY5gM3DaDhK9iiwhvnW555QtodD1sgvEcg5...",
        "plugin": "pqc_didpeer4_fm",
        "version": "0.1.0"
      }
    }
  ]
}
\end{lstlisting}



% ==> /wallet/did um zu schauen was personalisiertes

% LOGS anzeigen lassen vom Webserver und vom Agenten selbst

    %    - Überprüfung der Plugin-Registrierung in Logs \\
    %    - Testaufruf einer gepatchten Funktion (z.\,B. DID-Erstellung)
%   → FF1: Blockchain-DID-Registry funktioniert? \\
%   → FF2: Alle PQC-Algorithmen korrekt integriert? \\
%   → FF3: Performance-Vergleich klassisch vs. PQC \\
%   → FF4: Algorithmus-Wechsel ohne Code-Änderung möglich? \\
%    \\
%      - Funktionalitätstests (UC1-UC7) \\
%      - Kryptografische Validierung (Signatur-Verifikation)

% https://dspace.bracu.ac.bd/xmlui/bitstream/handle/10361/25158/24141271,%2020101496,%202010360,%2020101053_CSE.pdf?sequence=1&isAllowed=y#cite.0@indyGithub

\subsubsection{Finales Artefakt}

Das finale Artefakt der zweiten Iteration repräsentiert einen funktionsfähigen SSI-Prototypen mit vollständiger Post-Quantum-Kryptografie-Integration auf Application-Layer-Ebene. Die Architektur vereint die in Iteration~1 etablierte Transport-Layer-Sicherung mittels PQC-Sidecar-Proxies mit einer tiefgreifenden Anwendungsschicht-Integration durch das entwickelte \texttt{pqc\_did\_peer4\_fm}-Plugin.

Die Kernkomponente bildet das ACA-Py-Plugin mit dreischichtiger Architektur. Die Kryptografie-Abstraktionsschicht kapselt native \texttt{liboqs}-Operationen und exponiert eine Python-API für ML-DSA-65 und ML-KEM-768. Die DID-Verarbeitungsschicht orchestriert Generierung, Auflösung und Kodierung PQC-fähiger \texttt{did:peer:4}-Identifikatoren. Die Integration-Patching-Schicht realisiert transparentes Monkey-Patching kritischer ACA-Py-Kernfunktionen ohne Modifikation des Framework-Quellcodes.

Hinsichtlich der in Kapitel~4.2.1 definierten Designziele erfüllt das finale Artefakt sämtliche Anforderungen. Das Designziel zu FF1 (Systemarchitektur \& Compliance) wird durch die native Unterstützung quantenresistenter Signaturen in den DID-Dokumenten adressiert, wodurch die Authentizität von Identitätsnachweisen unabhängig vom Transportkanal langfristig gegenüber Quantencomputer-Angriffen gewährleistet bleibt. Das Designziel zu FF2 (Algorithmenauswahl \& Sicherheitsbewertung) manifestiert sich in der erfolgreichen Integration von ML-DSA-65 für digitale Signaturen innerhalb der \texttt{did:peer:4}-Strukturen, was die praktische Machbarkeit von PQC-Signaturen in dezentralen Identifikatoren nachweist. Das Designziel zu FF3 (Kryptografische Agilität) wird durch die Erweiterung der Multicodec-Registry um provisorische Präfixe für ML-DSA-65 (\texttt{0xd065}) und ML-KEM-768 (\texttt{0xe018}) sowie die abstrahierte Kryptografie-Schicht realisiert, welche die Koexistenz klassischer und post-quanten Verfahren innerhalb der DID-Methoden ermöglicht.

Das Multi-Stage-Build-Dockerfile integriert alle Abhängigkeiten in ein kohärentes Container-Image: Stage~1 kompiliert OpenSSL~3.5.4 mit nativer ML-KEM/ML-DSA-Unterstützung, Stage~2 baut \texttt{liboqs}~0.14.0, Stage~3 generiert das ACA-Py-Wheel, und Stage~4 fusioniert alle Artefakte in ein produktionsfähiges Runtime-Image. Die formative Evaluation validierte die funktionale Korrektheit durch erfolgreiche Plugin-Registrierung beim Agent-Start sowie korrekte Generierung von \texttt{did:peer:4}-Long-Form-DIDs mit PQC-Schlüsselmaterial im Out-of-Band-Invitation-Workflow.












\newpage
\section{Summative Evaluation}
        - Evaluationsmethodik (FEDS)
\subsection{Funktionalitätstests}
       - Vollständige UC1-UC7-Validierung \\
       Use Cases? ==> \parencite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}
%       - KRITIS-Szenarien (Energie, Gesundheit, Wasser)
% \subsection{Performance-Analyse}
%        - Latenz-Messungen (Baseline, PQC, Hybrid) \\
%        - Durchsatz-Analyse \\
%        - Speicher- und Rechenaufwand \\
%        - Skalierbarkeitstest
\subsection{Sicherheitsbewertung}
       - Kryptografische Stärke (NIST Security Level) \\
       - Threat-Modeling \\
       - Resilience-Tests
\subsection{Compliance-Validierung}
       - BSI-Anforderungen (IDM, KRY) \\
       - DSGVO, NIS2 \\
       - Auditierbarkeit




% \newpage
% \section{Systemarchitektur und Design} \label{sec:Systemarchitektur und Design}