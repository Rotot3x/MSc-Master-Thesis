\newpage
\section{Methodik} \label{sec:Methodik}

\fixme{2,3333 Seiten BILDER/TABELLEN ==> kann erweitert werden}

\subsection{Systematische Literaturrecherche} \label{sec:Systematische Literaturrecherche}

Die systematische Literaturrecherche dieser Masterarbeit folgt ausgewählten Methoden der \ac{PRISMA} 2020 Richtlinien zur strukturierten Identifikation, Selektion, Bewertung und Synthese einschlägiger Studien, wodurch eine belastbare Grundlage für die Analyse der Forschungslücke und die Ableitung der Forschungsfragen geschaffen wird \parencite[S. 1]{page_PRISMA2020Statementupdatedguidelinereportingsystematicreviews_2021}. Dieses Vorgehen bietet einen strukturierten Ansatz zur Durchführung und Dokumentation von Literaturrecherchen, der die Qualität und Vollständigkeit der Berichterstattung verbessert und einen transparenten und reproduzierbaren Prozess gewährleistet \parencite[S. 1]{page_PRISMA2020Statementupdatedguidelinereportingsystematicreviews_2021}.

Die systematische Literaturrecherche wurde in zwei zeitlich getrennten Iterationen durchgeführt, um den dynamischen Charakter des Forschungsfeldes zu adressieren und die Aktualität der Wissensbasis sicherzustellen. Beide Iterationen sind ausführlich dokumentiert in \ref{sec:Anhang_Dokumentation_der_systematischen_Literaturrecherche} und dienen ausschließlich der Problemidentifikation, der Ergründung des Forschungsstands sowie der Ableitung der Forschungslücke und initialen Forschungsfragen.

Der konsolidierte Suchprozess in der Datenbank EBSCO führte über beide Phasen hinweg zur Identifikation von insgesamt 95 potenziellen Quellen. Davon entfielen 61 Publikationen auf die erste Iteration im Mai 2025 (siehe \autoref{fig:PRISMA_Flussdiagramm_iteration1}) und 34 Publikationen auf die zweite Iteration im November 2025 (siehe \autoref{fig:PRISMA_Flussdiagramm_Iteration2}). Die methodische Konsistenz wurde dabei durch die Anwendung identischer Suchstrategien und Selektionskriterien in beiden Zeiträumen sichergestellt.

Nach der Bereinigung von Duplikaten und der Anwendung der Ein- und Ausschlusskriterien verblieb ein fokussierter Bestand an hochrelevanten Studien. Eine detaillierte Übersicht der identifizierten Quellen findet sich in \autoref{tab:quellenuebersicht_Iteration1} für die erste und \autoref{tab:quellenuebersicht_iteration2} für die zweite Phase. Die vollständige Aufschlüsselung der Selektionsschritte sowie die zugehörigen Flussdiagramme sind zudem gesammelt in \ref{sec:Anhang_Dokumentation_der_systematischen_Literaturrecherche} aufgeführt.

\fixme{Anhangskapitel fixen ==> Transparente Dokumentation // Hat noch komische Texte}

\subsection{Design Science Research} \label{Design Science Research}

\ac{DSR} bildet den methodischen Rahmen dieser Masterarbeit. \ac{DSR} stellt neben der verhaltenswissenschaftlichen Forschung ein eigenständiges Forschungsparadigma dar \parencite[S. 75]{hevner_DesignScienceInformationsystemsresearch_2004}. Während verhaltenswissenschaftliche Ansätze Theorien zur Erklärung oder Vorhersage entwickeln, fokussiert DSR auf die Erschaffung innovativer Artefakte zur Erweiterung menschlicher und organisatorischer Fähigkeiten \parencite[S. 75]{hevner_DesignScienceInformationsystemsresearch_2004}. Fundamental ist \ac{DSR} ein lösungsorientiertes Paradigma \parencite[S. 76]{hevner_DesignScienceInformationsystemsresearch_2004}, dessen Prinzip darin besteht, Wissen durch den Bau und die Anwendung eines Artefakts zu gewinnen \parencite[S. 82]{hevner_DesignScienceInformationsystemsresearch_2004}.

Das Information Systems Research Framework (\autoref{fig:hevner2004_framework}) nach \textcite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004} strukturiert den Forschungsprozess durch drei Hauptkomponenten.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{dsr_ISR_Framework.png}
    \caption{Information Systems Research Framework}
    \begin{flushleft}
    \textit{Anmerkung.} Aus \textcite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}.
    \end{flushleft}
    \label{fig:hevner2004_framework}
\end{figure}

Die \textbf{Environment}-Komponente definiert den Problemraum \parencite[S. 108]{simon_SciencesArtificial_1996} mit Menschen, Organisationen und Technologien sowie den Geschäftsanforderungen \parencite[S. 7--11]{silver_InformationTechnologyInteractionModelFoundationMBACoreCourse_1995}. Für diese Arbeit bilden kritische Infrastrukturen die Environment mit ihren Anforderungen an Post-Quantum-Sicherheit und selbstbestimmte Identitätsverwaltung. Die \textbf{IS Research}-Komponente umfasst Build/Evaluate-Aktivitäten für Artefakte \parencite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}. Hier erfolgt die Instanziierung und Evaluation eines PQC-fähigen SSI-Prototypen, der speziell für den Einsatz in kritischen Infrastrukturen konzipiert ist. Die \textbf{Knowledge Base} liefert Foundations (Theorien, Frameworks, Konstrukte) und Methodologies (Evaluationsmethoden) \parencite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}. Sie umfasst für diese Arbeit SSI-Standards, NIST-PQC-Algorithmen und KRITIS-Anforderungen. Rigor wird durch angemessene Anwendung dieser Wissensbasis erreicht \parencite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}.

\subsubsection{Zyklen}

\textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007} identifiziert drei eng verbundene Aktivitätszyklen, die in jedem DSR-Projekt präsent sein müssen (\autoref{fig:3-cycle-model}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{3-cycle.png}
    \caption{Design Science Research Zyklen}
    \begin{flushleft}
    \textit{Anmerkung.} Aus \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007}.
    \end{flushleft}
    \label{fig:3-cycle-model}
\end{figure}

Der \textbf{Relevance Cycle} initiiert DSR mit Anforderungen aus der Anwendungsdomäne und fordert Field Testing des Outputs \parencite[S. 88-89]{hevner_ThreeCycleViewDesignScienceResearch_2007}. In dieser Arbeit manifestiert sich dies durch die iterative Identifikation von KRITIS-Anforderungen an an Sicherheit, Compliance und Kryptoagilität in zwei Implementierungszyklen. Dazu gehören quantenresistente Kommunikations- und Signaturverfahren, die Einhaltung relevanter Regulierungsvorgaben sowie die Wahrung von Datenschutz und technischer Resilienz. Die entwickelten Artefakte werden kontinuierlich in Laborumgebungen getestet, wobei Erkenntnisse aus der ersten Iteration die Designziele der zweiten Iteration prägen. Der \textbf{Rigor Cycle} verbindet DSR-Aktivitäten mit der Wissensbasis, um Innovation zu gewährleisten \parencite[S. 88-90]{hevner_ThreeCycleViewDesignScienceResearch_2007}. In dieser Arbeit wird dieser Zyklus durch die kontinuierliche Integration wissenschaftlicher Grundlagen etablierter SSI-Frameworks, NIST-standardisierter PQC-Algorithmen und KRITIS-Standards operationalisiert. Der \textbf{Design Cycle} strukturiert die Artefaktentwicklung als iterativen Prozess zwischen Konstruktion und Evaluation \parencite[S. 90--91]{hevner_ThreeCycleViewDesignScienceResearch_2007}. In dieser Arbeit erfolgt dies in zwei aufeinanderfolgenden Iterationen, wobei jede Iteration Feedback für die Designverbesserung liefert und die Erkenntnisse in die nächste Iteration einfließen.

\subsubsection{Artefakte}

\textcite[S. 255]{march_DesignNaturalScienceresearchinformationtechnology_1995} identifizieren vier Artefakttypen: Constructs, Models, Methods und Instantiations. \textbf{Constructs} stellen die Sprache bereit, in der Probleme und Lösungen definiert werden, und beeinflussen die Problemkonzeption \parencite[S. 78, 83]{hevner_DesignScienceInformationsystemsresearch_2004}. \textbf{Models} repräsentieren das Designproblem und den Lösungsraum, unterstützen das Problemverständnis und ermöglichen die Erkundung von Designentscheidungen \parencite[S. 78-79]{hevner_DesignScienceInformationsystemsresearch_2004}. \textbf{Methods} definieren Prozesse zur Problemlösung, von formalen Algorithmen bis zu Best-Practice-Beschreibungen \parencite[S. 79]{hevner_DesignScienceInformationsystemsresearch_2004}. \textbf{Instantiations} demonstrieren Machbarkeit durch Implementierung in einem funktionierenden System und liefern Beweis durch Konstruktion \parencite[S. 79, 84]{hevner_DesignScienceInformationsystemsresearch_2004}.

Diese Arbeit entwickelt eine \textit{Instantiation} in Form eines funktionsfähigen Prototyps eines blockchain-basierten SSI-Systems mit integrierter Post-Quantum-Kryptographie für KRITIS, welcher die technische Machbarkeit und praktische Anwendbarkeit des Ansatzes demonstriert.

\subsubsection{Richtlinien}

\textcite[S. 82]{hevner_DesignScienceInformationsystemsresearch_2004} formulieren sieben Richtlinien für \ac{DSR}, die jeweils in einer qualitätsvollen Forschungsarbeit adressiert werden sollten. Diese Richtlinien bilden einen strukturierten Rahmen zur Durchführung und Bewertung von Design-Science-Forschung und gewährleisten, dass sowohl wissenschaftliche Rigor als auch praktische Relevanz erreicht werden.

\textbf{Guideline 1: Design as an Artifact} - Design-Science-Forschung muss ein brauchbares Artefakt produzieren \parencite[S. 82]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit erfüllt dies durch eine funktionsfähige Instantiation eines blockchain-basierten SSI-Systems mit integrierter Post-Quantum-Kryptographie.

\textbf{Guideline 2: Problem Relevance} - Design-Science-Forschung zielt auf technologiebasierte Lösungen für relevante Geschäftsprobleme \parencite[S. 84--85]{hevner_DesignScienceInformationsystemsresearch_2004}. Die Relevanz ergibt sich aus der Quantenbedrohung für KRITIS-Kryptographie und dem Bedarf an datenschutzfreundlichen Identitätslösungen.

\textbf{Guideline 3: Design Evaluation} - Die Nützlichkeit und Wirksamkeit eines Design-Artefakts müssen rigoros demonstriert werden \parencite[S. 85]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit validiert Funktionalität, Compliance und Kryptoagilität.

\textbf{Guideline 4: Research Contributions} - \ac{DSR} muss klare Beiträge zu Design-Artefakt, Foundations oder Methodologies liefern \parencite[S. 87]{hevner_DesignScienceInformationsystemsresearch_2004}. Der Beitrag liegt in der neuartigen Integration von PQC in SSI-Systeme für KRITIS-Kontexte.

\textbf{Guideline 5: Research Rigor} - \ac{DSR} beruht auf rigoroser Anwendung von Methoden in Konstruktion und Evaluation \parencite[S. 87]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit nutzt etablierte Frameworks (Hyperledger Indy, ACA-Py, Aries), NIST-standardisierte PQC-Algorithmen und wissenschaftlich hergeleitete Konzepte der Kryptoagilität.

\textbf{Guideline 6: Design as a Search Process} - Die Suche nach einem effektiven Artefakt erfordert iterative Exploration unter Berücksichtigung der Problemumgebung \parencite[S. 87--88]{hevner_DesignScienceInformationsystemsresearch_2004}. Der Design Cycle dieser Arbeit manifestiert sich als iterativer Prozess, bei dem Erkenntnisse aus einer Iteration die Designziele der nachfolgenden Iteration prägen.

\textbf{Guideline 7: Communication of Research} - Design-Science-Forschung muss effektiv sowohl für technologie-orientierte als auch für management-orientierte Audiences präsentiert werden \parencite[S. 90]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit adressiert dies durch eine umfassende Dokumentation des entwickelten Prototypen, systematische Darstellung der Evaluationsergebnisse sowie die explizite Ableitung \fixme{praktischer Implikationen} für kritische Infrastrukturen.

\subsection{FEDS-Framework} \label{sec:FEDS-Framework}

Nach \textcite[S. 2]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} ist die Evaluation von Design-Artefakten eine Schlüsselaktivität des \ac{DSR}, ohne die die Forschung auf der Ebene theoretischer Annahmen über die Utility eines Artefakts verbleibt, ohne Evidenz für dessen tatsächliche Funktionsfähigkeit zu liefern. Um diese Lücke zu schließen und Rigor sicherzustellen, folgt diese Arbeit dem \ac{FEDS}-Framework nach \textcite[S. 2, 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}, welches den Evaluationsprozess in vier iterative Schritte unterteilt, um die Strategie passgenau auf die spezifischen Projektrisiken abzustimmen.

Das \ac{FEDS}-Framework unterscheidet dabei fundamental zwischen zwei Dimensionen der Evaluation: der funktionalen Absicht (Why to evaluate) und dem Paradigma (How to evaluate). Hinsichtlich der Absicht wird zwischen formativer Evaluation, die der kontinuierlichen Verbesserung während der Entwicklung dient, und summativer Evaluation, die eine abschließende Bewertung der Zielerreichung vornimmt, differenziert. Bezüglich des Paradigmas unterscheidet das Framework zwischen Artificial Evaluation, die in kontrollierten Laborumgebungen stattfindet, und Naturalistic Evaluation, welche die Artefakte in realen organisatorischen Umfeldern unter echten Bedingungen prüft \parencite[S. 2, 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Im Folgenden wird der vierstufige FEDS-Prozess für die vorliegende Arbeit erläutert.

\subsubsection{Schritt 1: Explikation der Evaluationsziele}
Der erste Schritt des Frameworks verlangt die Explikation der Evaluationsziele, um Konflikte zwischen konkurrierenden Anforderungen wie Rigor, Risikominimierung und Effizienz aufzulösen \parencite[S. 6--7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für die Entwicklung eines blockchain-basierten \ac{SSI}-Protypen mit \ac{PQC} im \ac{KRITIS}-Kontext ergeben sich hieraus spezifische Prioritäten:

\textbf{Rigour (Efficacy vs. Effectiveness):} Das primäre Ziel dieser Arbeit ist der Nachweis der \textit{Efficacy}. Dies bedeutet den rigorosen Beleg, dass das instanziierte Artefakt (die \ac{PQC}-Integration in SSI) den beobachteten Effekt (sichere, quantenresistente Identitätsverifikation) kausal verursacht und nicht externe Störfaktoren \parencite[S. 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Da es sich bei \ac{KRITIS}-Komponenten um sicherheitskritische Infrastruktur handelt, muss vor einem Feldtest (\enquote{Effectiveness} in realer Umgebung) zwingend die funktionale Korrektheit in einer kontrollierten Umgebung bewiesen werden, um \enquote{False Positives}, eine fälschliche Annahme der Sicherheit, auszuschließen \parencite[S. 3]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.
    
\textbf{Risikoreduktion (Technical Risk):} Das Hauptrisiko dieser Arbeit ist technischer Natur. Es besteht die Unsicherheit, ob die \ac{PQC}-Algorithmen (ML-DSA, ML-KEM) technisch in bestehende SSI-Frameworks (Hyperledger Aries) integriert werden können, ohne deren Kernfunktionen zu brechen. Soziale Risiken (z.B. Benutzerakzeptanz der Wallet-App) werden als nachrangig eingestuft und nicht evaluiert.
    
\textbf{Ausschluss von Effizienz-Zielen:} In Anlehnung an die Design-Science-Leitlinien wird explizit darauf hingewiesen, dass eine quantitative Performance-Evaluation (\enquote{Efficiency}) nicht Ziel dieser Arbeit ist. Die verwendeten \ac{PQC}-Referenzimplementierungen befinden sich in einem frühen Stadium, weshalb Laufzeitmessungen keine valide Aussagekraft für zukünftige produktive Systeme hätten.

\subsubsection{Schritt 2: Wahl der Evaluationsstrategie}
Basierend auf den identifizierten Zielen und Risiken wird für diese Arbeit die \textbf{Technical Risk \& Efficacy Strategy} gewählt, welche mit formativen, artifiziellen Tests beginnt und in einer summativen, artifiziellen Evaluation endet (\autoref{fig:feds_strategy}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{FEDS_eval_strat}
    \caption{Gewählte Evaluationsstrategie im FEDS-Framework}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung in Anlehnung an \textcite[S. 4]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.
    \end{flushleft}
    \label{fig:feds_strategy}
\end{figure}

Diese Strategie ist nach \textcite[S. 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} dann indiziert, wenn das primäre Entwicklungsrisiko technischer Natur ist und Evaluationen in realen Umgebungen aus Sicherheits- oder Kostengründen nicht durchführbar sind.
Ein naturalisitischer Ansatz (\enquote{Human Risk \& Effectiveness}) wird verworfen, da der Zugriff auf reale \ac{KRITIS}-Netzwerke für experimentelle kryptografische Prototypen ethisch und regulatorisch nicht vertretbar ist und die Technologie noch nicht den Reifegrad für Endanwendertests besitzt.

\subsubsection{Schritt 3: Bestimmung der zu evaluierenden Eigenschaften}
Der dritte Schritt definiert die konkreten Eigenschaften, die evaluiert werden sollen \parencite[S. 7--8]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für das entwickelte Artefakt leiten sich diese direkt aus den in Kapitel~\ref{sec:Anforderungsanalyse} definierten Anforderungen ab:

\begin{enumerate}
    \item \textbf{Fidelity (Funktionale Korrektheit):} Das System muss in der Lage sein, den vollständigen SSI-Lebenszyklus (Issuance, Verification, Revocation) unter Verwendung von PQC-Signaturen fehlerfrei durchzuführen. Es wird geprüft, ob die Artefakte (Agenten, Ledger, Wallet) spezifikationsgemäß interagieren.
    \item \textbf{KRITIS-Compliance (Sicherheit):} Es wird evaluiert, ob die implementierten Mechanismen den regulatorischen Vorgaben entsprechen. Dies umfasst die strikte Durchsetzung von TLS 1.3, die Verwendung hybrider Verfahren und die Netzwerksegmentierung.
    \item \textbf{Interoperabilität:} Die Fähigkeit des modifizierten Systems, Standard-DIDComm-Nachrichten trotz der veränderten kryptografischen Payload zu verarbeiten, ist ein kritisches Kriterium für die Efficacy.
\end{enumerate}

\subsubsection{Schritt 4: Design der individuellen Evaluationsepisoden}
\label{sec:Schritt4-Design der individuellen Evaluationsepisoden}

Der vierte Schritt umfasst das Design konkreter Evaluationsepisoden \parencite[S. 8]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für diese Arbeit wurden drei diskrete Episoden definiert, die parallel zu den Entwicklungszyklen verlaufen und in \autoref{tab:eval_episodes} dem jeweiligen Arbeitsfortschritt zugeordnet sind.

\begin{longtable}{L{1.5cm}L{5cm}L{8.5cm}}
    \caption{Evaluationsepisoden nach \ac{FEDS}}
    \label{tab:eval_episodes} \\
    \toprule
    \textbf{Ep.} & \textbf{Phase \& Art (FEDS)} & \textbf{Fokus / Methode} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Ep.} & \textbf{Phase \& Art (FEDS)} & \textbf{Fokus / Methode} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung der Evaluationsstrategie in Anlehnung an das \ac{FEDS}-Framework von \textcite{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.} \\
    \endlastfoot
    1 & 
    Iteration 1 (Kapitel~\ref{sec:formative_evaluation_iteration1}) \newline 
    \textit{Formativ, Artifiziell} &
    White-Box Tests und Log-Analyse der Transportverschlüsselung sowie der Infrastrukturkomponenten. \\
    \midrule
    2 & 
    Iteration 2 (Kapitel~\ref{sec:formative_evaluation_iteration2}) \newline
    \textit{Formativ, Artifiziell} &
    Integrationstests der Plugin-Architektur, DIDComm-Verarbeitung und Validierung der PQC-Signaturen. \\
    \midrule
    3 & 
    Final (Kapitel~\ref{sec:Summative Evaluation}) \newline
    \textit{Summativ, Artifiziell} &
    Requirement Tracing und Validierung der \ac{KRITIS}-Compliance am integrierten Gesamtsystem. \\
\end{longtable}

\textbf{Episode 1 (Formativ):} Diese Episode erfolgt parallel zur ersten Iteration und fokussiert sich auf die Validierung der \textit{Transport-Layer-Security}. Da in dieser Phase fundamentale Infrastrukturkomponenten wie \glslink{Sidecar Proxy}{Sidecar Proxies} entwickelt werden, dient die formative Evaluation primär dazu, Designfehler so früh wie möglich zu identifizieren \parencite[S. 6, 7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Methodisch erfolgt dies durch die Analyse von Handshake-Protokollen und Cipher-Suites.

\textbf{Episode 2 (Formativ):} In der zweiten Iteration verlagert sich der Fokus auf den \textit{Application-Layer}. Hier wird formativ geprüft, ob die entwickelten Python-Plugins korrekt in den ACA-Py-Core geladen werden und ob die erweiterte Kryptografiebibliothek (liboqs) korrekt angesprochen wird.

\textbf{Episode 3 (Summativ):} Die abschließende Evaluation in Kapitel~\ref{sec:Summative Evaluation} führt alle Komponenten zusammen. Sie dient dem rigorosen Nachweis, dass das Gesamtsystem die eingangs definierten Forschungsfragen beantwortet. Hierbei wird geprüft, ob die Efficacy des \ac{PQC}-\ac{SSI}-Prototypen für \ac{KRITIS}-Anwendungsfälle gegeben ist, ohne reale Risiken einzugehen.

\subsection{DSRM Prozessmodell} \label{DSRM Prozessmodell}

Zur Sicherstellung einer rigorosen methodischen Fundierung orientiert sich der Forschungsablauf dieser Arbeit am \ac{DSRM} Prozessmodell nach \textcite[S. 46]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}, welches einen Rahmen für die Durchführung und Präsentation von \ac{DSR} bereitstellt um die wissenschaftliche Validität von Design-Artefakten zu gewährleisten.

\fixme{Da die vorliegende Arbeit durch die spezifischen Bedrohungen des Quantencomputings für bestehende Infrastrukturen und die daraus resultierenden regulatorischen Anforderungen für \ac{KRITIS} motiviert ist} (Kapitel~\ref{sec:Problemstellung und Motivation}), folgt das Forschungsvorhaben einer \enquote{Problem-Centered Initiation}. Dies entspricht dem klassischen Einstieg in den \ac{DSRM}-Prozess über die erste Phase (\autoref{fig:peffers_dsrm}) \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.

Neben der \enquote{Objective-Centered Solution}, die durch einen Bedarf in der Industrie oder Forschung ausgelöst wird (Phase 2), definieren die Autoren eine \enquote{Design \& Development Centered Initiation} auf Basis existierender Artefakte für explizite Problembereiche (Phase 3), sowie eine \enquote{Client-/Context-Initiated Solution}, welche auf der Beobachtung einer praktischen Lösung basiert (Phase 4), als drei weitere Einstiegspunkte \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{DSRM Process Model_red.png}
    \caption{DSRM Process Model}
    \begin{flushleft}
    \textit{Anmerkung.} Adaptiert aus \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.
    \end{flushleft}
    \label{fig:peffers_dsrm}
\end{figure}

Die Operationalisierung der sechs Phasen des \ac{DSRM} beginnt mit der Phase \enquote{Problem Identification and Motivation} \parencite[S. 52--55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}. Die Definition des spezifischen Forschungsproblems und dessen Relevanz für kritische Infrastrukturen wurde hierfür in Kapitel~\ref{sec:Problemstellung und Motivation} dargelegt. 

Darauf aufbauend werden in der Phase \enquote{Define the Objectives for a Solution} \parencite[S. 55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} aus der Problemanalyse konkrete Forschungsfragen (Kapitel~\ref{sec:Zielsetzung und Forschungsfragen}) und designrelevante Ziele für jede Iteration (Kapitel~\ref{sec:Designziele_Iteration_1} und Kapitel~\ref{sec:Designziele_Iteration_2}) abgeleitet, welche als Grundlage für die späteren Evaluationsphasen dienen.

Den Kern der Arbeit bildet die Phase \enquote{Design and Development} \parencite[S. 55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}, welche die Konzeption der Architektur sowie die technische Implementierung des \ac{PQC}-\ac{SSI}-Prototypen in beiden Iterationen umfasst (Kapitel~\ref{sec:Iterative Artefaktentwicklung}). Diese Phase operationalisiert die systematische Umsetzung der in den vorherigen Phasen definierten Anforderungen in ein funktionsfähiges Artefakt.

Die Eignung dieses Artefakts zur Problemlösung wird im Rahmen der Phase \enquote{Demonstration} \parencite[S. 55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} validiert. Diese erfolgt durch formative Evaluationsepisoden während der beiden Iterationen, welche schrittweise die Funktionsfähigkeit des Artefakts durch modulare Tests unter kontrollierten Bedingungen (Kapitel~\ref{sec:formative_evaluation_iteration1} und \ref{sec:formative_evaluation_iteration2}), bis hin zum vollständigen Prototypen (Kapitel~\ref{sec:Summative Evaluation}) nachweisen. 

Daran anschließend wird in der Phase \enquote{Evaluation} \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}strukturiert nach dem \ac{FEDS}-Framework (Kapitel~\ref{sec:FEDS-Framework}) in mehreren diskrete Evaluationsepisoden eine systematische Bewertung des Artefakts vorgenommen. Formative Episoden während beider Iterationen (Kapitel~\ref{sec:formative_evaluation_iteration1} und \ref{sec:formative_evaluation_iteration2}) adressieren technische Einzelfunktionen und Designfehler frühzeitig, die abschließende summative Evaluation in Kapitel~\ref{sec:Summative Evaluation} validiert systematisch die funktionale Korrektheit, \ac{KRITIS}-Compliance und Kryptoagilität des integrierten Gesamtsystems.

Den Abschluss bildet die Phase \enquote{Communication} \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}, in der die Ergebnisse, der Designprozess und die Evaluation durch die vorliegende schriftliche Ausarbeitung dokumentiert und der wissenschaftlichen Gemeinschaft zur Verfügung gestellt werden.

Obwohl das Modell sequenziell dargestellt ist, handelt es sich bei der Entwicklung in Kapitel~\ref{sec:Iterative Artefaktentwicklung} um einen iterativen Prozess, der Rücksprünge von der Evaluation zur Design-Phase erlaubt, um das Artefakt schrittweise zu verfeinern \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.

\newpage
\section{Erste Iteration der Artefaktentwicklung}
\label{sec:Erste Iteration der Artefaktentwicklung}

\subsection{Designziele dieser Iteration} \label{sec:Designziele_Iteration_1}

Die Designziele dieser Iteration leiten sich unmittelbar aus den in Kapitel~\ref{sec:Zielsetzung und Forschungsfragen} definierten Forschungsfragen ab und werden operationalisiert durch eine schichtenbasierte Architektur, die die Quantensicherheit auf der Transportebene verankert. 

Im Fokus von FF1 (Systemarchitektur \& Compliance) steht die Etablierung einer modularen Architektur mit klarer Separation zwischen SSI-Agenten, DLT-Infrastruktur und quantensicherer Transportschicht auf Basis ausgewählter Frameworks und Technologien. Das Design soll die Kernherausforderung, Post-Quantum-Kryptografie nicht-invasiv und modular zu integrieren, adressieren.

Bezüglich FF2 (Algorithmenauswahl und Sicherheitsbewertung) liegt das Designziel auf der Erprobung quantenresistenter kryptografischer Primitive für die Transportebene auf Basis standardisierter Algorithmen und hybrider Schlüsselaustauschverfahren. Die formative Evaluierung soll dabei die technische Machbarkeit dieser Algorithmen in der Infrastruktur validieren und Erkenntnisse für die nachgelagerte Iteration generieren.

Für FF3 (Kryptografische Agilität) zielt diese Iteration auf die architektonische Vorbereitung für Austauschbarkeit kryptografischer Algorithmen ab. Das Design soll durch modulare Infrastrukturkomponenten die Voraussetzungen für zukünftige Algorithmenupdates ohne grundlegende Systemumgestaltung schaffen.

\subsection{Anforderungsanalyse} \label{sec:Anforderungsanalyse}

\subsubsection{Funktionale Anforderungen} \label{sec:Funktionale Anforderungen}

Basierend auf der Analyse von \textcite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021} lassen sich für das SSI-System sechs zentrale funktionale Anforderungen identifizieren, die den den vollständigen Lebenszyklus digitaler Identitätsnachweise ab decken (\autoref{tab:functional_requirements}).

\begin{longtable}{L{1cm}L{4cm}L{9cm}}
    \caption{Funktionale Anforderungen an SSI-Systeme}
    \label{tab:functional_requirements} \\
    \toprule
    \textbf{Nr.} & \textbf{Funktionale Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Nr.} & \textbf{Funktionale Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung auf Basis der Auflistungen und des Sequenzdiagramms in Anlehnung an \textcite[S. 130-132]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}.} \\
    \endlastfoot
    1 & Issuer Discovery &
    Das System muss die Auffindbarkeit von publizierten Credential Schemata des Issuers digitaler Identitätsnachweise ermöglichen. \\
    \midrule
    2 & Connection Creation &
    Das System muss Verbindungen zwischen den Akteuren des SSI-Ökosystems etablieren können. \\
    \midrule
    3 & Credential Creation &
    Das System muss Funktionalität zur Erstellung und Ausstellung digitaler Credentials bereitstellen. \\
    \midrule
    4 & Verification with Credentials &
    Das System muss einen Verifikationsprozess zwischen Identity Holder, Verifier und Blockchain-basierter \ac{VDR} durch Validierung eines Identitätsnachweises ermöglichen. \\
    \midrule
    5 & Credential Revocation &
    Das System muss die Funktionalität zum Widerruf von Credentials unterstützen. \\
    \midrule
    6 & Credential Deletion &
    Das System muss die Funktionalität zur Löschung von Credentials unterstützen. \\
\end{longtable}

\subsubsection{KRITIS-spezifische Compliance-Anforderungen} \label{sec:KRITIS-spezifische Compliance-Anforderungen}

Die in \autoref{tab:compliance_requirements} konsolidierten Anforderungen definieren den normativen Rahmen für die Gestaltung und Evaluierung des \ac{PQC}-\ac{SSI}-Prototypen im Kontext KRITIS.

Im Bereich der \textbf{kryptografischen Verfahren} (Nr. 1-4) basieren die Vorgaben primär auf den Technischen Richtlinien des BSI. Für die Migration auf Post-Quantum-Kryptografie ist insbesondere die Wahl spezifischer Parameter-Sets für ML-DSA (NIST Level 3/5) und ML-KEM (Level 3/5) sowie die zwingende Implementierung hybrider Schlüsseleinigung vorgeschrieben, um sowohl Integrität als auch langfristige Vertraulichkeit gegen Quantencomputer-Angriffe zu gewährleisten \parencite[Kap. 2.2, 2.4, 5.3.4.2]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. Ergänzend fordert die TR-02102-2 den Einsatz moderner Transportverschlüsselung via TLS 1.3, um durch Perfect Forward Secrecy (PFS) die Kommunikationskanäle abzusichern \parencite[Kap. 3.2]{bsi_TechnischeRichtlinieTR021022KryptographischeVerfahrenEmpfehlungenundSchlussellangenTeil2VerwendungTransport_2025}.

Hinsichtlich der \textbf{Betriebssicherheit} (Nr. 5-6) leiten sich die Anforderungen direkt aus dem IT-Sicherheitsgesetz 2.0 (BSIG) und internationalen Standards ab. Essenziell für KRITIS-Betreiber ist hierbei die Implementierung effektiver \gls{SzA} durch umfassende Protokollierung sicherheitsrelevanter Ereignisse gemäß § 8a BSIG \parencite[Nr. 101, 103]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024}. Flankierend schreibt die ISO/IEC 27001 eine strikte logische Netzsegmentierung vor, um die Ausbreitung potenzieller Sicherheitsvorfälle innerhalb der Infrastruktur zu begrenzen \parencite[Control A.8.22]{iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022}.

Die dritte Säule bildet der \textbf{Datenschutz} (Nr. 7-9) auf Basis der DSGVO. Hierbei stehen Prinzipien wie \textit{Privacy by Design} gemäß Art. 25 und Datenminimierung nach Art. 5 im Fokus. Zudem muss das Recht auf Löschung nach Art. 17 durch geeignete Architekturmuster, etwa die Trennung von Identifikatoren und Inhaltsdaten, technisch gewährleistet werden \parencite[Art. 5, 17, 25]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}.

\begin{longtable}{L{1cm}L{4cm}L{9cm}}
    \caption{Compliance Anforderungen an SSI-Systeme im KRITIS-Kontext}
    \label{tab:compliance_requirements} \\
    \toprule
    \textbf{Nr.} & \textbf{Compliance Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Nr.} & \textbf{Compliance Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung auf Basis von \textcite{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025,bsi_TechnischeRichtlinieTR021022KryptographischeVerfahrenEmpfehlungenundSchlussellangenTeil2VerwendungTransport_2025,bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024,iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022,daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}.} \\
    \endlastfoot
    1 & Einhaltung spezifischer Parameter-Sets für ML-DSA &
    Zur Gewährleistung der vom BSI geforderten Sicherheitsniveaus dürfen für das Verfahren ML-DSA ausschließlich die Parameter-Sets verwendet werden, die den NIST Security Strength Categories 3 oder 5 entsprechen. Konkret sind dies ML-DSA-65 oder ML-DSA-87 \parencite[Kap. 5.3.4.2]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025} \\
    \midrule
    2 & Einhaltung spezifischer Parameter-Sets für ML-KEM &
    Für den langfristigen Schutz vertraulicher Informationen mittels des gitterbasierten Schlüsselkapselungsverfahrens ML-KEM dürfen gemäß BSI-Einschätzung ausschließlich Parametersätze verwendet werden, die den NIST Security Strength Categories 3 oder 5 entsprechen. Zulässig sind demnach ML-KEM-768 sowie ML-KEM-1024 \parencite[Kap. 2.4.3]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. \\
    \midrule
    3 & Implementierung hybrider Schlüsseleinigung &
    Um langfristige Vertraulichkeit (Schutz vor \textit{Store Now, Decrypt Later}) zu gewährleisten, muss für die Schlüsseleinigung zwingend ein hybrides Verfahren implementiert werden, das ein anerkanntes klassisches Verfahren mit einem empfohlenen PQC-KEM kombiniert \parencite[Kap. 2.2, 2.4]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. \\
    \midrule
    4 & Bevorzugte Verwendung von TLS 1.3 &
    Für die Absicherung der Transportebene wird gemäß \textcite[Kap. 3.2]{bsi_TechnischeRichtlinieTR021022KryptographischeVerfahrenEmpfehlungenundSchlussellangenTeil2VerwendungTransport_2025} vorrangig das Protokoll TLS 1.3 empfohlen, da es PFS erzwingt und auf unsichere Cipher-Suites verzichtet. \\
    \midrule
    5 & Protokollierung sicherheitsrelevanter Ereignisse &
    Sicherheitsrelevante Ereignisse müssen auf System- und Netzebene zentral protokolliert werden, um eine zeitnahe Erkennung von Angriffen zu ermöglichen \parencite[Nr. 101, 103]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024}. \\
    \midrule
    6 & Logische Netzsegmentierung &
    Gruppen von Informationsdiensten, Benutzern und Informationssystemen sollten in den Netzwerken der Organisation getrennt werden \parencite[Control A.8.22]{iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022}. \\
    \midrule
    7 & Datenschutz durch Technikgestaltung (Privacy by Design) &
    Gemäß \textcite[Art. 25]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016} sind bereits bei der Entwicklung des Systems geeignete technische Maßnahmen zu treffen, die die Datenschutzgrundsätze addressieren. \\
    \midrule
    8 & Grundsatz der Datenminimierung &
    Personenbezogene Daten müssen dem Zweck angemessen und auf das notwendige Maß beschränkt sein. \parencite[Art. 5]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}. \\
    \midrule
    9 & Recht auf Löschung &
    Die betroffene Person hat das Recht, von dem Verantwortlichen die unverzügliche Löschung sie betreffender personenbezogener Daten zu verlangen. Der Verantwortliche ist verpflichtet, personenbezogene Daten unverzüglich zu löschen \parencite[Art. 17]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}. \\
\end{longtable}

\subsection{Framework- und Technologie-Auswahl}

Wie von \textcite[S. 3]{ghosh_DecentralizedCrossNetworkIdentityManagementBlockchainInteroperation_2021} demonstriert, setzt auch die vorliegende Arbeit auf existierende Konzepte und Tools für dezentrale Identitätsverwaltung als Bausteine für die Entwicklung des \ac{PQC}-\ac{SSI}-Prototypen. Die systematische Auswahl der Frameworks und Technologien -- bestehend aus der \ac{DLT}-Plattform, dem SSI-Framework, der Kryptografiebibliothek, der Revocation-Infrastruktur und dem \gls{Sidecar Proxy} -- wird transparent in \ref{sec:Anhang_Framework- und Technologie-Auswahl} dokumentiert und begründet.

\subsection{Architekturentwurf}

\subsubsection{Gesamtarchitektur}
\label{sec:Gesamtarchitektur_Iteration1}

Der Architekturentwurf dieser Iteration operationalisiert die in Kapitel~\ref{sec:Designziele_Iteration_1} definierten Designziele durch eine dreischichtige, containerbasierte Systemarchitektur, die Post-Quantum-Kryptografie auf der Transportebene verankert. Abbildung~\ref{fig:Architektur_Iteration1} visualisiert die Zielarchitektur, bestehend aus der DLT-Schicht mit vier Hyperledger-Indy-Validator-Nodes samt Ledger Browser, der Revocation-Schicht mit dediziertem Tails-Server sowie der SSI-Agenten-Schicht mit drei ACA-Py-Instanzen in den Rollen Issuer, Holder und Verifier.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Architektur_Iteration1}
    \caption{Architekturentwurf der ersten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Architektur_Iteration1}
\end{figure}

Das zentrale Architekturprinzip bildet das Sidecar Proxy Pattern (\ref{sec:Anhang_Sidecar Proxy}). Jede extern erreichbare Komponente wird durch einen NGINX-basierten \ac{PQC} Sidecar Proxy geschützt, der TLS-1.3-Verbindungen mit \glslink{Hybride Schemata}{hybrider Schlüsseleinigung} terminiert und im Fallback \ac{ECC} (X25519MLKEM768:x25519) unterstützt. Die Authentifizierung erfolgt über ML-DSA-65-signierte X.509-Zertifikate. In \autoref{fig:Architektur_Iteration1} wird diese verschlüsselte Kommunikation durch die rot-gestrichelten Verbindungspfeile zwischen den Sidecar Proxies visualisiert.

Die Backend-Dienste (Indy-Nodes, Webserver, Tails-Server und ACA-Py-Agents) verbleiben innerhalb isolierter interner Docker-Netzwerke und kommunizieren ausschließlich über unverschlüsseltes HTTP. Externe Zugriffe erfolgen ausschließlich über das gemeinsame Netzwerk sidecar\_proxy, das als quantensichere Kommunikationsdomäne fungiert und eine strikte Netzsegmentierung gemäß der sechsten \ac{KRITIS}-Anforderung (\autoref{tab:compliance_requirements}) gewährleistet.

\subsubsection{ACA-Py Applikationsarchitektur}
\label{sec:ACA-Py Applikationsarchitektur_Iteration1}

Die Architektur von \ac{ACA-Py} folgt einem modularen Designansatz, der durch eine strikte Trennung zwischen der generischen Protokollebene und der anwendungsspezifischen Geschäftslogik gekennzeichnet ist. Dieses Architekturmuster entkoppelt die kryptografischen Kernfunktionen und das DIDComm-Messaging (Agent) von der Steuerungslogik (Controller) \parencite{openwallet-foundation_AcapyREADMEmdMainopenwalletfoundationacapyGitHub_}. \autoref{fig:ACAPY_Application_Architecture_Iteration 1} visualisiert diese High-Level-Applikationsarchitektur und verdeutlicht die Interaktion der Schichten.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{ACAPY Application Architecture_Iteration 1}
    \caption{ACA-Py High Level Applikationsarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung auf Basis von \textcite{openwallet-foundation_AcapyREADMEmdMainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentAdminserverpymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentProtocolsout_of_bandv1_0routespymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentProtocolsissue_credentialv2_0routespymainopenwalletfoundationacapyGitHub_,decentralized-identity_AriesrfcsFeatures0434outofbandREADMEmdmaindecentralizedidentityariesrfcs_,decentralized-identity_AriesrfcsFeatures0023didexchangemaindecentralizedidentityariesrfcs_,decentralized-identity_AriesrfcsFeatures0453issuecredentialv2maindecentralizedidentityariesrfcsGitHub_,openwallet-foundation_AcapyAcapy_agentWalletaskarpymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentProtocolsout_of_bandv1_0managerpymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentAskarstorepymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentAskardidcommv1pymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentTransportinboundhttppymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentTransportoutboundhttppymainopenwalletfoundationacapyGitHub_}.
    \end{flushleft}
    \label{fig:ACAPY_Application_Architecture_Iteration 1}
\end{figure}

Layer 1 bildet eine HTTP-REST-API (Admin API), die über \enquote{server.py} implementiert wird \parencite{openwallet-foundation_AcapyAcapy_agentAdminserverpymainopenwalletfoundationacapyGitHub_}. Sie ermöglicht es Controller-Anwendungen den Agent über standardisierte Endpoints wie \enquote{/out-of-band/create-invitation} \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsout_of_bandv1_0routespymainopenwalletfoundationacapyGitHub_} oder \enquote{/issue-credential-2.0/send} \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsissue_credentialv2_0routespymainopenwalletfoundationacapyGitHub_} zu steuern, ohne direkt mit der Python-Codebasis zu interagieren. Die Endpunkte werden hierbei durch mehrere \enquote{routes.py} umgesetzt.

Layer 2 implementiert die SSI-Geschäftslogik als Protocol Handler durch mehrere \enquote{manager.py}, die Aries \ac{RFC}s umsetzen. Das Out-of-Band Protocol (RFC 0434) \parencite{decentralized-identity_AriesrfcsFeatures0434outofbandREADMEmdmaindecentralizedidentityariesrfcs_} generiert Invitation-Nachrichten mit \enquote{did\:peer\:4-DIDs} \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsout_of_bandv1_0managerpymainopenwalletfoundationacapyGitHub_}, das DID Exchange Protocol (RFC 0023) \parencite{decentralized-identity_AriesrfcsFeatures0023didexchangemaindecentralizedidentityariesrfcs_} authentifiziert Agent-Verbindungen mittels ED25519-Signaturen \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsdidexchangev1_0managerpymainopenwalletfoundationacapyGitHub_}, und das Issue Credential Protocol (RFC 0453) \parencite{decentralized-identity_AriesrfcsFeatures0453issuecredentialv2maindecentralizedidentityariesrfcsGitHub_} erstellt AnonCreds-Credentials \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsissue_credentialv2_0managerpymainopenwalletfoundationacapyGitHub_}.

Layer 3 abstrahiert die Schlüsselverwaltung durch das Aries-Askar-Wallet \parencite{openwallet-foundation_AcapyAcapy_agentWalletaskarpymainopenwalletfoundationacapyGitHub_}, das ED25519-Schlüsselpaare für Signaturen und X25519-Schlüsselpaare für Key Agreement generiert \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_}, diese mit Multicodec-Präfixen kodiert \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_} und verschlüsselt in einer SQLite-Datenbank ablegt \parencite{openwallet-foundation_AcapyAcapy_agentAskarstorepymainopenwalletfoundationacapyGitHub_}, wobei ChaCha20-Poly1305-Authenticated-Encryption verwendet wird \parencite{openwallet-foundation_AcapyAcapy_agentAskardidcommv1pymainopenwalletfoundationacapyGitHub_}.

Layer 4 realisiert das DIDComm-Messaging über \enquote{pack\_message()} und \enquote{unpack\_message()} \parencite{openwallet-foundation_AcapyAcapy_agentAskardidcommv1pymainopenwalletfoundationacapyGitHub_}, welches anschließend mittels HTTP-basierter Transport-Mechanismen für Inbound- \parencite{openwallet-foundation_AcapyAcapy_agentTransportinboundhttppymainopenwalletfoundationacapyGitHub_} und Outbound-Kommunikation \parencite{openwallet-foundation_AcapyAcapy_agentTransportoutboundhttppymainopenwalletfoundationacapyGitHub_} übertragen wird, wobei in der klassischen Architektur kein quantensicheres TLS verwendet wird.

\subsection{Implementierung}

Die Implementierung realisiert die Zertifikatsinfrastruktur mit ML-DSA-Signaturen, PQC-Sidecar-Proxies mit TLS~1.3 und hybrider Schlüsseleinigung, die Hyperledger-Indy-DLT-Schicht, die Revocation Registry sowie drei ACA-Py-Agenten, die mittels Docker-Compose mit expliziter Netzsegmentierung orchestriert werden. Die hierfür genutzte Entwicklungsumgebung ist in \ref{sec:Anhang_Setup der Entwicklungsumgebung} dokumentiert.

\subsubsection{Zertifikatsstruktur}
\label{sec:Zertifikatsstruktur}

Die Zertifikatsinfrastruktur für die PQC-Sidecar-Proxies basiert auf einer selbstsignierten Root \ac{CA}, die mit dem Post-Quantum-Signaturalgorithmus ML-DSA-87 erstellt wurde. Die Root \ac{CA} dient als Trust Anchor für alle in der Architektur verwendeten TLS-Zertifikate und gewährleistet, dass sämtliche Zertifikatssignaturen quantenresistent nach der höchsten \ac{NIST} Sicherheitsstufe 5 sind \parencite[S. 15]{nationalinstituteofstandardsandtechnologyus_ModulelatticebasedDigitalSignaturestandard_2024} .

Das Zertifikatserstellungsverfahren folgt einem fünfschrittigen Workflow, wie in \autoref{fig:Zertifikatserstellungsworkflow} dargestellt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Zertifikatserstellungsworkflow}
    \caption{Zertifikatserstellungsworkflow für PQC-basierte Sidecar-Proxies}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Zertifikatserstellungsworkflow}
\end{figure}

Zunächst wird der Root-CA-Schlüssel generiert (Step 1), gefolgt von der Erstellung des selbstsignierten Root-CA-Zertifikats mit einer Gültigkeit von zehn Jahren (Step 2). Anschließend werden für jeden Sidecar-Proxy dedizierte Schlüssel mit ML-DSA-65 generiert (Step 3), die ein besseres Verhältnis zwischen Sicherheit und Speicherbedarf bieten \parencite[S. 16]{nationalinstituteofstandardsandtechnologyus_ModulelatticebasedDigitalSignaturestandard_2024}. Für jeden Proxy wird ein Certificate Signing Request erstellt, der die erforderlichen Subject Alternative Names enthält (Step 4), bevor die Zertifikate abschließend von der Root CA mit ML-DSA-65 und SHA3-256 signiert werden (Step 5). Die detaillierte Implementierung dieses Workflows ist in \ref{sec:Anhang_Zertfikatserstellungsworkflow} dokumentiert.

\subsubsection{Sidecar Proxy nginx}
\label{sec:Sidecar Proxy nginx}

Die Implementierung der post-quanten-kryptographischen Absicherung auf Transport-Layer-Ebene basiert auf einer modifizierten Version des NGINX-Dockerfiles von \textcite{open-quantum-safe_OpenquantumsafeOqsdemosNginxDockerfile_2025} sowie spezifischen NGINX-Konfigurationsdateien für jeden \gls{Sidecar Proxy}. Beide Komponenten realisieren ein konsistentes Konzept bestehend aus Hybrid-Key-Exchange mit \ac{ECC} als Fallback, welches auf Transport-Layer-Ebene Anwendung findet.

Das modifizierte Dockerfile folgt dem Multi-Stage-Build-Prinzip nach \textcite[S. 1]{rosa_MiningMeasuringImpactchangepatternsimprovingsizebuildtimedockerimages_2025} und integriert OpenSSL 3.5.4, liboqs und den oqs-provider. \autoref{fig:Sidecar_Proxy_nginx_Dockerfile} visualisiert die zwei zentralen Phasen (Build-Stage und Runtime-Stage) sowie die Modifikationen gegenüber dem Original-Dockerfile (rote Markierungen). Die Hybrid-Key-Exchange mit \ac{ECC}-Fallback wird durch die DEFAULT-GROUPS-Konfiguration X25519MLKEM768:X25519 realisiert, eine Konvention, die sich konsistent durch die gesamte Implementierung zieht und in \ref{sec:Anhang_Dockerfile Sidecar Proxy nginx} ausführlich erläutert wird.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{2 Stage Sidecarproxy Dockerfile}
    \caption{Sidecar Proxy NGINX Dockerfile Multi-Stage Build}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Sidecar_Proxy_nginx_Dockerfile}
\end{figure}

Die NGINX-Konfigurationsdateien implementieren ein standardisiertes \gls{Sidecar Proxy} Pattern, das diese Architektur operationalisiert. Sie folgen einem konsistenten Schichtenmodell aus globalen Parametern, internen Service-Abstraktionen über Upstream-Blöcke und externen HTTPS-Endpunkten über Server-Blöcke. TLS~1.3 wird durch die Direktive ssl\_ecdh\_curve X25519MLKEM768:X25519 konfiguriert (Listing~\ref{lst:nginx_holder.conf}), wodurch Schlüsselaustausch und Fallback auf klassische \ac{ECC}-basierte Kurven ermöglicht werden. Die aktivierte Direktive ssl\_protocols TLSv1.3 wird durch SSL-Zertifikate mit ML-DSA-65-Signaturalgorithmus ergänzt, sodass sowohl der Schlüsselaustausch als auch die Server-Authentifikation post-quantensicher erfolgen. Die gesamte Konfiguration wird in \ref{sec:Anhang_nginx_holder.conf} erläutert.

\subsubsection{DLT-Infrastruktur}

Für die \ac{PQC}-Integration Transport-Layer-Ebene wurde die von-network-Architektur um einen PQC Nginx Sidecar Proxy erweitert.
Diese Modifikation stellt die zentrale Anpassung gegenüber dem Original-Quellcode \parencite{bcgov_GitHubBcgovVonnetworkportabledevelopmentlevelIndyNodenetwork_} dar und betrifft primär die docker-compose.yml-Konfigurationsdatei (Listing \ref{lst:docker-compose.yml-DLT-Infrastruktur}), sowie die Hinzufügung eines neuen Verzeichnisses \enquote{pqc\_sidecarproxy\_nginx/}, welches die in Kapitel~\ref{sec:Sidecar Proxy nginx} und Kapitel~\ref{sec:Zertifikatsstruktur} vorgestellten Dockerfile-, Nginx-Konfigurationsdatei und Zertifikate für den quantensicheren \gls{Sidecar Proxy} enthält. Der Webserver-Container, der im Original-Setup direkt auf Port 9000 exponiert ist \parencite{bcgov_VonnetworkDockercomposeymlMainbcgovvonnetworkGitHub_}, verbleibt in der modifizierten Architektur ausschließlich im internen Docker-Netzwerk \enquote{von}. Stattdessen terminiert der neu hinzugefügte pqc-sidecarproxy-webserver-Container alle eingehenden \ac{TLS}-1.3-Verbindungen auf Port 8000 und leitet die Anfragen nach erfolgreicher \glslink{Hybride Schemata}{hybrider Schlüsselvereinbarung} und ML-DSA-65-Zertifikatsverifikation als unverschlüsseltes HTTP an den internen Webserver-Container weiter. Die unmodifizierte von-network-Implementierung wird in Kapitel~\ref{sec:Anhang_DLT-Infrastruktur} näher erläutert.

Die Integration des Sidecar Proxies erforderte die Definition eines zusätzlichen, extern zugänglichen Docker-Netzwerks \enquote{von\_sidecarproxy}, das als gemeinsame Kommunikationsebene für alle PQC-Proxies der Gesamtarchitektur dient. Dieses Netzwerk wird in der docker-compose.yml (Listing \ref{lst:docker-compose.yml-DLT-Infrastruktur}) als \enquote{external: true} deklariert. Der pqc-sidecarproxy-webserver-Container ist sowohl mit dem internen von-Netzwerk (für Backend-Kommunikation) als auch mit dem externen von\_sidecarproxy-Netzwerk (für Client-Zugriffe) verbunden, wodurch eine strikte Netzwerksegmentierung zwischen interner und externer Kommunikation gewährleistet wird.

\subsubsection{Revocation Registry}

Für die Integration in die Post-Quantum-gesicherte Gesamtarchitektur wurde der indy-tails-server analog zur DLT-Infrastruktur um einen PQC Nginx Sidecar Proxy erweitert. Diese Modifikation betrifft primär die Docker-Compose-Konfigurationsdatei (Listing \ref{lst:docker-compose.yml-Revocation-Registry}), in der ein zusätzlicher Service \enquote{pqc-sidecarproxy-tails-server} definiert wurde, sowie die Hinzufügung eines neuen Verzeichnisses \enquote{pqc\_sidecarproxy\_nginx/}, welches die in Kapitel~\ref{sec:Sidecar Proxy nginx} und Kapitel~\ref{sec:Zertifikatsstruktur} vorgestellten Dockerfile-, Nginx-Konfigurationsdatei und Zertifikate für den quantensicheren \gls{Sidecar Proxy} enthält. Der ursprüngliche Tails-Server-Container verbleibt im internen Docker-Netzwerk \enquote{tails-server} und exponiert Port 6543 ausschließlich innerhalb dieses Netzwerks. Der neu hinzugefügte PQC-Proxy-Container terminiert alle externen \ac{TLS}-1.3-Verbindungen auf Port 6543 und leitet die Anfragen nach erfolgreicher erfolgreicher \glslink{Hybride Schemata}{hybrider Schlüsselvereinbarung} und ML-DSA-65-Zertifikatsverifikation als unverschlüsseltes HTTP an den internen Tails-Server weiter. Die unmodifizierte indy-tails-server-Implementierung wird in Kapitel~\ref{sec:Anhang_Revocation Registry} näher erläutert.

Die Netzwerk-Integration folgt dem etablierten \gls{Sidecar Proxy} Pattern. Der \enquote{pqc-sidecarproxy-tails-server}-Container ist sowohl mit dem internen \enquote{tails-server}-Netzwerk (für Backend-Kommunikation) als auch mit dem externen, manuell erstellten \enquote{von\_sidecarproxy}-Netzwerk (für Client-Zugriffe) verbunden. Diese Dual-Network-Architektur erzwingt, dass alle externen Zugriffe auf den Tails-Server über den quantensicheren \gls{Sidecar Proxy} geleitet werden.

\subsubsection{SSI-Agenten} \label{SSI-Agenten}

Die SSI-Agent-Schicht bildet die Anwendungsebene der Gesamtarchitektur und implementiert die drei klassischen Rollen des SSI-Ökosystems Issuer, Holder und Verifier (Kapitel~\ref{sec:Self-Sovereign Identity}) samt ihrer dedizierten PQC Nginx Sidecar Proxies. Die Architektur folgt dem in Kapitel~\ref{sec:ACA-Py Applikationsarchitektur} beschriebenen Referenzmodell, alle drei Agenten basieren auf dem unmodifizierten \ac{ACA-Py} Base-Image (Listing \ref{lst:Dockerfile-acapy-base}) und werden ausschließlich über Kommandozeilen-Parameter konfiguriert, ohne Änderungen am ACA-Py-Quellcode vorzunehmen.

Listing \ref{lst:docker-compose.yml-SSI-Agenten} zeigt die Docker-Compose-Konfiguration der drei ACA-Py-Agenten innerhalb der Gesamtarchitektur. Die Agent-Konfiguration erfolgt hierbei vollständig deklarativ über Docker-Compose-Service-Definitionen, die jeweils den \enquote{start}-Befehl von \ac{ACA-Py} mit rollenspezifischen Parametern aufrufen. Jeder Agent wird in einem dedizierten Docker-Netzwerk isoliert betrieben und über einen PQC Nginx Sidecar Proxy mit quantensicherer TLS-1.3-Verschlüsselung nach außen exponiert. Die Wallet-Konfiguration nutzt persistente Docker-Volumes zur Speicherung von DIDs, Credentials und Connections über Container-Neustarts hinweg. Die Agents verbinden sich über PQC-gesicherte Proxies mit der DLT-Infrastruktur und der Revocation Registry. Auto-Response-Features ermöglichen vollständig scriptgesteuerte SSI-Workflows ohne manuelle Interaktion. Die Netzwerk-Architektur folgt einem strikten Isolation-Prinzip, sodass Agents nur über das externe \enquote{von\_sidecarproxy}-Netzwerk untereinander kommunizieren können. Health-Checks und Service-Dependencies orchestrieren deterministische Startup-Sequenzen und eliminieren Race-Conditions während des Deployments.
Eine ausführliche Darstellung der Agent-Konfigurationsparameter und der Sidecar-Proxy-Architektur findet sich in \ref{sec:Anhang_SSI-Agenten}.

\subsubsection{Docker Orchestrierung der Gesamtarchitektur} \label{sec:Docker Orchestrierung der Gesamtarchitektur}

Die in den vorangegangenen Abschnitten beschriebenen Einzelkomponenten -- Zertifikatsinfrastruktur, PQC-Sidecar-Proxies, DLT-Infrastruktur, Revocation Registry und SSI-Agenten -- werden mittels einer mehrstufigen Docker-Compose-Orchestrierung zu einem funktionsfähigen Gesamtsystem integriert. Der Startprozess der Gesamtarchitektur folgt einer deterministischen Sequenz, die in Listing~\ref{lst:Docker-Compose-Start-der-Gesamtarchitektur} dokumentiert ist und die korrekten Abhängigkeiten zwischen den Infrastrukturschichten gewährleistet.

Die Orchestrierung gliedert sich in drei sequenzielle Phasen, die jeweils durch separate Docker-Compose-Konfigurationen gesteuert werden. In der ersten Phase wird die DLT-Infrastruktur über das von-network-Management-Skript (Listing~\ref{lst:von-network-manage-script}) initialisiert, wodurch die vier Indy-Validator-Nodes, der Genesis-Webserver sowie der zugehörige PQC-Sidecar-Proxy gestartet werden. Diese Phase erzeugt das gemeinsame externe Docker-Netzwerk \enquote{von\_sidecarproxy}, das als zentrale Kommunikationsschicht für alle quantensicheren Verbindungen dient. Die zweite Phase umfasst die Initialisierung der Revocation Registry mittels des indy-tails-server-Management-Skripts (Listing~\ref{lst:indy-tails-server-manage-script}), wodurch der Tails-Server-Container sowie dessen PQC-Proxy-Frontend bereitgestellt werden. In der dritten Phase werden schließlich die SSI-Agenten gemeinsam mit ihren jeweiligen PQC-Sidecar-Proxies über die projektspezifische Docker-Compose-Konfiguration (Listing~\ref{lst:docker-compose.yml-SSI-Agenten}) gestartet.

Die in \autoref{fig:Docker-Compose-Übersicht-Iteration-1} visualisierte Containerarchitektur verdeutlicht die resultierende Systemtopologie. Die Gesamtarchitektur umfasst insgesamt 14 Container, die sich auf die drei funktionalen Schichten verteilen. Die DLT-Schicht besteht aus insgesamt sechs Containern, den vier Validator-Nodes, einem Webserver und einem PQC Sidecar Proxy. Die Revocation-Schicht umfasst insgesamt zwei Container, einen Tails-Server und dessen PQC Sidecar Proxy. Die Agent-Schicht besteht aus insgesamt sechs Containern für die drei SSI-Agenten und ihre jeweiligen PQC Sidecar Proxies.

Die Netzwerktopologie nutzt sechs dedizierte Docker-Bridges, um die logische Separation der Schichten zu realisieren. Das hope\_hope-holder-, hope\_hope-issuer- und hope\_hope-verifier-Netzwerk verbinden jeweils die SSI-Agenten mit der DLT-Schicht. Das docker\_tails-server-Netzwerk isoliert die Revocation-Infrastruktur, während das von\_sidecarproxy-Netzwerk die PQC-Sidecar-Proxies konnektiviert. Das von\_von-Netzwerk integriert die Validator-Nodes untereinander und mit der Revocation-Schicht.

Die Datenpersistenz wird durch elf Docker Volumes realisiert. Während docker\_nginx-logs und von\_nginx-logs die Webserver-Logs aggregieren, speichern hope\_holder-data, hope\_issuer-data und hope\_verifier-data die lokalen Wallets und kryptografischen Materialien der SSI-Agenten. Die Validator-Node-Datenbank wird durch von\_node1-data bis von\_node4-data persistiert, während von\_webserver-cli und von\_webserver-ledger die Ledger-Zustandsdaten und CLI-Konfigurationen verwalten. Diese Volumenstruktur entkoppelt den Containern-Lebenszyklus vom Datenschicksal und ermöglicht die Wiederaufnahme der Systemzustände über Container-Neustarts hinweg.

Die \enquote{depends\_on}-Direktiven in den Docker-Compose-Konfigurationen (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry} und Listing~\ref{lst:docker-compose.yml-SSI-Agenten}) definieren explizite Startup-Abhängigkeiten, die Race-Conditions während des Deployment-Prozesses eliminieren. Die PQC Sidecar Proxies werden vor den ihnen zugeordneten Backend-Services gestartet, und die SSI-Agenten warten auf die vollständige Initialisierung der Infrastruktur-Services, bevor sie ihre Genesis-Transaktionsdatei abrufen. Diese Orchestrierung gewährleistet eine deterministische Startup-Sequenz und stellt sicher, dass alle Komponenten beim Erreichen ihres operativen Zustands auf vollständig verfügbare Abhängigkeiten zugreifen können.

Die \enquote{depends\_on}-Direktiven in den Docker-Compose-Konfigurationen (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry} und Listing~\ref{lst:docker-compose.yml-SSI-Agenten}) definieren explizite Startup-Abhängigkeiten, die über reine Ausführungsreihenfolgen hinausgehen. Ohne Synchronisation führen verfrühte Interaktionen abhängiger Services zu \enquote{faulty interactions} während der Boot-Phase \parencite[S. 25]{deiasio_FrameworkMicroservicesSynchronization_2021}. Die implementierte Konfiguration eliminiert diese Race-Conditions, indem sie sicherstellt, dass die PQC Sidecar Proxies nicht gestartet werden, bevor die ihnen zugeordneten Backend-Services den Status (\enquote{ready}) erreichen. Diese Orchestrierung erzwingt eine deterministische Startup-Sequenz, die verhindert, dass abhängige Komponenten auf Dienste zugreifen, die sich zwar im Status \textit{Running}, aber noch nicht im Status \textit{Ready} befinden \parencite[S. 29]{deiasio_FrameworkMicroservicesSynchronization_2021}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{docker_compose_übersicht.png}
    \caption{Docker-Compose-Übersicht der ersten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Docker-Compose-Übersicht-Iteration-1}
\end{figure}

\subsection{Formative Evaluation}
\label{sec:formative_evaluation_iteration1}

In Übereinstimmung mit dem in Kapitel~\ref{sec:Schritt4-Design der individuellen Evaluationsepisoden} entworfenen Evaluationsdesign setzt dieser Abschnitt die erste definierte Evaluationsepisode (\autoref{tab:eval_episodes}) um. Charakterisiert als formative und artifizielle Untersuchung, liegt der Fokus dieser Phase exklusiv auf der Validierung der Transport-Layer-Security sowie der korrekten Konfiguration der Infrastrukturkomponenten. Ziel ist es, gemäß den Prinzipien von \textcite[S. 6, 7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} Designfehler in der Sidecar-Architektur frühzeitig zu identifizieren.

Methodisch erfolgt dies primär durch White-Box-Tests. Da bei diesem Verfahren die internen Strukturen und Implementierungsdetails der Software bekannt sind und gezielt in die Prüfung einbezogen werden \parencite[S. 10]{myers_ArtSoftwareTesting_2012}, eignet es sich besonders gut, um die korrekte Konfiguration der kryptographischen Primitive innerhalb der Container-Architektur durch eine detaillierte Analyse der Handshake-Logs zu validieren.

Für die technische Durchführung dieser Analysen war die Bereitstellung eines \ac{PQC}-fähigen Browsers zwingend erforderlich, da aktuelle Produktivbrowser noch keine Post-Quanten-Kryptographie in ihren \ac{TLS}-Implementierungen unterstützen. Diese Limitation führt bei Verbindungsversuchen zu \ac{PQC}-fähigen Servern unweigerlich zu einem Cipher-Mismatch, wie in \autoref{fig:Cipher-Mismatch-Blockchain-Webserver} veranschaulicht. Um diese Inkompatibilität zu überwinden, wurde ein Chromium-basierter Browser mit integrierter \ac{PQC}-Unterstützung kompiliert (siehe \ref{sec:Anhang_Eigenkompilation eines Chromium-Browsers mit PQC-Unterstützung}). Dieser ermöglicht die Durchführung von TLS-Handshakes mit hybriden sowie rein \ac{PQC}-basierten Algorithmen und dient als fundamentale Testplattform für die experimentelle Analyse der implementierten Verfahren.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_blockchain_webserver_CIPHER_MISMATCH.png}
    \caption{Cipher Mismatch bei Validierung der TLS-1.3-Verbindung des Blockchain-Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Cipher-Mismatch-Blockchain-Webserver}
\end{figure}

\subsubsection{Validierung der Zertifikatskette und ML-DSA-Signaturen}

Zur Verifikation der kryptographischen Integrität der implementierten \ac{PKI} wurde die Zertifikatskette der Sidecar-Proxies mittels openssl-Diagnosewerkzeugen analysiert. Ziel war der Nachweis, dass die ausgelieferten X.509-Zertifikate korrekt auf den spezifizierten Post-Quanten-Signaturalgorithmen basieren. Die Inspektion des vom Issuer-Agenten-Proxy bereitgestellten Zertifikats (\autoref{fig:Successful-Validation-Issuer-MLDSA-Cert}) bestätigt, dass der öffentliche Schlüssel des Leaf-Zertifikats (\enquote{pqc reverseproxy issuer agent}) den Algorithmus \enquote{ML-DSA-65} verwendet. Des Weiteren belegt der Signaturalgorithmus \enquote{ML-DSA-87}, dass die Zertifikatskette valide durch die \enquote{Master Thesis PQC Root CA} signiert wurde, was die erfolgreiche Generierung und Einbindung der Dilithium-basierten Zertifikate in den TLS-Handshake beweist.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_issuer_mldsa_cert.png}
    \caption{Erfolgreiche Validierung des ML-DSA-Zertifikats des Issuer-Agenten}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-MLDSA-Cert}
\end{figure}

\subsubsection{Validierung der TLS 1.3 Algorithmen-Aushandlung}

Die erfolgreiche Integration der PQC-Algorithmen in das Transportprotokoll wurde durch einen Verbindungsaufbau mittels \enquote{openssl s\_client} verifiziert. Wie in \autoref{fig:Successful-Validation-Issuer-TLS1.3} dargestellt, konnte erfolgreich eine TLS-1.3-Sitzung etabliert werden. Die Analyse der Handshake-Parameter bestätigt die Verwendung der hybrid-post-quanten Schlüsselaustauschgruppe \enquote{X25519MLKEM768}, welche den klassischen elliptischen Kurvenalgorithmus X25519 mit dem KEM-Verfahren ML-KEM-768 kombiniert. Zudem wird für die Authentifizierung des Peer-Zertifikats der Signaturalgorithmus \enquote{mldsa65} ausgewiesen. Diese Ergebnisse validieren die korrekte Konfiguration der OQS-Provider-Bibliothek innerhalb der Proxy-Komponenten und belegen die praktische Funktionsfähigkeit des hybriden Schlüsselaustauschs im Zusammenspiel mit PQC-Signaturen.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_issuer_TLS1.3.png}
    \caption{Erfolgreiche Validierung der TLS-1.3-Verbindung des Issuer-Agenten}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-TLS1.3}
\end{figure}

\subsubsection{Validierung der Ledger-Initialisierung}

Die operative Funktionsfähigkeit des Hyperledger Indy Netzwerks wurde primär über das Web-Interface des Blockchain-Servers validiert. Wie in \autoref{fig:Successful-Validation-Blockchain-Webserver} dargestellt, zeigen die Statusindikatoren aller vier Validator-Nodes eine aktive Beteiligung am Konsensus-Protokoll (Status Node1-4), womit der Distributed Ledger erfolgreich initialisiert ist. Simultan belegt diese Abbildung die korrekte PQC-Absicherung der Webserver-Komponente. Der Zugriff erfolgt über den eigens kompilierten PQC-Chromium-Browser, dessen Security-Panel explizit eine authentifizierte \ac{TLS}-1.3-Verbindung unter Verwendung der hybriden Schlüsselaustauschgruppe \enquote{X25519MLKEM768} ausweist.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_blockchain_webserver.png}
    \caption{Erfolgreiche Validierung der TLS-1.3-Verbindung des Blockchain-Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Blockchain-Webserver}
\end{figure}

Als zweite notwendige Bedingung für die spätere Anbindung der SSI-Agenten wurde die Verfügbarkeit der Genesis-Datei verifiziert. \autoref{fig:Successful-Validation-Genesis-File-Blockchain-Webserver} dokumentiert den Abruf des Endpunkts \enquote{/genesis} mittels \enquote{curl}. Die erfolgreiche Rückgabe der JSON-formatierten Genesis-Transaktionen bestätigt, dass die für die Anbindung externer Clients erforderlichen Netzwerkinformationen korrekt publiziert werden.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_genesis.png}
    \caption{Erfolgreiche Validierung der Genesis-Datei des Blockchain-Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Genesis-File-Blockchain-Webserver}
\end{figure}

\subsubsection{Validierung der ACA-Py API-Verfügbarkeit}

Die funktionale Erreichbarkeit der SSI-Agenten wurde durch eine systematische Analyse der Initialisierungsphase und der anschließenden API-Verfügbarkeit validiert. Die Logging-Ausgabe des Issuer-Agenten (Listing~\ref{lst:Issuer-Agent-Boot-Logs}) dokumentiert den erfolgreichen Abruf der Genesis-Datei und die vollständige Ledger-Konfiguration. Die Erstellung eines neuen Wallet-Profils mit Askar-Backend und die erfolgreiche Initialisierung der Inbound- und Outbound-Transports demonstrieren die korrekte Konfiguration des ACA-Py-Agents. Die durchgeführten Health-Checks über den Endpunkt \enquote{/status/ready} bestätigen die vollständige Initialisierung und Bereitschaft des Agenten.

Die Visualisierung der Swagger-basierten Admin-Oberfläche (\autoref{fig:Successful-Validation-Issuer-Agent-ACA-Py-Swagger-API}) ergänzt diese technischen Log-Daten durch den Nachweis, dass die Admin-API über den PQC-Reverse-Proxy fehlerfrei erreichbar ist und alle administrativen Endpunkte zur Steuerung der Agenten-Komponente bereitstellt. Die Tatsache, dass die Swagger-Oberfläche unter dem PQC-gesicherten HTTPS-Endpoint vollständig funktionsfähig ist, belegt die korrekte TLS-Terminierung am Proxy sowie die fehlerfreie Weiterleitung der HTTP-Anfragen an den ACA-Py-Container.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_Issuer_Agent_Swagger_API.png}
    \caption{Erfolgreiche Validierung der Issuer Agent ACA-Py Swagger Admin API}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-Agent-ACA-Py-Swagger-API}
\end{figure}

\subsubsection{Validierung der Netzwerkisolation}

Die integrale Sicherheitseigenschaft der Netzwerksegmentierung wurde durch eine Inspektion der Docker-Netzwerktopologie und systematische Erreichbarkeitstests validiert. \autoref{fig:Darstellung-Network-Isolation} belegt diese Topologie anhand des \enquote{docker network inspect}-Outputs: Der Issuer-Agent befindet sich exklusiv im Netzwerksegment \enquote{hope\_hope-issuer}, während der Holder-Agent im Segment \enquote{hope\_hope-holder} isoliert ist. In jedem dieser Segmente fungiert der zugehörige PQC-Sidecar-Proxy als einziger Ingress-Punkt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_network_isolation.png}
    \caption{Darstellung der Netzwerkisolation innerhalb der Gesamtarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Darstellung-Network-Isolation}
\end{figure}

\autoref{fig:Successful-Validation-Network-Isolation-Through-Tests} demonstriert die Wirksamkeit dieser Isolation auf zwei Ebenen. Erstens zeigt die Prozessliste (\enquote{docker ps}), dass lediglich die Sidecar-Proxies externe Ports (8020, 8030, 8040) an das Host-System binden, während die Ports der ACA-Py-Container nicht exponiert sind. Zweitens beweisen die Inter-Container-Verbindungstests die logische Trennung. Ein direkter Zugriffsversuch aus dem \enquote{issuer-agent}-Container auf den \enquote{holder-agent} schlägt mit einem DNS-Auflösungsfehler (\enquote{Could not resolve host}) fehl, da keine Routing-Route zwischen den isolierten Netzwerkbrücken existiert. Im Gegensatz dazu ist der lokale Zugriff des \enquote{pqc-sidecarproxy-holder} auf seinen zugehörigen Agenten erfolgreich möglich.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_network_isolation_through_tests.png}
    \caption{Erfolgreiche Validierung der Netzwerkisolation innerhalb der Gesamtarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Network-Isolation-Through-Tests}
\end{figure}

\subsection{Erkenntnisse und Anpassungsbedarfe}
\label{subsec:findings_adaptation_needs}

Die erste Iteration bildet das fundamentale technologische Fundament der Forschungsarbeit. Die formative Evaluation (Kapitel~\ref{sec:formative_evaluation_iteration1}) validierte die operative Integrität der entwickelten Architektur. Die verteilten Micro-Services, der Hyperledger Indy Ledger und die PQC-Sidecar-Proxies interagieren funktional korrekt. Diese Initialphase generierte jedoch spezifische Erkenntnisse, die eine gezielte Weiterentwicklung in der zweiten Iteration motivieren. Diese werden nachfolgend in Bezug auf die Designziele analysiert.

\subsubsection{Abgleich mit den Designzielen und kritische Erkenntnisse}
\label{subsubsec:design_goals_critique}

Das primäre Designziel, die Absicherung der Transportebene in einem SSI-Ökosystem mittels Post-Quanten-Kryptographie, wurde vollständig erreicht. Die erfolgreiche Validierung des Sidecar-Musters belegt die Machbarkeit einer transparenten PQC-Migration für Legacy-Systeme (ACA-Py, Indy Node) ohne Eingriffe in deren Kerncode. Die implementierte Micro-Segmentation erfüllt zudem die architektonischen Anforderungen an logische Netzsegmentierung in \ac{KRITIS}-Umgebungen (\autoref{tab:compliance_requirements}).

Durch die strikte Entkopplung der kryptographischen Terminierung von der Business-Logik durch die Sidecar-Proxy-Architektur konnte eine PQC-Integration realisiert werden, die die Kernprozesse der Identitätsverwaltung funktional nicht beeinträchtigt. Diese architektonische Entscheidung ermöglicht es, sicherheitskritische Updates an der Krypto-Komponente vorzunehmen, ohne die Integrität der komplexen SSI-Logik zu gefährden. Die empirische Validierung der Zertifikatsketten und TLS-1.3-Handshake-Protokolle (\autoref{sec:formative_evaluation_iteration1}) bestätigt die technische Reife dieser Architekturentscheidung.

Bezüglich der Algorithmenauswahl und Sicherheitsbewertung operationalisiert die erste Iteration die in Tabelle~\ref{tab:compliance_requirements} definierten BSI-Vorgaben für Post-Quantum-Kryptografie durch die Implementierung der NIST-standardisierten Algorithmen ML-DSA-65 und ML-KEM-768, welche explizit die NIST Security Strength Categories 3/5 erfüllen \parencite[Kap.~2.4, 5.3.4.2]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. Die formative Evaluation bestätigte die technische Machbarkeit dieser Algorithmen in der Sidecar-Proxy-Infrastruktur durch die erfolgreiche Validierung hybrider Zertifikatsketten und TLS-1.3-Handshake-Protokolle mit der Schlüsselaustauschgruppe \enquote{X25519MLKEM768}.

Bezüglich der kryptografischen Agilität zeigt die erste Iteration, dass das Designziel einer architektonischen Vorbereitung auf Algorithmenaustauschbarkeit erreicht wurde. Die containerbasierte Sidecar-Architektur ermglicht es, kryptografische Bibliotheken durch Rolling Updates der Proxy-Images auszutauschen, ohne ACA-Py oder die übrige Systemlogik anzupassen, was direkt die von \textcite[S. 102]{mehrez_CryptoAgilityProperties_2018} geforderte \enquote{Extensibility} kryptoagiler Systeme adressiert. Gleichzeitig nutzt die TLS-1.3-Integration eine konfigurationsbasierte Fallback-Kette (\enquote{DEFAULT\_GROUPS:X25519:ML-KEM-768:mlkem768x25519:mlkem1024}), sodass hybride und klassische Verfahren orthogonal ausgehandelt und bei Inkompatibilitäten automatisch gewechselt werden können \parencite[S. 26]{rescorla_TransportLayerSecurityTLSProtocolVersion13_2018}. Diese Protokoll- und Infrastrukturmechanismen realisieren damit zentrale Kryptoagilitäts-Eigenschaften wie \enquote{Fungibility} und \enquote{Updateability} \parencite[S. 102--103]{mehrez_CryptoAgilityProperties_2018} und entsprechen dem Erfordernis, kryptografische Komponenten ohne grundlegende Systemumgestaltung migrieren zu können \parencite[S. 670]{kreutzer_Kryptoagilitaet_2024a}.

Eine zentrale Limitation identifizierte jedoch die Analyse der Sicherheitsmodelle. Während die Transportebene durch die Sidecar-Proxies vollständig quantensicher abgesichert ist (\gls{Data-In-Motion}), verbleiben Verifiable Credentials und DID-Dokumente (\gls{Data-At-Rest}) mittels klassischer Kryptografie verschlüsselt. Diese Diskrepanz zwischen Transportschutz (PQC-gesichert) und Datenpersistierung (klassische Kryptografie) widerspricht dem mehrschichtigen Sicherheitsansatz \enquote{Defense in Depth} von \textcite[S. 242--243]{alsaqour_DefenseDepthMultilayersecurity_2021}, bei dem konsistente, sich gegenseitig verstärkende Kontrollen auf mehreren Ebenen implementiert werden, um Ressourcen und Assets umfassend zu schützen. Diese Erkenntnisse folgern eine Erweiterung des Sicherheitsmodells von der Transportebene auf die Applikationsschicht in der zweiten Iteration.

\subsubsection{Design-Refinements und Operationalisierung der zweiten Iteration}
\label{subsubsec:design_refinements_iteration2}

Die systematische Analyse der Evaluationsergebnisse führt zu zwei konvergenten Design-Refinements, die die identifizierten Sicherheitslücken adressieren und die zweite Iteration strukturieren.

\textbf{Refinement 1: Applikationsebenen-Integration der Post-Quanten-Kryptografie.} Dieses Refinement adressiert die identifizierte Sicherheitslücke durch technische Erweiterung der PQC-Integration von der Transportebene auf die Applikationsebene. Die direkte Einbindung der \emph{liboqs}-Bibliothek in die ACA-Py-Agenten ermöglicht ML-DSA-65-Signaturen für Verifiable Credentials und DIDComm-Nachrichten, wodurch die kritische Diskrepanz zwischen quantensicherer Transportverschlüsselung und ungeschützter Datenpersistierung geschlossen wird. Die Implementierung als modulares Plugin-System realisiert das Open-Closed-Prinzip \parencite[S. 99]{martin_AgileSoftwareDevelopmentprinciplespatternspractices_2003} und ermöglicht eine nicht-invasive Erweiterung der ACA-Py-Kernarchitektur, ohne deren Codebasis zu modifizieren.

\textbf{Refinement 2: Hybride Sicherheitsarchitektur mit redundanter Tiefenstaffelung.} Dieses Refinement etabliert ein übergeordnetes Defense-in-Depth-Modell durch beibehaltene Sidecar-Proxies als erste Verteidigungslinie (Transport Layer Security) bei gleichzeitiger Quantensicherung der Datenobjekte auf Anwendungsebene (Application Layer Security). Diese redundante Absicherung schafft eine tiefengestaffelte Sicherheitsarchitektur, bei der ein Bruch einzelner Schichten, nicht automatisch zum Kollaps der Gesamtsicherheit führt. Das Refinement implementiert damit die von \textcite[S. 242--243]{alsaqour_DefenseDepthMultilayersecurity_2021} geforderte Prinzipienkonsistenz über alle Architekturebenen hinweg und gewährleistet die Resilienz des Systems gegen hybride Angriffszenarien.



\newpage
\section{Zweite Iteration der Artefaktentwicklung}
\label{Zweite Iteration der Artefaktentwicklung}

\subsection{Designziele dieser Iteration} \label{sec:Designziele_Iteration_2}

Die zweite Iteration der Artefaktentwicklung baut auf der in Iteration 1 erfolgreich validierten Basisarchitektur auf und korrespondiert erneut mit der DSRM-Phase 2 \textit{Objectives} nach \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}. Der Fokus dieser Iteration liegt auf der Erweiterung des Prototyps um eine tiefgreifende PQC-Integration auf der Anwendungsebene (Application Layer). Im Kontext des Drei-Zyklen-Modells nach \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007} wird der Design Cycle intensiviert, um die kryptografische Sicherheit von der reinen Transportsicherung (TLS) auf die tatsächlichen Nutzdaten (Verifiable Credentials und DID-Dokumente) auszuweiten und somit eine Ende-zu-Ende-Sicherheit zu gewährleisten.

Die Designziele dieser Iteration leiten sich konsistent aus den in Kapitel~\ref{sec:Zielsetzung und Forschungsfragen} definierten Forschungsfragen ab, wobei eine inhaltliche Vertiefung der technischen Anforderungen erfolgt.

Bezüglich FF1 (Systemarchitektur \& Compliance) wird das Ziel verfolgt, die SSI-Kernprozesse so zu modifizieren, dass sie quantenresistente Signaturen und Schlüsselformate nativ unterstützen. Das Design muss sicherstellen, dass die Unveränderlichkeit und Authentizität von Identitätsnachweisen unabhängig vom Transportkanal auch langfristig gegenüber Quantencomputer-Angriffen gewährleistet bleibt, was eine zentrale Anforderung für den Einsatz in KRITIS-Umgebungen darstellt \parencite[.S 25]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}.

Hinsichtlich FF2 (Algorithmenauswahl \& Sicherheitsbewertung) wird das Ziel verfolgt, die praktische Machbarkeit von NIST-standardisierten Post-Quantum-Algorithmen in den Kernkomponenten des SSI-Systems nachzuweisen. Der Fokus liegt auf der Integration quantenresistenter Signatur- und Verschlüsselungsverfahren auf der Applikationsebene, um die digitale Authentizität und Integrität von Identitätsnachweisen langfristig gegen Quantencomputer-Angriffe zu schützen.

Für FF3 (Kryptografische Agilität) zielt diese Iteration auf die Implementierung von Agilitätsmechanismen direkt in den Datenstrukturen ab. Das System soll so gestaltet werden, dass es hybride Szenarien unterstützt und eine Koexistenz sowie den nahtlosen Wechsel zwischen klassischen (z.\,B. Ed25519) und post-quanten Kryptografieverfahren innerhalb der DID-Methoden und Credential-Definitionen ermöglicht, ohne die Interoperabilität grundlegend zu gefährden.

\subsection{Architekturentwurf}

\subsubsection{Gesamtarchitektur}

Die Gesamtarchitektur der zweiten Iteration erweitert die in Kapitel~\ref{sec:Gesamtarchitektur_Iteration1} etablierte dreischichtige Containerarchitektur um eine zusätzliche Kryptoebene auf der Anwendungsschicht. Während die in der ersten Iteration implementierte Sidecar-Proxy-Architektur mit TLS~1.3 und hybrider Schlüsseleinigung (X25519 + ML-KEM-768) vollständig beibehalten wird und weiterhin die Transportverschlüsselung zwischen den Komponenten gewährleistet, wird in dieser Iteration die kryptografische Absicherung auf die SSI-Agenten-Schicht ausgeweitet.

\autoref{fig:Gesamtarchitektur_Iteration2} visualisiert diese Erweiterung durch die Integration von \enquote{PQC-PLUGIN}-Modulen in die drei ACA-Py-Instanzen (Issuer, Holder, Verifier). Diese Plugin-Module ermöglichen die Verwendung quantenresistenter Signaturalgorithmen (ML-DSA-65) innerhalb von Verifiable Credentials und Decentralized Identifiers sowie die Verwendung quantenresistenter Schlüsselkapselungsverfahren (ML-KEM-768) für die DIDComm-Messaging-Verschlüsselung. Durch diese duale Architektur mit Sidecar-Proxies für die Transportebene und Plugin-Module für die Applikationsebene wird eine durchgängige Ende-zu-Ende-Quantenresistenz realisiert, die sowohl \gls{Data-In-Motion} als auch \gls{Data-At-Rest} schützt. Die DLT-Infrastruktur (vier Hyperledger-Indy-Validator-Nodes, Ledger-Browser, Webserver), die Revocation Registry (Tails-Server) sowie die zugrundeliegende Docker-Netzwerktopologie bleiben strukturell unverändert und gewährleisten die Kontinuität der in Iteration~1 validierten Infrastrukturkomponenten.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Gesamtarchitektur_Iteration2}
    \caption{Gesamtarchitekturentwurf der zweiten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Gesamtarchitektur_Iteration2}
\end{figure}

\subsubsection{ACA-Py Applikationsarchitektur}

Während Kapitel~\ref{sec:ACA-Py Applikationsarchitektur_Iteration1} die klassische Applikationsarchitektur als geschichtete, unveränderliche Referenzimplementierung vorstellt, demonstriert die zweite Iteration die transparente Applikationsschicht-Integration von PQC durch ein modulares Plugin-System, das bestehendes Kerncode-Design respektiert und durch gezieltes Patching erweitert. ACA-Py-Plugins ermöglichen hierbei eine standardisierte Erweiterbarkeit, ohne die ACA-Py-Codebasis zu überlasten \parencite{_ACAPyPluginsACAPyDocs_}. 

\autoref{fig:ACAPY_Application_Architecture_Iteration2_PQC} visualisiert diese erweiterte Architektur und verdeutlicht die Integration des PQC-Plugins als zentrale Interceptions- und Delegationsschicht. Die roten Markierungen heben die Unterschiede zur klassischen ACA-Py Applikationsarchitektur (\autoref{fig:ACAPY_Application_Architecture_Iteration_1}) hervor. Das Plugin ist seitlich an alle vier klassischen Schichten (Protocol Handlers, Wallet Interface, Transport Layer, externe Business Logic) angebunden, woraus sich bidirektionale Pfeile ergeben. Diese Bidirektionalität symbolisiert die transparente Interception. Wenn eine klassische Schicht eine Operation initiiert, wird diese zunächst vom Plugin abgefangen. Das Plugin führt eine PQC-äquivalente Operation durch und gibt das Ergebnis an die ursprüngliche Schicht zurück. Diese Interceptions-Delegation ermöglicht es dem Plugin, als Zwischenschicht zu fungieren, ohne die übergeordnete Geschäftslogik zu modifizieren. Die Erweiterungen manifestieren sich somit nicht nur auf vier Architekturebenen, sondern auch in der Rolle des Plugins als verteilte, querschichtliche Integrationsfläche, die nachfolgend charakterisiert werden.

Die Protocol Handlers-Schicht wird durch eine PQC-Interception-Delegation erweitert. Während die klassische Architektur DID Exchange, Credential Issuance und Presentation Proof ausschließlich mit Signaturen klassischer Kryptografie durchführt \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_}, delegiert die erweiterte Variante diese Operationen an das Plugin, das ML-DSA-65 als Signaturverfahren verwendet.

Die Wallet Interface-Schicht wird nicht ersetzt, sondern erweitert. Das klassische Aries-Askar-Backend bleibt vollständig funktionsfähig und verwaltet weiterhin klassische Kryptografie \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_}. Parallel dazu registriert das Plugin zusätzliche Operationsmethoden für die PQC-Schlüssel ML-DSA-65-Signaturen, ML-KEM-768-Key-Encapsulation und angepasste Speicherfunktionen, die die größeren Schlüssellängen in der bestehenden SQLite-Struktur persistieren. Diese Erweiterung ist nicht-invasiv und erhält die ChaCha20-Poly1305-Verschlüsselung der Wallet-Datenbank.

Die Key-Type-Registry und DIDComm-Verschlüsselung werden dynamisch erweitert. Das Plugin registriert ML-DSA-65 und ML-KEM-768 als vollwertige Schlüsseltypen neben den klassischen Varianten ed25519 und x25519 \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_}. Die DIDComm-Verschlüsselung wird orthogonal erweitert, sodass PQC-Nachrichten ML-KEM-768-Key-Encapsulation nutzen.

Die Integration-Patching-Schicht realisiert die transparente Einbettung der PQC-Funktionalität durch gezieltes \gls{Monkey-Patching}, das kritische Funktionen der bestehenden Schichten zur Laufzeit überschreibt, ohne den ACA-Py-Quellcode zu modifizieren. Dies ermöglicht die Einbindung von PQC-Operationen (Schlüsselgenerierung, Signatur, Key-Encapsulation) in bestehende Workflows und erlaubt hybride Betriebsweisen, bei denen Agenten je nach Plugin-Ladezustand klassische oder quantenresistente Schlüssel erzeugen.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{ACA-Py Applikationsarchitektur mit PQC-Integration}
    \caption{ACA-Py High Level Applikationsarchitektur mit PQC-Integration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung auf Basis von \autoref{fig:ACAPY_Application_Architecture_Iteration 1}.
    \end{flushleft}
    \label{fig:ACAPY_Application_Architecture_Iteration2_PQC}
\end{figure}

\subsection{Implementierung}

Die Implementierung der PQC-Unterstützung auf Application-Ebene folgt einem zweistufigen Ansatz. In der ersten Stufe wird das pqc\_didpeer4\_fm-Plugin entwickelt, das sich in den ACA-Py Plugin-Mechanismus nach \textcite{_ACAPyPluginsACAPyDocs_,_ACAPyPluginsACAPyPlugins_,openwallet-foundation_OpenwalletfoundationAcapyplugins_2025} einfügt. Das Plugin ist als Python-Paket strukturiert und definiert einen setup-Entrypoint, der beim Agent-Start aufgerufen wird. Über den PluginContext erhält das Plugin unmittelbaren Zugriff auf zentrale Agent-Komponenten wie die Wallet, das DIDComm-System und die Protocol Registry. Diese Architektur ermöglicht es Plugins, neue Protokolle zu registrieren oder bestehende Funktionen durch Monkey-Patching zu erweitern, ohne den ACA-Py Kern zu modifizieren. Die zweite Stufe integriert das entwickelte Plugin in die containerisierte Deployment-Infrastruktur. Dabei wird das Plugin als Abhängigkeit in dem Dockerfile definiert, sodass es während des Container-Builds installiert wird. Anschließend erfolgt die Konfiguration über docker-compose, indem der ACA-Py Service mit den erforderlichen Umgebungsvariablen und Plugin-Parametern initialisiert wird.

Der Aufbau des PQC-Plugins gliedert sich in drei funktionale Schichten, in die die in \autoref{fig:pqc_didpeer4_fm_directory_structure} dargestellten 15 Module eingeteilt sind. Diese Architektur garantiert vollständige PQC-Funktionalität ohne Änderungen am ACA-Py-Quellcode.

Die Kryptografische Abstraktionsschicht bildet die Grundlage und abstrahiert die Komplexität der liboqs-C-Bibliothek durch ein Python-Wrapper-Modul (liboqs\_wrapper.py). Sie stellt einheitliche Operationen für ML-DSA-65 (digitale Signaturen) und ML-KEM-768 (Schlüsselencapsulation) bereit und garantiert, dass kryptografisches Schlüsselmaterial als Byte-Sequenzen serialisiert wird, was eine Voraussetzung für Wallet-Persistierung und Multi-Codec-Kodierungen darstellt.

Die DID-Verarbeitungsschicht orchestriert die vollständige Lebenszyklusbearbeitung von PQC-fähigen did:peer:4-Identifikatoren. Dazu zählen, die Erzeugung und Auflösung (pqc\_peer4\_creator.py, pqc\_peer4\_resolver.py), W3C-konforme Multicodecs (pqc\_multicodec.py, pqc\_multikey.py) und standardisierte DIDComm-Nachrichtenverschlüsselung (pqc\_didcomm\_v1.py). Diese Schicht verbindet kryptografische Primitive mit Identity-Protokollen und ermöglicht hybrid-sichere Kommunikation zwischen PQC- und klassischen Agenten.

Die Integration-Patching-Schicht implementiert die transparente Einbettung in ACA-Py durch gezieltes \gls{Monkey-Patching} und Registry-Erweiterungen. Neun spezialisierte Module patchen Wallet-Operationen (askar\_pqc\_patch.py, wallet\_patch.py), Connection-Management (base\_manager\_patch.py, connection\_target\_patch.py), Schlüsseltyp-Infrastruktur (key\_types.py, key\_type\_patches.py), Validierungslogik (validator\_patch.py), Multicodec-Registries (multicodec\_patch.py) und koordinieren deren Installation (monkey\_patches.py).

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 liboqs\_wrapper.py.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

\subsubsection{Pluginentwicklung: Kryptografie-Abstraktionsschicht}

Die Kryptografie-Abstraktionsschicht bildet die unterste Ebene der PQC-Integration und wird durch das Modul liboqs\_wrapper.py (\autoref{fig:pqc_didpeer4_fm_directory_structure_Kryptografie-Abstraktionsschicht}) realisiert. Dieses Modul kapselt die nativen Operationen der C-basierten liboqs-Bibliothek und stellt eine Python-API für die NIST-standardisierten PQC-Algorithmen ML-DSA-65 und ML-KEM-768 bereit.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_Kryptografie-Abstraktionsschicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 \textbf{liboqs\_wrapper.py}.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Die Implementierung (Listing~\ref{lst:liboqs_wrapper.py}) definiert eine LibOQSWrapper-Klasse mit sechs Kernmethoden. Die ersten beiden Methoden generate\_ml\_dsa\_65\_keypair() und generate\_ml\_kem\_768\_keypair() erzeugen kryptografische Schlüsselpaare, sign\_ml\_dsa\_65() und verify\_ml\_dsa\_65() implementieren digitale Signaturen, während encapsulate\_ml\_kem\_768() und decapsulate\_ml\_kem\_768() die Key Encapsulation für sichere Schlüsselvereinbarung realisieren.

Die Wrapper-Architektur abstrahiert die komplexen \ac{FFI}-Aufrufe an die liboqs-C-Bibliothek und stellt sicher, dass Schlüsselmaterial ausschließlich als Byte-Arrays serialisiert wird, was eine Voraussetzung für die Persistierung in der Aries-Askar-Wallet \parencite{_EntryAries_askarEntryRust_} und die Kodierung in Multicodec-Formaten \parencite{multiformats_MultiformatsMulticodec_2025} darstellt. Das Singleton-Pattern (get\_liboqs()) gewährleistet eine einzige globale Instanz zur Vermeidung redundanter Initialisierungen. Diese Abstraktionsschicht ermöglicht es den höheren Modulen (DID-Generierung, DIDComm-Verschlüsselung), PQC-Operationen durchzuführen, ohne direkte Abhängigkeiten zur liboqs-C-API zu haben.

\subsubsection{Pluginentwicklung: DID-Verarbeitungsschicht}

Die DID-Verarbeitungsschicht (siehe Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_DID-Verarbeitungsschicht}) orchestriert die Erzeugung, Auflösung und Kodierung von PQC-fähigen did:peer:4-Identifikatoren sowie die DIDComm-Nachrichtenverschlüsselung. Diese Schicht umfasst sechs funktional gekoppelte Module, die gemeinsam eine standardkonforme Integration von Post-Quantum-Kryptografie in das did:peer:4-Ökosystem realisieren.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_DID-Verarbeitungsschicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 liboqs\_wrapper.py.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 \textbf{pqc\_didcomm\_v1.py}.
.4 \textbf{pqc\_multicodec.py}.
.4 \textbf{pqc\_multikey.py}.
.4 \textbf{pqc\_peer4\_creator.py}.
.4 \textbf{pqc\_peer4\_resolver.py}.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Das Modul pqc\_peer4\_creator.py (Listing~\ref{lst:pqc_peer4_creator.py}) implementiert die Funktion create\_pqc\_peer4\_did(), die aus zwei PQC-Schlüsselpaaren (ML-DSA-65 für authentication/assertionMethod, ML-KEM-768 für keyAgreement) einen did:peer:4-Long-Form-Identifier generiert. Die Schlüssel werden über die Wallet-API erzeugt, in Multikey-Format transformiert und als KeySpec-Objekte in einem did:peer:4-Input-Dokument strukturiert, wobei die Reihenfolge der Schlüssel deren Fragment-IDs determiniert (\#key-0 für Signaturen, \#key-1 für Verschlüsselung in recipientKeys). Das Gegenstück pqc\_peer4\_resolver.py (Listing~\ref{lst:pqc_peer4_resolver.py}) registriert einen DID-Resolver für die peer-Methode, der did:peer:4-Long-Form-DIDs in DID-Dokumente auflöst und dabei PQC-Multicodec-Präfixe korrekt dekodiert.

Die Multiformat-Kodierung nach \parencite[Kap. 5.6]{w3c_ControlledIdentifiersV11_2025} wird durch drei Module realisiert. Das Modul pqc\_multicodec.py (Listing~\ref{lst:pqc_multicodec.py}) definiert eine Multicodec-Registry mit provisorischen Präfixen (ML-DSA-65: 0xd065, ML-KEM-768: 0xe018) und stellt Wrapper-Funktionen (wrap\_pqc(), unwrap\_pqc()) für Präfix-Operationen bereit. Das Modul pqc\_multikey.py (Listing~\ref{lst:pqc_multikey.py}) transformiert Schlüsselinformationen in das Multikey-Format durch Verkettung von Multicodec-Präfix und Schlüsselmaterial sowie Base58-Kodierung mit Multibase-Präfix \enquote{z} (Base58btc), wodurch Multikeys wie \enquote{z6MNxxx...} (ML-DSA-65) oder \enquote{z6MK768xxx...} (ML-KEM-768) entstehen. Das Modul pqc\_didcomm\_v1.py (Listing~\ref{lst:pqc_didcomm_v1.py}) erweitert die DIDComm-v1-Envelope-Verarbeitung um PQC-Unterstützung. Hier detektieren die beiden Methoden pack\_message\_pqc() und unpack\_message\_pqc() automatisch anhand der unterschiedlichen Schlüssellängen ob PQC- oder klassische Kryptografie verwendet werden muss, und generieren JWE-Envelopes mit angepassten Algorithmus-Headern. Die Content Encryption erfolgt weiterhin mit XChaCha20-Poly1305,  während der Content Encryption Key mittels ML-KEM-768 Key Encapsulation für jeden Empfänger verschlüsselt wird. Diese Schicht ermöglicht eine hybride Betriebsweise, bei der PQC- und klassische Agenten koexistieren können, solange jeweils homogene Verschlüsselungsmodi verwendet werden.

\subsubsection{Pluginentwicklung: Integration-Patching-Schicht}

Die Integration-Patching-Schicht (Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_Integration-Patching-Schicht}) implementiert die transparente Einbettung der PQC-Funktionalität in den ACA-Py-Kern durch gezieltes Monkey-Patching kritischer Funktionen und Erweiterung globaler Registries. Diese Schicht umfasst neun Module, die gemeinsam eine vollständig transparente PQC-Integration ohne Modifikation des ACA-Py-Quellcodes ermöglichen, sodass existierende Workflows und API-Aufrufe unverändert funktionsfähig bleiben.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_Integration-Patching-Schicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 \textbf{askar\_pqc\_patch.py}.
.4 \textbf{base\_manager\_patch.py}.
.4 \textbf{connection\_target\_patch.py}.
.4 \textbf{key\_type\_patches.py}.
.4 \textbf{key\_types.py}.
.4 liboqs\_wrapper.py.
.4 \textbf{monkey\_patches.py}.
.4 \textbf{multicodec\_patch.py}.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 \textbf{validator\_patch.py}.
.4 \textbf{wallet\_patch.py}.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Das zentrale Orchestrierungsmodul monkey\_patches.py (Listing~\ref{lst:monkey_patches.py}) koordiniert die Installation aller Patches durch die Funktion apply\_all\_patches(), die beim Plugin-Setup aufgerufen wird. Dieses Modul überschreibt Methoden der Klasse BaseConnectionManager (z.\,B. create\_did\_peer\_4(), \_extract\_key\_material\_in\_base58\_format(), long\_did\_peer\_4\_to\_short()) und delegiert deren Implementierung an spezialisierte Patch-Module, wobei die ursprünglichen Methoden als Fallback-Referenzen gespeichert werden. Das Modul base\_manager\_patch.py (Listing~\ref{lst:base_manager_patch.py}) stellt die PQC-Implementierungen dieser BaseConnectionManager-Methoden bereit: create\_did\_peer\_4\_pqc\_complete() generiert did:peer:4-DIDs mit ML-DSA-65- und ML-KEM-768-Schlüsseln anstelle klassischer ED25519/X25519-Schlüssel, \_extract\_key\_material\_in\_base58\_format\_pqc() extrahiert PQC-Schlüsselmaterial aus DID-Dokumenten unter Berücksichtigung der größeren Schlüssellängen, und record\_keys\_for\_resolvable\_did\_pqc() persistiert beide PQC-Schlüssel (Signatur- und Verschlüsselungsschlüssel) in der Wallet-Datenbank.

Die Wallet-Integration erfolgt durch drei Module: askar\_pqc\_patch.py (Listing~\ref{lst:askar_pqc_patch.py}) patcht die Aries-Askar-Funktionen create\_keypair() zur Unterstützung von PQC-Schlüsselgenerierung mittels liboqs sowie pack\_message() und unpack\_message() zur Integration der PQC-DIDComm-v1-Implementierung aus pqc\_didcomm\_v1.py. wallet\_patch.py (Listing~\ref{lst:wallet_patch.py}) erweitert die Methode get\_local\_did\_for\_verkey() der AskarWallet-Klasse, um ML-KEM-768-Verkeys korrekt in der Datenbank zu lokalisieren. Dies stellt eine kritische Anpassung dar, da klassische Verkey-Lookups, wie in der Originalmethode get\_local\_did\_for\_verkey() \parencite{openwallet-foundation_AcapyAcapy_agentWalletaskarpymainopenwalletfoundationacapyGitHub_} demonstriert, nur für 32-Byte-ED25519-Schlüssel ausgelegt sind. connection\_target\_patch.py (Listing~\ref{lst:connection_target_patch.py}) passt das Marshmallow-Schema der ConnectionTarget-Klasse an, indem die Validierungsregeln für recipient\_keys PQC-konforme Schlüssellängen akzeptieren.

Die Erweiterung der Schlüsseltyp-Infrastruktur erfolgt durch zwei Module: key\_types.py (Listing~\ref{lst:key_types.py}) definiert neue KeyType-Konstanten (ML\_DSA\_65, ML\_KEM\_768) mit Metadaten wie NIST-FIPS-Referenzen, Schlüssellängen und Multicodec-Präfixen. key\_type\_patches.py (Listing~\ref{lst:key_type_patches.py}) registriert diese KeyTypes in der globalen ACA-Py-Registry durch register\_pqc\_key\_types(), erweitert die Admin-API-Schemata (patch\_api\_key\_type\_schemas()) zur Akzeptanz von PQC-KeyType-Strings in JSON-Requests, und patcht Algorithmus-Mappings (patch\_alg\_mappings\_for\_pqc()) für JWS/JWE-Header-Generierung. multicodec\_patch.py (Listing~\ref{lst:multicodec_patch.py}) erweitert die globale SupportedCodecs-Enumeration durch dynamisches Hinzufügen von ML-DSA-65- und ML-KEM-768-Multicodec-Einträgen, sodass Multicodec-Dekodierungsfunktionen aus multiformats-Bibliotheken PQC-Präfixe verarbeiten können.

Das Modul validator\_patch.py (Listing~\ref{lst:validator_patch.py}) patcht die JWSHeaderKid-Validierungsklasse, die standardmäßig nur klassische DID-Formate (did:key, did:sov) in JWS-Header-kid-Feldern akzeptiert, um did:peer:4-Identifier zu unterstützen. Dies ist eine Voraussetzung für ML-DSA-65-signierte DID-Exchange-AttachDecorators. 

Diese neun Module bilden gemeinsam eine Patch-Architektur, die durch sequenzielle Installation beim Plugin-Setup (orchestriert in \_\_init\_\_.py) eine vollständige PQC-Funktionalität in ACA-Py injiziert, ohne dass Änderungen an Controllern, Admin-API-Endpunkten oder externen Business-Logic-Schichten erforderlich sind.

\subsubsection{Dockerfile-Modifikation}

In der zweiten Iteration wurde das ACA-Py Docker-Base-Image (Listing~\ref{lst:Dockerfile-acapy-base}) aus der ersten Iteration (Kapitel~\ref{SSI-Agenten}) auf einen vier-stufigen Multi-Stage-Build erweitert (Listing~\ref{lst:Dockerfile-acapy-base-pqc} visualisiert dargestellt in \autoref{fig:Iteration2_Acapy_Multi_Stage_Build}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Iteration2_Acapy_Multi_Stage Build.png}
    \caption{ACA-Py Multi-Stage Build Dockerfile mit PQC-Integration (Iteration 2)}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Iteration2_Acapy_Multi_Stage_Build}
\end{figure}

Stage~1 kompiliert OpenSSL~3.5.4 mit FIPS-Modul und nativer ML-KEM/ML-DSA-Unterstützung, Stage~2 baut liboqs~0.14.0 als Shared Library, Stage~3 bleibt identisch zur ersten Iteration (Poetry-basiertes ACA-Py-Wheel), und Stage~4 integriert alle Artefakte durch \enquote{COPY --from}-Direktiven aus den Builder-Stages. Die Runtime-Stage überschreibt System-OpenSSL-Symlinks mittels \enquote{ln -sf}, aktualisiert Shared-Library-Pfade via \enquote{ldconfig}, importiert das PQC-Root-CA-Zertifikat in den System-Trust-Store (\enquote{update-ca-certificates}), und installiert das pqc\_didpeer4\_fm-Plugin mithilfe von \enquote{pip} direkt in das Container-Image.

\subsubsection{Deployment in docker-compose.yml}

Das Deployment der PQC-fähigen SSI-Agenten erfolgt innerhalb der in der ersten Iteration (Kapitel~\ref{sec:Docker Orchestrierung der Gesamtarchitektur}) entwickelten docker-compose.yml-Orchestrierung, deren Evolution vom klassischen Setup (erste Iteration, Listing~\ref{lst:docker-compose.yml-SSI-Agenten}) zur PQC-Integration (zweite Iteration, Listing~\ref{lst:docker-compose.yml-SSI-Agenten-mit-acapy-base-pqc-und-plugin}) zwei zentrale Anpassungen umfasst. Während die Konfiguration der ersten Iteration noch das klassische ACA-Py-Base-Image ohne PQC-Unterstützung und Plugin-Aktivierung verwendet, wurde in der zweiten Iteration im Rahmen der ersten Anpassung die docker-compose.yml so modifiziert, dass alle drei Agent-Services (issuer, holder, verifier) das neue \texttt{acapy-base-pqc}-Image nutzen in welchem das pqc\_didpeer4\_fm-Plugin enthalten ist. Diese Änderung kann durch den Vergleich von \autoref{fig:Docker-Compose-Übersicht-Iteration-2} mit \autoref{fig:Docker-Compose-Übersicht-Iteration-1} nachvollzogen werden. Die zweite Anpassung erweitert die command-Direktive aller drei Agenten um den Parameter \enquote{--plugin pqc\_didpeer4\_fm}, der beim Agent start das pqc\_didpeer4\_fm-Plugin lädt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{docker_compose_übersicht_pqc_plugin.png}
    \caption{Docker-Compose-Übersicht der zweiten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Docker-Compose-Übersicht-Iteration-2}
\end{figure}

\subsection{Formative Evaluation} \label{sec:formative_evaluation_iteration2}

\subsubsection{Validierung des Plugin-Ladevorgangs bei Agent-Start}

Die erste formative Evaluationsmaßnahme bestand in der Validierung des korrekten Plugin-Ladevorgangs beim Start eines ACA-Py-Agenten. Dieser Test diente der Sicherstellung, dass die PQC-Integration transparent und ohne Beeinträchtigung der Standard-ACA-Py-Funktionalität erfolgt.

Listing~\ref{lst:Issuer-Agent-Boot-Logs} zeigt den Boot-Prozess eines Standard-ACA-Py-Agenten ohne PQC-Plugin. Nach der Registrierung der Default- und Askar-Plugins wird direkt mit der Ledger-Konfiguration und Wallet-Initialisierung fortgefahren. Im Vergleich dazu zeigt Listing~\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin} den erweiterten Boot-Prozess mit geladenem pqc\_didpeer4\_fm-Plugin. Zwischen der Askar-Plugin-Registrierung und der Ledger-Konfiguration erfolgt nun die Plugin-Initialisierung mit mehreren charakteristischen Schritten.

\begin{enumerate}
\item Askar-Patching: Die \_create\_keypair-Funktion wird durch eine PQC-fähige Variante ersetzt, die ML-DSA-65 und ML-KEM-768 unterstützt. Zusätzlich werden Session-Methoden (insert\_key, fetch\_key, update\_key) und AskarWallet.assign\_kid\_to\_key() gepatcht.
\item KeyType-Registry-Erweiterung: Die neuen Schlüsseltypen ml-dsa-65 und ml-kem-768 werden in der ACA-Py KeyTypes-Registry registriert und die API-Schemas zur Laufzeit erweitert.
\item did:peer:4-Erweiterung: Die unterstützten Schlüsseltypen für did:peer:4 werden von ['ed25519', 'x25519'] auf ['ed25519', 'x25519', 'ml-dsa-65', 'ml-kem-768'] erweitert.
\item Multicodec-Patching: Die SupportedCodecs-Klasse wird für PQC-Multicodec-Präfixe erweitert (ML-DSA-65: 0xd065, ML-KEM-768: 0xe018).
\item DIDComm-Patching: AskarWallet.pack\_message() und unpack\_message() werden für ML-KEM-768-basierte Verschlüsselung angepasst. Die AttachDecorator-Klasse wird für ML-DSA-65-JWS-Signaturen erweitert.
\item Monkey-Patches: Die BaseConnectionManager-Methoden (create\_did\_peer\_4, record\_keys\_for\_resolvable\_did, etc.) werden durch PQC-fähige Varianten ersetzt.
\end{enumerate}

\subsubsection{Validierung der Pluginfunktionalität: Out-of-Band Invitation mit did:peer:4}

Die zweite formative Evaluationsmaßnahme validierte die Kernfunktionalität des Plugins: die transparente Erstellung von PQC-fähigen did:peer:4-DIDs während des Out-of-Band-Invitation-Prozesses.

Listing~\ref{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-vor-OOB-Invitation} zeigt die initiale Wallet-Abfrage eines frisch gestarteten Issuer-Agenten. Das leere results-Array bestätigt, dass noch keine DIDs im Wallet vorhanden sind.

\refstepcounter{manualListingCounter}
\label{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-vor-OOB-Invitation}
\begin{lstlisting}[language=bash, caption={Zweite Iteration - Wallet DID Abfrage vor Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X GET https://host.docker.internal:8021/wallet/did | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    15  100    15    0     0   1083      0 --:--:-- --:--:-- --:--:--  1153
{
  "results": []
}
\end{lstlisting}

Anschließend wurde mittels \enquote{POST /out-of-band/create-invitation} mit dem Parameter \enquote{use\_did\_method: 'did:peer:4'} eine Einladung erstellt (Listing~\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}). Die API-Response enthält eine vollständige did:peer:4-Langform-DID im services-Array der Invitation, erkennbar am charakteristischen Format \enquote{did:peer:4zQm...:z25g...}.

\refstepcounter{manualListingCounter}
\label{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}
\begin{lstlisting}[language=bash, caption={Zweite Iteration - Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X POST https://host.docker.internal:8021/out-of-band/create-invitation     -H "Content-Type: application/json"     -d '{
      "handshake_protocols": ["https://didcomm.org/didexchange/1.1"],
      "use_did_method": "did:peer:4",
      "my_label": "Issuer Test"
    }' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 16198  100 16051  100   147  91160    834 --:--:-- --:--:-- --:--:-- 91514
{
  "state": "initial",
  "trace": false,
  "invi_msg_id": "89e9cc87-318f-49aa-a61a-fc805706cd8d",
  "oob_id": "70998122-5a5b-4020-8b5f-ae5884af20b3",
  "invitation": {
    "@type": "https://didcomm.org/out-of-band/1.1/invitation",
    "@id": "89e9cc87-318f-49aa-a61a-fc805706cd8d",
    "label": "Issuer Test",
    "handshake_protocols": [
      "https://didcomm.org/didexchange/1.1"
    ],
    "services": [
      "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc..."
    ]
  },
  "invitation_url": "https://host.docker.internal:8020?oob=eyJAdHlwZSI6ICJodHR..."
}
\end{lstlisting}

Die entscheidende Validierung erfolgt in Listing~\ref{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-nach-OOB-Invitation} durch eine erneute Wallet-Abfrage nach der Invitation-Erstellung. Die Response zeigt nun die automatisch generierte PQC-DID mit folgenden charakteristischen Merkmalen:

\begin{itemize}
\item Dual-Key-Struktur: Das key\_type-Feld weist den Wert ml-dsa-65 auf, während die Metadata zusätzlich kem\_verkey (ML-KEM-768) enthält. Dies bestätigt die erfolgreiche Implementierung der Hybrid-Kryptografie mit getrennten Schlüsseln für digitale Signaturen und Schlüsselvereinbarung.
\item PQC-Metadata: Die Metadaten enthalten explizite Marker (pqc\_enabled: true, signature\_algorithm: "ml-dsa-65", key\_agreement\_algorithm: "ml-kem-768"), die eine eindeutige Identifikation PQC-fähiger DIDs zur Laufzeit ermöglichen.
\item Key Identifier: Das kem\_key\_kid-Feld referenziert den KEM-Schlüssel über den DID-URL-Fragment-Identifier \#key-1, was der did:peer:4-Spezifikation entspricht, bei der Verification-Methods sequenziell nummeriert werden (\#key-0 für Authentication, \#key-1 für Key Agreement).
\end{itemize}

\refstepcounter{manualListingCounter}
\label{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-nach-OOB-Invitation}
\begin{lstlisting}[language=bash, caption={Zweite Iteration - Wallet DID Abfrage nach Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X GET https://host.docker.internal:8021/wallet/did | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 17778  100 17778    0     0  1655k      0 --:--:-- --:--:-- --:--:-- 1736k
{
  "results": [
    {
      "did": "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc...",
      "verkey": "2BvJSsMeLjejWKygFBC1qFPLqUvvTzfed7y2Btp...",
      "posture": "wallet_only",
      "key_type": "ml-dsa-65",
      "method": "did:peer:4",
      "metadata": {
        "invitation_reuse": "true",
        "pqc_enabled": true,
        "signature_algorithm": "ml-dsa-65",
        "key_agreement_algorithm": "ml-kem-768",
        "kem_key_kid": "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc...D6SUGP43VJWg#key-1",
        "kem_verkey": "h6ngVfG9n2qF1SY5gM3DaDhK9iiwhvnW555QtodD1sgvEcg5...",
        "plugin": "pqc_didpeer4_fm",
        "version": "0.1.0"
      }
    }
  ]
}
\end{lstlisting}

\subsection{Finales Artefakt}

Das finale Artefakt der zweiten Iteration repräsentiert einen funktionsfähigen SSI-Prototypen mit vollständiger Post-Quantum-Kryptografie-Integration auf Application-Layer-Ebene. Die Architektur vereint die in Iteration~1 etablierte Transport-Layer-Sicherung mittels PQC-Sidecar-Proxies mit einer tiefgreifenden Anwendungsschicht-Integration durch das entwickelte pqc\_did\_peer4\_fm-Plugin.

Die Kernkomponente bildet das ACA-Py-Plugin mit dreischichtiger Architektur. Die Kryptografie-Abstraktionsschicht kapselt native liboqs-Operationen und exponiert eine Python-API für ML-DSA-65 und ML-KEM-768. Die DID-Verarbeitungsschicht orchestriert Generierung, Auflösung und Kodierung PQC-fähiger did:peer:4-Identifikatoren. Die Integration-Patching-Schicht realisiert transparentes Monkey-Patching kritischer ACA-Py-Kernfunktionen ohne Modifikation des Framework-Quellcodes.

Hinsichtlich der in Kapitel~4.2.1 definierten Designziele erfüllt das finale Artefakt sämtliche Anforderungen. Das Designziel zu FF1 (Systemarchitektur \& Compliance) wird durch die native Unterstützung quantenresistenter Signaturen in den DID-Dokumenten adressiert, wodurch die Authentizität von Identitätsnachweisen unabhängig vom Transportkanal langfristig gegenüber Quantencomputer-Angriffen gewährleistet bleibt. Das Designziel zu FF2 (Algorithmenauswahl \& Sicherheitsbewertung) manifestiert sich in der erfolgreichen Integration von ML-DSA-65 für digitale Signaturen innerhalb der did:peer:4-Strukturen, was die praktische Machbarkeit von PQC-Signaturen in dezentralen Identifikatoren nachweist. Das Designziel zu FF3 (Kryptografische Agilität) wird durch die Erweiterung der Multicodec-Registry um provisorische Präfixe für ML-DSA-65 (0xd065) und ML-KEM-768 (0xe018) sowie die abstrahierte Kryptografie-Schicht realisiert, welche die Koexistenz klassischer und post-quanten Verfahren innerhalb der DID-Methoden ermöglicht.

Das Multi-Stage-Build-Dockerfile integriert alle Abhängigkeiten in ein kohärentes Container-Image: Stage~1 kompiliert OpenSSL~3.5.4 mit nativer ML-KEM/ML-DSA-Unterstützung, Stage~2 baut liboqs~0.14.0, Stage~3 generiert das ACA-Py-Wheel, und Stage~4 fusioniert alle Artefakte in ein produktionsfähiges Runtime-Image. Die formative Evaluation validierte die funktionale Korrektheit durch erfolgreiche Plugin-Registrierung beim Agent-Start sowie korrekte Generierung von did:peer:4-Long-Form-DIDs mit PQC-Schlüsselmaterial im Out-of-Band-Invitation-Workflow.












\newpage
\section{Summative Evaluation} \label{sec:Summative Evaluation}
        - Evaluationsmethodik (FEDS)


Im Rahmen der summativen Evaluation wurde das finale Artefakt aus \fixme{KAPITEL} mithilfe des in \ref{sec:Anhang_Summative Evaluation} dargestellten Jupyter Notebooks evaluiert.

KRITIS Szenario ...  Ziel der Evaluation ist die Validierung der funktionalen Anforderungen gemäß Kapitel~\ref{sec:Funktionale Anforderungen}.

- Erst Initialisierung des Artefakts durch:

==> \ref{sec:Anhang_Teil1-Setup-Verbindungstests}
    Variablendeklaration und Helper Funktionen ==> Listing~\ref{lst:Jupyter-Notebook-Cell-1}

    Infrastrukturcheck und Zeigen der Ledgerinitialisierung durch Abruf der Ledgertransaktionen (Validator-Node-Registrierung) ==> Listing~\ref{lst:Jupyter-Notebook-Cell-2-output}

==> \ref{sec:Anhang_Teil2-DID-Setup-Ledger-Registration-KRITIS-Identitäten}
    - ANlegen von Issuer DID lokal im acapy agent ==> Listing~\ref{lst:Jupyter-Notebook-Cell-3-output}
    - Registrieren als ENDORSER auf Ledger ==> Listing~\ref{lst:Jupyter-Notebook-Cell-4-output}
    - Walletansicht indy ed25519 posted mit true

\subsection{Validierung der funktionalen Anforderungen}

\subsubsection{Issuer Discovery}

Die funktionale Anforderung FR1 fordert, dass das System die Auffindbarkeit von publizierten Credential-Schemata des Issuers digitaler Identitätsnachweise ermöglichen muss. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines dreiphasigen, Ledger-basierten Discovery-Mechanismus demonstriert (Listing~\ref{lst:Jupyter-Notebook-Cell-8} und Listing~\ref{lst:Jupyter-Notebook-Cell-8-output}). 

Phase 1 extrahiert alle TRUST\_ANCHOR-Identitäten (Role \texttt{'101'}) aus NYM-Transaktionen des Domain Ledgers, wobei im KRITIS-Szenario der Issuer \enquote{Energienetzbetreiber} mit DID \texttt{9pbXiFBZZGwXKp61HQBz3J} identifiziert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-8-output}, Zeilen 7--17). 

Phase 2 verifiziert sechs kryptographische Eigenschaften (DID-Identifier, Ed25519-Verkey, TRUST\_ANCHOR-Role, Endorser, On-Ledger-Aktivitäten, Registrierungszeitpunkt) mittels der Funktion \texttt{verify\_issuer\_identity()}, wobei für den identifizierten Issuer alle Eigenschaften erfolgreich validiert werden (Listing~\ref{lst:Jupyter-Notebook-Cell-8-output}, Zeilen 24--29). 

Phase 3 filtert SCHEMA-Transaktionen nach dem Schema-Namen \texttt{kritis\_emergency\_maintenance\_cert}, extrahiert den Issuer-DID aus dem Schema-Identifier-Format \texttt{<issuer\_did>:2:<schema\_name>:<version>} und führt eine Cross-Referenzierung mit den TRUST\_ANCHOR-Identitäten durch (Listing~\ref{lst:Jupyter-Notebook-Cell-8-output}, Zeilen 39--60).


\subsubsection{Connection Creation}

Die funktionale Anforderung FR2 fordert, dass das System Verbindungen zwischen den Akteuren des SSI-Ökosystems etablieren muss. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines dreiphasigen Out-of-Band-Invitation-Protokolls mit did:peer:4-basierter Post-Quantum-Kryptographie demonstriert (Listing~\ref{lst:Jupyter-Notebook-Cell-9}, Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Listing~\ref{lst:Jupyter-Notebook-Cell-10} und Listing~\ref{lst:Jupyter-Notebook-Cell-10-output}).

Phase~1 implementiert einen Pre-Check existierender Connections via \texttt{GET /connections} auf beiden Agenten, um redundante Connection-Erstellungen zu vermeiden, wobei im KRITIS-Szenario keine existierenden Connections gefunden werden und eine neue Etablierung ausgelöst wird (Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Zeilen~5--10).

Phase~2 realisiert die Connection-Etablierung mittels Aries RFC~0434 Out-of-Band Protocol: Der Inviter erstellt eine Invitation mit \texttt{POST /out-of-band/create-invitation} unter Verwendung von \texttt{use\_did\_method: "did:peer:4"}, wobei die Response eine \texttt{invitation\_msg\_id} als eindeutigen Identifier enthält (Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Zeile~14). Der Invitee akzeptiert die Invitation via \texttt{POST /out-of-band/receive-invitation}, wodurch das DIDComm DIDExchange-Protokoll initiiert und did:peer:4-DIDs mit ML-DSA-65-Schlüsselmaterial generiert werden (Listing~\ref{lst:Jupyter-Notebook-Cell-12-output} zeigt die resultierenden DIDs mit Metadata \texttt{pqc\_enabled: true}, \texttt{signature\_algorithm: ml-dsa-65}, \texttt{key\_agreement\_algorithm: ml-kem-768}). Der Inviter identifiziert seine Connection anhand der \texttt{invitation\_msg\_id} durch Iteration über alle Connections, wobei die erfolgreiche Zuordnung mit übereinstimmender \texttt{invitation\_msg\_id} und State \texttt{active} validiert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Zeilen~23--27).

Phase~3 validiert den Connection-Status durch Abruf detaillierter Connection-Informationen via \texttt{GET /connections/\{conn\_id\}} auf beiden Seiten, wobei die Konsistenz durch Vergleich der \texttt{invitation\_msg\_id}, komplementäre \texttt{their\_role}-Werte (\texttt{inviter}/\texttt{invitee}) und beidseitigen State \texttt{active} verifiziert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Zeilen~31--45). Die Connection-Übersicht (Listing~\ref{lst:Jupyter-Notebook-Cell-11-output}) gruppiert Connections anhand der \texttt{invitation\_msg\_id} und zeigt zwei aktive Connection-Paare: Issuer<-->Holder (Connection~Group~1) und Holder<-->Verifier (Connection~Group~2), wodurch die vollständige Konnektivität des SSI-Dreiecks validiert wird.

\subsubsection{Credential Creation}

Die funktionale Anforderung FR3 fordert, dass das System Funktionalität zur Erstellung und Ausstellung digitaler Credentials bereitstellen muss. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines mehrstufigen Credential-Issuance-Workflows mit Revocation-Registry-Integration demonstriert (Listing~\ref{lst:Jupyter-Notebook-Cell-13}, Listing~\ref{lst:Jupyter-Notebook-Cell-13-output} und Listing~\ref{lst:Jupyter-Notebook-Cell-14-output}).

Der Issuer initiiert die Credential-Ausstellung durch Versenden eines Credential Offers via \texttt{POST /issue-credential-2.0/send-offer} mit einer Credential Preview, die neun KRITIS-spezifische Attribute enthält (Identität: \texttt{first\_name}, \texttt{name}, \texttt{organisation}; Berechtigung: \texttt{cert\_type}, \texttt{facility\_type}, \texttt{security\_clearance\_level}; Zeitgültigkeit: \texttt{epoch\_valid\_from}, \texttt{epoch\_valid\_until}; Rolle: \texttt{role}), wobei die Ausstellung über die in FR2 etablierte Connection (\texttt{connection\_id}) und die in FR1 identifizierte Credential Definition (\texttt{cred\_def\_id}) erfolgt (Listing~\ref{lst:Jupyter-Notebook-Cell-13}, Zeilen~8--31). Die Response enthält eine Exchange ID zur Nachverfolgung des Issuance-Prozesses, wobei der initiale State \texttt{offer-sent} den erfolgreichen Versand bestätigt (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeilen~3--5).

Der Holder akzeptiert das Credential Offer automatisch (\texttt{auto-store=true} Konfiguration), wodurch das Aries RFC~0453 Issue Credential v2.0 Protocol den vollständigen State-Machine-Durchlauf (\texttt{offer-sent} → \texttt{request-sent} → \texttt{credential-issued} → \texttt{done}) ausführt und das Credential im Holder Wallet persistiert. Nach einer Wartezeit von 5 Sekunden (Listing~\ref{lst:Jupyter-Notebook-Cell-13}, Zeile~55) zeigt der Status-Check auf Issuer-Seite den finalen State \texttt{done} (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeile~11), während der Holder-Wallet-Abruf via \texttt{GET /credentials} das gespeicherte Credential mit Referent \texttt{39ac5fc4-efc2-45eb-9a21-01c589757b65} und allen neun Attributen bestätigt (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeilen~14--22).

Die Revocation-Registry-Integration extrahiert zwei kritische Identifier aus der Issuer-Exchange-Response: Die Revocation Registry ID (\texttt{9pbXiFBZZGwXKp61HQBz3J:4:...:CL\_ACCUM:...}) identifiziert die auf dem Indy Ledger publizierte Revocation Registry (Type~113 REVOC\_REG\_DEF Transaction), während die Credential Revocation ID (\texttt{1}) die Position des Credentials im Revocation-Accumulator spezifiziert (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeilen~26--28). Diese IDs werden für den Revocation-Workflow (FR5) benötigt und demonstrieren die Integration von Credential Issuance und Revocation Management im Gesamtsystem.

Die Holder-Credentials-Übersicht (Listing~\ref{lst:Jupyter-Notebook-Cell-14-output}) zeigt das vollständig ausgestellte KRITIS-Notfall-Wartungszertifikat mit allen Attributen, dem Schema-Identifier \texttt{...kritis\_emergency\_maintenance\_cert:1.1} aus FR1, der Credential-Definition-ID aus dem Schema-basierten Discovery-Prozess und dem initialen Revoked-Status \texttt{False}, der die Gültigkeit des Credentials bestätigt (Zeilen~6--19). Der Issuer Credential Registry Check via \texttt{GET /issue-credential-2.0/records} validiert die serverseitige Persistierung des Exchange Records (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeilen~35--38), wobei die Verfügbarkeit des Records die Aktivierung des \texttt{--preserve-exchange-records}-Flags bestätigt, das für Audit-Zwecke und Revocation-Management in KRITIS-Kontexten erforderlich ist.

\subsubsection{Verification with Credentials}

Die funktionale Anforderung FR4 fordert, dass das System einen Verifikationsprozess zwischen Identity Holder, Verifier und Blockchain-basierter Verifiable Data Registry (VDR) durch Validierung eines Identitätsnachweises ermöglichen muss. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines vierstufigen Privacy-Preserving-Verification-Workflows mit Zero-Knowledge-Proofs, Revocation-Detection und Zeitgültigkeitsprüfung demonstriert (Listing~\ref{lst:Jupyter-Notebook-Cell-15} bis Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}).

Der Verifier initiiert den Verifikationsprozess durch Versenden eines Proof Requests via \texttt{POST /present-proof-2.0/send-request} mit einer Indy-Proof-Request-Struktur, die fünf offengelegte Attribute (\texttt{requested\_attributes}: \texttt{cert\_type}, \texttt{facility\_type}, \texttt{epoch\_valid\_from}, \texttt{epoch\_valid\_until}, \texttt{role}) und ein Zero-Knowledge-Predicate (\texttt{requested\_predicates}: \texttt{security\_clearance\_level >= 2}) fordert, während drei Identitätsattribute (\texttt{first\_name}, \texttt{name}, \texttt{organisation}) durch Selective Disclosure geschützt bleiben (Listing~\ref{lst:Jupyter-Notebook-Cell-15}, Zeilen~21--56). Alle Attribute und Predicates enthalten eine \texttt{non\_revoked}-Constraint mit Zeitintervall \texttt{\{from: 0, to: current\_timestamp\}}, die eine Ledger-basierte Echtzeit-Revocation-Prüfung gegen die Revocation Registry erzwingt (Zeilen~24, 30, 36, 42, 48, 54). Der initiale State \texttt{request-sent} bestätigt die erfolgreiche Übermittlung des Proof Requests über die in FR2 etablierte Connection (Listing~\ref{lst:Jupyter-Notebook-Cell-15-Output}, Zeilen~11--12).

Der Holder empfängt den Proof Request (State \texttt{request-received}) und ruft via \texttt{GET /present-proof-2.0/records/\{pres\_ex\_id\}/credentials} alle Credentials ab, die die Proof-Request-Anforderungen erfüllen, wobei die Schema-ID und Credential-Definition-ID aus FR1 und FR3 zur Filterung verwendet werden (Listing~\ref{lst:Jupyter-Notebook-Cell-16-Output}, Zeilen~4--19). Der Holder konstruiert ein \texttt{requested\_credentials}-Objekt durch Mapping der fünf Attribute-Referents (\texttt{attr1\_referent} bis \texttt{attr5\_referent}) und des Predicate-Referents (\texttt{pred1\_clearance}) auf die Credential-ID \texttt{39ac5fc4...}, wobei Attribute mit \texttt{revealed: true} gekennzeichnet werden, während das Predicate ohne Offenlegung des Attributwerts evaluiert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-17-Output}, Zeilen~6--11). Der Versand der Presentation via \texttt{POST .../send-presentation} erzeugt einen Zero-Knowledge-Proof, der kryptographisch beweist, dass der Holder ein Credential mit den geforderten Attributen und erfülltem Predicate besitzt, ohne die unrevealed Attribute offenzulegen (Zeilen~18--26).

Der Verifier empfängt die Presentation (State \texttt{done}, \texttt{verified: true}) und extrahiert die revealed Attributes durch dreistufiges Mapping: (1) Abruf der Attribute-Namen aus \texttt{by\_format.pres\_request.indy.requested\_attributes}, (2) Abruf der Attribut-Werte aus \texttt{by\_format.pres.indy.requested\_proof.revealed\_attrs}, (3) Konstruktion eines Name-Value-Mappings (Listing~\ref{lst:Jupyter-Notebook-Cell-18}, Zeilen~30--44), wodurch fünf offengelegte Attribute (\texttt{cert\_type: Notfall-Wartungsberechtigung}, \texttt{facility\_type: Umspannwerk Nord-Ost}, \texttt{epoch\_valid\_from: 1765026000}, \texttt{epoch\_valid\_until: 1765033200}, \texttt{role: Notfalltechniker}) extrahiert werden (Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}, Zeilen~5--9). Die drei Identitätsattribute bleiben durch Selective Disclosure geschützt und werden als \enquote{NICHT offengelegt (Zero-Knowledge-Proof)} ausgewiesen, wodurch Privacy by Design gemäß DSGVO Art.~25 realisiert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}, Zeilen~11--14).

Die Blockchain-basierte Revocation-Prüfung validiert den Credential-Status durch Vergleich des Indy-Proof-Timestamps mit dem Revocation-Registry-Delta auf dem Ledger, wobei State \texttt{done} und \texttt{verified: true} bestätigen, dass das Credential zum Verifikationszeitpunkt nicht revoked war (Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}, Zeile~18). Die Zeitgültigkeitsprüfung vergleicht einen aktuellen Epoch-Timestamp (Beispielwert \texttt{1765029600}) mit den extrahierten Zeitgrenzen (\texttt{epoch\_valid\_from: 1765026000}, \texttt{epoch\_valid\_until: 1765033200}), wobei die Bedingung \texttt{epoch\_valid\_from <= current\_epoch <= epoch\_valid\_until} die zeitliche Gültigkeit bestätigt (Zeilen~20--27). Die Zero-Knowledge-Predicate-Auswertung extrahiert das erfüllte Predicate \texttt{security\_clearance\_level >= 2} aus \texttt{requested\_proof.predicates}, wobei die exakte Clearance-Stufe (ob Ü2 oder Ü3) durch die ZKP-Eigenschaft verborgen bleibt (Zeilen~29--33).

Die finale Zugriffsentscheidung kombiniert drei Validierungsergebnisse in einer logischen UND-Verknüpfung (\texttt{not is\_revoked AND is\_time\_valid AND has\_required\_clearance}), die im demonstrierten KRITIS-Szenario zum Ergebnis \enquote{ZUGANG GEWÄHRT} führt, da alle Bedingungen erfüllt sind (Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}, Zeilen~36--42). Die Verifiable Data Registry (VDR)-Integration manifestiert sich durch drei Ledger-basierte Validierungsschritte: (1) Schema-Validation via Schema-ID aus FR1, (2) Credential-Definition-Validation via Cred-Def-ID, (3) Revocation-Registry-Validation via \texttt{non\_revoked}-Constraint, wodurch alle kryptographischen Artefakte (Schema, Cred-Def, RevReg-Def, RevReg-Delta) vom Hyperledger Indy Ledger abgerufen und validiert werden.

\subsubsection{Credential Revocation}

Die funktionale Anforderung zur Credential Revocation fordert, dass das System die Ungültigkeitserklärung ausgestellter Credentials ermöglichen muss, wobei Verifier die Gültigkeit kryptographisch überprüfen können. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines dreiphasigen Revocation-Workflows demonstriert: Registry-Management, Two-Phase-Revocation (Staging + Publishing) sowie Non-Revocation-Proof Verification.

Phase~1 implementiert die Verwaltung von Revocation Registries durch den Issuer. Listing~\ref{lst:Jupyter-Notebook-Cell-19} demonstriert den Abruf aktiver Revocation Registries via \texttt{GET /revocation/registries/created?state=active}. Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-19-output}) zeigt zwei aktive Registries mit jeweils 100 Credential-Kapazität. Jede Registry enthält kritische Metadaten: \texttt{rev\_reg\_id} (eindeutige Registry-Identifier), \texttt{tails\_hash} (kryptographischer Hash der Tails-File für Zero-Knowledge Non-Revocation-Proofs), \texttt{tails\_local\_path} (lokaler Speicherort der Tails-File) sowie \texttt{issuer\_did} (did:indy des Issuers). Die Tails-File ist essentiell für die kryptographische Accumulator-basierte Revocation-Prüfung nach dem CL-Signature-Schema und wird vom Holder benötigt, um Non-Revocation-Proofs zu generieren.

Phase~2 realisiert die Two-Phase-Revocation durch Staging und Ledger-Publishing. Listing~\ref{lst:Jupyter-Notebook-Cell-20} demonstriert die Staging-Phase via \texttt{POST /revocation/revoke} mit \texttt{publish: false}. Die Revocation-Request referenziert das Credential durch \texttt{rev\_reg\_id} (Registry-Identifier) und \texttt{cred\_rev\_id} (Credential-spezifische Revocation-ID, hier: \texttt{"1"}). Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-20-output}) bestätigt den Status \texttt{"Pending"} -- die Revocation ist lokal staged, jedoch noch nicht auf dem Ledger publiziert. Listing~\ref{lst:Jupyter-Notebook-Cell-21} führt die Publishing-Phase aus via \texttt{POST /revocation/publish-revocations}. Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-21-output}) zeigt die erfolgreiche Ledger-Transaktion: Typ \texttt{114 (REVOC\_REG\_ENTRY)}, Sequence Number \texttt{14}, mit kryptographischen Accumulator-Updates (\texttt{prevAccum}, \texttt{accum}) und der Liste revokierter Credential-IDs (\texttt{revoked: [1]}). Die Ledger-Transaktion ist durch ED25519-Signatur des Issuers authentifiziert und via Byzantine Fault Tolerance konsistent repliziert.

Phase~3 validiert die Revocation-Enforcement durch Proof-Verification. Listing~\ref{lst:Jupyter-Notebook-Cell-14-output-revocation} zeigt das Holder-Wallet nach Revocation mit \texttt{Revoked Status: True}. Listings~\ref{lst:Jupyter-Notebook-Cell-15-output-revocation} bis \ref{lst:Jupyter-Notebook-Cell-17-output-revocation} demonstrieren den Proof-Request- und Presentation-Workflow: Der Holder wählt das revokierte Credential aus (Auto-Select via \texttt{auto\_present: true}), versucht einen Non-Revocation-Proof zu generieren, jedoch schlägt die Proof-Generierung fehl, da der kryptographische Accumulator das Credential als revoked markiert. Listing~\ref{lst:Jupyter-Notebook-Cell-18-output-revocation} zeigt die finale Verifier-Entscheidung: \texttt{Verified: false}, \texttt{Credential ist REVOKED}, \texttt{ZUGANG VERWEIGERT}. Trotz zeitlicher Gültigkeit (Epoch-Check erfüllt: \texttt{1765026000 <= 1765029600 <= 1765033200}) und erfülltem ZKP-Predicate (\texttt{security\_clearance\_level >= 2}) wird der Zugang verweigert, da die Revocation-Prüfung fehlschlägt. Dies demonstriert die Enforcement-Priorität: Revocation-Status dominiert alle anderen Validierungskriterien und stellt sicher, dass kompromittierte Credentials sofort unwirksam werden -- eine kritische Sicherheitsanforderung für KRITIS-Infrastrukturen.

\subsubsection{Credential Deletion}

Die funktionale Anforderung zur Credential Deletion fordert, dass Holder die Möglichkeit besitzen müssen, Credentials lokal aus ihrem Wallet zu entfernen, wobei diese Operation ausschließlich die lokale Datenhaltung betrifft und vom Ledger-basierten Revocation-Mechanismus zu unterscheiden ist. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines dreiphasigen Deletion-Workflows demonstriert: Pre-Deletion Inventory, Credential Deletion sowie Post-Deletion Verification.

Phase~1 implementiert das Pre-Deletion Inventory durch Abruf aller im Holder-Wallet gespeicherten Credentials (Listing~\ref{lst:Jupyter-Notebook-Cell-22}, Zeilen~7--43). Via \texttt{GET /credentials} werden alle Credential-Metadaten abgerufen, wobei für jedes Credential der \texttt{referent} (eindeutige Wallet-Identifier), \texttt{schema\_id}, \texttt{cred\_def\_id} sowie der Revocation-Status via \texttt{GET /credential/revoked/\{referent\}} ermittelt wird. Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~1--19) zeigt ein Credential mit \texttt{Revoked: True} -- dieses Credential wurde zuvor via Ledger-Revocation ungültig erklärt (Cell~20--21), befindet sich jedoch weiterhin im lokalen Wallet. Die Auflistung aller Attribute (\texttt{security\_clearance\_level: 2}, \texttt{role: Notfalltechniker}, \texttt{facility\_type: Umspannwerk Nord-Ost}) demonstriert, dass revokierte Credentials im Wallet persistieren, bis der Holder sie explizit löscht. Die \texttt{referent}-Identifier werden in der Liste \texttt{credentials\_to\_delete} gespeichert (Zeile~34) für die nachfolgende Deletion-Phase.

Phase~2 realisiert die Credential Deletion durch iterative Deletion aller erfassten Credentials (Listing~\ref{lst:Jupyter-Notebook-Cell-22}, Zeilen~45--75). Für jeden \texttt{credential\_id} wird via \texttt{DELETE /credential/\{credential\_id\}} die lokale Wallet-Entfernung ausgeführt. Die \texttt{api\_delete()}-Hilfsfunktion behandelt HTTP~204~No~Content Responses korrekt (erfolgreiches Löschen ohne Response-Body). Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~21--30) zeigt die erfolgreiche Deletion: \texttt{Gelöscht: 1/1}, wobei die Deletion Summary die Erfolgsrate dokumentiert. Diese Phase demonstriert die Holder-Autonomie über lokale Wallet-Daten -- der Holder kann Credentials unilateral entfernen, ohne Issuer-Interaktion oder Ledger-Transaktion.

Phase~3 validiert die Deletion-Enforcement durch Post-Deletion Verification (Listing~\ref{lst:Jupyter-Notebook-Cell-22}, Zeilen~77--115). Ein erneuter Abruf via \texttt{GET /credentials} bestätigt das leere Wallet: \texttt{Holder Wallet ist jetzt LEER (alle Credentials gelöscht)} (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~32--36). Die explizite Unterscheidung zwischen lokaler Deletion und Ledger-Revocation wird durch Hinweise dokumentiert (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~38--43): \texttt{Credential ist LOKAL im Wallet gelöscht}, \texttt{Credential ist NICHT auf dem Ledger revoked}, \texttt{Issuer kann das Credential weiterhin sehen}. Diese Differenzierung ist kritisch für das Verständnis des SSI-Sicherheitsmodells: Lokale Deletion entfernt das Credential aus der Holder-Verfügungsgewalt (kein Proof mehr generierbar), jedoch bleibt die Ledger-basierte Revocation-Historie intakt (\texttt{--preserve-exchange-records} beim Issuer aktiv). Für KRITIS-konforme Audit-Trails bedeutet dies: Die Credential-Issuance-History ist unveränderlich auf dem Ledger gespeichert, während der Holder die Privacy-wahrende Möglichkeit besitzt, lokale Credential-Kopien zu entfernen.

%       - KRITIS-Szenarien (Energie, Gesundheit, Wasser)
% \subsection{Performance-Analyse}
%        - Latenz-Messungen (Baseline, PQC, Hybrid) \\
%        - Durchsatz-Analyse \\
%        - Speicher- und Rechenaufwand \\
%        - Skalierbarkeitstest



\subsection{Validierung der KRITIS-Compliance-Anforderungen}

\subsubsection{Einhaltung spezifischer Parameter-Sets für ML-DSA}

Die Compliance-Anforderung zur Einhaltung BSI-konformer ML-DSA Parameter-Sets (NIST Security Strength Category 3 oder 5) wird durch strategische Verwendung zweier Sicherheitsstufen erfüllt: ML-DSA-65 (Category 3) für operationale Signaturen sowie ML-DSA-87 (Category 5) für die Root Certificate Authority. Das finale Artefakt implementiert ML-DSA in drei Schichten: (1)~TLS~1.3 Server-Zertifikate für alle fünf Nginx Sidecar Proxies (hopE-Agenten: Issuer/Holder/Verifier, VON-Network Webserver, Tails Server) werden mittels ML-DSA-65 signiert, konfiguriert via Build-Argument (SIG\_ALG: mldsa65) in den Docker-Infrastruktur-Definitionen (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry}, Listing~\ref{lst:docker-compose.yml-SSI-Agenten}), wobei die Root CA als langfristiger Trust-Anchor mit der höheren Sicherheitsstufe ML-DSA-87 geschützt ist (Listing~\ref{lst:Zertifikatserstellungsworkflow}). (2)~did:peer:4 Signing Keys für dezentrale Agent-to-Agent Authentifizierung werden mit ML-DSA-65 generiert (Listing~\ref{lst:key_types.py}). (3)~DIDComm~v1 Authcrypt Message-Signierung nutzt ML-DSA-65 via LibOQS-Integration (Listing~\ref{lst:liboqs_wrapper.py}) für kryptographisch verifizierbare Sender-Authentifizierung in verschlüsselten Nachrichten.

Die erfolgreiche operationale Integration von ML-DSA-65 wird zum einen durch \autoref{fig:Successful-Validation-Issuer-TLS1.3} demonstriert, welches die TLS~1.3 Verbindung zum Issuer-Agenten mit ML-DSA-65 signiertem Server-Zertifikat validiert, und zum anderen durch die Wallet-Übersicht in Listing~\ref{lst:Jupyter-Notebook-Cell-12-output} demonstriert, in welcher alle drei SSI-Agenten key\_type: "ml-dsa-65" für did:peer:4 DIDs nutzen.

\subsubsection{Einhaltung spezifischer Parameter-Sets für ML-KEM}

Diese Anforderung wird durch systemweite Implementierung von ML-KEM-768 (Category 3) erfüllt. Das finale Artefakt implementiert ML-KEM-768 in zwei Schichten: (1)~TLS~1.3 Key Exchange für alle fünf Nginx Sidecar Proxies nutzt ML-KEM-768 konfiguriert via \texttt{DEFAULT\_GROUPS=X25519MLKEM768} in den Docker-Infrastruktur-Definitionen (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry}, Listing~\ref{lst:docker-compose.yml-SSI-Agenten}) sowie via \texttt{ssl\_ecdh\_curve X25519MLKEM768} in den Nginx-Konfigurationen (Listing~\ref{lst:nginx-pqc-konfiguration}). (2)~did:peer:4 Key Agreement für dezentrale Agent-to-Agent Verschlüsselung wird mit ML-KEM-768 realisiert (Listing~\ref{lst:key_types.py}), womit DIDComm-Nachrichten mittels Post-Quantum-resistenter Schlüsselkapselung verschlüsselt werden.

Die erfolgreiche operationale Integration von ML-KEM-768 wird zum einen durch \autoref{fig:Successful-Validation-Issuer-TLS1.3} demonstriert, welches die TLS~1.3 Verbindung zum Issuer-Agenten mit ML-DSA-65 signiertem Server-Zertifikat validiert, und zum anderen durch die Wallet-Übersicht in Listing~\ref{lst:Jupyter-Notebook-Cell-12-output} demonstriert, in welcher alle drei SSI-Agenten key\_type: "ml-dsa-65" für did:peer:4 DIDs nutzen.

\subsubsection{Implementierung hybrider Schlüsseleinigung}

Die BSI-Anforderung zur hybriden Schlüsseleinigung (Kombination klassisches Verfahren mit PQC-KEM) wird durch X25519+ML-KEM-768 Hybrid-Modus erfüllt. Das finale Artefakt implementiert hybride Schlüsseleinigung systemweit via \texttt{DEFAULT\_GROUPS=X25519MLKEM768:mlkem768:x25519} in allen Docker-Infrastruktur-Definitionen (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry}, Listing~\ref{lst:docker-compose.yml-SSI-Agenten}), wobei die Priorisierung X25519MLKEM768 als primären Hybrid-Modus sicherstellt. Die TLS~1.3 Verbindungen aller fünf Nginx Sidecar Proxies kombinieren elliptische Kurven-Kryptographie (X25519, klassisch) mit gitterbasiertem ML-KEM-768 (Post-Quantum) für Perfect Forward Secrecy, wobei OpenSSL~3.5.4 mit nativer PQC-Unterstützung die kryptographische Verknüpfung beider Shared Secrets via Key Derivation Function durchführt (Listing~\ref{lst:nginx-pqc-konfiguration}). Zusätzlich implementiert did:peer:4 hybride Key Agreement zwischen X25519- und ML-KEM-768-Keys aus DID Documents für DIDComm Message Encryption (Listing~\ref{lst:key_types.py}). Die Fallback-Strategie \texttt{mlkem768:x25519} gewährleistet Interoperabilität mit Peers ohne Hybrid-Unterstützung, wobei reine PQC-Verschlüsselung via ML-KEM-768 Vorrang vor klassischem X25519 hat. Diese Architektur entspricht BSI-TR-02102-1 Kapitel~2.2 und 2.4 zur Absicherung gegen kryptanalytische Durchbrüche sowohl im klassischen als auch im Quantum-Computing-Bereich.

\subsubsection{Bevorzugte Verwendung von TLS 1.3}
  
Die BSI-Empfehlung zur vorrangigen Verwendung von TLS~1.3 wird durch systemweite TLS~1.3-Enforcement erfüllt. Das finale Artefakt erzwingt TLS~1.3 in allen fünf Nginx Sidecar Proxies via \texttt{ssl\_protocols TLSv1.3;} in den Konfigurationsdateien (Listing~\ref{lst:nginx_holder.conf}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{summative_evaluation_TLS1.2_error.png}
    \caption{TLS 1.2 Verbindungsversuch zum Issuer-Agenten schlägt fehl (TLS 1.3 Enforcement)}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Summative_Evaluation_TLS1.2_Error}
\end{figure}

\autoref{fig:Summative_Evaluation_TLS1.2_Error} demonstriert das Fehlschlagen des TLS~1.2 Verbindungsversuchs zum Issuer-Agenten.

Für \gls{SzA}

\subsubsection{Protokollierung Sicherheitsrelevanter Ereignisse}

Das finale Artefakt implementiert Protokollierung auf drei Ebenen:

(1)~ACA-Py Agent-Level Logging protokolliert alle Authentifizierungsversuche (Connection Requests, Credential Issuance, Proof Presentations), Zustandsübergänge (State Machines für Issue-Credential/Present-Proof Protokolle) sowie Fehlerzustände via \texttt{--log-level info} in den Docker-Infrastruktur-Definitionen (Listing~\ref{lst:docker-compose.yml-SSI-Agenten}). Listing~\ref{lst:issuer-acapy-agent-logs} demonstriert das Logging sicherheitsrelevanter kryptographischer Events wie ML-DSA-65 Signature Verification, Schlüsselabruf via DID-Resolution und erfolgreiche/fehlgeschlagene DIDcomm-Decryption während des Credential-Issuance-Workflows.

(2)~Nginx Access \& Error Logs auf allen fünf Sidecar Proxies protokollieren TLS-Handshakes, HTTP-Requests sowie fehlgeschlagene Verbindungsversuche, persistiert in Docker Volumes \texttt{nginx-logs} (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry}). Listing~\ref{lst:issuer-nginx-logs} demonstriert das Logging der HTTP-Security-Events auf Proxy-Ebene, Connection-Authentifizierung, Request-Authentifizierung via User-Agent, sowie Request-Body-Buffering für PQC-Schlüsselmaterialien.

(3)~VON-Network Ledger Transaction Logs erfassen alle Blockchain-Operationen (NYM-Transaktionen für DID-Registrierung, SCHEMA/CRED\_DEF-Publikationen, REVOC\_REG\_ENTRY für Revocations) mit Zeitstempeln und Sequence Numbers für unveränderlichen Audit-Trail (demonstriert in Listing~\ref{lst:Jupyter-Notebook-Cell-4-output}, Listing~\ref{lst:Jupyter-Notebook-Cell-21-output}).

\subsubsection{Logische Netzsegmentierung}

Das finale Artefakt implementiert strikte Netzwerk-Segmentierung mittels dedizierter Docker Networks: 

(1)~hopE-Agenten nutzen isolierte Networks \texttt{hope-issuer}, \texttt{hope-holder}, \texttt{hope-verifier} pro Agent, wobei nur die zugehörigen Sidecar Proxies Zugriff haben (Listing~\ref{lst:docker-compose.yml-SSI-Agenten}). 

(2)~Shared Network \texttt{von\_sidecarproxy} verbindet ausschließlich die PQC Sidecar Proxies untereinander für Agent-to-Agent Kommunikation, während interne Agent-Container isoliert bleiben. 

(3)~VON-Network Blockchain-Nodes operieren im dedizierten \texttt{von} Network mit separatem \texttt{sidecarproxy} Network für Webserver-Zugriff (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}). 

(4)~Tails Server nutzt isoliertes \texttt{tails-server} Network mit kontrolliertem Zugang via \texttt{von\_sidecarproxy} (Listing~\ref{lst:docker-compose.yml-Revocation-Registry}). 

\autoref{fig:Docker-Compose-Übersicht-Iteration-1} und \autoref{fig:Darstellung-Network-Isolation} demonstrieren die logische Netzwerksegmentierung.

\subsubsection{Datenschutz durch Technikgestaltung (Privacy by Design)}
% Die Architektur realisiert dies durch den konsequenten Verzicht auf die Speicherung personenbezogener Daten (PII) auf dem unveränderlichen Ledger (Off-Chain-Architektur) und die Nutzung von Zero-Knowledge Proofs

Die DSGVO-Anforderung zu Privacy by Design (Art.~25) wird durch architektonische Trennung von öffentlichen Identifikatoren und personenbezogenen Daten erfüllt. Das finale Artefakt realisiert konsequente Off-Chain-Architektur: (1)~Personenbezogene Daten (PII) wie Name, Organisation, Sicherheitsfreigabe werden ausschließlich in verschlüsselten Verifiable Credentials gespeichert, die lokal im Holder-Wallet persistiert sind (demonstriert in Listing~\ref{lst:Jupyter-Notebook-Cell-14-output}), niemals auf dem unveränderlichen Blockchain-Ledger. (2)~Ledger-Transaktionen enthalten ausschließlich kryptographische Identifikatoren (Schema-IDs, Credential-Definition-IDs, Revocation-Registry-IDs) sowie Public Keys, jedoch keine personenbezogenen Attribute (Listing~\ref{lst:Jupyter-Notebook-Cell-4-output}, Listing~\ref{lst:Jupyter-Notebook-Cell-21-output}). (3)~Zero-Knowledge Proofs ermöglichen selektive Offenlegung: Der Verifier erhält nur explizit angeforderte Attribute (\texttt{revealed\_attrs}), während sensible Daten wie Vorname, Nachname, Organisation durch \texttt{unrevealed}-Status geschützt bleiben, sowie Predicate-basierte Proofs (\texttt{security\_clearance\_level >= 2}) ohne Offenlegung exakter Werte (Listing~\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}). Diese Architektur stellt Privacy by Default sicher, da personenbezogene Daten per Design dezentral beim Holder verbleiben und nur kryptographisch verifizierbare Proofs ausgetauscht werden, womit DSGVO Art.~25 Konformität erreicht wird.

\subsubsection{Grundsatz der Datenminimierung}
% Durch den Einsatz von \textit{Pairwise DIDs} (did:peer) für jede Interaktion statt einer globalen ID wird die Korrelierbarkeit von Daten minimiert und Profilbildung technisch unterbunden

Das finale Artefakt addressiert Datenminimierung in drei Dimensionen:

(1)~Pairwise did:peer:4 DIDs eliminieren globale Identifikatoren: Für jede Agent-to-Agent Connection wird eine dedizierte DID generiert (Listing~\ref{lst:Jupyter-Notebook-Cell-12-output} zeigt pro Agent 3--4 verschiedene did:peer:4 DIDs), wodurch Transaktionskorrelation über verschiedene Verifier hinweg technisch unterbunden wird -- ein kompromittierter Verifier kann keine Aktivitäten des Holders bei anderen Verifiern nachverfolgen. 

(2)~Selective Disclosure in Proof Presentations: Der Holder offenbart ausschließlich die vom Verifier angeforderten Attribute (\texttt{revealed\_attrs}: \texttt{cert\_type, facility\_type, epoch\_valid\_from/until, role}), während Identitätsdaten (\texttt{first\_name, name, organisation}) unrevealed bleiben (Listing~\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}, Zeilen~12--19), wodurch nur zweckgebundene Minimaldaten übermittelt werden. 

(3)~Predicate-basierte Zero-Knowledge Proofs reduzieren Datenoffenlegung weiter: Statt exakte Sicherheitsfreigabe-Stufe zu übermitteln, beweist der Holder kryptographisch \texttt{security\_clearance\_level >= 2} ohne Preisgabe, ob Stufe 2 oder 3 vorliegt (Listing~\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}, Zeilen~21--26). 

Diese mehrstufige Datenminimierung verhindert Profilbildung und unnötige Datensammlung, womit DSGVO-konforme Zweckbindung technisch durchgesetzt wird.

\subsubsection{Recht auf Löschung}
% Durch die strikte Trennung von öffentlichen Identifikatoren (Ledger) und privaten Daten (lokale Wallet) ist eine Löschung technisch vollständig realisierbar, indem die lokale Wallet und die zugehörigen kryptografischen Schlüssel vernichtet werden (Crypto-Shredding)

Die DSGVO-Anforderung zum Recht auf Löschung (Art.~17) wird durch strikte Trennung von Ledger-Identifikatoren und Wallet-Daten erfüllt. Das finale Artefakt realisiert vollständige Löschbarkeit personenbezogener Daten mittels Crypto-Shredding: (1)~Lokale Credential-Deletion entfernt Credentials aus dem Holder-Wallet via \texttt{DELETE /credential/\{credential\_id\}}, demonstriert in Listing~\ref{lst:Jupyter-Notebook-Cell-22}: Nach Deletion ist das Wallet leer (\texttt{Holder Wallet ist jetzt LEER}), womit alle personenbezogenen Attribute (Name, Organisation, Sicherheitsfreigabe) irreversibel gelöscht sind. (2)~Crypto-Shredding durch Wallet-Destruction: Da Credentials im Holder-Wallet mit dem Wallet-Key verschlüsselt persistiert sind (\texttt{holder\_wallet\_key}), führt die Vernichtung des Wallet-Keys zur kryptographischen Unlesbarkeit aller Credential-Daten, selbst wenn Backups existieren -- ohne Key ist Decryption unmöglich. (3)~Ledger-Immutabilität ohne Privacy-Verletzung: Während Blockchain-Transaktionen (Schema-IDs, Cred-Def-IDs, Revocation-Entries) unveränderlich auf dem Ledger verbleiben, enthalten diese per Design keine personenbezogenen Daten, sondern ausschließlich kryptographische Identifier, wodurch Art.~17 DSGVO erfüllt wird (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~38--43: \texttt{Credential ist LOKAL im Wallet gelöscht, NICHT auf dem Ledger revoked}). Diese Architektur gewährleistet vollständige Löschung von PII bei gleichzeitiger Beibehaltung der Audit-Trail-Integrität für KRITIS-Compliance, womit die Balance zwischen DSGVO-Rechten und regulatorischen Anforderungen erreicht wird.

\subsection{Validierung der Kryptoagilität}

\subsubsection{Transportlayer}

Die Implementierung realisiert Kryptoagilität mithilfe der eingebauten Mechanismen in TLS 1.3, welche explizit entwickelt wurden, um eine modulare Austauschbarkeit kryptografischer Primitive zu gewährleisten. Im Gegensatz zu früheren Protokollversionen entkoppelt TLS 1.3 die Aushandlung von Cipher Suite, Schlüsselaustauschverfahren und Signaturalgorithmen vollständig voneinander. Diese Parameter werden orthogonal ausgehandelt, wodurch jeder Mechanismus unabhängig modifiziert werden kann \cite[S. 26]{rescorla_TransportLayerSecurityTLSProtocolVersion13_2018}.
Diese Trennung wird technisch durch die \texttt{supported\_groups}-Erweiterung realisiert, die es Endpunkten erlaubt, präferierte Schlüsselaustauschverfahren unabhängig vom symmetrischen Verschlüsselungsverfahren (AEAD) auszuhandeln \cite[S. 47]{rescorla_TransportLayerSecurityTLSProtocolVersion13_2018}.

Dieser Ansatz korrespondiert direkt mit den von \textcite[S. 102]{mehrez_CryptoAgilityProperties_2018} identifizierten Kryptoagilitätseigenschaften. Spezifisch adressiert die hier gewählte Architektur die Eigenschaft der \enquote{Extensibility}, die Fähigkeit, neue Algorithmen effizient hinzuzufügen, sowie die \enquote{Removability}, das elegante Außerbetriebnehmen veralteter Verfahren, ohne Gefährdung der Systemintegrität.

Die konkrete Umsetzung dieser Agilität in der vorliegenden Arbeit nutzt diese Protokollstruktur, um eine nahtlose Migration zu ermöglichen. Konkret wurde eine konfigurationsbasierte Algorithm-Fallback-Chain via \texttt{DEFAULT\_GROUPS=X25519MLKEM768:mlkem768:x25519:mlkem1024} (Listing~\ref{lst:Dockerfile-Sidecar-Proxy-nginx}) implementiert. Diese Konfiguration instruiert den TLS-Handshake, primär hybride Verfahren zu nutzen, bietet jedoch eine automatische Rückfalloption (Fallback) auf rein klassische Verfahren (\texttt{x25519}) im Falle einer Inkompatibilität. Damit erfüllt die Lösung die Anforderung der \enquote{Fungibility} nach \textcite[S. 102]{mehrez_CryptoAgilityProperties_2018}, die es Systemen erlaubt, Algorithmen auszutauschen. Ebenfalls wird die erste Eigenschaft nach \textcite[S. 19]{cyberresilienceworkshopseriescommittee_CryptographicAgilityInteroperabilityProceedingsWorkshop_2017} adressiert Algorithmen in Echtzeit basierend auf ihrer kombinierten Sicherheitsfunktion auszuwählen.

\autoref{fig:Summative_Evaluation_TLS1.3_Kryptoagilität} demonstriert den kryptoagilen Fallback-Prozess von X25519+ML-KEM-768 zu X25519 im TLS 1.3 Protokoll.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{summative_evaluation_TLS1.3_kryptoagilität.png}
    \caption{TLS 1.3 Kryptoagiler Fallback von X25519+ML-KEM-768 zu X25519}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Summative_Evaluation_TLS1.3_Kryptoagilität}
\end{figure}

\subsubsection{Applikationslayer}

Die Kryptoagilität des SSI-Systems auf Applikationsebene manifestiert sich in der Erfüllung der ersten und zweiten Anforderung von \textcite[S. 19--20]{cyberresilienceworkshopseriescommittee_CryptographicAgilityInteroperabilityProceedingsWorkshop_2017} Sicherheitsalgorithmen in Echtzeit auf Basis ihrer kombinierten Sicherheitsfunktionen auszuwählen, und die Möglichkeit zu eröffnen, neue kryptographische Funktionen bzw. Algorithmen in bestehende Hard- und Software zu integrieren.

Dafür nutzt das SSI-System die Plugin-Architektur von Aries Cloud Agent Python (ACA-Py), die es ermöglicht, bestehende kryptographische Workflows durch gezielte Eingriffe zu modifizieren, ohne den Kerncode der Agenten zu verändern. Dieses Designprinzip entspricht dem \enquote{Open/Closed Principle} der Softwareentwicklung, welches besagt, dass Softwaremodule offen für Erweiterungen, jedoch geschlossen für Modifikationen sein sollten \cite[S. 99]{martin_AgileSoftwareDevelopmentprinciplespatternspractices_2003}.

Dafür implementiert das Plugin einen metadatengesteuerten Ansatz zur Algorithmenauswahl. Wie in Listing~\ref{lst:Jupyter-Notebook-Cell-9-Demonstration-Kryptoagilität-ed25519} demonstriert, kann der gewünschte Schlüsseltyp durch Übergabe des Parameters \enquote{metadata: \{key\_type : ed25519\}} explizit spezifiziert werden.

Bei der Verarbeitung einer Out-of-Band (OOB) Invitation durchläuft das System folgenden Entscheidungsbaum: Der \enquote{OutOfBandManager} empfängt die Metadata-Parameter aus der API-Anfrage und propagiert diese an die DID-Erstellungslogik. In der Funktion \enquote{create\_did\_peer\_4\_conditional\_pqc} (Listing~\ref{lst:base_manager_patch.py}) erfolgt eine Auswertung des \enquote{key\_type}-Parameters. Wird der Wert \enquote{ed25519} erkannt, delegiert das Plugin die gesamte DID-Erstellung an die ursprüngliche ACA-Py-Implementierung (\enquote{\_original\_create\_did\_peer\_4}), wodurch ein vollständiger Fallback auf klassische Kryptographie ohne Plugin-Interferenz gewährleistet wird. Fehlt die Metadata-Spezifikation aktiviert das System standardmäßig die Post-Quantum-Kryptographie mit den Algorithmen ML-DSA-65 für digitale Signaturen und ML-KEM-768 für Schlüsselkapselung.

Die erfolgreiche Validierung dieser Kryptoagilität zeigt Listing~\ref{lst:Jupyter-Notebook-Cell-9-Demonstration-Kryptoagilität-ed25519-output}. Trotz aktiviertem Plugin etabliert sich eine vollständig ED25519-basierte Verbindung zwischen Issuer- und Holder-Agent. Die Verbindung erreicht den Status \enquote{active} auf beiden Seiten, was die korrekte Durchführung des DID Exchange-Protokolls mit klassischen Algorithmen bestätigt.

Listing~\ref{lst:Jupyter-Notebook-Cell-11-Demonstration-Kryptoagilität-ed25519-output} verifiziert die persistierte Kryptographie-Konfiguration auf Wallet-Ebene. Die Inspektion der gespeicherten DIDs zeigt konsistent den Wert \enquote{{key\_type}:{ed25519}}. Insbesondere die Abwesenheit von PQC-spezifischen Metadata-Markern wie \enquote{pqc\_enabled}, \enquote{signature\_algorithm} oder \enquote{kem\_verkey} in den DID-Metadaten bestätigt, dass das Plugin keinerlei modifizierende Eingriffe in den ED25519-Workflow vorgenommen hat.

% \newpage
% \section{Systemarchitektur und Design} \label{sec:Systemarchitektur und Design}