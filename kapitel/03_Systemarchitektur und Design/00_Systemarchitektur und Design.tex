\newpage
\section{Methodik} \label{sec:Methodik}

\fixme{2,3333 Seiten BILDER/TABELLEN ==> kann erweitert werden}

\subsection{Systematische Literaturrecherche} \label{sec:Systematische Literaturrecherche}

Die systematische Literaturrecherche dieser Masterarbeit folgt ausgewählten Methoden der \ac{PRISMA} 2020 Richtlinien zur strukturierten Identifikation, Selektion, Bewertung und Synthese einschlägiger Studien, wodurch eine belastbare Grundlage für die Analyse der Forschungslücke und die Ableitung der Forschungsfragen geschaffen wird \parencite[S. 1]{page_PRISMA2020Statementupdatedguidelinereportingsystematicreviews_2021}. Dieses Vorgehen bietet einen strukturierten Ansatz zur Durchführung und Dokumentation von Literaturrecherchen, der die Qualität und Vollständigkeit der Berichterstattung verbessert und einen transparenten und reproduzierbaren Prozess gewährleistet \parencite[S. 1]{page_PRISMA2020Statementupdatedguidelinereportingsystematicreviews_2021}.

Die systematische Literaturrecherche wurde in zwei zeitlich getrennten Iterationen durchgeführt, um den dynamischen Charakter des Forschungsfeldes zu adressieren und die Aktualität der Wissensbasis sicherzustellen. Beide Iterationen sind ausführlich dokumentiert in \ref{sec:Anhang_Dokumentation_der_systematischen_Literaturrecherche} und dienen ausschließlich der Problemidentifikation, der Ergründung des Forschungsstands sowie der Ableitung der Forschungslücke und initialen Forschungsfragen.

Der konsolidierte Suchprozess in der Datenbank EBSCO führte über beide Phasen hinweg zur Identifikation von insgesamt 95 potenziellen Quellen. Davon entfielen 61 Publikationen auf die erste Iteration im Mai 2025 (siehe \autoref{fig:PRISMA_Flussdiagramm_iteration1}) und 34 Publikationen auf die zweite Iteration im November 2025 (siehe \autoref{fig:PRISMA_Flussdiagramm_Iteration2}). Die methodische Konsistenz wurde dabei durch die Anwendung identischer Suchstrategien und Selektionskriterien in beiden Zeiträumen sichergestellt.

Nach der Bereinigung von Duplikaten und der Anwendung der Ein- und Ausschlusskriterien verblieb ein fokussierter Bestand an hochrelevanten Studien. Eine detaillierte Übersicht der identifizierten Quellen findet sich in \autoref{tab:quellenuebersicht_Iteration1} für die erste und \autoref{tab:quellenuebersicht_iteration2} für die zweite Phase. Die vollständige Aufschlüsselung der Selektionsschritte sowie die zugehörigen Flussdiagramme sind zudem gesammelt in \ref{sec:Anhang_Dokumentation_der_systematischen_Literaturrecherche} aufgeführt.

\fixme{Anhangskapitel fixen ==> Transparente Dokumentation // Hat noch komische Texte}

\subsection{Design Science Research} \label{Design Science Research}

\ac{DSR} bildet den methodischen Rahmen dieser Masterarbeit. \ac{DSR} stellt neben der verhaltenswissenschaftlichen Forschung ein eigenständiges Forschungsparadigma dar \parencite[S. 75]{hevner_DesignScienceInformationsystemsresearch_2004}. Während verhaltenswissenschaftliche Ansätze Theorien zur Erklärung oder Vorhersage entwickeln, fokussiert DSR auf die Erschaffung innovativer Artefakte zur Erweiterung menschlicher und organisatorischer Fähigkeiten \parencite[S. 75]{hevner_DesignScienceInformationsystemsresearch_2004}. Fundamental ist \ac{DSR} ein lösungsorientiertes Paradigma \parencite[S. 76]{hevner_DesignScienceInformationsystemsresearch_2004}, dessen Prinzip darin besteht, Wissen durch den Bau und die Anwendung eines Artefakts zu gewinnen \parencite[S. 82]{hevner_DesignScienceInformationsystemsresearch_2004}.

Das Information Systems Research Framework (\autoref{fig:hevner2004_framework}) nach \textcite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004} strukturiert den Forschungsprozess durch drei Hauptkomponenten.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{dsr_ISR_Framework.png}
    \caption{Information Systems Research Framework}
    \begin{flushleft}
    \textit{Anmerkung.} Aus \textcite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}.
    \end{flushleft}
    \label{fig:hevner2004_framework}
\end{figure}

Die \textbf{Environment}-Komponente definiert den Problemraum \parencite[S. 108]{simon_SciencesArtificial_1996} mit Menschen, Organisationen und Technologien sowie den Geschäftsanforderungen \parencite[S. 7--11]{silver_InformationTechnologyInteractionModelFoundationMBACoreCourse_1995}. Für diese Arbeit bilden kritische Infrastrukturen die Environment mit ihren Anforderungen an Post-Quantum-Sicherheit und selbstbestimmte Identitätsverwaltung. Die \textbf{IS Research}-Komponente umfasst Build/Evaluate-Aktivitäten für Artefakte \parencite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}. Hier erfolgt die Instanziierung und Evaluation eines PQC-fähigen SSI-Prototypen, der speziell für den Einsatz in kritischen Infrastrukturen konzipiert ist. Die \textbf{Knowledge Base} liefert Foundations (Theorien, Frameworks, Konstrukte) und Methodologies (Evaluationsmethoden) \parencite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}. Sie umfasst für diese Arbeit SSI-Standards, NIST-PQC-Algorithmen und KRITIS-Anforderungen. Rigor wird durch angemessene Anwendung dieser Wissensbasis erreicht \parencite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}.

\subsubsection{Zyklen}

\textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007} identifiziert drei eng verbundene Aktivitätszyklen, die in jedem DSR-Projekt präsent sein müssen (\autoref{fig:3-cycle-model}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{3-cycle.png}
    \caption{Design Science Research Zyklen}
    \begin{flushleft}
    \textit{Anmerkung.} Aus \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007}.
    \end{flushleft}
    \label{fig:3-cycle-model}
\end{figure}

Der \textbf{Relevance Cycle} initiiert DSR mit Anforderungen aus der Anwendungsdomäne und fordert Field Testing des Outputs \parencite[S. 88-89]{hevner_ThreeCycleViewDesignScienceResearch_2007}. In dieser Arbeit manifestiert sich dies durch die iterative Identifikation von KRITIS-Anforderungen an an Sicherheit, Compliance und Kryptoagilität in zwei Implementierungszyklen. Dazu gehören quantenresistente Kommunikations- und Signaturverfahren, die Einhaltung relevanter Regulierungsvorgaben sowie die Wahrung von Datenschutz und technischer Resilienz. Die entwickelten Artefakte werden kontinuierlich in Laborumgebungen getestet, wobei Erkenntnisse aus der ersten Iteration die Designziele der zweiten Iteration prägen. Der \textbf{Rigor Cycle} verbindet DSR-Aktivitäten mit der Wissensbasis, um Innovation zu gewährleisten \parencite[S. 88-90]{hevner_ThreeCycleViewDesignScienceResearch_2007}. In dieser Arbeit wird dieser Zyklus durch die kontinuierliche Integration wissenschaftlicher Grundlagen etablierter SSI-Frameworks, NIST-standardisierter PQC-Algorithmen und KRITIS-Standards operationalisiert. Der \textbf{Design Cycle} strukturiert die Artefaktentwicklung als iterativen Prozess zwischen Konstruktion und Evaluation \parencite[S. 90--91]{hevner_ThreeCycleViewDesignScienceResearch_2007}. In dieser Arbeit erfolgt dies in zwei aufeinanderfolgenden Iterationen, wobei jede Iteration Feedback für die Designverbesserung liefert und die Erkenntnisse in die nächste Iteration einfließen.

\subsubsection{Artefakte}

\textcite[S. 255]{march_DesignNaturalScienceresearchinformationtechnology_1995} identifizieren vier Artefakttypen: Constructs, Models, Methods und Instantiations. \textbf{Constructs} stellen die Sprache bereit, in der Probleme und Lösungen definiert werden, und beeinflussen die Problemkonzeption \parencite[S. 78, 83]{hevner_DesignScienceInformationsystemsresearch_2004}. \textbf{Models} repräsentieren das Designproblem und den Lösungsraum, unterstützen das Problemverständnis und ermöglichen die Erkundung von Designentscheidungen \parencite[S. 78-79]{hevner_DesignScienceInformationsystemsresearch_2004}. \textbf{Methods} definieren Prozesse zur Problemlösung, von formalen Algorithmen bis zu Best-Practice-Beschreibungen \parencite[S. 79]{hevner_DesignScienceInformationsystemsresearch_2004}. \textbf{Instantiations} demonstrieren Machbarkeit durch Implementierung in einem funktionierenden System und liefern Beweis durch Konstruktion \parencite[S. 79, 84]{hevner_DesignScienceInformationsystemsresearch_2004}.

Diese Arbeit entwickelt eine \textit{Instantiation} in Form eines funktionsfähigen Prototyps eines blockchain-basierten SSI-Systems mit integrierter Post-Quantum-Kryptographie für KRITIS, welcher die technische Machbarkeit und praktische Anwendbarkeit des Ansatzes demonstriert.

\subsubsection{Richtlinien}

\textcite[S. 82]{hevner_DesignScienceInformationsystemsresearch_2004} formulieren sieben Richtlinien für \ac{DSR}, die jeweils in einer qualitätsvollen Forschungsarbeit adressiert werden sollten. Diese Richtlinien bilden einen strukturierten Rahmen zur Durchführung und Bewertung von Design-Science-Forschung und gewährleisten, dass sowohl wissenschaftliche Rigor als auch praktische Relevanz erreicht werden.

\textbf{Guideline 1: Design as an Artifact} - Design-Science-Forschung muss ein brauchbares Artefakt produzieren \parencite[S. 82]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit erfüllt dies durch eine funktionsfähige Instantiation eines blockchain-basierten SSI-Systems mit integrierter Post-Quantum-Kryptographie.

\textbf{Guideline 2: Problem Relevance} - Design-Science-Forschung zielt auf technologiebasierte Lösungen für relevante Geschäftsprobleme \parencite[S. 84--85]{hevner_DesignScienceInformationsystemsresearch_2004}. Die Relevanz ergibt sich aus der Quantenbedrohung für KRITIS-Kryptographie und dem Bedarf an datenschutzfreundlichen Identitätslösungen.

\textbf{Guideline 3: Design Evaluation} - Die Nützlichkeit und Wirksamkeit eines Design-Artefakts müssen rigoros demonstriert werden \parencite[S. 85]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit validiert Funktionalität, Compliance und Kryptoagilität.

\textbf{Guideline 4: Research Contributions} - \ac{DSR} muss klare Beiträge zu Design-Artefakt, Foundations oder Methodologies liefern \parencite[S. 87]{hevner_DesignScienceInformationsystemsresearch_2004}. Der Beitrag liegt in der neuartigen Integration von PQC in SSI-Systeme für KRITIS-Kontexte.

\textbf{Guideline 5: Research Rigor} - \ac{DSR} beruht auf rigoroser Anwendung von Methoden in Konstruktion und Evaluation \parencite[S. 87]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit nutzt etablierte Frameworks (Hyperledger Indy, ACA-Py, Aries), NIST-standardisierte PQC-Algorithmen und wissenschaftlich hergeleitete Konzepte der Kryptoagilität.

\textbf{Guideline 6: Design as a Search Process} - Die Suche nach einem effektiven Artefakt erfordert iterative Exploration unter Berücksichtigung der Problemumgebung \parencite[S. 87--88]{hevner_DesignScienceInformationsystemsresearch_2004}. Der Design Cycle dieser Arbeit manifestiert sich als iterativer Prozess, bei dem Erkenntnisse aus einer Iteration die Designziele der nachfolgenden Iteration prägen.

\textbf{Guideline 7: Communication of Research} - Design-Science-Forschung muss effektiv sowohl für technologie-orientierte als auch für management-orientierte Audiences präsentiert werden \parencite[S. 90]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit adressiert dies durch eine umfassende Dokumentation des entwickelten Prototypen, systematische Darstellung der Evaluationsergebnisse sowie die explizite Ableitung \fixme{praktischer Implikationen} für kritische Infrastrukturen.

\subsection{FEDS-Framework} \label{sec:FEDS-Framework}

Nach \textcite[S. 2]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} ist die Evaluation von Design-Artefakten eine Schlüsselaktivität des \ac{DSR}, ohne die die Forschung auf der Ebene theoretischer Annahmen über die Utility eines Artefakts verbleibt, ohne Evidenz für dessen tatsächliche Funktionsfähigkeit zu liefern. Um diese Lücke zu schließen und Rigor sicherzustellen, folgt diese Arbeit dem \ac{FEDS}-Framework nach \textcite[S. 2, 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}, welches den Evaluationsprozess in vier iterative Schritte unterteilt, um die Strategie passgenau auf die spezifischen Projektrisiken abzustimmen.

Das \ac{FEDS}-Framework unterscheidet dabei fundamental zwischen zwei Dimensionen der Evaluation: der funktionalen Absicht (Why to evaluate) und dem Paradigma (How to evaluate). Hinsichtlich der Absicht wird zwischen formativer Evaluation, die der kontinuierlichen Verbesserung während der Entwicklung dient, und summativer Evaluation, die eine abschließende Bewertung der Zielerreichung vornimmt, differenziert. Bezüglich des Paradigmas unterscheidet das Framework zwischen Artificial Evaluation, die in kontrollierten Laborumgebungen stattfindet, und Naturalistic Evaluation, welche die Artefakte in realen organisatorischen Umfeldern unter echten Bedingungen prüft \parencite[S. 2, 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Im Folgenden wird der vierstufige FEDS-Prozess für die vorliegende Arbeit erläutert.

\subsubsection{Schritt 1: Explikation der Evaluationsziele}
Der erste Schritt des Frameworks verlangt die Explikation der Evaluationsziele, um Konflikte zwischen konkurrierenden Anforderungen wie Rigor, Risikominimierung und Effizienz aufzulösen \parencite[S. 6--7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für die Entwicklung eines blockchain-basierten \ac{SSI}-Protypen mit \ac{PQC} im \ac{KRITIS}-Kontext ergeben sich hieraus spezifische Prioritäten:

\textbf{Rigour (Efficacy vs. Effectiveness):} Das primäre Ziel dieser Arbeit ist der Nachweis der \textit{Efficacy}. Dies bedeutet den rigorosen Beleg, dass das instanziierte Artefakt (die \ac{PQC}-Integration in SSI) den beobachteten Effekt (sichere, quantenresistente Identitätsverifikation) kausal verursacht und nicht externe Störfaktoren \parencite[S. 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Da es sich bei \ac{KRITIS}-Komponenten um sicherheitskritische Infrastruktur handelt, muss vor einem Feldtest (\enquote{Effectiveness} in realer Umgebung) zwingend die funktionale Korrektheit in einer kontrollierten Umgebung bewiesen werden, um \enquote{False Positives}, eine fälschliche Annahme der Sicherheit, auszuschließen \parencite[S. 3]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.
    
\textbf{Risikoreduktion (Technical Risk):} Das Hauptrisiko dieser Arbeit ist technischer Natur. Es besteht die Unsicherheit, ob die \ac{PQC}-Algorithmen (ML-DSA, ML-KEM) technisch in bestehende SSI-Frameworks (Hyperledger Aries) integriert werden können, ohne deren Kernfunktionen zu brechen. Soziale Risiken (z.B. Benutzerakzeptanz der Wallet-App) werden als nachrangig eingestuft und nicht evaluiert.
    
\textbf{Ausschluss von Effizienz-Zielen:} In Anlehnung an die Design-Science-Leitlinien wird explizit darauf hingewiesen, dass eine quantitative Performance-Evaluation (\enquote{Efficiency}) nicht Ziel dieser Arbeit ist. Die verwendeten \ac{PQC}-Referenzimplementierungen befinden sich in einem frühen Stadium, weshalb Laufzeitmessungen keine valide Aussagekraft für zukünftige produktive Systeme hätten.

\subsubsection{Schritt 2: Wahl der Evaluationsstrategie}
Basierend auf den identifizierten Zielen und Risiken wird für diese Arbeit die \textbf{Technical Risk \& Efficacy Strategy} gewählt, welche mit formativen, artifiziellen Tests beginnt und in einer summativen, artifiziellen Evaluation endet (\autoref{fig:feds_strategy}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{FEDS_eval_strat}
    \caption{Gewählte Evaluationsstrategie im FEDS-Framework}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung in Anlehnung an \textcite[S. 4]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.
    \end{flushleft}
    \label{fig:feds_strategy}
\end{figure}

Diese Strategie ist nach \textcite[S. 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} dann indiziert, wenn das primäre Entwicklungsrisiko technischer Natur ist und Evaluationen in realen Umgebungen aus Sicherheits- oder Kostengründen nicht durchführbar sind.
Ein naturalisitischer Ansatz (\enquote{Human Risk \& Effectiveness}) wird verworfen, da der Zugriff auf reale \ac{KRITIS}-Netzwerke für experimentelle kryptografische Prototypen ethisch und regulatorisch nicht vertretbar ist und die Technologie noch nicht den Reifegrad für Endanwendertests besitzt.

\subsubsection{Schritt 3: Bestimmung der zu evaluierenden Eigenschaften}
Der dritte Schritt definiert die konkreten Eigenschaften, die evaluiert werden sollen \parencite[S. 7--8]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für das entwickelte Artefakt leiten sich diese direkt aus den in Kapitel~\ref{sec:Anforderungsanalyse} definierten Anforderungen ab:

\begin{enumerate}
    \item \textbf{Fidelity (Funktionale Korrektheit):} Das System muss in der Lage sein, den vollständigen SSI-Lebenszyklus (Issuance, Verification, Revocation) unter Verwendung von PQC-Signaturen fehlerfrei durchzuführen. Es wird geprüft, ob die Artefakte (Agenten, Ledger, Wallet) spezifikationsgemäß interagieren.
    \item \textbf{KRITIS-Compliance (Sicherheit):} Es wird evaluiert, ob die implementierten Mechanismen den regulatorischen Vorgaben entsprechen. Dies umfasst die strikte Durchsetzung von TLS 1.3, die Verwendung hybrider Verfahren und die Netzwerksegmentierung.
    \item \textbf{Interoperabilität:} Die Fähigkeit des modifizierten Systems, Standard-DIDComm-Nachrichten trotz der veränderten kryptografischen Payload zu verarbeiten, ist ein kritisches Kriterium für die Efficacy.
\end{enumerate}

\subsubsection{Schritt 4: Design der individuellen Evaluationsepisoden}
Der vierte Schritt umfasst das Design konkreter Evaluationsepisoden \parencite[S. 8]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für diese Arbeit wurden drei diskrete Episoden definiert, die parallel zu den Entwicklungszyklen verlaufen und in \autoref{tab:eval_episodes} dem jeweiligen Arbeitsfortschritt zugeordnet sind.

\begin{longtable}{L{1.5cm}L{5cm}L{8.5cm}}
    \caption{Evaluationsepisoden nach \ac{FEDS}}
    \label{tab:eval_episodes} \\
    \toprule
    \textbf{Ep.} & \textbf{Phase \& Art (FEDS)} & \textbf{Fokus / Methode} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Ep.} & \textbf{Phase \& Art (FEDS)} & \textbf{Fokus / Methode} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung der Evaluationsstrategie in Anlehnung an das \ac{FEDS}-Framework von \textcite{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.} \\
    \endlastfoot
    1 & 
    Iteration 1 (Kapitel~\ref{sec:formative_evaluation_iteration1}) \newline 
    \textit{Formativ, Artifiziell} &
    White-Box Tests und Log-Analyse der Transportverschlüsselung sowie der Infrastrukturkomponenten. \\
    \midrule
    2 & 
    Iteration 2 (Kapitel~\ref{sec:formative_evaluation_iteration2}) \newline
    \textit{Formativ, Artifiziell} &
    Integrationstests der Plugin-Architektur, DIDComm-Verarbeitung und Validierung der PQC-Signaturen. \\
    \midrule
    3 & 
    Final (Kapitel~\ref{sec:Summative Evaluation}) \newline
    \textit{Summativ, Artifiziell} &
    Requirement Tracing und Validierung der \ac{KRITIS}-Compliance am integrierten Gesamtsystem. \\
\end{longtable}

\textbf{Episode 1 (Formativ):} Diese Episode erfolgt parallel zur ersten Iteration und fokussiert sich auf die Validierung der \textit{Transport-Layer-Security}. Da in dieser Phase fundamentale Infrastrukturkomponenten wie \glslink{Sidecar Proxy}{Sidecar Proxies} entwickelt werden, dient die formative Evaluation primär dazu, Designfehler so früh wie möglich zu identifizieren \parencite[S. 6, 7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Methodisch erfolgt dies durch die Analyse von Handshake-Protokollen und Cipher-Suites.

\textbf{Episode 2 (Formativ):} In der zweiten Iteration verlagert sich der Fokus auf den \textit{Application-Layer}. Hier wird formativ geprüft, ob die entwickelten Python-Plugins korrekt in den ACA-Py-Core geladen werden und ob die erweiterte Kryptografiebibliothek (liboqs) korrekt angesprochen wird.

\textbf{Episode 3 (Summativ):} Die abschließende Evaluation in Kapitel~\ref{sec:Summative Evaluation} führt alle Komponenten zusammen. Sie dient dem rigorosen Nachweis, dass das Gesamtsystem die eingangs definierten Forschungsfragen beantwortet. Hierbei wird geprüft, ob die Efficacy des \ac{PQC}-\ac{SSI}-Prototypen für \ac{KRITIS}-Anwendungsfälle gegeben ist, ohne reale Risiken einzugehen.

\subsection{DSRM Prozessmodell} \label{DSRM Prozessmodell}

Zur Sicherstellung einer rigorosen methodischen Fundierung orientiert sich der Forschungsablauf dieser Arbeit am \ac{DSRM} Prozessmodell nach \textcite[S. 46]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}, welches einen Rahmen für die Durchführung und Präsentation von \ac{DSR} bereitstellt um die wissenschaftliche Validität von Design-Artefakten zu gewährleisten.

\fixme{Da die vorliegende Arbeit durch die spezifischen Bedrohungen des Quantencomputings für bestehende Infrastrukturen und die daraus resultierenden regulatorischen Anforderungen für \ac{KRITIS} motiviert ist} (Kapitel~\ref{sec:Problemstellung und Motivation}), folgt das Forschungsvorhaben einer \enquote{Problem-Centered Initiation}. Dies entspricht dem klassischen Einstieg in den \ac{DSRM}-Prozess über die erste Phase (\autoref{fig:peffers_dsrm}) \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.

Neben der \enquote{Objective-Centered Solution}, die durch einen Bedarf in der Industrie oder Forschung ausgelöst wird (Phase 2), definieren die Autoren eine \enquote{Design \& Development Centered Initiation} auf Basis existierender Artefakte für explizite Problembereiche (Phase 3), sowie eine \enquote{Client-/Context-Initiated Solution}, welche auf der Beobachtung einer praktischen Lösung basiert (Phase 4), als drei weitere Einstiegspunkte \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{DSRM Process Model_red.png}
    \caption{DSRM Process Model}
    \begin{flushleft}
    \textit{Anmerkung.} Adaptiert aus \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.
    \end{flushleft}
    \label{fig:peffers_dsrm}
\end{figure}

Die Operationalisierung der sechs Phasen des \ac{DSRM} beginnt mit der Phase \enquote{Problem Identification and Motivation} \parencite[S. 52--55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}. Die Definition des spezifischen Forschungsproblems und dessen Relevanz für kritische Infrastrukturen wurde hierfür in Kapitel~\ref{sec:Problemstellung und Motivation} dargelegt. 

Darauf aufbauend werden in der Phase \enquote{Define the Objectives for a Solution} \parencite[S. 55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} aus der Problemanalyse konkrete Forschungsfragen (Kapitel~\ref{sec:Zielsetzung und Forschungsfragen}) und designrelevante Ziele für jede Iteration (Kapitel~\ref{sec:Designziele_Iteration_1} und Kapitel~\ref{sec:Designziele_Iteration_2}) abgeleitet, welche als Grundlage für die späteren Evaluationsphasen dienen.

Den Kern der Arbeit bildet die Phase \enquote{Design and Development} \parencite[S. 55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}, welche die Konzeption der Architektur sowie die technische Implementierung des \ac{PQC}-\ac{SSI}-Prototypen in beiden Iterationen umfasst (Kapitel~\ref{sec:Iterative Artefaktentwicklung}). Diese Phase operationalisiert die systematische Umsetzung der in den vorherigen Phasen definierten Anforderungen in ein funktionsfähiges Artefakt.

Die Eignung dieses Artefakts zur Problemlösung wird im Rahmen der Phase \enquote{Demonstration} \parencite[S. 55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} validiert. Diese erfolgt durch formative Evaluationsepisoden während der beiden Iterationen, welche schrittweise die Funktionsfähigkeit des Artefakts durch modulare Tests unter kontrollierten Bedingungen (Kapitel~\ref{sec:formative_evaluation_iteration1} und \ref{sec:formative_evaluation_iteration2}), bis hin zum vollständigen Prototypen (Kapitel~\ref{sec:Summative Evaluation}) nachweisen. 

Daran anschließend wird in der Phase \enquote{Evaluation} \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}strukturiert nach dem \ac{FEDS}-Framework (Kapitel~\ref{sec:FEDS-Framework}) in mehreren diskrete Evaluationsepisoden eine systematische Bewertung des Artefakts vorgenommen. Formative Episoden während beider Iterationen (Kapitel~\ref{sec:formative_evaluation_iteration1} und \ref{sec:formative_evaluation_iteration2}) adressieren technische Einzelfunktionen und Designfehler frühzeitig, die abschließende summative Evaluation in Kapitel~\ref{sec:Summative Evaluation} validiert systematisch die funktionale Korrektheit, \ac{KRITIS}-Compliance und Kryptoagilität des integrierten Gesamtsystems.

Den Abschluss bildet die Phase \enquote{Communication} \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}, in der die Ergebnisse, der Designprozess und die Evaluation durch die vorliegende schriftliche Ausarbeitung dokumentiert und der wissenschaftlichen Gemeinschaft zur Verfügung gestellt werden.

Obwohl das Modell sequenziell dargestellt ist, handelt es sich bei der Entwicklung in Kapitel~\ref{sec:Iterative Artefaktentwicklung} um einen iterativen Prozess, der Rücksprünge von der Evaluation zur Design-Phase erlaubt, um das Artefakt schrittweise zu verfeinern \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.

\newpage
\section{Erste Iteration der Artefaktentwicklung}
\label{sec:Erste Iteration der Artefaktentwicklung}

\subsection{Designziele dieser Iteration} \label{sec:Designziele_Iteration_1}

Die Designziele dieser Iteration leiten sich unmittelbar aus den in Kapitel~\ref{sec:Zielsetzung und Forschungsfragen} definierten Forschungsfragen ab und werden operationalisiert durch eine schichtenbasierte Architektur, die die Quantensicherheit auf der Transportebene verankert. 

Im Fokus von FF1 (Systemarchitektur \& Compliance) steht die Etablierung einer modularen Architektur mit klarer Separation zwischen SSI-Agenten, DLT-Infrastruktur und quantensicherer Transportschicht auf Basis ausgewählter Frameworks und Technologien. Das Design soll die Kernherausforderung, Post-Quantum-Kryptografie nicht-invasiv und modular zu integrieren, adressieren.

Bezüglich FF2 (Algorithmenauswahl und Sicherheitsbewertung) liegt das Designziel auf der Erprobung quantenresistenter kryptografischer Primitive für die Transportebene auf Basis standardisierter Algorithmen und hybrider Schlüsselaustauschverfahren. Die formative Evaluierung soll dabei die technische Machbarkeit dieser Algorithmen in der Infrastruktur validieren und Erkenntnisse für die nachgelagerte Iteration generieren.

Für FF3 (Kryptografische Agilität) zielt diese Iteration auf die architektonische Vorbereitung für Austauschbarkeit kryptografischer Algorithmen ab. Das Design soll durch modulare Infrastrukturkomponenten die Voraussetzungen für zukünftige Algorithmenupdates ohne grundlegende Systemumgestaltung schaffen.

\subsection{Anforderungsanalyse} \label{sec:Anforderungsanalyse}

\subsubsection{Funktionale Anforderungen} \label{sec:Funktionale Anforderungen}

Basierend auf der Analyse von \textcite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021} lassen sich für das SSI-System sechs zentrale funktionale Anforderungen identifizieren, die den den vollständigen Lebenszyklus digitaler Identitätsnachweise ab decken (\autoref{tab:functional_requirements}).

\begin{longtable}{L{1cm}L{4cm}L{9cm}}
    \caption{Funktionale Anforderungen an SSI-Systeme}
    \label{tab:functional_requirements} \\
    \toprule
    \textbf{Nr.} & \textbf{Funktionale Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Nr.} & \textbf{Funktionale Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung auf Basis der Auflistungen und des Sequenzdiagramms in Anlehnung an \textcite[S. 130-132]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}.} \\
    \endlastfoot
    1 & Issuer Discovery &
    Das System muss die Auffindbarkeit von publizierten Credential Schemata des Issuers digitaler Identitätsnachweise ermöglichen. \\
    \midrule
    2 & Connection Creation &
    Das System muss Verbindungen zwischen den Akteuren des SSI-Ökosystems etablieren können. \\
    \midrule
    3 & Credential Creation &
    Das System muss Funktionalität zur Erstellung und Ausstellung digitaler Credentials bereitstellen. \\
    \midrule
    4 & Verification with Credentials &
    Das System muss einen Verifikationsprozess zwischen Identity Holder, Verifier und Blockchain-basierter \ac{VDR} durch Validierung eines Identitätsnachweises ermöglichen. \\
    \midrule
    5 & Credential Revocation &
    Das System muss die Funktionalität zum Widerruf von Credentials unterstützen. \\
    \midrule
    6 & Credential Deletion &
    Das System muss die Funktionalität zur Löschung von Credentials unterstützen. \\
\end{longtable}

\subsubsection{KRITIS-spezifische Compliance-Anforderungen} \label{sec:KRITIS-spezifische Compliance-Anforderungen}

Die in \autoref{tab:compliance_requirements} konsolidierten Anforderungen definieren den normativen Rahmen für die Gestaltung und Evaluierung des \ac{PQC}-\ac{SSI}-Prototypen im Kontext KRITIS.

Im Bereich der \textbf{kryptografischen Verfahren} (Nr. 1-4) basieren die Vorgaben primär auf den Technischen Richtlinien des BSI. Für die Migration auf Post-Quantum-Kryptografie ist insbesondere die Wahl spezifischer Parameter-Sets für ML-DSA (NIST Level 3/5) und ML-KEM (Level 3/5) sowie die zwingende Implementierung hybrider Schlüsseleinigung vorgeschrieben, um sowohl Integrität als auch langfristige Vertraulichkeit gegen Quantencomputer-Angriffe zu gewährleisten \parencite[Kap. 2.2, 2.4, 5.3.4.2]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. Ergänzend fordert die TR-02102-2 den Einsatz moderner Transportverschlüsselung via TLS 1.3, um durch Perfect Forward Secrecy (PFS) die Kommunikationskanäle abzusichern \parencite[Kap. 3.2]{bsi_TechnischeRichtlinieTR021022KryptographischeVerfahrenEmpfehlungenundSchlussellangenTeil2VerwendungTransport_2025}.

Hinsichtlich der \textbf{Betriebssicherheit} (Nr. 5-6) leiten sich die Anforderungen direkt aus dem IT-Sicherheitsgesetz 2.0 (BSIG) und internationalen Standards ab. Essenziell für KRITIS-Betreiber ist hierbei die Implementierung effektiver \gls{SzA} durch umfassende Protokollierung sicherheitsrelevanter Ereignisse gemäß § 8a BSIG \parencite[Nr. 101, 103]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024}. Flankierend schreibt die ISO/IEC 27001 eine strikte logische Netzsegmentierung vor, um die Ausbreitung potenzieller Sicherheitsvorfälle innerhalb der Infrastruktur zu begrenzen \parencite[Control A.8.22]{iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022}.

Die dritte Säule bildet der \textbf{Datenschutz} (Nr. 7-9) auf Basis der DSGVO. Hierbei stehen Prinzipien wie \textit{Privacy by Design} gemäß Art. 25 und Datenminimierung nach Art. 5 im Fokus. Zudem muss das Recht auf Löschung nach Art. 17 durch geeignete Architekturmuster, etwa die Trennung von Identifikatoren und Inhaltsdaten, technisch gewährleistet werden \parencite[Art. 5, 17, 25]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}.

\begin{longtable}{L{1cm}L{4cm}L{9cm}}
    \caption{Compliance Anforderungen an SSI-Systeme im KRITIS-Kontext}
    \label{tab:compliance_requirements} \\
    \toprule
    \textbf{Nr.} & \textbf{Compliance Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Nr.} & \textbf{Compliance Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung auf Basis von \textcite{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025,bsi_TechnischeRichtlinieTR021022KryptographischeVerfahrenEmpfehlungenundSchlussellangenTeil2VerwendungTransport_2025,bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024,iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022,daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}.} \\
    \endlastfoot
    1 & Einhaltung spezifischer Parameter-Sets für ML-DSA &
    Zur Gewährleistung der vom BSI geforderten Sicherheitsniveaus dürfen für das Verfahren ML-DSA ausschließlich die Parameter-Sets verwendet werden, die den NIST Security Strength Categories 3 oder 5 entsprechen. Konkret sind dies ML-DSA-65 oder ML-DSA-87 \parencite[Kap. 5.3.4.2]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025} \\
    \midrule
    2 & Einhaltung spezifischer Parameter-Sets für ML-KEM &
    Für den langfristigen Schutz vertraulicher Informationen mittels des gitterbasierten Schlüsselkapselungsverfahrens ML-KEM dürfen gemäß BSI-Einschätzung ausschließlich Parametersätze verwendet werden, die den NIST Security Strength Categories 3 oder 5 entsprechen. Zulässig sind demnach ML-KEM-768 sowie ML-KEM-1024 \parencite[Kap. 2.4.3]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. \\
    \midrule
    3 & Implementierung hybrider Schlüsseleinigung &
    Um langfristige Vertraulichkeit (Schutz vor \textit{Store Now, Decrypt Later}) zu gewährleisten, muss für die Schlüsseleinigung zwingend ein hybrides Verfahren implementiert werden, das ein anerkanntes klassisches Verfahren mit einem empfohlenen PQC-KEM kombiniert \parencite[Kap. 2.2, 2.4]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. \\
    \midrule
    4 & Bevorzugte Verwendung von TLS 1.3 &
    Für die Absicherung der Transportebene wird gemäß \textcite[Kap. 3.2]{bsi_TechnischeRichtlinieTR021022KryptographischeVerfahrenEmpfehlungenundSchlussellangenTeil2VerwendungTransport_2025} vorrangig das Protokoll TLS 1.3 empfohlen, da es PFS erzwingt und auf unsichere Cipher-Suites verzichtet. \\
    \midrule
    5 & Protokollierung sicherheitsrelevanter Ereignisse &
    Sicherheitsrelevante Ereignisse müssen auf System- und Netzebene zentral protokolliert werden, um eine zeitnahe Erkennung von Angriffen zu ermöglichen \parencite[Nr. 101, 103]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024}. \\
    \midrule
    6 & Logische Netzsegmentierung &
    Gruppen von Informationsdiensten, Benutzern und Informationssystemen sollten in den Netzwerken der Organisation getrennt werden \parencite[Control A.8.22]{iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022}. \\
    \midrule
    7 & Datenschutz durch Technikgestaltung (Privacy by Design) &
    Gemäß \textcite[Art. 25]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016} sind bereits bei der Entwicklung des Systems geeignete technische Maßnahmen zu treffen, die die Datenschutzgrundsätze addressieren. \\
    \midrule
    8 & Grundsatz der Datenminimierung &
    Personenbezogene Daten müssen dem Zweck angemessen und auf das notwendige Maß beschränkt sein. \parencite[Art. 5]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}. \\
    \midrule
    9 & Recht auf Löschung &
    Die betroffene Person hat das Recht, von dem Verantwortlichen die unverzügliche Löschung sie betreffender personenbezogener Daten zu verlangen. Der Verantwortliche ist verpflichtet, personenbezogene Daten unverzüglich zu löschen \parencite[Art. 17]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}. \\
\end{longtable}

\subsection{Framework- und Technologie-Auswahl}

Wie von \textcite[S.\,3]{ghosh_DecentralizedCrossNetworkIdentityManagementBlockchainInteroperation_2021} demonstriert, setzt auch die vorliegende Arbeit auf existierende Konzepte und Tools für dezentrale Identitätsverwaltung als Bausteine für die Entwicklung des \ac{PQC}-\ac{SSI}-Prototypen. Die systematische Auswahl der Frameworks und Technologien -- bestehend aus der \ac{DLT}-Plattform, dem SSI-Framework, der Kryptografiebibliothek, der Revocation-Infrastruktur und dem \gls{Sidecar Proxy} -- wird transparent in \ref{sec:Anhang_Framework- und Technologie-Auswahl} dokumentiert und begründet.

\subsection{Architekturentwurf}

Der Architekturentwurf dieser Iteration operationalisiert die in Kapitel~\ref{sec:Designziele_Iteration_1} definierten Designziele durch eine dreischichtige, containerbasierte Systemarchitektur, die Post-Quantum-Kryptografie auf der Transportebene verankert. Abbildung~\ref{fig:Architektur_Iteration1} visualisiert die Zielarchitektur, bestehend aus der DLT-Schicht mit vier Hyperledger-Indy-Validator-Nodes samt Ledger Browser, der Revocation-Schicht mit dediziertem Tails-Server sowie der SSI-Agenten-Schicht mit drei ACA-Py-Instanzen in den Rollen Issuer, Holder und Verifier.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Architektur_Iteration1}
    \caption{Architekturentwurf der ersten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Architektur_Iteration1}
\end{figure}

Das zentrale Architekturprinzip bildet das Sidecar Proxy Pattern (\ref{sec:Anhang_Sidecar Proxy}). Jede extern erreichbare Komponente wird durch einen NGINX-basierten \ac{PQC} Sidecar Proxy geschützt, der TLS-1.3-Verbindungen mit \glslink{Hybride Schemata}{hybrider Schlüsseleinigung} terminiert und im Fallback \ac{ECC} (X25519MLKEM768:x25519) unterstützt. Die Authentifizierung erfolgt über ML-DSA-65-signierte X.509-Zertifikate. In \autoref{fig:Architektur_Iteration1} wird diese verschlüsselte Kommunikation durch die rot-gestrichelten Verbindungspfeile zwischen den Sidecar Proxies visualisiert.

Die Backend-Dienste (Indy-Nodes, Webserver, Tails-Server und ACA-Py-Agents) verbleiben innerhalb isolierter interner Docker-Netzwerke und kommunizieren ausschließlich über unverschlüsseltes HTTP. Externe Zugriffe erfolgen ausschließlich über das gemeinsame Netzwerk sidecar\_proxy, das als quantensichere Kommunikationsdomäne fungiert und eine strikte Netzsegmentierung gemäß der sechsten \ac{KRITIS}-Anforderung (\autoref{tab:compliance_requirements}) gewährleistet.

\subsection{Implementierung}

Die Entwicklungsumgebung wird beschrieben in \ref{sec:Anhang_Setup der Entwicklungsumgebung}.

\subsubsection{Zertifikatsstruktur}

Die Zertifikatsinfrastruktur für die PQC-Sidecar-Proxies basiert auf einer selbstsignierten Root \ac{CA}, die mit dem Post-Quantum-Signaturalgorithmus ML-DSA-87 erstellt wurde. Die Root \ac{CA} dient als Trust Anchor für alle in der Architektur verwendeten TLS-Zertifikate und gewährleistet, dass sämtliche Zertifikatssignaturen quantenresistent nach der höchsten \ac{NIST} Sicherheitsstufe 5 sind \parencite[S. 15]{nationalinstituteofstandardsandtechnologyus_ModulelatticebasedDigitalSignaturestandard_2024} .

Das Zertifikatserstellungsverfahren folgt einem fünfschrittigen Workflow, wie in \autoref{fig:Zertifikatserstellungsworkflow} dargestellt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Zertifikatserstellungsworkflow}
    \caption{Zertifikatserstellungsworkflow für PQC-basierte Sidecar-Proxies}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Zertifikatserstellungsworkflow}
\end{figure}

Zunächst wird der Root-CA-Schlüssel generiert (Step 1), gefolgt von der Erstellung des selbstsignierten Root-CA-Zertifikats mit einer Gültigkeit von zehn Jahren (Step 2). Anschließend werden für jeden Sidecar-Proxy dedizierte Schlüssel mit ML-DSA-65 generiert (Step 3), die ein besseres Verhältnis zwischen Sicherheit und Speicherbedarf bieten \parencite[S. 16]{nationalinstituteofstandardsandtechnologyus_ModulelatticebasedDigitalSignaturestandard_2024}. Für jeden Proxy wird ein Certificate Signing Request erstellt, der die erforderlichen Subject Alternative Names enthält (Step 4), bevor die Zertifikate abschließend von der Root CA mit ML-DSA-65 und SHA3-256 signiert werden (Step 5). Die detaillierte Implementierung dieses Workflows ist in \ref{sec:Anhang_Zertfikatserstellungsworkflow} dokumentiert.

\subsubsection{Sidecar Proxy nginx}
\label{sec:Sidecar Proxy nginx}

Die Implementierung der post-quanten-kryptographischen Absicherung auf Transport-Layer-Ebene basiert zum einen auf einer modifizierten Version des NGINX-Dockerfiles von \textcite{open-quantum-safe_OpenquantumsafeOqsdemosNginxDockerfile_2025}, zum anderen auf spezifischen NGINX-Konfigurationsdateien für jeden Sidecar-Proxy, welche beide \ac{PQC} mit \ac{ECC} als Fallback realisieren.

\paragraph*{Dockerfile}

\autoref{fig:Sidecar_Proxy_nginx_Dockerfile} visualisiert den zweistufigen Aufbau des modifizierten Dockerfiles (Listing~\ref{lst:Dockerfile-Sidecar-Proxy-nginx}) für eine post-quantenfähige NGINX-Sidecar-Proxy-Lösung, die auf die Integration von OpenSSL 3.5.4 und dem OQS Provider ausgerichtet ist. Hybrid-Key-Exchange mit \ac{ECC} als Fallback wird innerhalb des Dockerfiles durch die DEFAULT-GROUPS-Konfiguration X25519MLKEM768:X25519 realisiert.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{2 Stage Sidecarproxy Dockerfile}
    \caption{Sidecar Proxy NGINX Dockerfile Multi-Stage Build}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Sidecar_Proxy_nginx_Dockerfile}
\end{figure}

 Das modifizierte Dockerfile folgt dabei dem Multi-Stage-Build-Prinzip, einer Optimierungsstrategie nach \textcite[S. 1]{rosa_MiningMeasuringImpactchangepatternsimprovingsizebuildtimedockerimages_2025}. Die zwei zentralen Phasen (Build-Stage und Runtime-Stage) samt der  gegenüber dem Original-Dockerfile \parencite{open-quantum-safe_OpenquantumsafeOqsdemosNginxDockerfile_2025} vorgenommenen Modifikationen (in \autoref{fig:Sidecar_Proxy_nginx_Dockerfile} in rot markiert) werden in \ref{sec:Anhang_Dockerfile Sidecar Proxy nginx} näher erläutert.

\paragraph*{nginx.conf}

Die NGINX-Konfigurationsdateien implementieren ein standardisiertes \gls{Sidecar Proxy} Pattern für die post-quantensichere Verschlüsselung von Datenverkehr auf Transport-Layer-Ebene. Wie in Listing~\ref{lst:nginx_holder.conf} dargestellt, wird TLS~1.3 mit Hybrid-Key-Exchange mittels der Direktive ssl\_ecdh\_curve X25519MLKEM768:X25519 konfiguriert, die einen Fallback auf klassische \ac{ECC}-basierte Kurven ermöglicht. Alle Konfigurationsdateien folgen dabei einem konsistenten Schichtenmodell aus globalen Parametern, internen Service-Abstraktionen über Upstream-Blöcke und externen HTTPS-Endpunkten über Server-Blöcke. Das zentrale Sicherheitsmerkmal ist die aktivierte Direktive ssl\_protocols TLSv1.3 in Kombination mit der Elliptic-Curve-Konfiguration, die den Hybrid-Key-Exchange zwischen klassischer ECC und dem ML-KEM-768-Algorithmus realisiert. Komplementär werden SSL-Zertifikate mit ML-DSA-65-Signaturalgorithmus eingebunden, sodass sowohl der Schlüsselaustausch als auch die Server-Authentifikation post-quantensicher erfolgen. Die gesamte Konfigurationen wird in \ref{sec:Anhang_nginx_holder.conf} erläutert.

\subsubsection{DLT-Infrastruktur}

Für die \ac{PQC}-Integration Transport-Layer-Ebene wurde die von-network-Architektur um einen PQC Nginx Sidecar Proxy erweitert.
Diese Modifikation stellt die zentrale Anpassung gegenüber dem Original-Quellcode \parencite{bcgov_GitHubBcgovVonnetworkportabledevelopmentlevelIndyNodenetwork_} dar und betrifft primär die docker-compose.yml-Konfigurationsdatei (Listing \ref{lst:docker-compose.yml-DLT-Infrastruktur}) sowie die Hinzufügung eines neuen Verzeichnisses pqc\_sidecarproxy\_nginx/, das die in Kapitel~\ref{sec:Sidecar Proxy nginx} vorgestellten Dockerfile- und Nginx-Konfigurationsdateien für den quantensicheren Reverse Proxy enthält. Der Webserver-Container, der im Original-Setup direkt auf Port 9000 exponiert wurde \parencite{bcgov_VonnetworkDockercomposeymlMainbcgovvonnetworkGitHub_}, verbleibt in der modifizierten Architektur ausschließlich im internen Docker-Netzwerk von. Stattdessen terminiert der neu hinzugefügte pqc-sidecarproxy-webserver-Container alle eingehenden \ac{TLS}-1.3-Verbindungen auf Port 8000 und leitet die Anfragen nach erfolgreicher \glslink{Hybride Schemata}{hybrider Schlüsselvereinbarung} und ML-DSA-65-Zertifikatsverifikation als unverschlüsseltes HTTP an den internen Webserver-Container weiter. Die unmodifizierte von-network-Implementierung wird in Kapitel~\ref{sec:Anhang_DLT-Infrastruktur} näher erläutert.

Die Integration des Sidecar Proxies erforderte die Definition eines zusätzlichen, extern zugänglichen Docker-Netzwerks von\_sidecarproxy, das als gemeinsame Kommunikationsebene für alle PQC-Proxies der Gesamtarchitektur dient. Dieses Netzwerk wird in der docker-compose.yml (Listing \ref{lst:docker-compose.yml-DLT-Infrastruktur}) als \enquote{external: true} deklariert. Der pqc-sidecarproxy-webserver-Container ist sowohl mit dem internen von-Netzwerk (für Backend-Kommunikation) als auch mit dem externen von\_sidecarproxy-Netzwerk (für Client-Zugriffe) verbunden, wodurch eine strikte Netzwerksegmentierung zwischen interner und externer Kommunikation gewährleistet wird.

% Zusammenfassend beschränkt sich die Modifikation des von-network-Projekts auf die Hinzufügung einer PQC-Transport-Layer-Sicherheitsebene, während die Core-Funktionalität der Indy-Blockchain-Infrastruktur vollständig erhalten bleibt. Diese minimalinvasive Anpassungsstrategie entspricht dem Sidecar-Pattern-Prinzip, das eine klare Separation zwischen kryptografischen Sicherheitsmechanismen (Proxy-Ebene) und Geschäftslogik (Blockchain-Ebene) etabliert. Die Wiederverwendbarkeit des etablierten von-network-Codes reduziert die Implementierungskomplexität und gewährleistet, dass die DLT-Infrastruktur auf bewährten, produktionserprobten Komponenten basiert, während die quantensichere Absicherung als modulare Erweiterungsschicht implementiert wird.

\subsubsection{Revocation Registry}

Die Implementierung der Revocation-Registry-Infrastruktur basiert auf dem offiziellen \textit{indy-tails-server}-Repository \parencite{bcgov_GitHubBcgovIndytailsserverThissoftwarestoresmakesavailabletailsfilesuseHyperledger_}, das einen dedizierten File-Server für die Speicherung und Distribution von Revocation-Registry-Tails-Dateien bereitstellt. Im Kontext von AnonCreds -- dem Privacy-Preserving-Credential-Format von Hyperledger Indy -- werden Tails-Dateien benötigt, um Non-Revocation-Proofs zu generieren und zu verifizieren, ohne dabei die gesamte Revocation-Registry-Datenstruktur im Ledger zu speichern. Der Tails-Server fungiert als zentraler Storage-Service, auf den sowohl Credential-Issuer (zum Upload der Tails-Dateien) als auch Verifier (zum Download für Proof-Verifikation) zugreifen.

Die unmodifizierte indy-tails-server-Implementierung stellt eine Python-basierte REST-API bereit, die zwei primäre Operationen unterstützt: Das Hochladen von Tails-Dateien über HTTP-PUT-Requests auf die Endpoints \texttt{/hash/\{tails-hash\}} oder \texttt{/\{revoc\_reg\_id\}} sowie das Abrufen von Tails-Dateien über HTTP-GET-Requests. Die Server-Architektur implementiert eine Hash-basierte Integritätsvalidierung, bei der der SHA-256-Hash der hochgeladenen Datei mit dem in der URL spezifizierten Hash verglichen wird, um Dateikorruption oder Manipulation zu detektieren. Die Tails-Dateien werden im Dateisystem des Containers persistiert, wobei der Speicherpfad über die Umgebungsvariable \texttt{STORAGE\_PATH} konfigurierbar ist.

Für die Integration in die Post-Quantum-gesicherte Gesamtarchitektur wurde der indy-tails-server analog zur DLT-Infrastruktur um einen PQC Nginx Sidecar Proxy erweitert. Diese Modifikation betrifft primär die Docker-Compose-Konfigurationsdatei (Listing \ref{lst:docker-compose.yml-Revocation-Registry}), in der ein zusätzlicher Service \texttt{pqc-sidecarproxy-tails-server} definiert wurde, sowie die Hin-
zufügung eines neuen Verzeichnisses pqc\_sidecarproxy\_nginx/, das die \fixme{in Kapitel XY vorgestellten} Dockerfile- und Nginx-Konfigurationsdateien für den
quantensicheren Reverse Proxy enthält. Der ursprüngliche Tails-Server-Container verbleibt im internen Docker-Netzwerk \texttt{tails-server} und exponiert Port 6543 ausschließlich innerhalb dieses Netzwerks. Der neu hinzugefügte PQC-Proxy-Container terminiert alle externen TLS-1.3-Verbindungen auf Port 6543 und leitet die Anfragen nach erfolgreicher quantensicherer Authentifizierung (ML-DSA-65-Zertifikatsverifikation) und Schlüsselvereinbarung (ML-KEM-768) als unverschlüsseltes HTTP an den internen Tails-Server weiter.

Die Netzwerk-Integration folgt dem etablierten Sidecar-Pattern: Der \texttt{pqc-sidecarproxy-tails-server}-Container ist sowohl mit dem internen \texttt{tails-server}-Netzwerk (für Backend-Kommunikation) als auch mit dem externen, manuell erstellten \texttt{von\_sidecarproxy}-Netzwerk (für Client-Zugriffe) verbunden. Diese Dual-Network-Architektur erzwingt, dass alle externen Zugriffe auf den Tails-Server -- sowohl von ACA-Py-Issuer-Agents beim Upload als auch von Verifier-Agents beim Download -- über den quantensicheren Reverse Proxy geleitet werden.

Die funktionale Logik des Tails-Servers -- einschließlich File-Upload-Validierung, Hash-Verifikation und Storage-Management -- bleibt vollständig unverändert. Dies umfasst die Python-basierte REST-API-Implementierung, die Multi-Part-File-Upload-Handler sowie die Fehlerbehandlung für invalide Hashes oder fehlende Dateien. Die Beibehaltung des Original-Codes gewährleistet, dass die Revocation-Mechanismen kompatibel mit Standard-AnonCreds-Implementierungen bleiben und ausschließlich die Transport-Layer-Sicherheit durch Post-Quantum-Kryptografie erweitert wird.

% Ein wesentlicher Aspekt der Tails-Server-Integration ist die Performance-Charakteristik in Abhängigkeit von der Revocation-Registry-Größe. Bei der Erstellung einer Credential Definition mit aktivierter Revocation wird ein Parameter \texttt{revocation\_registry\_size} spezifiziert, der die maximale Anzahl widerrufbarer Credentials festlegt. Die Größe der resultierenden Tails-Datei korreliert linear mit der Registry-Größe: Eine Registry mit 3\,000 Einträgen erzeugt eine 768\,KB-Datei, während 32\,768 Einträge eine 8,4\,MB-Datei generieren. Diese Dateien müssen von Verifier-Agents während der Proof-Verifikation heruntergeladen werden, wobei der PQC-Proxy-Overhead durch ML-KEM-768-Schlüsselaustausch die Transfer-Latenz geringfügig erhöht. Empirische Tests zeigten, dass die zusätzliche TLS-1.3-Handshake-Latenz mit ML-KEM-768 im Vergleich zu klassischem X25519 durchschnittlich 15--25\,ms beträgt, was bei typischen Tails-File-Transfer-Zeiten von mehreren Sekunden vernachlässigbar ist.

Die Docker-Compose-Orchestrierung des Tails-Servers definiert ein persistentes Volume \texttt{tails-files}, das den \texttt{STORAGE\_PATH}-Verzeichnis-Mount bereitstellt. Dieses Volume gewährleistet, dass hochgeladene Tails-Dateien über Container-Neustarts hinweg erhalten bleiben, was insbesondere in Entwicklungsumgebungen relevant ist, in denen Credential Definitions mit Revocation Registry wiederverwendet werden sollen. Die Health-Check-Konfiguration des Proxy-Containers überwacht die Verfügbarkeit des HTTPS-Endpoints und stellt sicher, dass nachgelagerte Services (ACA-Py-Agents) erst starten, wenn die Tails-Server-Infrastruktur vollständig einsatzbereit ist.

% Zusammenfassend beschränkt sich die Modifikation des indy-tails-server-Projekts auf die Integration einer quantensicheren Transport-Layer-Sicherheitsebene, während die Core-Funktionalität des Revocation-Registry-File-Servers vollständig erhalten bleibt. Diese Anpassungsstrategie entspricht dem übergeordneten Architekturprinzip, bestehende, produktionserprobte Hyperledger-Komponenten mit minimalen Eingriffen zu erweitern und die Post-Quantum-Kryptografie als modulare, nicht-invasive Sicherheitsschicht zu implementieren. Die resultierende Architektur gewährleistet, dass alle Tails-File-Transfers -- sowohl Upload durch Issuer als auch Download durch Verifier -- über ML-KEM-768-gesicherte TLS-1.3-Verbindungen erfolgen und somit resistent gegen zukünftige Angriffe durch Quantencomputer sind.

\subsubsection{SSI-Agenten} \label{SSI-Agenten}

Die Implementierung der Self-Sovereign-Identity-Agenten basiert auf Hyperledger Aries Cloud Agent Python (ACA-Py) \parencite{openwallet-foundation_GitHubOpenwalletfoundationAcapyACAPyfoundationbuildingdecentralizedidentityapplicationsservicesrunningnonmobile_}, der offiziellen Referenzimplementierung des Aries Interop Profile (AIP) 2.0. ACA-Py stellt eine vollständige SSI-Agent-Infrastruktur bereit, die alle erforderlichen Protokolle für DID-basierte Verbindungen, Credential Issuance, Presentation Exchange und Revocation Management implementiert. Die Architektur folgt dem Controller-Pattern, bei dem der Agent als eigenständiger Service agiert und über eine REST-API (Admin API) von externen Controller-Anwendungen gesteuert wird.

In der vorliegenden Iteration-1-Implementierung wurden drei ACA-Py-Agent-Instanzen deployt, die die klassischen SSI-Rollen abbilden: Ein \textit{Issuer Agent}, der Credentials ausstellt; ein \textit{Holder Agent}, der Credentials empfängt und speichert; sowie ein \textit{Verifier Agent}, der Proof-Requests erstellt und Presentations verifiziert \fixme{folgt theorie kapitel XY}. Alle drei Agents verwenden das unmodifizierte ACA-Py-Base-Image (Listing \ref{lst:Dockerfile-acapy-base}) aus dem offiziellen Hyperledger-Repository und werden ausschließlich über Kommandozeilen-Parameter konfiguriert, ohne Änderungen am ACA-Py-Quellcode vorzunehmen.

Listing \ref{lst:docker-compose.yml-SSI-Agenten} zeigt die Docker-Compose-Konfiguration der drei ACA-Py-Agenten innerhalb der Gesamtarchitektur. Die Agent-Konfiguration erfolgt hierbei vollständig deklarativ über Docker-Compose-Service-Definitionen, die jeweils den \texttt{start}-Befehl von ACA-Py mit rollenspezifischen Parametern aufrufen. Zentrale Konfigurationsparameter umfassen \texttt{--label} (zur Identifikation des Agents), \texttt{--inbound-transport http 0.0.0.0 <port>} (zur Definition des DIDComm-Message-Endpoints), \texttt{--outbound-transport http} (für ausgehende Verbindungen), \texttt{--admin 0.0.0.0 <port>} (zur Aktivierung der Admin-API) sowie \texttt{--wallet-type askar} (zur Spezifikation des Wallet-Backends). Alle Agents verwenden Aries Askar als Wallet-Implementierung, das eine moderne, in Rust implementierte Wallet-Architektur mit ChaCha20-Poly1305-Verschlüsselung und Argon2id-Key-Derivation bereitstellt.

Ein kritischer Konfigurationsparameter ist \texttt{--endpoint https://host.docker.internal:<port>}, der spezifiziert, unter welcher URL der Agent für eingehende DIDComm-Verbindungen erreichbar ist. Dieser Parameter wird in Out-of-Band-Invitations und DID-Exchange-Nachrichten eingebettet und muss auf den externen PQC-Proxy-Endpoint zeigen, nicht auf den internen Agent-Container. Beispielsweise konfiguriert der Issuer-Agent \texttt{--endpoint https://host.docker.internal:8020}, wodurch andere Agents ihre DIDComm-Nachrichten an den PQC-Proxy auf Port 8020 senden, der diese nach TLS-Terminierung an den internen Issuer-Container weiterleitet. Diese Indirektion ist essentiell, um sicherzustellen, dass alle Agent-zu-Agent-Verbindungen die Post-Quantum-gesicherte Transport-Layer-Sicherheit nutzen.

Die Wallet-Konfiguration erfolgt über die Parameter \texttt{--wallet-name <name>}, \texttt{--wallet-key <key>} und \texttt{--auto-provision}, wobei letzterer sicherstellt, dass das Wallet automatisch beim ersten Start initialisiert wird. Jedes Wallet wird in einem dedizierten Docker-Volume persistiert (\texttt{issuer-data}, \texttt{holder-data}, \texttt{verifier-data}), sodass DID-Keypairs, Credentials und Connections über Container-Neustarts hinweg erhalten bleiben. Die Wallet-Verschlüsselung mittels ChaCha20-Poly1305 gewährleistet, dass gespeicherte kryptografische Schlüssel selbst bei Kompromittierung des Host-Filesystems nicht ohne den Wallet-Key extrahiert werden können.

Ein wesentlicher Aspekt der Agent-Konfiguration ist die Anbindung an die DLT-Infrastruktur über den Parameter \texttt{--genesis-url https://host.docker.internal:8000/genesis}. Diese URL referenziert den PQC-gesicherten Webserver der DLT-Infrastruktur und ermöglicht es den Agents, beim Start die Genesis-Transaktionsdatei über eine quantensichere TLS-1.3-Verbindung abzurufen. Analog dazu wird die Verbindung zur Revocation Registry über \texttt{--tails-server-base-url https://host.docker.internal:6543} konfiguriert, wobei ebenfalls der PQC Nginx Sidecar Proxy als Endpoint fungiert. Die Verwendung von \texttt{host.docker.internal} ermöglicht dabei die Adressierung des Docker-Hosts aus Container-Perspektive und abstrahiert plattformspezifische Netzwerk-Unterschiede zwischen Linux, macOS und Windows.

Zusätzlich zu den grundlegenden Konfigurations-Parametern aktivieren die Agents mehrere Auto-Response-Features, die für Entwicklungs- und Testzwecke die manuelle Interaktion reduzieren: \texttt{--auto-accept-invites} (automatisches Akzeptieren von Connection-Invitations), \texttt{--auto-respond-credential-proposal}, \texttt{--auto-respond-credential-offer} und \texttt{--auto-respond-credential-request} (automatische Credential-Exchange-Antworten beim Issuer), \texttt{--auto-store-credential} (automatisches Speichern empfangener Credentials beim Holder) sowie \texttt{--auto-verify-presentation} (automatische Presentation-Verifikation beim Verifier). Diese Automatisierungen ermöglichen vollständig scriptgesteuerte SSI-Workflows über die Admin-API, wie sie in Jupyter-Notebook-basierten Demonstrationen implementiert sind.

Für die Post-Quantum-Absicherung der Agent-Kommunikation wurde analog zur DLT-Infrastruktur und Revocation Registry ein dedizierter PQC Nginx Sidecar Proxy pro Agent implementiert. Die Docker-Compose-Konfiguration definiert drei zusätzliche Services -- \texttt{pqc-sidecarproxy-issuer}, \texttt{pqc-sidecarproxy-holder} und \texttt{pqc-sidecarproxy-verifier} --, die jeweils als Reverse Proxy vor dem zugehörigen Agent platziert werden. Jeder Agent-Container exponiert zwei interne HTTP-Ports: einen für Inbound-Transport (8020, 8030, 8040) und einen für die Admin-API (8021, 8031, 8041). Diese Ports sind ausschließlich im agent-spezifischen internen Docker-Netzwerk (\texttt{hope-issuer}, \texttt{hope-holder}, \texttt{hope-verifier}) zugänglich.

Die Sidecar Proxies terminieren alle eingehenden TLS-1.3-Verbindungen und leiten die Anfragen nach erfolgreicher quantensicherer Authentifizierung und Schlüsselvereinbarung als unverschlüsseltes HTTP an die internen Agent-Ports weiter. Jeder Proxy ist mit zwei Docker-Netzwerken verbunden: dem agent-spezifischen internen Netzwerk für Backend-Kommunikation sowie dem gemeinsamen externen \texttt{von\_sidecarproxy}-Netzwerk für Client-Zugriffe. Diese Dual-Network-Architektur erzwingt, dass sämtliche externe Kommunikation -- einschließlich DIDComm-Nachrichten zwischen Agents, Admin-API-Zugriffe durch Controller-Anwendungen sowie Ledger- und Tails-Server-Requests -- über quantensichere TLS-Verbindungen erfolgt.

Die Netzwerk-Architektur folgt einem strikten Isolation-Prinzip: Jeder Agent residiert in einem dedizierten internen Docker-Netzwerk, das ausschließlich den Agent-Container und den zugehörigen PQC-Proxy umfasst. Die Agents können untereinander nicht direkt kommunizieren, sondern ausschließlich über das externe \texttt{von\_sidecarproxy}-Netzwerk, das die PQC-Proxies verbindet. Diese Segmentierung erzeugt eine Defense-in-Depth-Architektur, bei der selbst bei einer Kompromittierung eines Agent-Containers der Zugriff auf andere Agents durch Netzwerk-Isolation verhindert wird.

Die Health-Check-Konfiguration der Agent-Container überwacht die Verfügbarkeit der Admin-API mittels periodischer HTTP-Requests an \texttt{http://localhost:<admin-port>/status/ready}. Zusätzlich definieren die Service-Dependencies (\texttt{depends\_on}) eine Startup-Reihenfolge, die sicherstellt, dass die PQC-Proxies vor den Agents starten und dass die Infrastruktur-Services (von-network, Tails-Server) vollständig initialisiert sind, bevor die Agents ihre Genesis-Datei abrufen. Diese Orchestrierung eliminiert Race-Conditions während des Deployment-Prozesses und gewährleistet eine deterministische Startup-Sequenz.

%Zusammenfassend basiert die SSI-Agent-Implementierung auf vollständig unmodifizierten ACA-Py-Komponenten, wobei die Post-Quantum-Kryptografie ausschließlich über externe Nginx-Sidecar-Proxies integriert wird. Diese nicht-invasive Architektur gewährleistet, dass die Agents mit Standard-Aries-Protokollen und -Workflows kompatibel bleiben, während alle externen Kommunikationskanäle durch ML-KEM-768-basierte Schlüsselvereinbarung und ML-DSA-65-Zertifikatsauthentifizierung quantensicher abgesichert sind. Die strikte Netzwerk-Segmentierung und das Sidecar-Pattern etablieren eine klare Separation zwischen kryptografischer Transport-Sicherheit und SSI-Geschäftslogik, was die Grundlage für nachfolgende Iterationen bildet, in denen PQC schrittweise auf die Application-Layer-Ebene erweitert wird.

\subsubsection{Docker Orchestrierung der Gesamtarchitektur} \label{Docker Orchestrierung der Gesamtarchitektur}

\fixme{manage scripts im Anhang hinterlegen?}

Die in den vorangegangenen Abschnitten beschriebenen Einzelkomponenten -- Zertifikatsinfrastruktur, PQC-Sidecar-Proxies, DLT-Infrastruktur, Revocation Registry und SSI-Agenten -- werden mittels einer mehrstufigen Docker-Compose-Orchestrierung zu einem funktionsfähigen Gesamtsystem integriert. Der Startprozess der Gesamtarchitektur folgt einer deterministischen Sequenz, die in Listing~\ref{lst:Docker-Compose-Start-der-Gesamtarchitektur} dokumentiert ist und die korrekten Abhängigkeiten zwischen den Infrastrukturschichten gewährleistet.

Die Orchestrierung gliedert sich in drei sequenzielle Phasen, die jeweils durch separate Docker-Compose-Konfigurationen gesteuert werden. In der ersten Phase wird die DLT-Infrastruktur über das \texttt{von-network}-Management-Skript initialisiert, wodurch die vier Indy-Validator-Nodes, der Genesis-Webserver sowie der zugehörige PQC-Sidecar-Proxy gestartet werden. Diese Phase erzeugt das gemeinsame externe Docker-Netzwerk \texttt{von\_sidecarproxy}, das als zentrale Kommunikationsschicht für alle quantensicheren Verbindungen dient. Die zweite Phase umfasst die Initialisierung der Revocation Registry mittels des \texttt{indy-tails-server}-Management-Skripts, wodurch der Tails-Server-Container sowie dessen PQC-Proxy-Frontend bereitgestellt werden. In der dritten Phase werden schließlich die SSI-Agenten -- Issuer, Holder und Verifier -- gemeinsam mit ihren jeweiligen PQC-Sidecar-Proxies über die projektspezifische Docker-Compose-Konfiguration gestartet.

\refstepcounter{manualListingCounter}
\label{lst:Docker-Compose-Start-der-Gesamtarchitektur}
\begin{lstlisting}[language=bash, caption={Docker Compose Start der Gesamtarchitektur}, numbers=left, frame=single]
(.venv) ferris@blockchain-ssi-pqc:~/github/MSc-blockchain-ssi-pqc$ ./von-network/manage start && ./indy-tails-server/docker/manage start && docker compose -f ./hopE/docker-compose.yml up -d
[+] Running 15/15
Network von_von                                 Created     0.0s 
Network von_sidecarproxy                        Created     0.0s 
Volume "von_webserver-ledger"                   Created     0.0s 
Volume "von_node1-data"                         Created     0.0s 
Volume "von_node3-data"                         Created     0.0s 
Volume "von_node2-data"                         Created     0.0s 
Volume "von_node4-data"                         Created     0.0s 
Volume "von_nginx-logs"                         Created     0.0s 
Volume "von_webserver-cli"                      Created     0.0s 
Container von-node4                             Started     0.6s 
Container von-webserver                         Started     0.4s 
Container von-node3                             Started     0.4s 
Container von-node2                             Started     0.5s 
Container von-node1                             Started     0.5s 
Container von-pqc-sidecarproxy-webserver        Started     0.6s 
Want to see the scrolling container logs? Run "./manage logs"
[+] Running 4/4
Network docker_tails-server                     Created     0.0s 
Volume "docker_nginx-logs"                      Created     0.0s 
Container docker-tails-server-1                 Started     0.3s 
Container pqc-sidecarproxy-tails-server         Started     0.5s 
Run './manage logs' for logs
WARN[0000] /home/ferris/github/MSc-blockchain-ssi-pqc/hopE/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion 
[+] Running 13/13
Network hope_hope-issuer                        Created     0.0s 
Network hope_hope-holder                        Created     0.0s 
Network hope_hope-verifier                      Created     0.0s 
Volume "hope_issuer-data"                       Created     0.0s 
Volume "hope_holder-data"                       Created     0.0s 
Volume "hope_verifier-data"                     Created     0.0s 
Volume "hope_nginx-logs"                        Created     0.0s 
Container issuer-agent                          Started     0.6s 
Container holder-agent                          Started     0.5s 
Container verifier-agent                        Started     0.5s 
Container pqc-sidecarproxy-holder               Started     1.3s 
Container pqc-sidecarproxy-issuer               Started     1.0s 
Container pqc-sidecarproxy-verifier             Started     1.2s
\end{lstlisting}


Die in \autoref{fig:Docker-Compose-Übersicht-Iteration-1} visualisierte Containerarchitektur verdeutlicht die resultierende Systemtopologie. Die Gesamtarchitektur umfasst insgesamt 14 Container, die sich auf die drei funktionalen Schichten verteilen: Die DLT-Schicht besteht aus sechs Containern -- vier Validator-Nodes, einem Webserver und einem PQC-Proxy. Die Revocation-Schicht umfasst zwei Container für den Tails-Server und dessen PQC-Proxy. Die Agent-Schicht besteht aus sechs Containern für die drei SSI-Agenten und ihre jeweiligen PQC-Proxies.

% Die Netzwerksegmentierung folgt einem strikten Isolation-Prinzip. Jede funktionale Einheit -- DLT-Infrastruktur, Revocation Registry sowie jeder einzelne SSI-Agent -- residiert in einem dedizierten internen Docker-Netzwerk, das ausschließlich den jeweiligen Service-Container und den zugehörigen PQC-Proxy umfasst. Die einzige Verbindung zwischen diesen isolierten Netzwerken erfolgt über das externe \texttt{von\_sidecarproxy}-Netzwerk, an das alle PQC-Proxies angebunden sind. Diese Architektur erzwingt, dass sämtliche inter-service Kommunikation -- einschließlich DIDComm-Nachrichten zwischen Agenten, Admin-API-Zugriffe, Genesis-File-Abrufe und Tails-Server-Requests -- ausschließlich über die quantensicheren TLS-1.3-Verbindungen mit ML-KEM-768-Schlüsselvereinbarung und ML-DSA-65-Zertifikatsauthentifizierung erfolgt.

Die \texttt{depends\_on}-Direktiven in den Docker-Compose-Konfigurationen definieren explizite Startup-Abhängigkeiten, die Race-Conditions während des Deployment-Prozesses eliminieren. Die PQC-Proxies werden vor den ihnen zugeordneten Backend-Services gestartet, und die SSI-Agenten warten auf die vollständige Initialisierung der Infrastruktur-Services, bevor sie ihre Genesis-Transaktionsdatei abrufen. Diese Orchestrierung gewährleistet eine deterministische Startup-Sequenz und stellt sicher, dass alle Komponenten beim Erreichen ihres operativen Zustands auf vollständig verfügbare Abhängigkeiten zugreifen können.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{docker_compose_übersicht.png}
    \caption{Docker-Compose-Übersicht der ersten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Docker-Compose-Übersicht-Iteration-1}
\end{figure}

\subsection{Formative Evaluation}
\label{sec:formative_evaluation_iteration1}

Die formative Evaluation dieser Iteration orientiert sich an der \textit{Technical Risk \& Efficacy Strategy} des FEDS-Frameworks nach \textcite[S. 4--5]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} und erfolgt unter einem künstlichen Evaluationsparadigma in der Laborumgebung. Ziel ist die Validierung der technischen Funktionsfähigkeit der implementierten Komponenten als Voraussetzung für die nachfolgende Iteration, nicht jedoch die vollständige Prüfung gegen die in Kapitel~\ref{sec:Anforderungsanalyse} definierten Anforderungen -- diese erfolgt im Rahmen der summativen Evaluation in Kapitel~\ref{sec:Summative Evaluation}.

Für die formative Evaluation während der ersten Iteration war die Bereitstellung eines PQC-fähigen Browsers zwingend erforderlich, da aktuelle Produktivbrowser keine Post-Quanten-Kryptographie in ihren TLS-Implementierungen unterstützen. Diese Limitation führt bei Verbindungsversuchen zu PQC-fähigen Servern zu einem Cipher-Mismatch, wie in \autoref{fig:Cipher-Mismatch-Blockchain-Webserver} veranschaulicht. Um diese Inkompatibilität zu überwinden, wurde ein Chromium-basierter Browser mit integrierter PQC-Unterstützung kompiliert (\ref{Eigenkompilation eines Chromium-Browsers mit PQC-Unterstützung}). Dieser selbstkompilierte Browser ermöglicht die Durchführung von TLS-Handshakes mit hybriden und rein PQ-basierten Algorithmen und dient als fundamentale Testplattform für die experimentelle Analyse von PQC-Verfahren im Kontext realer Webanwendungen.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_blockchain_webserver_CIPHER_MISMATCH.png}
    \caption{Cipher Mismatch bei Validierung der TLS-1.3-Verbindung des Blockchain-Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Cipher-Mismatch-Blockchain-Webserver}
\end{figure}

\subsubsection{Validierung der Zertifikatskette und ML-DSA-Signaturen}

Zur Verifikation der kryptographischen Integrität der implementierten Public-Key-Infrastruktur wurde die Zertifikatskette der Sidecar-Proxies mittels \texttt{openssl}-Diagnosewerkzeugen analysiert. Ziel war der Nachweis, dass die ausgelieferten X.509-Zertifikate korrekt auf den spezifizierten Post-Quanten-Signaturalgorithmen basieren. Die Inspektion des vom Issuer-Agenten-Proxy bereitgestellten Zertifikats (\autoref{fig:Successful-Validation-Issuer-MLDSA-Cert}) bestätigt, dass der öffentliche Schlüssel des Leaf-Zertifikats (\textit{pqc reverseproxy issuer agent}) den Algorithmus \texttt{ML-DSA-65} verwendet. Des Weiteren belegt der Signaturalgorithmus \texttt{ML-DSA-87}, dass die Zertifikatskette valide durch die \textit{Master Thesis PQC Root CA} signiert wurde, was die erfolgreiche Generierung und Einbindung der Dilithium-basierten Zertifikate in den TLS-Handshake beweist.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_issuer_mldsa_cert.png}
    \caption{Erfolgreiche Validierung des ML-DSA-Zertifikats des Issuer-Agenten}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-MLDSA-Cert}
\end{figure}

\subsubsection{Validierung der TLS 1.3 Algorithmen-Aushandlung}

Die erfolgreiche Integration der PQC-Algorithmen in das Transportprotokoll wurde durch einen Verbindungsaufbau mittels \texttt{openssl s\_client} verifiziert. Wie in \autoref{fig:Successful-Validation-Issuer-TLS1.3} dargestellt, konnte erfolgreich eine TLS-1.3-Sitzung etabliert werden. Die Analyse der Handshake-Parameter bestätigt die Verwendung der hybrid-post-quanten Schlüsselaustauschgruppe \texttt{X25519MLKEM768}, welche den klassischen elliptischen Kurvenalgorithmus X25519 mit dem KEM-Verfahren ML-KEM-768 kombiniert. Zudem wird für die Authentifizierung des Peer-Zertifikats der Signaturalgorithmus \texttt{mldsa65} (Dilithium) ausgewiesen. Diese Ergebnisse validieren die korrekte Konfiguration der OQS-Provider-Bibliothek innerhalb der Proxy-Komponenten und belegen die praktische Funktionsfähigkeit des hybriden Schlüsselaustauschs im Zusammenspiel mit PQC-Signaturen.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_issuer_TLS1.3.png}
    \caption{Erfolgreiche Validierung der TLS-1.3-Verbindung des Issuer-Agenten}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-TLS1.3}
\end{figure}

\subsubsection{Validierung der Ledger-Initialisierung}

Die operative Funktionsfähigkeit des Hyperledger Indy Netzwerks wurde primär über das Web-Interface des Blockchain-Servers validiert. Wie in \autoref{fig:Successful-Validation-Blockchain-Webserver} dargestellt, zeigen die Statusindikatoren aller vier Validator-Nodes eine aktive Beteiligung am Konsensus-Protokoll (Status \textit{Node1--4}), womit der Distributed Ledger erfolgreich initialisiert ist. Simultan belegt diese Abbildung die korrekte PQC-Absicherung der Webserver-Komponente: Der Zugriff erfolgt über den eigens kompilierten PQC-Chromium-Browser, dessen Security-Panel explizit eine authentifizierte TLS-1.3-Verbindung unter Verwendung der hybriden Schlüsselaustauschgruppe \texttt{X25519MLKEM768} ausweist.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_blockchain_webserver.png}
    \caption{Erfolgreiche Validierung der TLS-1.3-Verbindung des Blockchain-Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Blockchain-Webserver}
\end{figure}

Als zweite notwendige Bedingung für die spätere Anbindung der SSI-Agenten (ACA-Py) wurde die Verfügbarkeit der Genesis-Datei verifiziert. \autoref{fig:Successful-Validation-Genesis-File-Blockchain-Webserver} dokumentiert den Abruf des \texttt{/genesis}-Endpunkts mittels \texttt{curl}. Die erfolgreiche Rückgabe der JSON-formatierten Genesis-Transaktionen bestätigt, dass die für das Bootstrapping externer Clients erforderlichen Netzwerkinformationen korrekt publiziert werden.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_genesis.png}
    \caption{Erfolgreiche Validierung der Genesis-Datei des Blockchain-Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Genesis-File-Blockchain-Webserver}
\end{figure}

\subsubsection{Validierung der ACA-Py API-Verfügbarkeit}

Die funktionale Erreichbarkeit der SSI-Agenten wurde durch eine systematische Analyse der Initialisierungsphase und der anschließenden API-Verfügbarkeit validiert. Die Logging-Ausgabe des Issuer-Agenten (Listing~\ref{lst:Issuer-Agent-Boot-Logs}) dokumentiert die erfolgreiche Genesis-Datei-Abrufung über \texttt{https://host.docker.internal:8000/genesis} (Zeile 3) und die vollständige Ledger-Konfiguration (Zeile 8). Die Erstellung eines neuen Wallet-Profils mit Askar-Backend (Zeile 5) und die erfolgreiche Initialisierung der Inbound- und Outbound-Transports (Zeile 10--26) demonstrieren die korrekte Konfiguration des ACA-Py-Agents. Die durchgeführten Health-Checks über den \texttt{/status/ready}-Endpunkt (Zeile 51--52) bestätigen die vollständige Initialisierung und Bereitschaft des Agenten.

Die Visualisierung der Swagger-basierten Admin-Oberfläche (\autoref{fig:Successful-Validation-Issuer-Agent-ACA-Py-Swagger-API}) ergänzt diese technischen Log-Daten durch den Nachweis, dass die Admin-API über den PQC-Reverse-Proxy fehlerfrei erreichbar ist und alle administrativen Endpunkte zur Steuerung der Agenten-Komponente bereitstellt. Die Tatsache, dass die Swagger-Oberfläche unter dem PQC-gesicherten HTTPS-Endpoint vollständig funktionsfähig ist, belegt die korrekte TLS-Terminierung am Proxy sowie die fehlerfreie Weiterleitung der HTTP-Anfragen an den ACA-Py-Container.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_Issuer_Agent_Swagger_API.png}
    \caption{Erfolgreiche Validierung der Issuer Agent ACA-Py Swagger Admin API}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-Agent-ACA-Py-Swagger-API}
\end{figure}

\subsubsection{Validierung der Netzwerkisolation}

Die integrale Sicherheitseigenschaft der Netzwerksegmentierung wurde durch eine Inspektion der Docker-Netzwerktopologie und systematische Erreichbarkeitstests validiert. Die Architektur implementiert ein striktes Micro-Segmentation-Konzept, bei dem jeder SSI-Akteur in einem dedizierten, isolierten Subnetz operiert. \autoref{fig:Darstellung-Network-Isolation} belegt diese Topologie anhand des \texttt{docker network inspect}-Outputs: Der Issuer-Agent befindet sich exklusiv im Netzwerksegment \texttt{hope\_hope-issuer}, während der Holder-Agent im Segment \texttt{hope\_hope-holder} isoliert ist. In jedem dieser Segmente fungiert der zugehörige PQC-Sidecar-Proxy als einziger Ingress-Punkt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_network_isolation.png}
    \caption{Darstellung der Netzwerkisolation innerhalb der Gesamtarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Darstellung-Network-Isolation}
\end{figure}

\autoref{fig:Successful-Validation-Network-Isolation-Through-Tests} demonstriert die Wirksamkeit dieser Isolation auf zwei Ebenen. Erstens zeigt die Prozessliste (\texttt{docker ps}), dass lediglich die Sidecar-Proxies externe Ports (z.\,B. 8020, 8030, 8040) an das Host-System binden, während die Ports der ACA-Py-Container (z.\,B. \texttt{issuer-agent}) nicht exponiert sind. Zweitens beweisen die Inter-Container-Verbindungstests die logische Trennung: Ein direkter Zugriffsversuch aus dem \texttt{issuer-agent}-Container auf den \texttt{holder-agent} schlägt mit einem DNS-Auflösungsfehler (\textit{Could not resolve host}) fehl, da keine Routing-Route zwischen den isolierten Netzwerkbrücken existiert. Im Gegensatz dazu ist der lokale Zugriff des \texttt{pqc-sidecarproxy-holder} auf seinen zugehörigen Agenten erfolgreich möglich. Diese Konfiguration erzwingt, dass jegliche Kommunikation zwischen den Akteuren das Host-Netzwerk passieren muss, wo sie durch die in den Proxies terminierte Post-Quanten-Kryptographie (TLS 1.3 mit ML-KEM) abgesichert wird.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_network_isolation_through_tests.png}
    \caption{Erfolgreiche Validierung der Netzwerkisolation innerhalb der Gesamtarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Network-Isolation-Through-Tests}
\end{figure}

\subsection{Erkenntnisse und Anpassungsbedarfe}

Die erste Iteration bildet das fundamentale technologische Fundament der Forschungsarbeit. Die formative Evaluation (Kapitel \ref{sec:Formative-Evaluation-I1}) validierte die operative Integrität der entwickelten Architektur: Die verteilten Micro-Services, der Hyperledger Indy Ledger und die PQC-Sidecar-Proxies interagieren funktional korrekt. Diese Initialphase generierte jedoch spezifische Erkenntnisse, die eine gezielte Weiterentwicklung in der zweiten Iteration motivieren. Diese werden nachfolgend in Bezug auf die Designziele und die Funktionsmerkmale (FF) analysiert.

\subsubsection{Abgleich mit den Designzielen der ersten Iteration}

Das primäre Designziel, die Absicherung der Transportebene in einem SSI-Ökosystem mittels Post-Quanten-Kryptographie, wurde vollständig erreicht. Die erfolgreiche Validierung des Sidecar-Musters belegt die Machbarkeit einer transparenten PQC-Migration für Legacy-Systeme (ACA-Py, Indy Node) ohne Eingriffe in deren Kerncode. Die implementierte Micro-Segmentation erfüllt zudem die architektonischen Anforderungen an Netzwerkisolation und Angriffsflächenminimierung in KRITIS-Umgebungen.

\subsubsection{FF1: Funktionale SSI-Kernprozesse \& Systemarchitektur}

Die implementierte Sidecar-Proxy-Architektur erwies sich als effektives Design-Pattern zur Realisierung einer \emph{Separation of Concerns} im KRITIS-Kontext. Durch die strikte Entkopplung der kryptographischen Terminierung (Proxy) von der Business-Logik (SSI-Agent) konnte eine PQC-Integration realisiert werden, die die Kernprozesse der Identitätsverwaltung funktional nicht beeinträchtigt. Diese architektonische Entscheidung ermöglicht es, sicherheitskritische Updates an der Krypto-Komponente vorzunehmen, ohne die Integrität der komplexen SSI-Logik zu gefährden.

\subsubsection{FF2: Sicherheit, Compliance \& Algorithmenwahl}

Die Implementierung von ML-KEM-768 und ML-DSA-65 bestätigte die technische Reife dieser Algorithmen für den produktiven Einsatz. Die durchgeführten Tests validierten die Interoperabilität von hybriden Zertifikatsketten. Eine zentrale Erkenntnis ist jedoch, dass Sicherheit im KRITIS-Kontext über die Transportebene hinausgehen muss. Die aktuelle Transportverschlüsselung schützt zwar Daten "in Transit", bietet aber keine Ende-zu-Ende-Integrität auf Anwendungsebene (z.B. für VCs im Ruhezustand). Eine Erweiterung des Sicherheitsmodells auf die Applikationsschicht ist daher für Defense-in-Depth unerlässlich.

\subsubsection{FF3: Kryptografische Agilität}

Entgegen der Annahme, dass statische Proxy-Konfigurationen starr sind, offenbarten die Tests, dass die gewählte Container-Architektur in Kombination mit TLS 1.3 ein hohes Maß an \textit{operativer Krypto-Agilität} bietet.
Erstens ermöglicht die Containerisierung (Docker) den Austausch kryptografischer Bibliotheken durch einfache Image-Updates. Ein Algorithmenwechsel erfordert lediglich den Austausch des Proxy-Containers ("Rolling Update"), ohne dass der SSI-Agent (Business-Logik) gestoppt oder rekompiliert werden muss \textcite{docker2017rolling}. Dies realisiert eine Agilität auf Infrastrukturebene.
Zweitens erlaubt das TLS 1.3-Protokoll eine dynamische Aushandlung (Negotiation) der Cipher Suites \textcite{keyfactor2023tls}. Die Sidecar-Proxies können so konfiguriert werden, dass sie mehrere PQC-Algorithmen parallel unterstützen und je nach Client-Fähigkeit den stärksten gemeinsamen Standard wählen. Dies stellt eine Protokoll-basierte Agilität dar.
Drittens begünstigt die Micro-Segmentation granulare Migrationspfade: Einzelne Netzwerksegmente (z.B. nur der Issuer) können isoliert auf neuere Algorithmen umgestellt werden, ohne das Gesamtsystem zu gefährden \textcite{colortokens2025microsegmentation}.

\subsubsection{Design-Refinements für die zweite Iteration}

Basierend auf diesen Erkenntnissen wird das Design für Iteration 2 gezielt erweitert, um PQC zusätzlich auf der Applikationsebene zu verankern:

\begin{itemize}
\item \textbf{Application-Layer-PQC:} Integration der \emph{liboqs} direkt in die SSI-Agenten. Dies ermöglicht PQC-Signaturen für VCs und DIDComm-Nachrichten, wodurch eine Ende-zu-Ende-Integrität unabhängig vom Transportkanal gewährleistet wird (Adressierung FF2).
\item \textbf{Hybride Sicherheitsarchitektur:} Beibehaltung der Sidecar-Proxies als erste Verteidigungslinie (Transport Security) bei gleichzeitiger Härtung der Datenobjekte selbst (Application Security). Dies schafft Redundanz und Tiefenverteidigung.
\end{itemize}

\newpage
\section{Zweite Iteration der Artefaktentwicklung}
\label{Zweite Iteration der Artefaktentwicklung}

\subsection{Designziele dieser Iteration} \label{sec:Designziele_Iteration_2}
%   ALLE FF, mit SCHWERPUNKT auf FF2 (PQC), FF3 (Performance) \\
%   → FF1 (Architektur): Blockchain-Integration finalisieren \\
%   → FF1 (Architektur): Compliance-Layer finalisieren (BSI, DSGVO) \
%   → FF2 (Algorithmen): Vollständige PQC-Suite (ML-DSA, ML-KEM) \\
%   → FF2 (Algorithmen): Hybride Schemata implementieren \
%   → FF3 (Kryptoagilität): Plugin-System für Algorithmen implementieren
%   → FF3 (Kryptoagilität): Key-Rotation-Mechanismus validieren

Die zweite Iteration der Artefaktentwicklung baut auf der in Iteration 1 erfolgreich validierten Basisarchitektur auf und korrespondiert erneut mit der DSRM-Phase 2 \textit{Objectives} nach \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}. Der Fokus dieser Iteration liegt auf der Erweiterung des Prototyps um eine tiefgreifende PQC-Integration auf der Anwendungsebene (Application Layer). Im Kontext des Drei-Zyklen-Modells nach \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007} wird der Design Cycle intensiviert, um die kryptografische Sicherheit von der reinen Transportsicherung (TLS) auf die tatsächlichen Nutzdaten (Verifiable Credentials und DID-Dokumente) auszuweiten und somit eine Ende-zu-Ende-Sicherheit zu gewährleisten.

Die Designziele dieser Iteration leiten sich konsistent aus den in Kapitel~\ref{sec:Zielsetzung und Forschungsfragen} definierten Forschungsfragen ab, wobei eine inhaltliche Vertiefung der technischen Anforderungen erfolgt:

Bezüglich \textbf{FF1 (Systemarchitektur \& Compliance)} wird das Ziel verfolgt, die SSI-Kernprozesse - insbesondere Issuance und Verification - so zu modifizieren, dass sie quantenresistente Signaturen und Schlüsselformate nativ unterstützen. Das Design muss sicherstellen, dass die Unveränderlichkeit und Authentizität von Identitätsnachweisen unabhängig vom Transportkanal auch langfristig gegenüber Quantencomputer-Angriffen gewährleistet bleibt, was eine zentrale Anforderung für den Einsatz in KRITIS-Umgebungen darstellt.

Hinsichtlich \textbf{FF2 (Algorithmenauswahl \& Sicherheitsbewertung)} liegt der Fokus auf der Integration und Evaluierung des NIST-standardisierten Signaturalgorithmus ML-DSA (Dilithium) innerhalb der Credential-Strukturen. Das Designziel besteht darin, die praktische Machbarkeit von PQC-Signaturen in Verifiable Credentials (VCs) und Decentralized Identifiers (DIDs) nachzuweisen.

Für \textbf{FF3 (Kryptografische Agilität)} zielt diese Iteration auf die Implementierung von Agilitätsmechanismen direkt in den Datenstrukturen ab. Das System soll so gestaltet werden, dass es hybride Szenarien unterstützt und eine Koexistenz sowie den nahtlosen Wechsel zwischen klassischen (z.\,B. Ed25519) und post-quanten Kryptografieverfahren innerhalb der DID-Methoden und Credential-Definitionen ermöglicht, ohne die Interoperabilität grundlegend zu gefährden.

\subsection{Architekturentwurf}
%   - Application-Layer-PQC-Integration (liboqs in ACA-Py) \\
%   - Kryptoagiles Design (Plugin-Architektur) \\

\fixme{\url{https://github.com/decentralized-identity/aries-rfcs} ==> Aries RFCs referenzieren}

\subsubsection{Gesamtarchitektur}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Gesamtarchitektur_Iteration2}
    \caption{Gesamtarchitekturentwurf der zweiten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Gesamtarchitektur_Iteration2}
\end{figure}

\subsubsection{ACA-Py Applikationsarchitektur}

\fixme{Überflüssig?}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{ACAPY Application Architecture_Iteration 2.png}
    \caption{ACA-Py High Level Applikationsarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:ACAPY_Application_Architecture_Iteration2}
\end{figure}

Die Architektur von Hyperledger Aries Cloud Agent Python (ACA-Py) folgt einem fünfschichtigen Design mit klarer Verantwortlichkeitstrennung.

\textit{Layer 1} bildet eine zustandslose HTTP-REST-API (Admin API), die es Controller-Anwendungen ermöglicht, den Agent über standardisierte Endpoints wie \texttt{/out-of-band/create-invitation}, \texttt{/issue-credential-2.0/send} oder \texttt{/present-proof-2.0/send-request} zu steuern, ohne direkt mit der Python-Codebasis zu interagieren.

\textit{Layer 2} implementiert die SSI-Geschäftslogik als Protocol Handler, die Aries RFCs (Request for Comments) in Form zustandsbasierter State Machines umsetzen: Das Out-of-Band Protocol (RFC 0434) generiert Invitation-Nachrichten mit \texttt{did:peer:4}-DIDs, das DID Exchange Protocol (RFC 0023) authentifiziert Agent-Verbindungen mittels ED25519-Signaturen, das Issue Credential Protocol (RFC 0453) erstellt AnonCreds-CL-signierte Credentials, und das Present Proof Protocol (RFC 0454) orchestriert Zero-Knowledge-Proof-basierte Presentations.

\textit{Layer 3} abstrahiert die Schlüsselverwaltung durch das Aries-Askar-Wallet, das ED25519-Schlüsselpaare (32 Bytes, für Signaturen) und X25519-Schlüsselpaare (32 Bytes, für Key Agreement) generiert, diese mit Multicodec-Präfixen (\texttt{0xed}, \texttt{0xec}) kodiert und verschlüsselt in einer SQLite-Datenbank ablegt, wobei ChaCha20-Poly1305-Authenticated-Encryption nach Argon2id-basierter Schlüsselableitung verwendet wird.

\textit{Layer 4} realisiert DIDComm-Messaging über \texttt{pack\_message()} und \texttt{unpack\_message()}: Nachrichten werden mittels X25519-ECDH-Key-Agreement, HKDF-SHA256-Schlüsselableitung und XChaCha20-Poly1305-Verschlüsselung in JWE-Strukturen transformiert, die Vertraulichkeit und Integrität zwischen Agents gewährleisten.

\textit{Layer 5} implementiert HTTP- und WebSocket-basierte Transport-Mechanismen für Inbound- (\texttt{--inbound-transport http 0.0.0.0 8020}) und Outbound-Kommunikation, wobei in der klassischen Architektur kein quantensicheres TLS verwendet wird. Die gesamte kryptografische Basis -- ED25519 für DID-Authentifizierung, X25519 für DIDComm-Encryption und AnonCreds-CL-Signaturen für Credentials -- ist nicht quantenresistent, da elliptische Kurven durch Shor's Algorithmus auf Quantencomputern kompromittiert werden können, was die Notwendigkeit einer systematischen Post-Quantum-Kryptografie-Integration begründet.


\subsubsection{ACA-Py Applikationsarchitektur mit PQC-Integration}

Die Integration von Post-Quantum-Kryptografie in Hyperledger Aries Cloud Agent Python erfolgt über eine plugin-basierte Architektur, die sechs zentrale Design-Prinzipien verfolgt: Transparenz, Erweiterbarkeit, Interoperabilität, Defense-in-Depth, Standards-Konformität und Separierung von Belangen.
Abbildung~\ref{fig:ACAPY_Application_Architecture_Iteration2_PQC} visualisiert die erweiterte Architektur und hebt die Unterschiede zur klassischen Implementierung hervor.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{ACA-Py Applikationsarchitektur mit PQC-Integration.png}
    \caption{ACA-Py High Level Applikationsarchitektur mit PQC-Integration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:ACAPY_Application_Architecture_Iteration2_PQC}
\end{figure}

Das fundamentale Design-Prinzip der \textit{Transparenz} manifestiert sich in der vollständigen Beibehaltung der Controller-Application-Schnittstelle und der ACA-Py Admin API. Beide Schichten bleiben unverändert, wodurch bestehende Controller-Anwendungen -- beispielsweise Web-Applikationen, Jupyter-Notebooks oder CLI-Tools -- ohne Modifikationen weiterhin funktionieren. Die HTTP-REST-API exponiert identische Endpoints (\texttt{/out-of-band/create-invitation}, \texttt{/issue-credential-2.0/send}, etc.) mit strukturell unveränderten Request- und Response-Schemata. Diese Architekturentscheidung eliminiert Breaking Changes und ermöglicht eine schrittweise Migration: Controller-Code bleibt kompatibel, während die kryptografischen Primitive unterhalb der API-Ebene ausgetauscht werden. Das Diagramm markiert diese Schichten explizit mit \texttt{NO CHANGE}, um die Nicht-Invasivität der PQC-Integration zu verdeutlichen.

Die \textit{Erweiterbarkeit} der Architektur wird durch das Key-Type-Registry-Pattern gewährleistet. Das PQC-Plugin erweitert die Wallet-Schnittstelle um neue Schlüsseltypen (ML-DSA-65 für digitale Signaturen, ML-KEM-768 für Key Encapsulation), ohne die bestehende Registry zu modifizieren. Diese Erweiterung erfolgt zur Laufzeit durch Registrierung zusätzlicher \texttt{KeyType}-Objekte, die Multicodec-Präfixe (\texttt{0xd065} für ML-DSA-65, \texttt{0xe018} für ML-KEM-768), Multicodec-Namen und JWS-Algorithmus-Identifier definieren. Die Architektur nutzt pluggable Crypto Backends: Das PQC-Plugin bindet \texttt{liboqs-python} als kryptografische Engine ein, während klassische Operationen weiterhin über \texttt{libsodium} abgewickelt werden. Dieses Backend-Abstraktionsmodell erlaubt die Integration zukünftiger Post-Quantum-Algorithmen -- beispielsweise SLH-DSA (NIST FIPS-205) oder zukünftige NIST-Standardisierungsrunden -- durch Addition weiterer Backend-Module ohne Änderungen an der Core-Architektur.

Das Design gewährleistet \textit{Interoperabilität} durch explizite Fallback-Mechanismen zu klassischen Algorithmen. Die Wallet-Operation-Wrapper im Plugin implementieren Key-Type-Erkennung: Wenn eine Operation einen klassischen Schlüssel (ED25519, X25519) detektiert, delegiert sie an die ursprüngliche Implementierung; bei PQC-Schlüsseln erfolgt die Delegation an die \texttt{liboqs}-Integration. Diese Dual-Mode-Architektur ermöglicht hybride Deployments, in denen Agents sowohl mit PQC-fähigen als auch mit Legacy-Agents kommunizieren können. Zusätzlich unterstützt das Design explizit Hybrid-Kryptografie (X25519MLKEM768), bei der klassische und quantensichere Algorithmen kombiniert werden, um Crop-and-Paste-Resistenz gemäß BSI-Richtlinien zu erreichen. Die strukturelle JWE-Kompatibilität bleibt erhalten: DIDComm-Nachrichten verwenden weiterhin die JSON-Web-Encryption-Struktur mit \texttt{protected}, \texttt{recipients}, \texttt{iv}, \texttt{ciphertext} und \texttt{tag}-Feldern, wobei lediglich das \texttt{encrypted\_key}-Feld größere Ciphertexte aufnimmt (1088 Bytes für ML-KEM-768 statt circa 32 Bytes für X25519-ECDH) und der \texttt{alg}-Header den verwendeten Algorithmus spezifiziert.

Das Prinzip \textit{Defense-in-Depth} wird durch zweischichtige Quantenresistenz realisiert. Auf Transport-Layer-Ebene (Iteration 1, bereits implementiert) terminieren Nginx-Reverse-Proxies TLS-1.3-Verbindungen mit ML-KEM-768-Schlüsselaustausch und ML-DSA-65-Zertifikaten, wodurch alle HTTP-basierten Kommunikationskanäle quantensicher werden. Auf Application-Layer-Ebene (Iteration 2, Plugin-Integration) verschlüsselt das DIDComm-Messaging-Protokoll Nachrichten mittels ML-KEM-768-basierter Key Encapsulation, unabhängig vom zugrundeliegenden Transport-Protokoll. Diese doppelte Absicherung gewährleistet, dass selbst bei Kompromittierung der Transport-Layer-Infrastruktur (z.\,B.\ Proxy-Penetration) die End-to-End-verschlüsselten DIDComm-Nachrichten quantenresistent bleiben. Das Architekturdiagramm visualisiert diese Schichtung durch separate Markierungen für \texttt{Iteration 2: PQC within DIDComm} (Transport Layer) und die PQC-spezifischen Wallet-Operationen (\texttt{PQC Pack/Unpack}).

Die \textit{Standards-Konformität} manifestiert sich in der strukturellen Beibehaltung aller Aries RFCs. Das Out-of-Band Protocol (RFC 0434), DID Exchange Protocol (RFC 0023), Issue Credential Protocol (RFC 0453) und Present Proof Protocol (RFC 0454) bleiben als Python-Module unverändert; lediglich die von ihnen aufgerufenen Wallet-Operationen werden durch das Plugin abgefangen und an PQC-Implementierungen delegiert. Diese Interception-Architektur (im Diagramm als \texttt{PQC-Interception} und \texttt{Delegation to PQC-Plugin} markiert) gewährleistet, dass die State-Machine-Logik der Protokoll-Handler intakt bleibt. Die Multicodec-Spezifikation für ML-DSA-65 und ML-KEM-768 ist derzeit provisorisch (W3C-Standardisierung ausstehend), jedoch strukturell kompatibel mit dem bestehenden Multicodec-Framework. Die DIDComm-v1-JWE-Kompatibilität bleibt vollständig erhalten, sodass Messages zwischen PQC-fähigen und klassischen Agents ausgetauscht werden können, sofern beide Seiten die entsprechenden Algorithmen unterstützen.

Das Prinzip der \textit{Separierung von Belangen} reflektiert die schrittweise Migrationsstrategie. AnonCreds-Credentials verwenden weiterhin CL-Signaturen (Camenisch-Lysyanskaya), da der AnonCreds-Standard keine Post-Quantum-Signaturen spezifiziert und eine Änderung Inkompatibilität mit bestehenden Indy-Ledger-Deployments erzeugen würde. Diese Entscheidung isoliert die PQC-Integration auf die DID-Ebene (did:peer:4-Generierung mit ML-DSA-65/ML-KEM-768) und die Transport-Ebene (TLS 1.3 und DIDComm), während die Credential-Signatur-Ebene klassisch bleibt. Zukünftige Migrationen könnten W3C Verifiable Credentials mit PQC-Signaturen nutzen, ohne die bestehende AnonCreds-Infrastruktur zu beeinflussen. Diese Architektur vermeidet einen Big-Bang-Ansatz, bei dem alle kryptografischen Schichten simultan migriert werden müssten, zugunsten einer inkrementellen, risikominimierten Transition.

Die zentrale architektonische Innovation ist das \texttt{PQC Plugin}-Modul, das als Vermittlungsschicht zwischen Protocol Handlers, Wallet Interface und den kryptografischen Backends fungiert. Das Plugin umfasst vier Kernkomponenten: Den \texttt{liboqs Integration Layer}, der Python-Bindings zu den NIST-standardisierten Algorithmen bereitstellt; den \texttt{PQC did:peer:4 Generator}, der Dual-Key-DIDs (Signing Key: ML-DSA-65, Agreement Key: ML-KEM-768) mit korrekter Multicodec-Kodierung erzeugt; die \texttt{Protocol Interceptors}, die Aufrufe von Protocol Handlers abfangen und an PQC-Implementierungen delegieren; sowie die \texttt{Wallet Operation Wrappers}, die \texttt{create\_key()}, \texttt{sign\_message()}, \texttt{verify\_message()}, \texttt{pack\_message()} und \texttt{unpack\_message()} durch PQC-Varianten erweitern. Diese Komponenten werden beim Agent-Start durch die Plugin-Setup-Funktion registriert und installiert, wodurch die Interception-Logik zur Laufzeit aktiviert wird.

Die Wallet-Implementierung (Aries Askar mit SQLite-Backend) erfährt zwei wesentliche Erweiterungen: Die \texttt{Expanded Key-Type-Registry} speichert Metadaten für ML-DSA-65- und ML-KEM-768-Schlüssel, einschließlich Schlüsselgrößen (Public Key: 1952 Bytes bzw.\ 1184 Bytes, Private Key: 4000 Bytes bzw.\ 2400 Bytes) und Algorithmus-Identifiern. Die \texttt{PQC-Key-Storage}-Erweiterung persistiert diese Schlüssel verschlüsselt in der SQLite-Datenbank, wobei die bestehende ChaCha20-Poly1305-AEAD-Verschlüsselung nach Argon2id-Key-Derivation unverändert bleibt. Die Wallet-Schnittstelle exponiert neue Operationen (\texttt{PQC Key Operations}, \texttt{PQC Sign/Verify}, \texttt{PQC Pack/Unpack}), die transparent von den Protocol Handlers aufgerufen werden, ohne dass diese Kenntnis über die zugrundeliegenden Algorithmen besitzen müssen.

Die Architektur gewährleistet, dass alle Schichten oberhalb der Wallet-Schnittstelle -- insbesondere Protocol Handlers und Admin API -- keine Änderungen erfahren. Dies reduziert die Testoberfläche, da ausschließlich die Plugin-Komponenten und Wallet-Erweiterungen validiert werden müssen, während die etablierte Aries-Protokoll-Logik unverändert bleibt. Die resultierende Architektur kombiniert die Produktionsreife von Hyperledger Aries mit der Quantenresistenz von NIST-standardisierten Post-Quantum-Algorithmen, ohne die Interoperabilität mit bestehenden SSI-Deployments zu kompromittieren.


%  - PQC-Algorithmen-Integration (ML-DSA, ML-KEM) \\
%  - Kryptoagiles Design (Plugin-Architektur) \\
\subsection{Implementierung}

% Die Implementierung der PQC-Unterstützung auf Application-Ebene erfolgt durch das \texttt{pqc\_didpeer4\_fm}-Plugin, das über den ACA-Py Plugin-Mechanismus transparent in die Agent-Architektur integriert wird. ACA-Py definiert ein Plugin als Python-Paket mit einem \texttt{setup(context)}-Entrypoint, der beim Agent-Start aufgerufen wird und Zugriff auf zentrale Agent-Komponenten (Wallet, DIDComm, Protocol Registry) über einen \texttt{PluginContext} erhält. Plugins können entweder neue Protokolle registrieren oder bestehende Funktionen durch Monkey-Patching erweitern.

Die Implementierung der PQC-Unterstützung auf Application-Ebene folgt einem zweistufigen Ansatz. In der ersten Stufe wird das \texttt{pqc\_didpeer4\_fm}-Plugin entwickelt, das sich in den ACA-Py Plugin-Mechanismus einfügt. Das Plugin ist als Python-Paket strukturiert und definiert einen \texttt{setup(context)}-Entrypoint, der beim Agent-Start aufgerufen wird. Über den \texttt{PluginContext} erhält das Plugin unmittelbaren Zugriff auf zentrale Agent-Komponenten wie die Wallet, das DIDComm-System und die Protocol Registry. Diese Architektur ermöglicht es Plugins, neue Protokolle zu registrieren oder bestehende Funktionen durch Monkey-Patching zu erweitern, ohne den ACA-Py Kern zu modifizieren.

Die zweite Stufe integriert das entwickelte Plugin in die containerisierte Deployment-Infrastruktur. Dabei wird das Plugin als Abhängigkeit in der \texttt{Dockerfile} definiert, sodass es während des Container-Builds installiert wird. Anschließend erfolgt die Konfiguration über \texttt{docker-compose}, indem der ACA-Py Service mit den erforderlichen Umgebungsvariablen und Plugin-Parametern initialisiert wird. Diese Trennung von Plugin-Entwicklung und Deployment-Integration gewährleistet Modularität und Wartbarkeit.

\begin{figure}[h]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 liboqs\_wrapper.py.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

% Das \texttt{pqc\_didpeer4\_fm}-Plugin nutzt beide Erweiterungsmechanismen: Es registriert neue PQC-Schlüsseltypen über \texttt{key\_types.py} und \texttt{key\_type\_patches.py} in der globalen \texttt{KeyType}-Registry und erweitert durch Monkey-Patching bestehende ACA-Py-Funktionen. Die Plugin-Initialisierung in \texttt{\_\_init\_\_.py} orchestriert die schrittweise Integration aller Module beim Agent-Start.

Die Implementierung des PQC-Plugins gliedert sich in drei funktionale Schichten, in die die in \autoref{fig:pqc_didpeer4_fm_directory_structure} dargestellten 15 Module eingeteilt sind: 

Die \textit{Kryptografie-Abstraktionsschicht} (\texttt{liboqs\_wrapper.py}) kapselt ML-DSA-65- und ML-KEM-768-Operationen, 

die \textit{DID-Verarbeitungsschicht} umfasst \texttt{pqc\_peer4\_creator.py} (did:peer:4-Generierung), \texttt{pqc\_peer4\_resolver.py} (DID-Auflösung), \texttt{pqc\_multicodec.py} und \texttt{pqc\_multikey.py} (Multiformat-Kodierung) sowie \texttt{pqc\_didcomm\_v1.py} (DIDComm-Verschlüsselung), 

und die \textit{Integration-Patching-Schicht} mit \texttt{monkey\_patches.py} (zentrale Funktion-Interceptors), \texttt{askar\_pqc\_patch.py} und \texttt{wallet\_patch.py} (Wallet-Operationen), \texttt{base\_manager\_patch.py} und \texttt{connection\_target\_patch.py} (Connection-Management), \texttt{validator\_patch.py} (Input-Validierung) sowie \texttt{multicodec\_patch.py} (Multicodec-Registry-Erweiterung). Diese modulare Architektur ermöglicht eine vollständig transparente PQC-Integration ohne Modifikation des ACA-Py-Kerncodes.

% \paragraph{Kryptografie-Abstraktionsschicht (liboqs Integration Layer)}
% - Einbindung der liboqs-python-Bibliothek \\
% - ML-DSA-65 Signatur-Operationen \\
% - ML-KEM-768 Key Encapsulation

%  - liboqs-Wrapper-Implementierung (liboqs\_wrapper.py) \\
%   - ML-DSA-65 Signatur-Operationen \\
%   - ML-KEM-768 Key Encapsulation \\
%   - Fehlerbehandlung und Validierung

% \paragraph{PQC did:peer:4 Generator}
% - Multicodec und Multikey-Kodierung \\
% - did:peer:4 Struktur mit Dual-Keys

%   - DID-Generierung mit PQC-Schlüsseln (pqc\_peer4\_creator.py) \\
%   - DID-Auflösung (pqc\_peer4\_resolver.py) \\
%   - Multicodec-Kodierung (pqc\_multicodec.py, multicodec\_patch.py) \\
%   - Multikey-Transformation (pqc\_multikey.py) \\
%   - did:peer:4 Struktur mit Dual-Keys (ML-DSA-65 + ML-KEM-768)

% \paragraph{Protocol Interceptors (Monkey-Patching)}
% - Interception-Mechanismus \\
% - Connection Manager Interception \\
% - DID Exchange Signatur-Interception \\
% - Installation der Patches

%   - Interception-Mechanismus (\_\_init\_\_.py, monkey\_patches.py) \\
%   - Connection Manager Interception (base\_manager\_patch.py) \\
%   - DID Exchange und Connection Target (connection\_target\_patch.py) \\
%   - JWS-Validierung (validator\_patch.py) \\
%   - Installation der Patches (Reihenfolge und Abhängigkeiten)

% \paragraph{Wallet Operation Wrappers}
% - Key-Creation-Wrapper \\
% - Signatur-Wrapper (sign\_message / verify\_message) \\
% - DIDComm Pack/Unpack-Wrapper \\

%   - Askar-Integration (askar\_pqc\_patch.py)
%   - Key-Creation-Wrapper und Verkey-Lookup (wallet\_patch.py)
%   - Signatur-Wrapper (sign\_message / verify\_message)
%   - DIDComm Pack/Unpack-Wrapper (pqc\_didcomm\_v1.py)

% \paragraph{Key-Type-Registry-Erweiterung}
% - KeyType-Datenstruktur \\
% - Registrierung im Wallet \\
% - Fallback-Mechanismus \\

%   - KeyType-Definitionen (key\_types.py)
%   - Registry-Integration (key\_type\_patches.py)
%   - API-Schema-Anpassungen
%   - Fallback-Mechanismus

% \paragraph{Wallet-Speicherung und Persistierung}
% - SQLite-Schema (Aries Askar) \\

% \paragraph{Deployment und Konfiguration}
% - Plugin-Installation (Dockerfile.acapy-base-pqc)\\
% - Agent-Konfiguration \\
% - Umgebungsvariablen \\
% - Verifikation der Installation

%   - Plugin-Installation (Dockerfile.acapy-base-pqc, setup.py) \\
%   - Agent-Konfiguration (--plugin pqc\_didpeer4\_fm) \\
%   - Umgebungsvariablen (OQS\_DISABLE=0) \\
%   - Verifikation der Installation

\subsubsection{Pluginentwicklung: Kryptografie-Abstraktionsschicht}

Die Kryptografie-Abstraktionsschicht bildet die unterste Ebene der PQC-Integration und wird durch das Modul \texttt{liboqs\_wrapper.py} (Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_Kryptografie-Abstraktionsschicht}) realisiert. Dieses Modul kapselt die nativen Operationen der C-basierten liboqs-Bibliothek und stellt eine Python-API für die NIST-standardisierten PQC-Algorithmen ML-DSA-65 (Dilithium3, FIPS-204) und ML-KEM-768 (Kyber768, FIPS-203) bereit.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_Kryptografie-Abstraktionsschicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 \textbf{liboqs\_wrapper.py}.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Die Implementierung (Listing~\ref{lst:liboqs_wrapper.py}) definiert eine \texttt{LibOQSWrapper}-Klasse mit sechs Kern\-methoden: \texttt{generate\_ml\_dsa\_65\_keypair()} und \texttt{generate\_ml\_kem\_768\_keypair()} erzeugen kryptografische Schlüsselpaare, \texttt{sign\_ml\_dsa\_65()} und \texttt{verify\_ml\_dsa\_65()} implementieren digitale Signaturen, während \texttt{encapsulate\_ml\_kem\_768()} und \texttt{decapsulate\_ml\_kem\_768()} die Key Encapsulation für sichere Schlüsselvereinbarung realisieren.

Die Wrapper-Architektur abstrahiert die komplexen Foreign-Function-Interface-Aufrufe (FFI) an die liboqs-C-Bibliothek und stellt sicher, dass Schlüsselmaterial ausschließlich als Byte-Arrays (\texttt{bytes}) serialisiert wird - eine Voraussetzung für die Persistierung in der Aries-Askar-Wallet und die Kodierung in Multicodec-Formate. Das Singleton-Pattern (\texttt{get\_liboqs()}) gewährleistet eine einzige globale Instanz zur Vermeidung redundanter Initialisierungen. Diese Abstraktionsschicht ermöglicht es den höheren Modulen (DID-Generierung, DIDComm-Verschlüsselung), PQC-Operationen durchzuführen, ohne direkte Abhängigkeiten zur liboqs-C-API zu haben.

\subsubsection{Pluginentwicklung: DID-Verarbeitungsschicht}

Die DID-Verarbeitungsschicht (siehe Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_DID-Verarbeitungsschicht}) orchestriert die Erzeugung, Auflösung und Kodierung von PQC-fähigen did:peer:4-Identifikatoren sowie die DIDComm-Nachrichtenverschlüsselung. Diese Schicht umfasst sechs funktional gekoppelte Module, die gemeinsam eine standardkonforme Integration von Post-Quantum-Kryptografie in das did:peer:4-Ökosystem realisieren.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_DID-Verarbeitungsschicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 liboqs\_wrapper.py.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 \textbf{pqc\_didcomm\_v1.py}.
.4 \textbf{pqc\_multicodec.py}.
.4 \textbf{pqc\_multikey.py}.
.4 \textbf{pqc\_peer4\_creator.py}.
.4 \textbf{pqc\_peer4\_resolver.py}.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Das Modul \texttt{pqc\_peer4\_creator.py} (Listing~\ref{lst:pqc_peer4_creator.py}) implementiert die Funktion \texttt{create\_pqc\_peer4\_did()}, die aus zwei PQC-Schlüsselpaaren (ML-DSA-65 für \texttt{authentication}/\texttt{assertionMethod}, ML-KEM-768 für \texttt{keyAgreement}) einen did:peer:4-Long-Form-Identifier generiert. Die Schlüssel werden über die Wallet-API erzeugt, in Multikey-Format transformiert und als \texttt{KeySpec}-Objekte in einem did:peer:4-Input-Dokument strukturiert, wobei die Reihenfolge der Schlüssel deren Fragment-IDs determiniert (\texttt{\#key-0} für Signaturen, \texttt{\#key-1} für Verschlüsselung in \texttt{recipientKeys}). Das Gegenstück \texttt{pqc\_peer4\_resolver.py} (Listing~\ref{lst:pqc_peer4_resolver.py}) registriert einen DID-Resolver für die \texttt{peer}-Methode, der did:peer:4-Long-Form-DIDs in DID-Dokumente
  auflöst und dabei PQC-Multicodec-Präfixe korrekt dekodiert.

Die Multiformat-Kodierung wird durch drei Module realisiert: \texttt{pqc\_multicodec.py} (Listing~\ref{lst:pqc_multicodec.py}) definiert eine Multicodec-Registry mit provisorischen Präfixen gemäß W3C-Draft (ML-DSA-65: \texttt{0xd065}, ML-KEM-768: \texttt{0xe018}) und stellt Wrapper-Funktionen (\texttt{wrap\_pqc()}, \texttt{unwrap\_pqc()}) für Präfix-Operationen bereit. \texttt{pqc\_multikey.py} (Listing~\ref{lst:pqc_multikey.py}) transformiert Schlüsselinformationen in das Multikey-Format durch Verkettung von Multicodec-Präfix und Schlüsselmaterial sowie Base58-Kodierung mit Multibase-Präfix \texttt{z} (Base58btc), wodurch Multikeys wie \texttt{z6MNxxx...} (ML-DSA-65) oder \texttt{z6MK768xxx...} (ML-KEM-768) entstehen.

Das Modul \texttt{pqc\_didcomm\_v1.py} (Listing~\ref{lst:pqc_didcomm_v1.py}) erweitert die DIDComm-v1-Envelope-Verarbeitung um PQC-Unterstützung: \texttt{pack\_message\_pqc()} und \texttt{unpack\_message\_pqc()} detektieren automatisch anhand der Schlüssellänge (ML-KEM-768: 1184~Bytes $\approx$ 1615~Base58-Zeichen vs. X25519: 32~Bytes $\approx$ 44~Zeichen), ob PQC- oder klassische Kryptografie verwendet werden muss, und generieren JWE-Envelopes mit angepassten Algorithmus-Headern (\texttt{alg: "PQC-Authcrypt"} bzw. \texttt{"PQC-Anoncrypt"}). Die Content Encryption erfolgt weiterhin mit XChaCha20-Poly1305 (quantum-sicher für symmetrische Verschlüsselung), während der Content Encryption Key (CEK) mittels ML-KEM-768 Key Encapsulation für jeden Empfänger verschlüsselt wird - im Gegensatz zur klassischen ECDH-ES-basierten CEK-Vereinbarung. Diese Schicht ermöglicht eine hybride Betriebsweise, bei der PQC- und klassische Agenten koexistieren können, solange jeweils homogene Verschlüsselungsmodi verwendet werden.

\subsubsection{Pluginentwicklung: Integration-Patching-Schicht}

Die Integration-Patching-Schicht (siehe Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_Integration-Patching-Schicht}) implementiert die transparente Einbettung der PQC-Funktionalität in den ACA-Py-Kern durch gezieltes Monkey-Patching kritischer Funktionen und Erweiterung globaler Registries. Diese Schicht umfasst neun Module, die gemeinsam eine vollständig transparente PQC-Integration ohne Modifikation des ACA-Py-Quellcodes ermöglichen - existierende Workflows und API-Aufrufe bleiben unverändert funktionsfähig.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_Integration-Patching-Schicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 \textbf{askar\_pqc\_patch.py}.
.4 \textbf{base\_manager\_patch.py}.
.4 \textbf{connection\_target\_patch.py}.
.4 \textbf{key\_type\_patches.py}.
.4 \textbf{key\_types.py}.
.4 liboqs\_wrapper.py.
.4 \textbf{monkey\_patches.py}.
.4 \textbf{multicodec\_patch.py}.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 \textbf{validator\_patch.py}.
.4 \textbf{wallet\_patch.py}.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Das zentrale Orchestrierungsmodul \texttt{monkey\_patches.py} (Listing~\ref{lst:monkey_patches.py}) koordiniert die Installation aller Patches durch die Funktion \texttt{apply\_all\_patches()}, die beim Plugin-Setup aufgerufen wird. Dieses Modul überschreibt Methoden der Klasse \texttt{BaseConnectionManager} (z.\,B. \texttt{create\_did\_peer\_4()}, \texttt{\_extract\_key\_material\_in\_base58\_format()}, \texttt{long\_did\_peer\_4\_to\_short()}) und delegiert deren Implementierung an spezialisierte Patch-Module, wobei die ursprünglichen Methoden als Fallback-Referenzen gespeichert werden. Das Modul \texttt{base\_manager\_patch.py} (Listing~\ref{lst:base_manager_patch.py}) stellt die PQC-Implementierungen dieser \texttt{BaseConnectionManager}-Methoden bereit: \texttt{create\_did\_peer\_4\_pqc\_complete()} generiert did:peer:4-DIDs mit ML-DSA-65- und ML-KEM-768-Schlüsseln anstelle klassischer ED25519/X25519-Schlüssel, \texttt{\_extract\_key\_material\_in\_base58\_format\_pqc()} extrahiert PQC-Schlüsselmaterial aus DID-Dokumenten unter Berücksichtigung der größeren Schlüssellängen, und \texttt{record\_keys\_for\_resolvable\_did\_pqc()} persistiert beide PQC-Schlüssel (Signatur- und Verschlüsselungsschlüssel) in der Wallet-Datenbank.

Die Wallet-Integration erfolgt durch drei Module: \texttt{askar\_pqc\_patch.py} (Listing~\ref{lst:askar_pqc_patch.py}) patcht die Aries-Askar-Funktionen \texttt{create\_keypair()} zur Unterstützung von PQC-Schlüsselgenerierung mittels liboqs sowie \texttt{pack\_message()} und \texttt{unpack\_message()} zur Integration der PQC-DIDComm-v1-Implementierung aus \texttt{pqc\_didcomm\_v1.py}. \texttt{wallet\_patch.py} (Listing~\ref{lst:wallet_patch.py}) erweitert die Methode \texttt{get\_local\_did\_for\_verkey()} der \texttt{AskarWallet}-Klasse, um ML-KEM-768-Verkeys (1184~Bytes Länge) korrekt in der Datenbank zu lokalisieren – eine kritische Anpassung, da klassische Verkey-Lookups nur für 32-Byte-ED25519-Schlüssel ausgelegt sind. \texttt{connection\_target\_patch.py} (Listing~\ref{lst:connection_target_patch.py}) passt das Marshmallow-Schema der \texttt{ConnectionTarget}-Klasse an, indem die Validierungsregeln für \texttt{recipient\_keys} PQC-konforme Schlüssellängen akzeptieren (bisherige Validierung: exakt 44~Base58-Zeichen für ED25519).

Die Erweiterung der Schlüsseltyp-Infrastruktur erfolgt durch zwei Module: \texttt{key\_types.py} (Listing~\ref{lst:key_types.py}) definiert neue \texttt{KeyType}-Konstanten (\texttt{ML\_DSA\_65}, \texttt{ML\_KEM\_768}) mit Metadaten wie NIST-FIPS-Referenzen, Schlüssellängen und Multicodec-Präfixen. \texttt{key\_type\_patches.py} (Listing~\ref{lst:key_type_patches.py}) registriert diese KeyTypes in der globalen ACA-Py-Registry durch \texttt{register\_pqc\_key\_types()}, erweitert die Admin-API-Schemata (\texttt{patch\_api\_key\_type\_schemas()}) zur Akzeptanz von PQC-KeyType-Strings in JSON-Requests, und patcht Algorithmus-Mappings (\texttt{patch\_alg\_mappings\_for\_pqc()}) für JWS/JWE-Header-Generierung. \texttt{multicodec\_patch.py} (Listing~\ref{lst:multicodec_patch.py}) erweitert die globale \texttt{SupportedCodecs}-Enumeration durch dynamisches Hinzufügen von ML-DSA-65- und ML-KEM-768-Multicodec-Einträgen, sodass Multicodec-Dekodierungsfunktionen aus \texttt{multiformats}-Bibliotheken PQC-Präfixe verarbeiten können.

Das Modul \texttt{validator\_patch.py} (Listing~\ref{lst:validator_patch.py}) patcht die \texttt{JWSHeaderKid}-Validierungsklasse, die standardmäßig nur klassische DID-Formate (did:key, did:sov) in JWS-Header-\texttt{kid}-Feldern akzeptiert, um did:peer:4-Identifier zu unterstützen – eine Voraussetzung für ML-DSA-65-signierte DID-Exchange-AttachDecorators. Diese neun Module bilden gemeinsam eine Patch-Architektur, die durch sequenzielle Installation beim Plugin-Setup (orchestriert in \texttt{\_\_init\_\_.py}) eine vollständige PQC-Funktionalität in ACA-Py injiziert, ohne dass Änderungen an Controllern, Admin-API-Endpunkten oder externen Business-Logic-Schichten erforderlich sind.

% \paragraph{Deployment und Konfiguration}'
% - Plugin-Installation (Dockerfile.acapy-base-pqc) \\
% - Agent-Konfiguration \\
% - Umgebungsvariablen \\
% - Verifikation der Installation

%   - Umgebungsvariablen (OQS\_DISABLE=0) \\
%   - Verifikation der Installation

% Das Deployment des PQC-Plugins erfolgt über die Python-Package-Infrastruktur (siehe Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_Deployment}). Das Modul \texttt{setup.py} (Listing~\ref{lst:setup.py}) definiert das Plugin als installierbare Python-Distribution mit Entry-Point-Registration (\texttt{aries\_cloudagent.plugins = pqc\_didpeer4\_fm}), sodass ACA-Py das Plugin beim Start automatisch über setuptools-Discovery erkennt und die \texttt{setup()}-Funktion aus \texttt{\_\_init\_\_.py} aufruft. Die Plugin-Aktivierung erfolgt durch den Kommandozeilenparameter \texttt{--plugin pqc\_didpeer4\_fm} beim Agent-Start oder durch entsprechende Konfiguration in docker-compose.yml-Dateien. Das \texttt{README.md} (Listing~\ref{lst:README.md}) dokumentiert die Installation (\texttt{pip install -e .}), Konfigurationsparameter und den transparenten Integrationsmechanismus, der keine API-Änderungen erfordert - existierende Workflows wie \texttt{POST /out-of-band/create-invitation} mit Parameter \texttt{use\_did\_method: "did:peer:4"} erzeugen automatisch PQC-fähige DIDs anstelle klassischer ED25519-basierter Identifikatoren. Die Verifikation erfolgt über die Admin-API-Endpoint \texttt{GET /wallet/did}, die für PQC-DIDs erweiterte Metadaten (\texttt{pqc\_enabled: true}, \texttt{signature\_algorithm: "ml-dsa-65"}, \texttt{key\_agreement\_algorithm: "ml-kem-768"}) zurückgibt.

% \begin{figure}[H]
%   \flushleft
%   \caption{Verzeichnisstruktur des Projekts}
%   \label{fig:pqc_didpeer4_fm_directory_structure_Deployment}
% \dirtree{%
% .1 pqc\_didpeer4\_fm/.
% .2 pqc\_didpeer4\_fm/.
% .3 v1\_0/.
% .4 askar\_pqc\_patch.py.
% .4 base\_manager\_patch.py.
% .4 connection\_target\_patch.py.
% .4 key\_type\_patches.py.
% .4 key\_types.py.
% .4 liboqs\_wrapper.py.
% .4 monkey\_patches.py.
% .4 multicodec\_patch.py.
% .4 pqc\_didcomm\_v1.py.
% .4 pqc\_multicodec.py.
% .4 pqc\_multikey.py.
% .4 pqc\_peer4\_creator.py.
% .4 pqc\_peer4\_resolver.py.
% .4 validator\_patch.py.
% .4 wallet\_patch.py.
% .3 \_\_init\_\_.py.
% .2 \textbf{README.md}.
% .2 \textbf{setup.py}.
% }
% \begin{flushleft}
%     \textit{Anmerkung.} Eigene Darstellung.
% \end{flushleft}
% \end{figure}

% \textbf{Plugin-Installation}
%   - Weiterentwicklung vom Dockerfile.acapy-base zum Dockerfile.acapy-base-pqc + setup.py \\

\subsubsection{Dockerfile-Modifikation}

Für die Integration des Plugins wurde das ACA-Py Docker-Base-Image (Listing~\ref{lst:Dockerfile-acapy-base}) aus Iteration~1 Kapitel~\ref{SSI-Agenten} modifiziert. Die Baseline-Architektur von Iteration~1 verwendet einen 2-stufigen Build-Prozess (Poetry-Wheel-Building + Runtime-Installation) mit System-OpenSSL und unterstützt ausschließlich klassische Kryptografie (ED25519, X25519, RSA).

Iteration~2 (Listing~\ref{lst:Dockerfile-acapy-base-pqc}, siehe Abbildung~\ref{fig:Iteration2_Acapy_Multi_Stage_Build}) erweitert die Architektur auf einen 4-stufigen Multi-Stage-Build: Stage~1 kompiliert OpenSSL~3.5.4 mit FIPS-Modul und nativer ML-KEM/ML-DSA-Unterstützung, Stage~2 baut liboqs~0.14.0 als Shared Library, Stage~3 bleibt identisch zu Iteration~1 (Poetry-basiertes ACA-Py-Wheel), und Stage~4 integriert alle Artefakte durch \texttt{COPY --from}-Direktiven aus den Builder-Stages. Die Runtime-Stage überschreibt System-OpenSSL-Symlinks mittels \texttt{ln -sf}, aktualisiert Shared-Library-Pfade via \texttt{ldconfig}, importiert das PQC-Root-CA-Zertifikat in den System-Trust-Store (\texttt{update-ca-certificates}), und installiert das \texttt{pqc\_didpeer4\_fm}-Plugin mithilfe von pip direkt in das Container-Image.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Iteration2_Acapy_Multi_Stage Build.png}
    \caption{ACA-Py Multi-Stage Build Dockerfile mit PQC-Integration (Iteration 2)}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Iteration2_Acapy_Multi_Stage_Build}
\end{figure}

\subsubsection{Deployment in docker-compose.yml}

Das Deployment der PQC-fähigen SSI-Agenten erfolgt innerhalb der in Iteration 1 (Kapitel~\ref{Docker Orchestrierung der Gesamtarchitektur}) entwickelten docker-compose.yml-Orchestrierung, deren Evolution vom klassischen Setup (Iteration~1, Listing~\ref{lst:docker-compose.yml-SSI-Agenten}) zur PQC-Integration (Iteration~2, Listing~\ref{lst:docker-compose.yml-SSI-Agenten-mit-acapy-base-pqc-und-plugin}) zwei zentrale Anpassungen umfasst. Während die Iteration~1-Konfiguration noch das klassische ACA-Py-Base-Image ohne PQC-Unterstützung und Plugin-Aktivierung verwendet, wurde in Iteration~2 im Rahmen der ersten Anpassung die docker-compose.yml so modifiziert, dass alle drei Agent-Services (issuer, holder, verifier) das neue \texttt{acapy-base-pqc}-Image nutzen in welchem das \texttt{pqc\_didpeer4\_fm}-Plugin enthalten ist. Diese Änderung kann durch den Vergleich von \autoref{fig:Docker-Compose-Übersicht-Iteration-2} mit \autoref{fig:Docker-Compose-Übersicht-Iteration-1} nachvollzogen werden.

Die zweite Anpassung erweitert die \texttt{command}-Direktive aller drei Agenten um den Parameter \texttt{--plugin pqc\_didpeer4\_fm}, der beim Agent start das \texttt{pqc\_didpeer4\_fm}-Plugin lädt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{docker_compose_übersicht_pqc_plugin.png}
    \caption{Docker-Compose-Übersicht der Iteration 2 Architektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Docker-Compose-Übersicht-Iteration-2}
\end{figure}

\subsection{Formative Evaluation} \label{sec:formative_evaluation_iteration2}

\subsubsection{Validierung des Plugin-Ladevorgangs bei Agent-Start}
% - Issuer Agent Boot Log Iteration 1 vs Iteration 2 \\

% Listing~\ref{lst:Issuer-Agent-Boot-Logs} vs. Listing~\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}

Die erste formative Evaluationsmaßnahme bestand in der Validierung des korrekten Plugin-Ladevorgangs beim Start eines ACA-Py-Agenten. Dieser Test diente der Sicherstellung, dass die PQC-Integration transparent und ohne Beeinträchtigung der Standard-ACA-Py-Funktionalität erfolgt.

Listing~\ref{lst:Issuer-Agent-Boot-Logs} zeigt den Boot-Prozess eines Standard-ACA-Py-Agenten (Version 1.3.2) ohne PQC-Plugin. Nach der Registrierung der Default- und Askar-Plugins wird direkt mit der Ledger-Konfiguration und Wallet-Initialisierung fortgefahren.

Im Vergleich dazu zeigt Listing~\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin} den erweiterten Boot-Prozess mit geladenem \texttt{pqc\_didpeer4\_fm}-Plugin. Zwischen der Askar-Plugin-Registrierung und der Ledger-Konfiguration erfolgt nun die Plugin-Initialisierung mit mehreren charakteristischen Schritten:

\begin{enumerate}
\item \textbf{Askar-Patching:} Die \texttt{\_create\_keypair}-Funktion wird durch eine PQC-fähige Variante ersetzt, die ML-DSA-65 und ML-KEM-768 unterstützt. Zusätzlich werden \texttt{Session}-Methoden (\texttt{insert\_key}, \texttt{fetch\_key}, \texttt{update\_key}) und \texttt{AskarWallet.assign\_kid\_to\_key()} gepatcht.
\item \textbf{KeyType-Registry-Erweiterung:} Die neuen Schlüsseltypen \texttt{ml-dsa-65} und \texttt{ml-kem-768} werden in der ACA-Py KeyTypes-Registry registriert und die API-Schemas zur Laufzeit erweitert.
\item \textbf{did:peer:4-Erweiterung:} Die unterstützten Schlüsseltypen für did:peer:4 werden von \texttt{['ed25519', 'x25519']} auf \texttt{['ed25519', 'x25519', 'ml-dsa-65', 'ml-kem-768']} erweitert.
\item \textbf{Multicodec-Patching:} Die \texttt{SupportedCodecs}-Klasse wird für PQC-Multicodec-Präfixe erweitert (ML-DSA-65: \texttt{0xd065}, ML-KEM-768: \texttt{0xe018}).
\item \textbf{DIDComm-Patching:} \texttt{AskarWallet.pack\_message()} und \texttt{unpack\_message()} werden für ML-KEM-768-basierte Verschlüsselung angepasst. Die \texttt{AttachDecorator}-Klasse wird für ML-DSA-65-JWS-Signaturen erweitert.
\item \textbf{Monkey-Patches:} Die \texttt{BaseConnectionManager}-Methoden (\texttt{create\_did\_peer\_4}, \texttt{record\_keys\_for\_resolvable\_did}, etc.) werden durch PQC-fähige Varianten ersetzt.
\end{enumerate}



\subsubsection{Validierung der Pluginfunktionalität: Out-of-Band Invitation mit did:peer:4}

% did:peer:4 ==> /out-of-band/create-invitation
% - Admin-API Aufruf: \texttt{POST /out-of-band/create-invitation} mit Parameter \texttt{use\_did\_method: "did:peer:4"} \\

Die zweite formative Evaluationsmaßnahme validierte die Kernfunktionalität des Plugins: die transparente Erstellung von PQC-fähigen did:peer:4-DIDs während des Out-of-Band-Invitation-Prozesses.

Listing~\ref{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-vor-OOB-Invitation} zeigt die initiale Wallet-Abfrage eines frisch gestarteten Issuer-Agenten. Das leere \texttt{results}-Array bestätigt, dass noch keine DIDs im Wallet vorhanden sind.

\refstepcounter{manualListingCounter}
\label{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-vor-OOB-Invitation}
\begin{lstlisting}[language=bash, caption={Iteration 2 - Validierung der Pluginfunktionalität - Wallet DID Abfrage vor Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X GET https://host.docker.internal:8021/wallet/did | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    15  100    15    0     0   1083      0 --:--:-- --:--:-- --:--:--  1153
{
  "results": []
}
\end{lstlisting}

Anschließend wurde mittels \texttt{POST /out-of-band/create-invitation} mit dem Parameter \texttt{use\_did\_method: "did:peer:4"} eine Einladung erstellt (Listing~\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}). Die API-Response enthält eine vollständige did:peer:4-Langform-DID im \texttt{services}-Array der Invitation, erkennbar am charakteristischen Format \texttt{did:peer:4zQm...:z25g...}.

\refstepcounter{manualListingCounter}
\label{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}
\begin{lstlisting}[language=bash, caption={Iteration 2 - Validierung der Pluginfunktionalität - Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X POST https://host.docker.internal:8021/out-of-band/create-invitation     -H "Content-Type: application/json"     -d '{
      "handshake_protocols": ["https://didcomm.org/didexchange/1.1"],
      "use_did_method": "did:peer:4",
      "my_label": "Issuer Test"
    }' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 16198  100 16051  100   147  91160    834 --:--:-- --:--:-- --:--:-- 91514
{
  "state": "initial",
  "trace": false,
  "invi_msg_id": "89e9cc87-318f-49aa-a61a-fc805706cd8d",
  "oob_id": "70998122-5a5b-4020-8b5f-ae5884af20b3",
  "invitation": {
    "@type": "https://didcomm.org/out-of-band/1.1/invitation",
    "@id": "89e9cc87-318f-49aa-a61a-fc805706cd8d",
    "label": "Issuer Test",
    "handshake_protocols": [
      "https://didcomm.org/didexchange/1.1"
    ],
    "services": [
      "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc..."
    ]
  },
  "invitation_url": "https://host.docker.internal:8020?oob=eyJAdHlwZSI6ICJodHR..."
}
\end{lstlisting}

Die entscheidende Validierung erfolgt in Listing~\ref{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-nach-OOB-Invitation} durch eine erneute Wallet-Abfrage nach der Invitation-Erstellung. Die Response zeigt nun die automatisch generierte PQC-DID mit folgenden charakteristischen Merkmalen:

\begin{itemize}
\item \textbf{Dual-Key-Struktur:} Das \texttt{key\_type}-Feld weist den Wert \texttt{ml-dsa-65} auf, während die Metadata zusätzlich \texttt{kem\_verkey} (ML-KEM-768) enthält. Dies bestätigt die erfolgreiche Implementierung der Hybrid-Kryptografie mit getrennten Schlüsseln für digitale Signaturen und Schlüsselvereinbarung.
\item \textbf{PQC-Metadata:} Die Metadaten enthalten explizite Marker (\texttt{pqc\_enabled: true}, \texttt{signature\_algorithm: "ml-dsa-65"}, \texttt{key\_agreement\_algorithm: "ml-kem-768"}), die eine eindeutige Identifikation PQC-fähiger DIDs zur Laufzeit ermöglichen.
\item \textbf{Key Identifier:} Das \texttt{kem\_key\_kid}-Feld referenziert den KEM-Schlüssel über den DID-URL-Fragment-Identifier \texttt{\#key-1}, was der did:peer:4-Spezifikation entspricht, bei der Verification-Methods sequenziell nummeriert werden (\texttt{\#key-0} für Authentication, \texttt{\#key-1} für Key Agreement).
\end{itemize}

\refstepcounter{manualListingCounter}
\label{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-nach-OOB-Invitation}
\begin{lstlisting}[language=bash, caption={Iteration 2 - Validierung der Pluginfunktionalität - Wallet DID Abfrage nach Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X GET https://host.docker.internal:8021/wallet/did | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 17778  100 17778    0     0  1655k      0 --:--:-- --:--:-- --:--:-- 1736k
{
  "results": [
    {
      "did": "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc...",
      "verkey": "2BvJSsMeLjejWKygFBC1qFPLqUvvTzfed7y2Btp...",
      "posture": "wallet_only",
      "key_type": "ml-dsa-65",
      "method": "did:peer:4",
      "metadata": {
        "invitation_reuse": "true",
        "pqc_enabled": true,
        "signature_algorithm": "ml-dsa-65",
        "key_agreement_algorithm": "ml-kem-768",
        "kem_key_kid": "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc...D6SUGP43VJWg#key-1",
        "kem_verkey": "h6ngVfG9n2qF1SY5gM3DaDhK9iiwhvnW555QtodD1sgvEcg5...",
        "plugin": "pqc_didpeer4_fm",
        "version": "0.1.0"
      }
    }
  ]
}
\end{lstlisting}



% ==> /wallet/did um zu schauen was personalisiertes

% LOGS anzeigen lassen vom Webserver und vom Agenten selbst

    %    - Überprüfung der Plugin-Registrierung in Logs \\
    %    - Testaufruf einer gepatchten Funktion (z.\,B. DID-Erstellung)
%   → FF1: Blockchain-DID-Registry funktioniert? \\
%   → FF2: Alle PQC-Algorithmen korrekt integriert? \\
%   → FF3: Performance-Vergleich klassisch vs. PQC \\
%   → FF4: Algorithmus-Wechsel ohne Code-Änderung möglich? \\
%    \\
%      - Funktionalitätstests (UC1-UC7) \\
%      - Kryptografische Validierung (Signatur-Verifikation)

% https://dspace.bracu.ac.bd/xmlui/bitstream/handle/10361/25158/24141271,%2020101496,%202010360,%2020101053_CSE.pdf?sequence=1&isAllowed=y#cite.0@indyGithub

\subsection{Finales Artefakt}

Das finale Artefakt der zweiten Iteration repräsentiert einen funktionsfähigen SSI-Prototypen mit vollständiger Post-Quantum-Kryptografie-Integration auf Application-Layer-Ebene. Die Architektur vereint die in Iteration~1 etablierte Transport-Layer-Sicherung mittels PQC-Sidecar-Proxies mit einer tiefgreifenden Anwendungsschicht-Integration durch das entwickelte \texttt{pqc\_did\_peer4\_fm}-Plugin.

Die Kernkomponente bildet das ACA-Py-Plugin mit dreischichtiger Architektur. Die Kryptografie-Abstraktionsschicht kapselt native \texttt{liboqs}-Operationen und exponiert eine Python-API für ML-DSA-65 und ML-KEM-768. Die DID-Verarbeitungsschicht orchestriert Generierung, Auflösung und Kodierung PQC-fähiger \texttt{did:peer:4}-Identifikatoren. Die Integration-Patching-Schicht realisiert transparentes Monkey-Patching kritischer ACA-Py-Kernfunktionen ohne Modifikation des Framework-Quellcodes.

Hinsichtlich der in Kapitel~4.2.1 definierten Designziele erfüllt das finale Artefakt sämtliche Anforderungen. Das Designziel zu FF1 (Systemarchitektur \& Compliance) wird durch die native Unterstützung quantenresistenter Signaturen in den DID-Dokumenten adressiert, wodurch die Authentizität von Identitätsnachweisen unabhängig vom Transportkanal langfristig gegenüber Quantencomputer-Angriffen gewährleistet bleibt. Das Designziel zu FF2 (Algorithmenauswahl \& Sicherheitsbewertung) manifestiert sich in der erfolgreichen Integration von ML-DSA-65 für digitale Signaturen innerhalb der \texttt{did:peer:4}-Strukturen, was die praktische Machbarkeit von PQC-Signaturen in dezentralen Identifikatoren nachweist. Das Designziel zu FF3 (Kryptografische Agilität) wird durch die Erweiterung der Multicodec-Registry um provisorische Präfixe für ML-DSA-65 (\texttt{0xd065}) und ML-KEM-768 (\texttt{0xe018}) sowie die abstrahierte Kryptografie-Schicht realisiert, welche die Koexistenz klassischer und post-quanten Verfahren innerhalb der DID-Methoden ermöglicht.

Das Multi-Stage-Build-Dockerfile integriert alle Abhängigkeiten in ein kohärentes Container-Image: Stage~1 kompiliert OpenSSL~3.5.4 mit nativer ML-KEM/ML-DSA-Unterstützung, Stage~2 baut \texttt{liboqs}~0.14.0, Stage~3 generiert das ACA-Py-Wheel, und Stage~4 fusioniert alle Artefakte in ein produktionsfähiges Runtime-Image. Die formative Evaluation validierte die funktionale Korrektheit durch erfolgreiche Plugin-Registrierung beim Agent-Start sowie korrekte Generierung von \texttt{did:peer:4}-Long-Form-DIDs mit PQC-Schlüsselmaterial im Out-of-Band-Invitation-Workflow.












\newpage
\section{Summative Evaluation} \label{sec:Summative Evaluation}
        - Evaluationsmethodik (FEDS)


Im Rahmen der summativen Evaluation wurde das finale Artefakt aus \fixme{KAPITEL} mithilfe des in \ref{sec:Anhang_Summative Evaluation} dargestellten Jupyter Notebooks evaluiert.

KRITIS Szenario ...  Ziel der Evaluation ist die Validierung der funktionalen Anforderungen gemäß Kapitel~\ref{sec:Funktionale Anforderungen}.

- Erst Initialisierung des Artefakts durch:

==> \ref{sec:Anhang_Teil1-Setup-Verbindungstests}
    Variablendeklaration und Helper Funktionen ==> Listing~\ref{lst:Jupyter-Notebook-Cell-1}

    Infrastrukturcheck und Zeigen der Ledgerinitialisierung durch Abruf der Ledgertransaktionen (Validator-Node-Registrierung) ==> Listing~\ref{lst:Jupyter-Notebook-Cell-2-output}

==> \ref{sec:Anhang_Teil2-DID-Setup-Ledger-Registration-KRITIS-Identitäten}
    - ANlegen von Issuer DID lokal im acapy agent ==> Listing~\ref{lst:Jupyter-Notebook-Cell-3-output}
    - Registrieren als ENDORSER auf Ledger ==> Listing~\ref{lst:Jupyter-Notebook-Cell-4-output}
    - Walletansicht indy ed25519 posted mit true

\subsection{Validierung der funktionalen Anforderungen}

\subsubsection{Issuer Discovery}

Die funktionale Anforderung FR1 fordert, dass das System die Auffindbarkeit von publizierten Credential-Schemata des Issuers digitaler Identitätsnachweise ermöglichen muss. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines dreiphasigen, Ledger-basierten Discovery-Mechanismus demonstriert (Listing~\ref{lst:Jupyter-Notebook-Cell-8} und Listing~\ref{lst:Jupyter-Notebook-Cell-8-output}). 

Phase 1 extrahiert alle TRUST\_ANCHOR-Identitäten (Role \texttt{'101'}) aus NYM-Transaktionen des Domain Ledgers, wobei im KRITIS-Szenario der Issuer \enquote{Energienetzbetreiber} mit DID \texttt{9pbXiFBZZGwXKp61HQBz3J} identifiziert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-8-output}, Zeilen 7--17). 

Phase 2 verifiziert sechs kryptographische Eigenschaften (DID-Identifier, Ed25519-Verkey, TRUST\_ANCHOR-Role, Endorser, On-Ledger-Aktivitäten, Registrierungszeitpunkt) mittels der Funktion \texttt{verify\_issuer\_identity()}, wobei für den identifizierten Issuer alle Eigenschaften erfolgreich validiert werden (Listing~\ref{lst:Jupyter-Notebook-Cell-8-output}, Zeilen 24--29). 

Phase 3 filtert SCHEMA-Transaktionen nach dem Schema-Namen \texttt{kritis\_emergency\_maintenance\_cert}, extrahiert den Issuer-DID aus dem Schema-Identifier-Format \texttt{<issuer\_did>:2:<schema\_name>:<version>} und führt eine Cross-Referenzierung mit den TRUST\_ANCHOR-Identitäten durch (Listing~\ref{lst:Jupyter-Notebook-Cell-8-output}, Zeilen 39--60).


\subsubsection{Connection Creation}

Die funktionale Anforderung FR2 fordert, dass das System Verbindungen zwischen den Akteuren des SSI-Ökosystems etablieren muss. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines dreiphasigen Out-of-Band-Invitation-Protokolls mit did:peer:4-basierter Post-Quantum-Kryptographie demonstriert (Listing~\ref{lst:Jupyter-Notebook-Cell-9}, Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Listing~\ref{lst:Jupyter-Notebook-Cell-10} und Listing~\ref{lst:Jupyter-Notebook-Cell-10-output}).

Phase~1 implementiert einen Pre-Check existierender Connections via \texttt{GET /connections} auf beiden Agenten, um redundante Connection-Erstellungen zu vermeiden, wobei im KRITIS-Szenario keine existierenden Connections gefunden werden und eine neue Etablierung ausgelöst wird (Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Zeilen~5--10).

Phase~2 realisiert die Connection-Etablierung mittels Aries RFC~0434 Out-of-Band Protocol: Der Inviter erstellt eine Invitation mit \texttt{POST /out-of-band/create-invitation} unter Verwendung von \texttt{use\_did\_method: "did:peer:4"}, wobei die Response eine \texttt{invitation\_msg\_id} als eindeutigen Identifier enthält (Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Zeile~14). Der Invitee akzeptiert die Invitation via \texttt{POST /out-of-band/receive-invitation}, wodurch das DIDComm DIDExchange-Protokoll initiiert und did:peer:4-DIDs mit ML-DSA-65-Schlüsselmaterial generiert werden (Listing~\ref{lst:Jupyter-Notebook-Cell-12-output} zeigt die resultierenden DIDs mit Metadata \texttt{pqc\_enabled: true}, \texttt{signature\_algorithm: ml-dsa-65}, \texttt{key\_agreement\_algorithm: ml-kem-768}). Der Inviter identifiziert seine Connection anhand der \texttt{invitation\_msg\_id} durch Iteration über alle Connections, wobei die erfolgreiche Zuordnung mit übereinstimmender \texttt{invitation\_msg\_id} und State \texttt{active} validiert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Zeilen~23--27).

Phase~3 validiert den Connection-Status durch Abruf detaillierter Connection-Informationen via \texttt{GET /connections/\{conn\_id\}} auf beiden Seiten, wobei die Konsistenz durch Vergleich der \texttt{invitation\_msg\_id}, komplementäre \texttt{their\_role}-Werte (\texttt{inviter}/\texttt{invitee}) und beidseitigen State \texttt{active} verifiziert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-9-output}, Zeilen~31--45). Die Connection-Übersicht (Listing~\ref{lst:Jupyter-Notebook-Cell-11-output}) gruppiert Connections anhand der \texttt{invitation\_msg\_id} und zeigt zwei aktive Connection-Paare: Issuer<-->Holder (Connection~Group~1) und Holder<-->Verifier (Connection~Group~2), wodurch die vollständige Konnektivität des SSI-Dreiecks validiert wird.

\subsubsection{Credential Creation}

Die funktionale Anforderung FR3 fordert, dass das System Funktionalität zur Erstellung und Ausstellung digitaler Credentials bereitstellen muss. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines mehrstufigen Credential-Issuance-Workflows mit Revocation-Registry-Integration demonstriert (Listing~\ref{lst:Jupyter-Notebook-Cell-13}, Listing~\ref{lst:Jupyter-Notebook-Cell-13-output} und Listing~\ref{lst:Jupyter-Notebook-Cell-14-output}).

Der Issuer initiiert die Credential-Ausstellung durch Versenden eines Credential Offers via \texttt{POST /issue-credential-2.0/send-offer} mit einer Credential Preview, die neun KRITIS-spezifische Attribute enthält (Identität: \texttt{first\_name}, \texttt{name}, \texttt{organisation}; Berechtigung: \texttt{cert\_type}, \texttt{facility\_type}, \texttt{security\_clearance\_level}; Zeitgültigkeit: \texttt{epoch\_valid\_from}, \texttt{epoch\_valid\_until}; Rolle: \texttt{role}), wobei die Ausstellung über die in FR2 etablierte Connection (\texttt{connection\_id}) und die in FR1 identifizierte Credential Definition (\texttt{cred\_def\_id}) erfolgt (Listing~\ref{lst:Jupyter-Notebook-Cell-13}, Zeilen~8--31). Die Response enthält eine Exchange ID zur Nachverfolgung des Issuance-Prozesses, wobei der initiale State \texttt{offer-sent} den erfolgreichen Versand bestätigt (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeilen~3--5).

Der Holder akzeptiert das Credential Offer automatisch (\texttt{auto-store=true} Konfiguration), wodurch das Aries RFC~0453 Issue Credential v2.0 Protocol den vollständigen State-Machine-Durchlauf (\texttt{offer-sent} → \texttt{request-sent} → \texttt{credential-issued} → \texttt{done}) ausführt und das Credential im Holder Wallet persistiert. Nach einer Wartezeit von 5 Sekunden (Listing~\ref{lst:Jupyter-Notebook-Cell-13}, Zeile~55) zeigt der Status-Check auf Issuer-Seite den finalen State \texttt{done} (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeile~11), während der Holder-Wallet-Abruf via \texttt{GET /credentials} das gespeicherte Credential mit Referent \texttt{39ac5fc4-efc2-45eb-9a21-01c589757b65} und allen neun Attributen bestätigt (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeilen~14--22).

Die Revocation-Registry-Integration extrahiert zwei kritische Identifier aus der Issuer-Exchange-Response: Die Revocation Registry ID (\texttt{9pbXiFBZZGwXKp61HQBz3J:4:...:CL\_ACCUM:...}) identifiziert die auf dem Indy Ledger publizierte Revocation Registry (Type~113 REVOC\_REG\_DEF Transaction), während die Credential Revocation ID (\texttt{1}) die Position des Credentials im Revocation-Accumulator spezifiziert (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeilen~26--28). Diese IDs werden für den Revocation-Workflow (FR5) benötigt und demonstrieren die Integration von Credential Issuance und Revocation Management im Gesamtsystem.

Die Holder-Credentials-Übersicht (Listing~\ref{lst:Jupyter-Notebook-Cell-14-output}) zeigt das vollständig ausgestellte KRITIS-Notfall-Wartungszertifikat mit allen Attributen, dem Schema-Identifier \texttt{...kritis\_emergency\_maintenance\_cert:1.1} aus FR1, der Credential-Definition-ID aus dem Schema-basierten Discovery-Prozess und dem initialen Revoked-Status \texttt{False}, der die Gültigkeit des Credentials bestätigt (Zeilen~6--19). Der Issuer Credential Registry Check via \texttt{GET /issue-credential-2.0/records} validiert die serverseitige Persistierung des Exchange Records (Listing~\ref{lst:Jupyter-Notebook-Cell-13-output}, Zeilen~35--38), wobei die Verfügbarkeit des Records die Aktivierung des \texttt{--preserve-exchange-records}-Flags bestätigt, das für Audit-Zwecke und Revocation-Management in KRITIS-Kontexten erforderlich ist.

\subsubsection{Verification with Credentials}

Die funktionale Anforderung FR4 fordert, dass das System einen Verifikationsprozess zwischen Identity Holder, Verifier und Blockchain-basierter Verifiable Data Registry (VDR) durch Validierung eines Identitätsnachweises ermöglichen muss. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines vierstufigen Privacy-Preserving-Verification-Workflows mit Zero-Knowledge-Proofs, Revocation-Detection und Zeitgültigkeitsprüfung demonstriert (Listing~\ref{lst:Jupyter-Notebook-Cell-15} bis Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}).

Der Verifier initiiert den Verifikationsprozess durch Versenden eines Proof Requests via \texttt{POST /present-proof-2.0/send-request} mit einer Indy-Proof-Request-Struktur, die fünf offengelegte Attribute (\texttt{requested\_attributes}: \texttt{cert\_type}, \texttt{facility\_type}, \texttt{epoch\_valid\_from}, \texttt{epoch\_valid\_until}, \texttt{role}) und ein Zero-Knowledge-Predicate (\texttt{requested\_predicates}: \texttt{security\_clearance\_level >= 2}) fordert, während drei Identitätsattribute (\texttt{first\_name}, \texttt{name}, \texttt{organisation}) durch Selective Disclosure geschützt bleiben (Listing~\ref{lst:Jupyter-Notebook-Cell-15}, Zeilen~21--56). Alle Attribute und Predicates enthalten eine \texttt{non\_revoked}-Constraint mit Zeitintervall \texttt{\{from: 0, to: current\_timestamp\}}, die eine Ledger-basierte Echtzeit-Revocation-Prüfung gegen die Revocation Registry erzwingt (Zeilen~24, 30, 36, 42, 48, 54). Der initiale State \texttt{request-sent} bestätigt die erfolgreiche Übermittlung des Proof Requests über die in FR2 etablierte Connection (Listing~\ref{lst:Jupyter-Notebook-Cell-15-Output}, Zeilen~11--12).

Der Holder empfängt den Proof Request (State \texttt{request-received}) und ruft via \texttt{GET /present-proof-2.0/records/\{pres\_ex\_id\}/credentials} alle Credentials ab, die die Proof-Request-Anforderungen erfüllen, wobei die Schema-ID und Credential-Definition-ID aus FR1 und FR3 zur Filterung verwendet werden (Listing~\ref{lst:Jupyter-Notebook-Cell-16-Output}, Zeilen~4--19). Der Holder konstruiert ein \texttt{requested\_credentials}-Objekt durch Mapping der fünf Attribute-Referents (\texttt{attr1\_referent} bis \texttt{attr5\_referent}) und des Predicate-Referents (\texttt{pred1\_clearance}) auf die Credential-ID \texttt{39ac5fc4...}, wobei Attribute mit \texttt{revealed: true} gekennzeichnet werden, während das Predicate ohne Offenlegung des Attributwerts evaluiert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-17-Output}, Zeilen~6--11). Der Versand der Presentation via \texttt{POST .../send-presentation} erzeugt einen Zero-Knowledge-Proof, der kryptographisch beweist, dass der Holder ein Credential mit den geforderten Attributen und erfülltem Predicate besitzt, ohne die unrevealed Attribute offenzulegen (Zeilen~18--26).

Der Verifier empfängt die Presentation (State \texttt{done}, \texttt{verified: true}) und extrahiert die revealed Attributes durch dreistufiges Mapping: (1) Abruf der Attribute-Namen aus \texttt{by\_format.pres\_request.indy.requested\_attributes}, (2) Abruf der Attribut-Werte aus \texttt{by\_format.pres.indy.requested\_proof.revealed\_attrs}, (3) Konstruktion eines Name-Value-Mappings (Listing~\ref{lst:Jupyter-Notebook-Cell-18}, Zeilen~30--44), wodurch fünf offengelegte Attribute (\texttt{cert\_type: Notfall-Wartungsberechtigung}, \texttt{facility\_type: Umspannwerk Nord-Ost}, \texttt{epoch\_valid\_from: 1765026000}, \texttt{epoch\_valid\_until: 1765033200}, \texttt{role: Notfalltechniker}) extrahiert werden (Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}, Zeilen~5--9). Die drei Identitätsattribute bleiben durch Selective Disclosure geschützt und werden als \enquote{NICHT offengelegt (Zero-Knowledge-Proof)} ausgewiesen, wodurch Privacy by Design gemäß DSGVO Art.~25 realisiert wird (Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}, Zeilen~11--14).

Die Blockchain-basierte Revocation-Prüfung validiert den Credential-Status durch Vergleich des Indy-Proof-Timestamps mit dem Revocation-Registry-Delta auf dem Ledger, wobei State \texttt{done} und \texttt{verified: true} bestätigen, dass das Credential zum Verifikationszeitpunkt nicht revoked war (Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}, Zeile~18). Die Zeitgültigkeitsprüfung vergleicht einen aktuellen Epoch-Timestamp (Beispielwert \texttt{1765029600}) mit den extrahierten Zeitgrenzen (\texttt{epoch\_valid\_from: 1765026000}, \texttt{epoch\_valid\_until: 1765033200}), wobei die Bedingung \texttt{epoch\_valid\_from <= current\_epoch <= epoch\_valid\_until} die zeitliche Gültigkeit bestätigt (Zeilen~20--27). Die Zero-Knowledge-Predicate-Auswertung extrahiert das erfüllte Predicate \texttt{security\_clearance\_level >= 2} aus \texttt{requested\_proof.predicates}, wobei die exakte Clearance-Stufe (ob Ü2 oder Ü3) durch die ZKP-Eigenschaft verborgen bleibt (Zeilen~29--33).

Die finale Zugriffsentscheidung kombiniert drei Validierungsergebnisse in einer logischen UND-Verknüpfung (\texttt{not is\_revoked AND is\_time\_valid AND has\_required\_clearance}), die im demonstrierten KRITIS-Szenario zum Ergebnis \enquote{ZUGANG GEWÄHRT} führt, da alle Bedingungen erfüllt sind (Listing~\ref{lst:Jupyter-Notebook-Cell-18-Output}, Zeilen~36--42). Die Verifiable Data Registry (VDR)-Integration manifestiert sich durch drei Ledger-basierte Validierungsschritte: (1) Schema-Validation via Schema-ID aus FR1, (2) Credential-Definition-Validation via Cred-Def-ID, (3) Revocation-Registry-Validation via \texttt{non\_revoked}-Constraint, wodurch alle kryptographischen Artefakte (Schema, Cred-Def, RevReg-Def, RevReg-Delta) vom Hyperledger Indy Ledger abgerufen und validiert werden.

\subsubsection{Credential Revocation}

Die funktionale Anforderung zur Credential Revocation fordert, dass das System die Ungültigkeitserklärung ausgestellter Credentials ermöglichen muss, wobei Verifier die Gültigkeit kryptographisch überprüfen können. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines dreiphasigen Revocation-Workflows demonstriert: Registry-Management, Two-Phase-Revocation (Staging + Publishing) sowie Non-Revocation-Proof Verification.

Phase~1 implementiert die Verwaltung von Revocation Registries durch den Issuer. Listing~\ref{lst:Jupyter-Notebook-Cell-19} demonstriert den Abruf aktiver Revocation Registries via \texttt{GET /revocation/registries/created?state=active}. Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-19-output}) zeigt zwei aktive Registries mit jeweils 100 Credential-Kapazität. Jede Registry enthält kritische Metadaten: \texttt{rev\_reg\_id} (eindeutige Registry-Identifier), \texttt{tails\_hash} (kryptographischer Hash der Tails-File für Zero-Knowledge Non-Revocation-Proofs), \texttt{tails\_local\_path} (lokaler Speicherort der Tails-File) sowie \texttt{issuer\_did} (did:indy des Issuers). Die Tails-File ist essentiell für die kryptographische Accumulator-basierte Revocation-Prüfung nach dem CL-Signature-Schema und wird vom Holder benötigt, um Non-Revocation-Proofs zu generieren.

Phase~2 realisiert die Two-Phase-Revocation durch Staging und Ledger-Publishing. Listing~\ref{lst:Jupyter-Notebook-Cell-20} demonstriert die Staging-Phase via \texttt{POST /revocation/revoke} mit \texttt{publish: false}. Die Revocation-Request referenziert das Credential durch \texttt{rev\_reg\_id} (Registry-Identifier) und \texttt{cred\_rev\_id} (Credential-spezifische Revocation-ID, hier: \texttt{"1"}). Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-20-output}) bestätigt den Status \texttt{"Pending"} -- die Revocation ist lokal staged, jedoch noch nicht auf dem Ledger publiziert. Listing~\ref{lst:Jupyter-Notebook-Cell-21} führt die Publishing-Phase aus via \texttt{POST /revocation/publish-revocations}. Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-21-output}) zeigt die erfolgreiche Ledger-Transaktion: Typ \texttt{114 (REVOC\_REG\_ENTRY)}, Sequence Number \texttt{14}, mit kryptographischen Accumulator-Updates (\texttt{prevAccum}, \texttt{accum}) und der Liste revokierter Credential-IDs (\texttt{revoked: [1]}). Die Ledger-Transaktion ist durch ED25519-Signatur des Issuers authentifiziert und via Byzantine Fault Tolerance konsistent repliziert.

Phase~3 validiert die Revocation-Enforcement durch Proof-Verification. Listing~\ref{lst:Jupyter-Notebook-Cell-14-output-revocation} zeigt das Holder-Wallet nach Revocation mit \texttt{Revoked Status: True}. Listings~\ref{lst:Jupyter-Notebook-Cell-15-output-revocation} bis \ref{lst:Jupyter-Notebook-Cell-17-output-revocation} demonstrieren den Proof-Request- und Presentation-Workflow: Der Holder wählt das revokierte Credential aus (Auto-Select via \texttt{auto\_present: true}), versucht einen Non-Revocation-Proof zu generieren, jedoch schlägt die Proof-Generierung fehl, da der kryptographische Accumulator das Credential als revoked markiert. Listing~\ref{lst:Jupyter-Notebook-Cell-18-output-revocation} zeigt die finale Verifier-Entscheidung: \texttt{Verified: false}, \texttt{Credential ist REVOKED}, \texttt{ZUGANG VERWEIGERT}. Trotz zeitlicher Gültigkeit (Epoch-Check erfüllt: \texttt{1765026000 <= 1765029600 <= 1765033200}) und erfülltem ZKP-Predicate (\texttt{security\_clearance\_level >= 2}) wird der Zugang verweigert, da die Revocation-Prüfung fehlschlägt. Dies demonstriert die Enforcement-Priorität: Revocation-Status dominiert alle anderen Validierungskriterien und stellt sicher, dass kompromittierte Credentials sofort unwirksam werden -- eine kritische Sicherheitsanforderung für KRITIS-Infrastrukturen.

\subsubsection{Credential Deletion}

Die funktionale Anforderung zur Credential Deletion fordert, dass Holder die Möglichkeit besitzen müssen, Credentials lokal aus ihrem Wallet zu entfernen, wobei diese Operation ausschließlich die lokale Datenhaltung betrifft und vom Ledger-basierten Revocation-Mechanismus zu unterscheiden ist. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines dreiphasigen Deletion-Workflows demonstriert: Pre-Deletion Inventory, Credential Deletion sowie Post-Deletion Verification.

Phase~1 implementiert das Pre-Deletion Inventory durch Abruf aller im Holder-Wallet gespeicherten Credentials (Listing~\ref{lst:Jupyter-Notebook-Cell-22}, Zeilen~7--43). Via \texttt{GET /credentials} werden alle Credential-Metadaten abgerufen, wobei für jedes Credential der \texttt{referent} (eindeutige Wallet-Identifier), \texttt{schema\_id}, \texttt{cred\_def\_id} sowie der Revocation-Status via \texttt{GET /credential/revoked/\{referent\}} ermittelt wird. Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~1--19) zeigt ein Credential mit \texttt{Revoked: True} -- dieses Credential wurde zuvor via Ledger-Revocation ungültig erklärt (Cell~20--21), befindet sich jedoch weiterhin im lokalen Wallet. Die Auflistung aller Attribute (\texttt{security\_clearance\_level: 2}, \texttt{role: Notfalltechniker}, \texttt{facility\_type: Umspannwerk Nord-Ost}) demonstriert, dass revokierte Credentials im Wallet persistieren, bis der Holder sie explizit löscht. Die \texttt{referent}-Identifier werden in der Liste \texttt{credentials\_to\_delete} gespeichert (Zeile~34) für die nachfolgende Deletion-Phase.

Phase~2 realisiert die Credential Deletion durch iterative Deletion aller erfassten Credentials (Listing~\ref{lst:Jupyter-Notebook-Cell-22}, Zeilen~45--75). Für jeden \texttt{credential\_id} wird via \texttt{DELETE /credential/\{credential\_id\}} die lokale Wallet-Entfernung ausgeführt. Die \texttt{api\_delete()}-Hilfsfunktion behandelt HTTP~204~No~Content Responses korrekt (erfolgreiches Löschen ohne Response-Body). Das Output (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~21--30) zeigt die erfolgreiche Deletion: \texttt{Gelöscht: 1/1}, wobei die Deletion Summary die Erfolgsrate dokumentiert. Diese Phase demonstriert die Holder-Autonomie über lokale Wallet-Daten -- der Holder kann Credentials unilateral entfernen, ohne Issuer-Interaktion oder Ledger-Transaktion.

Phase~3 validiert die Deletion-Enforcement durch Post-Deletion Verification (Listing~\ref{lst:Jupyter-Notebook-Cell-22}, Zeilen~77--115). Ein erneuter Abruf via \texttt{GET /credentials} bestätigt das leere Wallet: \texttt{Holder Wallet ist jetzt LEER (alle Credentials gelöscht)} (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~32--36). Die explizite Unterscheidung zwischen lokaler Deletion und Ledger-Revocation wird durch Hinweise dokumentiert (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~38--43): \texttt{Credential ist LOKAL im Wallet gelöscht}, \texttt{Credential ist NICHT auf dem Ledger revoked}, \texttt{Issuer kann das Credential weiterhin sehen}. Diese Differenzierung ist kritisch für das Verständnis des SSI-Sicherheitsmodells: Lokale Deletion entfernt das Credential aus der Holder-Verfügungsgewalt (kein Proof mehr generierbar), jedoch bleibt die Ledger-basierte Revocation-Historie intakt (\texttt{--preserve-exchange-records} beim Issuer aktiv). Für KRITIS-konforme Audit-Trails bedeutet dies: Die Credential-Issuance-History ist unveränderlich auf dem Ledger gespeichert, während der Holder die Privacy-wahrende Möglichkeit besitzt, lokale Credential-Kopien zu entfernen.

%       - KRITIS-Szenarien (Energie, Gesundheit, Wasser)
% \subsection{Performance-Analyse}
%        - Latenz-Messungen (Baseline, PQC, Hybrid) \\
%        - Durchsatz-Analyse \\
%        - Speicher- und Rechenaufwand \\
%        - Skalierbarkeitstest



\subsection{Validierung der KRITIS-Compliance-Anforderungen}

\subsubsection{Einhaltung spezifischer Parameter-Sets für ML-DSA}

Die Compliance-Anforderung zur Einhaltung BSI-konformer ML-DSA Parameter-Sets (NIST Security Strength Category 3 oder 5) wird durch strategische Verwendung zweier Sicherheitsstufen erfüllt: ML-DSA-65 (Category 3) für operationale Signaturen sowie ML-DSA-87 (Category 5) für die Root Certificate Authority. Das finale Artefakt implementiert ML-DSA in drei Schichten: (1)~TLS~1.3 Server-Zertifikate für alle fünf Nginx Sidecar Proxies (hopE-Agenten: Issuer/Holder/Verifier, VON-Network Webserver, Tails Server) werden mittels ML-DSA-65 signiert, konfiguriert via Build-Argument (SIG\_ALG: mldsa65) in den Docker-Infrastruktur-Definitionen (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry}, Listing~\ref{lst:docker-compose.yml-SSI-Agenten}), wobei die Root CA als langfristiger Trust-Anchor mit der höheren Sicherheitsstufe ML-DSA-87 geschützt ist (Listing~\ref{lst:Zertifikatserstellungsworkflow}). (2)~did:peer:4 Signing Keys für dezentrale Agent-to-Agent Authentifizierung werden mit ML-DSA-65 generiert (Listing~\ref{lst:key_types.py}). (3)~DIDComm~v1 Authcrypt Message-Signierung nutzt ML-DSA-65 via LibOQS-Integration (Listing~\ref{lst:liboqs_wrapper.py}) für kryptographisch verifizierbare Sender-Authentifizierung in verschlüsselten Nachrichten.

Die erfolgreiche operationale Integration von ML-DSA-65 wird zum einen durch \autoref{fig:Successful-Validation-Issuer-TLS1.3} demonstriert, welches die TLS~1.3 Verbindung zum Issuer-Agenten mit ML-DSA-65 signiertem Server-Zertifikat validiert, und zum anderen durch die Wallet-Übersicht in Listing~\ref{lst:Jupyter-Notebook-Cell-12-output} demonstriert, in welcher alle drei SSI-Agenten key\_type: "ml-dsa-65" für did:peer:4 DIDs nutzen.

\subsubsection{Einhaltung spezifischer Parameter-Sets für ML-KEM}

Diese Anforderung wird durch systemweite Implementierung von ML-KEM-768 (Category 3) erfüllt. Das finale Artefakt implementiert ML-KEM-768 in zwei Schichten: (1)~TLS~1.3 Key Exchange für alle fünf Nginx Sidecar Proxies nutzt ML-KEM-768 konfiguriert via \texttt{DEFAULT\_GROUPS=X25519MLKEM768} in den Docker-Infrastruktur-Definitionen (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry}, Listing~\ref{lst:docker-compose.yml-SSI-Agenten}) sowie via \texttt{ssl\_ecdh\_curve X25519MLKEM768} in den Nginx-Konfigurationen (Listing~\ref{lst:nginx-pqc-konfiguration}). (2)~did:peer:4 Key Agreement für dezentrale Agent-to-Agent Verschlüsselung wird mit ML-KEM-768 realisiert (Listing~\ref{lst:key_types.py}), womit DIDComm-Nachrichten mittels Post-Quantum-resistenter Schlüsselkapselung verschlüsselt werden.

Die erfolgreiche operationale Integration von ML-KEM-768 wird zum einen durch \autoref{fig:Successful-Validation-Issuer-TLS1.3} demonstriert, welches die TLS~1.3 Verbindung zum Issuer-Agenten mit ML-DSA-65 signiertem Server-Zertifikat validiert, und zum anderen durch die Wallet-Übersicht in Listing~\ref{lst:Jupyter-Notebook-Cell-12-output} demonstriert, in welcher alle drei SSI-Agenten key\_type: "ml-dsa-65" für did:peer:4 DIDs nutzen.

\subsubsection{Implementierung hybrider Schlüsseleinigung}

Die BSI-Anforderung zur hybriden Schlüsseleinigung (Kombination klassisches Verfahren mit PQC-KEM) wird durch X25519+ML-KEM-768 Hybrid-Modus erfüllt. Das finale Artefakt implementiert hybride Schlüsseleinigung systemweit via \texttt{DEFAULT\_GROUPS=X25519MLKEM768:mlkem768:x25519} in allen Docker-Infrastruktur-Definitionen (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry}, Listing~\ref{lst:docker-compose.yml-SSI-Agenten}), wobei die Priorisierung X25519MLKEM768 als primären Hybrid-Modus sicherstellt. Die TLS~1.3 Verbindungen aller fünf Nginx Sidecar Proxies kombinieren elliptische Kurven-Kryptographie (X25519, klassisch) mit gitterbasiertem ML-KEM-768 (Post-Quantum) für Perfect Forward Secrecy, wobei OpenSSL~3.5.4 mit nativer PQC-Unterstützung die kryptographische Verknüpfung beider Shared Secrets via Key Derivation Function durchführt (Listing~\ref{lst:nginx-pqc-konfiguration}). Zusätzlich implementiert did:peer:4 hybride Key Agreement zwischen X25519- und ML-KEM-768-Keys aus DID Documents für DIDComm Message Encryption (Listing~\ref{lst:key_types.py}). Die Fallback-Strategie \texttt{mlkem768:x25519} gewährleistet Interoperabilität mit Peers ohne Hybrid-Unterstützung, wobei reine PQC-Verschlüsselung via ML-KEM-768 Vorrang vor klassischem X25519 hat. Diese Architektur entspricht BSI-TR-02102-1 Kapitel~2.2 und 2.4 zur Absicherung gegen kryptanalytische Durchbrüche sowohl im klassischen als auch im Quantum-Computing-Bereich.

\subsubsection{Bevorzugte Verwendung von TLS 1.3}
  
Die BSI-Empfehlung zur vorrangigen Verwendung von TLS~1.3 wird durch systemweite TLS~1.3-Enforcement erfüllt. Das finale Artefakt erzwingt TLS~1.3 in allen fünf Nginx Sidecar Proxies via \texttt{ssl\_protocols TLSv1.3;} in den Konfigurationsdateien (Listing~\ref{lst:nginx_holder.conf}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{summative_evaluation_TLS1.2_error.png}
    \caption{TLS 1.2 Verbindungsversuch zum Issuer-Agenten schlägt fehl (TLS 1.3 Enforcement)}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Summative_Evaluation_TLS1.2_Error}
\end{figure}

\autoref{fig:Summative_Evaluation_TLS1.2_Error} demonstriert das Fehlschlagen des TLS~1.2 Verbindungsversuchs zum Issuer-Agenten.

Für \gls{SzA}

\subsubsection{Protokollierung Sicherheitsrelevanter Ereignisse}

Das finale Artefakt implementiert Protokollierung auf drei Ebenen:

(1)~ACA-Py Agent-Level Logging protokolliert alle Authentifizierungsversuche (Connection Requests, Credential Issuance, Proof Presentations), Zustandsübergänge (State Machines für Issue-Credential/Present-Proof Protokolle) sowie Fehlerzustände via \texttt{--log-level info} in den Docker-Infrastruktur-Definitionen (Listing~\ref{lst:docker-compose.yml-SSI-Agenten}). Listing~\ref{lst:issuer-acapy-agent-logs} demonstriert das Logging sicherheitsrelevanter kryptographischer Events wie ML-DSA-65 Signature Verification, Schlüsselabruf via DID-Resolution und erfolgreiche/fehlgeschlagene DIDcomm-Decryption während des Credential-Issuance-Workflows.

(2)~Nginx Access \& Error Logs auf allen fünf Sidecar Proxies protokollieren TLS-Handshakes, HTTP-Requests sowie fehlgeschlagene Verbindungsversuche, persistiert in Docker Volumes \texttt{nginx-logs} (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~\ref{lst:docker-compose.yml-Revocation-Registry}). Listing~\ref{lst:issuer-nginx-logs} demonstriert das Logging der HTTP-Security-Events auf Proxy-Ebene, Connection-Authentifizierung, Request-Authentifizierung via User-Agent, sowie Request-Body-Buffering für PQC-Schlüsselmaterialien.

(3)~VON-Network Ledger Transaction Logs erfassen alle Blockchain-Operationen (NYM-Transaktionen für DID-Registrierung, SCHEMA/CRED\_DEF-Publikationen, REVOC\_REG\_ENTRY für Revocations) mit Zeitstempeln und Sequence Numbers für unveränderlichen Audit-Trail (demonstriert in Listing~\ref{lst:Jupyter-Notebook-Cell-4-output}, Listing~\ref{lst:Jupyter-Notebook-Cell-21-output}).

\subsubsection{Logische Netzsegmentierung}

Das finale Artefakt implementiert strikte Netzwerk-Segmentierung mittels dedizierter Docker Networks: 

(1)~hopE-Agenten nutzen isolierte Networks \texttt{hope-issuer}, \texttt{hope-holder}, \texttt{hope-verifier} pro Agent, wobei nur die zugehörigen Sidecar Proxies Zugriff haben (Listing~\ref{lst:docker-compose.yml-SSI-Agenten}). 

(2)~Shared Network \texttt{von\_sidecarproxy} verbindet ausschließlich die PQC Sidecar Proxies untereinander für Agent-to-Agent Kommunikation, während interne Agent-Container isoliert bleiben. 

(3)~VON-Network Blockchain-Nodes operieren im dedizierten \texttt{von} Network mit separatem \texttt{sidecarproxy} Network für Webserver-Zugriff (Listing~\ref{lst:docker-compose.yml-DLT-Infrastruktur}). 

(4)~Tails Server nutzt isoliertes \texttt{tails-server} Network mit kontrolliertem Zugang via \texttt{von\_sidecarproxy} (Listing~\ref{lst:docker-compose.yml-Revocation-Registry}). 

\autoref{fig:Docker-Compose-Übersicht-Iteration-1} und \autoref{fig:Darstellung-Network-Isolation} demonstrieren die logische Netzwerksegmentierung.

\subsubsection{Datenschutz durch Technikgestaltung (Privacy by Design)}
% Die Architektur realisiert dies durch den konsequenten Verzicht auf die Speicherung personenbezogener Daten (PII) auf dem unveränderlichen Ledger (Off-Chain-Architektur) und die Nutzung von Zero-Knowledge Proofs

Die DSGVO-Anforderung zu Privacy by Design (Art.~25) wird durch architektonische Trennung von öffentlichen Identifikatoren und personenbezogenen Daten erfüllt. Das finale Artefakt realisiert konsequente Off-Chain-Architektur: (1)~Personenbezogene Daten (PII) wie Name, Organisation, Sicherheitsfreigabe werden ausschließlich in verschlüsselten Verifiable Credentials gespeichert, die lokal im Holder-Wallet persistiert sind (demonstriert in Listing~\ref{lst:Jupyter-Notebook-Cell-14-output}), niemals auf dem unveränderlichen Blockchain-Ledger. (2)~Ledger-Transaktionen enthalten ausschließlich kryptographische Identifikatoren (Schema-IDs, Credential-Definition-IDs, Revocation-Registry-IDs) sowie Public Keys, jedoch keine personenbezogenen Attribute (Listing~\ref{lst:Jupyter-Notebook-Cell-4-output}, Listing~\ref{lst:Jupyter-Notebook-Cell-21-output}). (3)~Zero-Knowledge Proofs ermöglichen selektive Offenlegung: Der Verifier erhält nur explizit angeforderte Attribute (\texttt{revealed\_attrs}), während sensible Daten wie Vorname, Nachname, Organisation durch \texttt{unrevealed}-Status geschützt bleiben, sowie Predicate-basierte Proofs (\texttt{security\_clearance\_level >= 2}) ohne Offenlegung exakter Werte (Listing~\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}). Diese Architektur stellt Privacy by Default sicher, da personenbezogene Daten per Design dezentral beim Holder verbleiben und nur kryptographisch verifizierbare Proofs ausgetauscht werden, womit DSGVO Art.~25 Konformität erreicht wird.

\subsubsection{Grundsatz der Datenminimierung}
% Durch den Einsatz von \textit{Pairwise DIDs} (did:peer) für jede Interaktion statt einer globalen ID wird die Korrelierbarkeit von Daten minimiert und Profilbildung technisch unterbunden

Das finale Artefakt addressiert Datenminimierung in drei Dimensionen:

(1)~Pairwise did:peer:4 DIDs eliminieren globale Identifikatoren: Für jede Agent-to-Agent Connection wird eine dedizierte DID generiert (Listing~\ref{lst:Jupyter-Notebook-Cell-12-output} zeigt pro Agent 3--4 verschiedene did:peer:4 DIDs), wodurch Transaktionskorrelation über verschiedene Verifier hinweg technisch unterbunden wird -- ein kompromittierter Verifier kann keine Aktivitäten des Holders bei anderen Verifiern nachverfolgen. 

(2)~Selective Disclosure in Proof Presentations: Der Holder offenbart ausschließlich die vom Verifier angeforderten Attribute (\texttt{revealed\_attrs}: \texttt{cert\_type, facility\_type, epoch\_valid\_from/until, role}), während Identitätsdaten (\texttt{first\_name, name, organisation}) unrevealed bleiben (Listing~\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}, Zeilen~12--19), wodurch nur zweckgebundene Minimaldaten übermittelt werden. 

(3)~Predicate-basierte Zero-Knowledge Proofs reduzieren Datenoffenlegung weiter: Statt exakte Sicherheitsfreigabe-Stufe zu übermitteln, beweist der Holder kryptographisch \texttt{security\_clearance\_level >= 2} ohne Preisgabe, ob Stufe 2 oder 3 vorliegt (Listing~\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}, Zeilen~21--26). 

Diese mehrstufige Datenminimierung verhindert Profilbildung und unnötige Datensammlung, womit DSGVO-konforme Zweckbindung technisch durchgesetzt wird.

\subsubsection{Recht auf Löschung}
% Durch die strikte Trennung von öffentlichen Identifikatoren (Ledger) und privaten Daten (lokale Wallet) ist eine Löschung technisch vollständig realisierbar, indem die lokale Wallet und die zugehörigen kryptografischen Schlüssel vernichtet werden (Crypto-Shredding)

Die DSGVO-Anforderung zum Recht auf Löschung (Art.~17) wird durch strikte Trennung von Ledger-Identifikatoren und Wallet-Daten erfüllt. Das finale Artefakt realisiert vollständige Löschbarkeit personenbezogener Daten mittels Crypto-Shredding: (1)~Lokale Credential-Deletion entfernt Credentials aus dem Holder-Wallet via \texttt{DELETE /credential/\{credential\_id\}}, demonstriert in Listing~\ref{lst:Jupyter-Notebook-Cell-22}: Nach Deletion ist das Wallet leer (\texttt{Holder Wallet ist jetzt LEER}), womit alle personenbezogenen Attribute (Name, Organisation, Sicherheitsfreigabe) irreversibel gelöscht sind. (2)~Crypto-Shredding durch Wallet-Destruction: Da Credentials im Holder-Wallet mit dem Wallet-Key verschlüsselt persistiert sind (\texttt{holder\_wallet\_key}), führt die Vernichtung des Wallet-Keys zur kryptographischen Unlesbarkeit aller Credential-Daten, selbst wenn Backups existieren -- ohne Key ist Decryption unmöglich. (3)~Ledger-Immutabilität ohne Privacy-Verletzung: Während Blockchain-Transaktionen (Schema-IDs, Cred-Def-IDs, Revocation-Entries) unveränderlich auf dem Ledger verbleiben, enthalten diese per Design keine personenbezogenen Daten, sondern ausschließlich kryptographische Identifier, wodurch Art.~17 DSGVO erfüllt wird (Listing~\ref{lst:Jupyter-Notebook-Cell-22-output}, Zeilen~38--43: \texttt{Credential ist LOKAL im Wallet gelöscht, NICHT auf dem Ledger revoked}). Diese Architektur gewährleistet vollständige Löschung von PII bei gleichzeitiger Beibehaltung der Audit-Trail-Integrität für KRITIS-Compliance, womit die Balance zwischen DSGVO-Rechten und regulatorischen Anforderungen erreicht wird.

\subsection{Validierung der Kryptoagilität}

\subsubsection{Transportlayer}

Die Implementierung realisiert Kryptoagilität mithilfe der eingebauten Mechanismen in TLS 1.3, welche explizit entwickelt wurden, um eine modulare Austauschbarkeit kryptografischer Primitive zu gewährleisten. Im Gegensatz zu früheren Protokollversionen entkoppelt TLS 1.3 die Aushandlung von Cipher Suite, Schlüsselaustauschverfahren und Signaturalgorithmen vollständig voneinander. Diese Parameter werden orthogonal ausgehandelt, wodurch jeder Mechanismus unabhängig modifiziert werden kann \cite[S. 26]{rescorla_TransportLayerSecurityTLSProtocolVersion13_2018}.
Diese Trennung wird technisch durch die \texttt{supported\_groups}-Erweiterung realisiert, die es Endpunkten erlaubt, präferierte Schlüsselaustauschverfahren unabhängig vom symmetrischen Verschlüsselungsverfahren (AEAD) auszuhandeln \cite[S. 47]{rescorla_TransportLayerSecurityTLSProtocolVersion13_2018}.

Dieser Ansatz korrespondiert direkt mit den von \textcite[S. 102]{mehrez_CryptoAgilityProperties_2018} identifizierten Kryptoagilitätseigenschaften. Spezifisch adressiert die hier gewählte Architektur die Eigenschaft der \enquote{Extensibility}, die Fähigkeit, neue Algorithmen effizient hinzuzufügen, sowie die \enquote{Removability}, das elegante Außerbetriebnehmen veralteter Verfahren, ohne Gefährdung der Systemintegrität.

Die konkrete Umsetzung dieser Agilität in der vorliegenden Arbeit nutzt diese Protokollstruktur, um eine nahtlose Migration zu ermöglichen. Konkret wurde eine konfigurationsbasierte Algorithm-Fallback-Chain via \texttt{DEFAULT\_GROUPS=X25519MLKEM768:mlkem768:x25519:mlkem1024} (Listing~\ref{lst:Dockerfile-Sidecar-Proxy-nginx}) implementiert. Diese Konfiguration instruiert den TLS-Handshake, primär hybride Verfahren zu nutzen, bietet jedoch eine automatische Rückfalloption (Fallback) auf rein klassische Verfahren (\texttt{x25519}) im Falle einer Inkompatibilität. Damit erfüllt die Lösung die Anforderung der \enquote{Fungibility} nach \textcite[S. 102]{mehrez_CryptoAgilityProperties_2018}, die es Systemen erlaubt, Algorithmen auszutauschen. Ebenfalls wird die erste Eigenschaft nach \textcite[S. 19]{cyberresilienceworkshopseriescommittee_CryptographicAgilityInteroperabilityProceedingsWorkshop_2017} adressiert Algorithmen in Echtzeit basierend auf ihrer kombinierten Sicherheitsfunktion auszuwählen.

\autoref{fig:Summative_Evaluation_TLS1.3_Kryptoagilität} demonstriert den kryptoagilen Fallback-Prozess von X25519+ML-KEM-768 zu X25519 im TLS 1.3 Protokoll.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{summative_evaluation_TLS1.3_kryptoagilität.png}
    \caption{TLS 1.3 Kryptoagiler Fallback von X25519+ML-KEM-768 zu X25519}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Summative_Evaluation_TLS1.3_Kryptoagilität}
\end{figure}

\subsubsection{Applikationslayer}

Die Kryptoagilität des SSI-Systems auf Applikationsebene manifestiert sich in der Erfüllung der ersten und zweiten Anforderung von \textcite[S. 19--20]{cyberresilienceworkshopseriescommittee_CryptographicAgilityInteroperabilityProceedingsWorkshop_2017} Sicherheitsalgorithmen in Echtzeit auf Basis ihrer kombinierten Sicherheitsfunktionen auszuwählen, und die Möglichkeit zu eröffnen, neue kryptographische Funktionen bzw. Algorithmen in bestehende Hard- und Software zu integrieren.

Dafür nutzt das SSI-System die Plugin-Architektur von Aries Cloud Agent Python (ACA-Py), die es ermöglicht, bestehende kryptographische Workflows durch gezielte Eingriffe zu modifizieren, ohne den Kerncode der Agenten zu verändern. Dieses Designprinzip entspricht dem \enquote{Open/Closed Principle} der Softwareentwicklung, welches besagt, dass Softwaremodule offen für Erweiterungen, jedoch geschlossen für Modifikationen sein sollten \cite[S. 99]{martin_AgileSoftwareDevelopmentprinciplespatternspractices_2003}.

Dafür implementiert das Plugin einen metadatengesteuerten Ansatz zur Algorithmenauswahl. Wie in Listing~\ref{lst:Jupyter-Notebook-Cell-9-Demonstration-Kryptoagilität-ed25519} demonstriert, kann der gewünschte Schlüsseltyp durch Übergabe des Parameters \enquote{metadata: \{key\_type : ed25519\}} explizit spezifiziert werden.

Bei der Verarbeitung einer Out-of-Band (OOB) Invitation durchläuft das System folgenden Entscheidungsbaum: Der \enquote{OutOfBandManager} empfängt die Metadata-Parameter aus der API-Anfrage und propagiert diese an die DID-Erstellungslogik. In der Funktion \enquote{create\_did\_peer\_4\_conditional\_pqc} (Listing~\ref{lst:base_manager_patch.py}) erfolgt eine Auswertung des \enquote{key\_type}-Parameters. Wird der Wert \enquote{ed25519} erkannt, delegiert das Plugin die gesamte DID-Erstellung an die ursprüngliche ACA-Py-Implementierung (\enquote{\_original\_create\_did\_peer\_4}), wodurch ein vollständiger Fallback auf klassische Kryptographie ohne Plugin-Interferenz gewährleistet wird. Fehlt die Metadata-Spezifikation aktiviert das System standardmäßig die Post-Quantum-Kryptographie mit den Algorithmen ML-DSA-65 für digitale Signaturen und ML-KEM-768 für Schlüsselkapselung.

Die erfolgreiche Validierung dieser Kryptoagilität zeigt Listing~\ref{lst:Jupyter-Notebook-Cell-9-Demonstration-Kryptoagilität-ed25519-output}. Trotz aktiviertem Plugin etabliert sich eine vollständig ED25519-basierte Verbindung zwischen Issuer- und Holder-Agent. Die Verbindung erreicht den Status \enquote{active} auf beiden Seiten, was die korrekte Durchführung des DID Exchange-Protokolls mit klassischen Algorithmen bestätigt.

Listing~\ref{lst:Jupyter-Notebook-Cell-11-Demonstration-Kryptoagilität-ed25519-output} verifiziert die persistierte Kryptographie-Konfiguration auf Wallet-Ebene. Die Inspektion der gespeicherten DIDs zeigt konsistent den Wert \enquote{{key\_type}:{ed25519}}. Insbesondere die Abwesenheit von PQC-spezifischen Metadata-Markern wie \enquote{pqc\_enabled}, \enquote{signature\_algorithm} oder \enquote{kem\_verkey} in den DID-Metadaten bestätigt, dass das Plugin keinerlei modifizierende Eingriffe in den ED25519-Workflow vorgenommen hat.

% \newpage
% \section{Systemarchitektur und Design} \label{sec:Systemarchitektur und Design}