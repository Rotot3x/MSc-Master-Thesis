\newpage
\section{Methodik} \label{sec:Methodik}

\fixme{2,3333 Seiten BILDER/TABELLEN ==> kann erweitert werden}

\subsection{Systematische Literaturrecherche} \label{sec:Systematische Literaturrecherche}

Die systematische Literaturrecherche dieser Masterarbeit folgt ausgewählten Methoden der \ac{PRISMA} 2020 Richtlinien zur strukturierten Identifikation, Selektion, Bewertung und Synthese einschlägiger Studien, wodurch eine belastbare Grundlage für die Analyse der Forschungslücke und die Ableitung der Forschungsfragen geschaffen wird \parencite[S. 1]{page_PRISMA2020Statementupdatedguidelinereportingsystematicreviews_2021}. Dieses Vorgehen bietet einen strukturierten Ansatz zur Durchführung und Dokumentation von Literaturrecherchen, der die Qualität und Vollständigkeit der Berichterstattung verbessert und einen transparenten und reproduzierbaren Prozess gewährleistet \parencite[S. 1]{page_PRISMA2020Statementupdatedguidelinereportingsystematicreviews_2021}.

Die systematische Literaturrecherche wurde in zwei zeitlich getrennten Iterationen durchgeführt, um den dynamischen Charakter des Forschungsfeldes zu adressieren und die Aktualität der Wissensbasis sicherzustellen. Beide Iterationen sind ausführlich dokumentiert in \ref{sec:Anhang_Dokumentation_der_systematischen_Literaturrecherche} und dienen ausschließlich der Problemidentifikation, der Ergründung des Forschungsstands sowie der Ableitung der Forschungslücke und initialen Forschungsfragen.

Der konsolidierte Suchprozess in der Datenbank EBSCO führte über beide Phasen hinweg zur Identifikation von insgesamt 95 potenziellen Quellen. Davon entfielen 61 Publikationen auf die erste Iteration im Mai 2025 (siehe \autoref{fig:PRISMA_Flussdiagramm_iteration1}) und 34 Publikationen auf die zweite Iteration im November 2025 (siehe \autoref{fig:PRISMA_Flussdiagramm_Iteration2}). Die methodische Konsistenz wurde dabei durch die Anwendung identischer Suchstrategien und Selektionskriterien in beiden Zeiträumen sichergestellt.

Nach der Bereinigung von Duplikaten und der Anwendung der Ein- und Ausschlusskriterien verblieb ein fokussierter Bestand an hochrelevanten Studien. Eine detaillierte Übersicht der identifizierten Quellen findet sich in \autoref{tab:quellenuebersicht_Iteration1} für die erste und \autoref{tab:quellenuebersicht_iteration2} für die zweite Phase. Die vollständige Aufschlüsselung der Selektionsschritte sowie die zugehörigen Flussdiagramme sind zudem gesammelt in \ref{sec:Anhang_Dokumentation_der_systematischen_Literaturrecherche} aufgeführt.

\fixme{Anhangskapitel fixen ==> Transparente Dokumentation // Hat noch komische Texte}

\subsection{Design Science Research} \label{sec:Design Science Research}

\ac{DSR} bildet den methodischen Rahmen dieser Masterarbeit. \ac{DSR} stellt neben der verhaltenswissenschaftlichen Forschung ein eigenständiges Forschungsparadigma dar \parencite[S. 75]{hevner_DesignScienceInformationsystemsresearch_2004}. Während verhaltenswissenschaftliche Ansätze Theorien zur Erklärung oder Vorhersage entwickeln, fokussiert DSR auf die Erschaffung innovativer Artefakte zur Erweiterung menschlicher und organisatorischer Fähigkeiten \parencite[S. 75]{hevner_DesignScienceInformationsystemsresearch_2004}. Fundamental ist \ac{DSR} ein lösungsorientiertes Paradigma \parencite[S. 76]{hevner_DesignScienceInformationsystemsresearch_2004}, dessen Prinzip darin besteht, Wissen durch den Bau und die Anwendung eines Artefakts zu gewinnen \parencite[S. 82]{hevner_DesignScienceInformationsystemsresearch_2004}.

Das Information Systems Research Framework (\autoref{fig:hevner2004_framework}) nach \textcite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004} strukturiert den Forschungsprozess durch drei Hauptkomponenten.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{dsr_ISR_Framework.png}
    \caption{Information Systems Research Framework}
    \begin{flushleft}
    \textit{Anmerkung.} Aus \textcite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}.
    \end{flushleft}
    \label{fig:hevner2004_framework}
\end{figure}

Die \textbf{Environment}-Komponente definiert den Problemraum \parencite[S. 108]{simon_SciencesArtificial_1996} mit Menschen, Organisationen und Technologien sowie den Geschäftsanforderungen \parencite[S. 7--11]{silver_InformationTechnologyInteractionModelFoundationMBACoreCourse_1995}. Für diese Arbeit bilden kritische Infrastrukturen die Environment mit ihren Anforderungen an Post-Quantum-Sicherheit und selbstbestimmte Identitätsverwaltung. Die \textbf{IS Research}-Komponente umfasst Build/Evaluate-Aktivitäten für Artefakte \parencite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}. Hier erfolgt die Instanziierung und Evaluation eines PQC-fähigen SSI-Prototypen, der speziell für den Einsatz in kritischen Infrastrukturen konzipiert ist. Die \textbf{Knowledge Base} liefert Foundations (Theorien, Frameworks, Konstrukte) und Methodologies (Evaluationsmethoden) \parencite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}. Sie umfasst für diese Arbeit SSI-Standards, NIST-PQC-Algorithmen und KRITIS-Anforderungen. Rigor wird durch angemessene Anwendung dieser Wissensbasis erreicht \parencite[S. 80]{hevner_DesignScienceInformationsystemsresearch_2004}.

\subsubsection{Zyklen}

\textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007} identifiziert drei eng verbundene Aktivitätszyklen, die in jedem DSR-Projekt präsent sein müssen (\autoref{fig:3-cycle-model}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{3-cycle.png}
    \caption{Design Science Research Zyklen}
    \begin{flushleft}
    \textit{Anmerkung.} Aus \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007}.
    \end{flushleft}
    \label{fig:3-cycle-model}
\end{figure}

Der \textbf{Relevance Cycle} initiiert DSR mit Anforderungen aus der Anwendungsdomäne und fordert Field Testing des Outputs \parencite[S. 88-89]{hevner_ThreeCycleViewDesignScienceResearch_2007}. In dieser Arbeit manifestiert sich dies durch die iterative Identifikation von KRITIS-Anforderungen an an Sicherheit, Compliance und Kryptoagilität in zwei Implementierungszyklen. Dazu gehören quantenresistente Kommunikations- und Signaturverfahren, die Einhaltung relevanter Regulierungsvorgaben sowie die Wahrung von Datenschutz und technischer Resilienz. Die entwickelten Artefakte werden kontinuierlich in Laborumgebungen getestet, wobei Erkenntnisse aus der ersten Iteration die Designziele der zweiten Iteration prägen. Der \textbf{Rigor Cycle} verbindet DSR-Aktivitäten mit der Wissensbasis, um Innovation zu gewährleisten \parencite[S. 88-90]{hevner_ThreeCycleViewDesignScienceResearch_2007}. In dieser Arbeit wird dieser Zyklus durch die kontinuierliche Integration wissenschaftlicher Grundlagen etablierter SSI-Frameworks, NIST-standardisierter PQC-Algorithmen und KRITIS-Standards operationalisiert. Der \textbf{Design Cycle} strukturiert die Artefaktentwicklung als iterativen Prozess zwischen Konstruktion und Evaluation \parencite[S. 90--91]{hevner_ThreeCycleViewDesignScienceResearch_2007}. In dieser Arbeit erfolgt dies in zwei aufeinanderfolgenden Iterationen, wobei jede Iteration Feedback für die Designverbesserung liefert und die Erkenntnisse in die nächste Iteration einfließen.

\subsubsection{Artefakte}

\textcite[S. 255]{march_DesignNaturalScienceresearchinformationtechnology_1995} identifizieren vier Artefakttypen: Constructs, Models, Methods und Instantiations. \textbf{Constructs} stellen die Sprache bereit, in der Probleme und Lösungen definiert werden, und beeinflussen die Problemkonzeption \parencite[S. 78, 83]{hevner_DesignScienceInformationsystemsresearch_2004}. \textbf{Models} repräsentieren das Designproblem und den Lösungsraum, unterstützen das Problemverständnis und ermöglichen die Erkundung von Designentscheidungen \parencite[S. 78-79]{hevner_DesignScienceInformationsystemsresearch_2004}. \textbf{Methods} definieren Prozesse zur Problemlösung, von formalen Algorithmen bis zu Best-Practice-Beschreibungen \parencite[S. 79]{hevner_DesignScienceInformationsystemsresearch_2004}. \textbf{Instantiations} demonstrieren Machbarkeit durch Implementierung in einem funktionierenden System und liefern Beweis durch Konstruktion \parencite[S. 79, 84]{hevner_DesignScienceInformationsystemsresearch_2004}.

Diese Arbeit entwickelt eine \textit{Instantiation} in Form eines funktionsfähigen Prototypen eines blockchain-basierten SSI-Systems mit integrierter Post-Quantum-Kryptographie für KRITIS, welcher die technische Machbarkeit und praktische Anwendbarkeit des Ansatzes demonstriert.

\subsubsection{Richtlinien}

\textcite[S. 82]{hevner_DesignScienceInformationsystemsresearch_2004} formulieren sieben Richtlinien für \ac{DSR}, die jeweils in einer qualitätsvollen Forschungsarbeit adressiert werden sollten. Diese Richtlinien bilden einen strukturierten Rahmen zur Durchführung und Bewertung von Design-Science-Forschung und gewährleisten, dass sowohl wissenschaftliche Rigor als auch praktische Relevanz erreicht werden.

\textbf{Guideline 1: Design as an Artifact} - Design-Science-Forschung muss ein brauchbares Artefakt produzieren \parencite[S. 82]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit erfüllt dies durch eine funktionsfähige Instantiation eines blockchain-basierten SSI-Systems mit integrierter Post-Quantum-Kryptographie.

\textbf{Guideline 2: Problem Relevance} - Design-Science-Forschung zielt auf technologiebasierte Lösungen für relevante Geschäftsprobleme \parencite[S. 84--85]{hevner_DesignScienceInformationsystemsresearch_2004}. Die Relevanz ergibt sich aus der Quantenbedrohung für KRITIS-Kryptographie und dem Bedarf an datenschutzfreundlichen Identitätslösungen.

\textbf{Guideline 3: Design Evaluation} - Die Nützlichkeit und Wirksamkeit eines Design-Artefakts müssen rigoros demonstriert werden \parencite[S. 85]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit validiert Funktionalität, Compliance und Kryptoagilität.

\textbf{Guideline 4: Research Contributions} - \ac{DSR} muss klare Beiträge zu Design-Artefakt, Foundations oder Methodologies liefern \parencite[S. 87]{hevner_DesignScienceInformationsystemsresearch_2004}. Der Beitrag liegt in der neuartigen Integration von PQC in SSI-Systeme für KRITIS-Kontexte.

\textbf{Guideline 5: Research Rigor} - \ac{DSR} beruht auf rigoroser Anwendung von Methoden in Konstruktion und Evaluation \parencite[S. 87]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit nutzt etablierte Frameworks (Hyperledger Indy, ACA-Py, Aries), NIST-standardisierte PQC-Algorithmen und wissenschaftlich hergeleitete Konzepte der Kryptoagilität.

\textbf{Guideline 6: Design as a Search Process} - Die Suche nach einem effektiven Artefakt erfordert iterative Exploration unter Berücksichtigung der Problemumgebung \parencite[S. 87--88]{hevner_DesignScienceInformationsystemsresearch_2004}. Der Design Cycle dieser Arbeit manifestiert sich als iterativer Prozess, bei dem Erkenntnisse aus einer Iteration die Designziele der nachfolgenden Iteration prägen.

\textbf{Guideline 7: Communication of Research} - Design-Science-Forschung muss effektiv sowohl für technologie-orientierte als auch für management-orientierte Audiences präsentiert werden \parencite[S. 90]{hevner_DesignScienceInformationsystemsresearch_2004}. Diese Arbeit adressiert dies durch eine umfassende Dokumentation des entwickelten Prototypen, systematische Darstellung der Evaluationsergebnisse sowie die explizite Ableitung \fixme{praktischer Implikationen} für kritische Infrastrukturen.

\subsection{FEDS-Framework} \label{sec:FEDS-Framework}

Nach \textcite[S. 2]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} ist die Evaluation von Design-Artefakten eine Schlüsselaktivität des \ac{DSR}, ohne die die Forschung auf der Ebene theoretischer Annahmen über die Utility eines Artefakts verbleibt, ohne Evidenz für dessen tatsächliche Funktionsfähigkeit zu liefern. Um diese Lücke zu schließen und Rigor sicherzustellen, folgt diese Arbeit dem \ac{FEDS}-Framework nach \textcite[S. 2, 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}, welches den Evaluationsprozess in vier iterative Schritte unterteilt, um die Strategie passgenau auf die spezifischen Projektrisiken abzustimmen.

Das \ac{FEDS}-Framework unterscheidet dabei fundamental zwischen zwei Dimensionen der Evaluation: der funktionalen Absicht (Why to evaluate) und dem Paradigma (How to evaluate). Hinsichtlich der Absicht wird zwischen formativer Evaluation, die der kontinuierlichen Verbesserung während der Entwicklung dient, und summativer Evaluation, die eine abschließende Bewertung der Zielerreichung vornimmt, differenziert. Bezüglich des Paradigmas unterscheidet das Framework zwischen Artificial Evaluation, die in kontrollierten Laborumgebungen stattfindet, und Naturalistic Evaluation, welche die Artefakte in realen organisatorischen Umfeldern unter echten Bedingungen prüft \parencite[S. 2, 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Im Folgenden wird der vierstufige FEDS-Prozess für die vorliegende Arbeit erläutert.

\subsubsection{Schritt 1: Explikation der Evaluationsziele}
Der erste Schritt des Frameworks verlangt die Explikation der Evaluationsziele, um Konflikte zwischen konkurrierenden Anforderungen wie Rigor, Risikominimierung und Effizienz aufzulösen \parencite[S. 6--7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für die Entwicklung eines blockchain-basierten \ac{SSI}-Protypen mit \ac{PQC} im \ac{KRITIS}-Kontext ergeben sich hieraus spezifische Prioritäten:

\textbf{Rigour (Efficacy vs. Effectiveness):} Das primäre Ziel dieser Arbeit ist der Nachweis der \textit{Efficacy}. Dies bedeutet den rigorosen Beleg, dass das instanziierte Artefakt (die \ac{PQC}-Integration in SSI) den beobachteten Effekt (sichere, quantenresistente Identitätsverifikation) kausal verursacht und nicht externe Störfaktoren \parencite[S. 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Da es sich bei \ac{KRITIS}-Komponenten um sicherheitskritische Infrastruktur handelt, muss vor einem Feldtest (\enquote{Effectiveness} in realer Umgebung) zwingend die funktionale Korrektheit in einer kontrollierten Umgebung bewiesen werden, um \enquote{False Positives}, eine fälschliche Annahme der Sicherheit, auszuschließen \parencite[S. 3]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.
    
\textbf{Risikoreduktion (Technical Risk):} Das Hauptrisiko dieser Arbeit ist technischer Natur. Es besteht die Unsicherheit, ob die \ac{PQC}-Algorithmen (ML-DSA, ML-KEM) technisch in bestehende SSI-Frameworks (Hyperledger Aries) integriert werden können, ohne deren Kernfunktionen zu brechen. Soziale Risiken (z.B. Benutzerakzeptanz der Wallet-App) werden als nachrangig eingestuft und nicht evaluiert.
    
\textbf{Ausschluss von Effizienz-Zielen:} In Anlehnung an die Design-Science-Leitlinien wird explizit darauf hingewiesen, dass eine quantitative Performance-Evaluation (\enquote{Efficiency}) nicht Ziel dieser Arbeit ist. Die verwendeten \ac{PQC}-Referenzimplementierungen befinden sich in einem frühen Stadium, weshalb Laufzeitmessungen keine valide Aussagekraft für zukünftige produktive Systeme hätten.

\subsubsection{Schritt 2: Wahl der Evaluationsstrategie}
Basierend auf den identifizierten Zielen und Risiken wird für diese Arbeit die \textbf{Technical Risk \& Efficacy Strategy} gewählt, welche mit formativen, artifiziellen Tests beginnt und in einer summativen, artifiziellen Evaluation endet (\autoref{fig:feds_strategy}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{FEDS_eval_strat}
    \caption{Gewählte Evaluationsstrategie im FEDS-Framework}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung in Anlehnung an \textcite[S. 4]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.
    \end{flushleft}
    \label{fig:feds_strategy}
\end{figure}

Diese Strategie ist nach \textcite[S. 6]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} dann indiziert, wenn das primäre Entwicklungsrisiko technischer Natur ist und Evaluationen in realen Umgebungen aus Sicherheits- oder Kostengründen nicht durchführbar sind.
Ein naturalisitischer Ansatz (\enquote{Human Risk \& Effectiveness}) wird verworfen, da der Zugriff auf reale \ac{KRITIS}-Netzwerke für experimentelle kryptografische Prototypen ethisch und regulatorisch nicht vertretbar ist und die Technologie noch nicht den Reifegrad für Endanwendertests besitzt.

\subsubsection{Schritt 3: Bestimmung der zu evaluierenden Eigenschaften}
Der dritte Schritt definiert die konkreten Eigenschaften, die evaluiert werden sollen \parencite[S. 7--8]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für das entwickelte Artefakt leiten sich diese direkt aus den in Kapitel~\ref{sec:Anforderungsanalyse} definierten Anforderungen ab:

\begin{enumerate}
    \item \textbf{Fidelity (Funktionale Korrektheit):} Das System muss in der Lage sein, den vollständigen SSI-Lebenszyklus (Issuance, Verification, Revocation) unter Verwendung von PQC-Signaturen fehlerfrei durchzuführen. Es wird geprüft, ob die Artefakte (Agenten, Ledger, Wallet) spezifikationsgemäß interagieren.
    \item \textbf{KRITIS-Compliance (Sicherheit):} Es wird evaluiert, ob die implementierten Mechanismen den regulatorischen Vorgaben entsprechen. Dies umfasst die strikte Durchsetzung von TLS 1.3, die Verwendung hybrider Verfahren und die Netzwerksegmentierung.
    \item \textbf{Interoperabilität:} Die Fähigkeit des modifizierten Systems, Standard-\gls{DIDComm}-Nachrichten trotz der veränderten kryptografischen Payload zu verarbeiten, ist ein kritisches Kriterium für die Efficacy.
\end{enumerate}

\subsubsection{Schritt 4: Design der individuellen Evaluationsepisoden}
\label{sec:Schritt4-Design der individuellen Evaluationsepisoden}

Der vierte Schritt umfasst das Design konkreter Evaluationsepisoden \parencite[S. 8]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Für diese Arbeit wurden drei diskrete Episoden definiert, die parallel zu den Entwicklungszyklen verlaufen und in \autoref{tab:eval_episodes} dem jeweiligen Arbeitsfortschritt zugeordnet sind.

\begin{longtable}{L{1.5cm}L{5cm}L{8.5cm}}
    \caption{Evaluationsepisoden nach dem FEDS-Framework}
    \label{tab:eval_episodes} \\
    \toprule
    \textbf{Ep.} & \textbf{Phase \& Art (FEDS)} & \textbf{Fokus / Methode} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Ep.} & \textbf{Phase \& Art (FEDS)} & \textbf{Fokus / Methode} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung der Evaluationsstrategie in Anlehnung an das \ac{FEDS}-Framework von \textcite{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}.} \\
    \endlastfoot
    1 & 
    Iteration 1 (Kapitel~\ref{sec:formative_evaluation_iteration1}) \newline 
    \textit{Formativ, Artifiziell} &
    White-Box Tests und Log-Analyse der Transportverschlüsselung sowie der Infrastrukturkomponenten. \\
    \midrule
    2 & 
    Iteration 2 (Kapitel~\ref{sec:formative_evaluation_iteration2}) \newline
    \textit{Formativ, Artifiziell} &
    Integrationstests der Plugin-Architektur, \gls{DIDComm}-Verarbeitung und Validierung der PQC-Signaturen. \\
    \midrule
    3 & 
    Final (Kapitel~\ref{sec:Summative Evaluation}) \newline
    \textit{Summativ, Artifiziell} &
    Requirement Tracing und Validierung der \ac{KRITIS}-Compliance am integrierten Gesamtsystem. \\
\end{longtable}

\textbf{Episode 1 (Formativ):} Diese Episode erfolgt parallel zur ersten Iteration und fokussiert sich auf die Validierung der \textit{Transport-Layer-Security}. Da in dieser Phase fundamentale Infrastrukturkomponenten wie \glslink{Sidecar Proxy}{Sidecar Proxies} entwickelt werden, dient die formative Evaluation primär dazu, Designfehler so früh wie möglich zu identifizieren \parencite[S. 6, 7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016}. Methodisch erfolgt dies durch die Analyse von Handshake-Protokollen und Cipher-Suites.

\textbf{Episode 2 (Formativ):} In der zweiten Iteration verlagert sich der Fokus auf den \textit{Application-Layer}. Hier wird formativ geprüft, ob die entwickelten Python-Plugins korrekt in den ACA-Py-Core geladen werden und ob die erweiterte Kryptografiebibliothek (liboqs) korrekt angesprochen wird.

\textbf{Episode 3 (Summativ):} Die abschließende Evaluation in Kapitel~\ref{sec:Summative Evaluation} führt alle Komponenten zusammen. Sie dient dem rigorosen Nachweis, dass das Gesamtsystem die eingangs definierten Forschungsfragen beantwortet. Hierbei wird geprüft, ob die Efficacy des \ac{PQC}-\ac{SSI}-Prototypen für \ac{KRITIS}-Anwendungsfälle gegeben ist, ohne reale Risiken einzugehen.

\subsection{DSRM Prozessmodell} \label{DSRM Prozessmodell}

Zur Sicherstellung einer rigorosen methodischen Fundierung orientiert sich der Forschungsablauf dieser Arbeit am \ac{DSRM} Prozessmodell nach \textcite[S. 46]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}, welches einen Rahmen für die Durchführung und Präsentation von \ac{DSR} bereitstellt um die wissenschaftliche Validität von Design-Artefakten zu gewährleisten.

\fixme{Da die vorliegende Arbeit durch die spezifischen Bedrohungen des Quantencomputings für bestehende Infrastrukturen und die daraus resultierenden regulatorischen Anforderungen für \ac{KRITIS} motiviert ist} (Kapitel~\ref{sec:Problemstellung und Motivation}), folgt das Forschungsvorhaben einer \enquote{Problem-Centered Initiation}. Dies entspricht dem klassischen Einstieg in den \ac{DSRM}-Prozess über die erste Phase (\autoref{fig:peffers_dsrm}) \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.

Neben der \enquote{Objective-Centered Solution}, die durch einen Bedarf in der Industrie oder Forschung ausgelöst wird (Phase 2), definieren die Autoren eine \enquote{Design \& Development Centered Initiation} auf Basis existierender Artefakte für explizite Problembereiche (Phase 3), sowie eine \enquote{Client-/Context-Initiated Solution}, welche auf der Beobachtung einer praktischen Lösung basiert (Phase 4), als drei weitere Einstiegspunkte \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{DSRM Process Model_red.png}
    \caption{DSRM Process Model}
    \begin{flushleft}
    \textit{Anmerkung.} Adaptiert aus \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.
    \end{flushleft}
    \label{fig:peffers_dsrm}
\end{figure}

Die Operationalisierung der sechs Phasen des \ac{DSRM} beginnt mit der Phase \enquote{Problem Identification and Motivation} \parencite[S. 52--55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}. Die Definition des spezifischen Forschungsproblems und dessen Relevanz für kritische Infrastrukturen wurde hierfür in Kapitel~\ref{sec:Problemstellung und Motivation} dargelegt. 

Darauf aufbauend werden in der Phase \enquote{Define the Objectives for a Solution} \parencite[S. 55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} aus der Problemanalyse konkrete Forschungsfragen (Kapitel~\ref{sec:Zielsetzung und Forschungsfragen}) und designrelevante Ziele für jede Iteration (Kapitel~\ref{sec:Designziele_Iteration_1} und Kapitel~\ref{sec:Designziele_Iteration_2}) abgeleitet, welche als Grundlage für die späteren Evaluationsphasen dienen.

Den Kern der Arbeit bildet die Phase \enquote{Design and Development} \parencite[S. 55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}, welche die Konzeption der Architektur sowie die technische Implementierung des \ac{PQC}-\ac{SSI}-Prototypen in beiden Iterationen umfasst (Kapitel~\ref{sec:Iterative Artefaktentwicklung}). Diese Phase operationalisiert die systematische Umsetzung der in den vorherigen Phasen definierten Anforderungen in ein funktionsfähiges Artefakt.

Die Eignung dieses Artefakts zur Problemlösung wird im Rahmen der Phase \enquote{Demonstration} \parencite[S. 55]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007} validiert. Diese erfolgt durch formative Evaluationsepisoden während der beiden Iterationen, welche schrittweise die Funktionsfähigkeit des Artefakts durch modulare Tests unter kontrollierten Bedingungen (Kapitel~\ref{sec:formative_evaluation_iteration1} und \ref{sec:formative_evaluation_iteration2}), bis hin zum vollständigen Prototypen (Kapitel~\ref{sec:Summative Evaluation}) nachweisen. 

Daran anschließend wird in der Phase \enquote{Evaluation} \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}strukturiert nach dem \ac{FEDS}-Framework (Kapitel~\ref{sec:FEDS-Framework}) in mehreren diskrete Evaluationsepisoden eine systematische Bewertung des Artefakts vorgenommen. Formative Episoden während beider Iterationen (Kapitel~\ref{sec:formative_evaluation_iteration1} und \ref{sec:formative_evaluation_iteration2}) adressieren technische Einzelfunktionen und Designfehler frühzeitig, die abschließende summative Evaluation in Kapitel~\ref{sec:Summative Evaluation} validiert systematisch die funktionale Korrektheit, \ac{KRITIS}-Compliance und Kryptoagilität des integrierten Gesamtsystems.

Den Abschluss bildet die Phase \enquote{Communication} \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}, in der die Ergebnisse, der Designprozess und die Evaluation durch die vorliegende schriftliche Ausarbeitung dokumentiert und der wissenschaftlichen Gemeinschaft zur Verfügung gestellt werden.

Obwohl das Modell sequenziell dargestellt ist, handelt es sich bei der Entwicklung in Kapitel~\ref{sec:Iterative Artefaktentwicklung} um einen iterativen Prozess, der Rücksprünge von der Evaluation zur Design-Phase erlaubt, um das Artefakt schrittweise zu verfeinern \parencite[S. 56]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}.

\newpage
\section{Erste Iteration der Artefaktentwicklung}
\label{sec:Erste Iteration der Artefaktentwicklung}

\subsection{Designziele dieser Iteration} \label{sec:Designziele_Iteration_1}

Die Designziele dieser Iteration leiten sich unmittelbar aus den in Kapitel~\ref{sec:Zielsetzung und Forschungsfragen} definierten Forschungsfragen ab und werden operationalisiert durch eine schichtenbasierte Architektur, die die Quantensicherheit auf der Transportebene verankert. 

Im Fokus von FF1 (Systemarchitektur \& Compliance) steht die Etablierung einer modularen Architektur mit klarer Separation zwischen SSI-Agenten, DLT-Infrastruktur und quantensicherer Transportschicht auf Basis ausgewählter Frameworks und Technologien. Das Design soll die Kernherausforderung, Post-Quantum-Kryptografie nicht-invasiv und modular zu integrieren, adressieren.

Bezüglich FF2 (Algorithmenauswahl und Sicherheitsbewertung) liegt das Designziel auf der Erprobung quantenresistenter kryptografischer Primitive für die Transportebene auf Basis standardisierter Algorithmen und hybrider Schlüsselaustauschverfahren. Die formative Evaluierung soll dabei die technische Machbarkeit dieser Algorithmen in der Infrastruktur validieren und Erkenntnisse für die nachgelagerte Iteration generieren.

Für FF3 (Kryptografische Agilität) zielt diese Iteration auf die architektonische Vorbereitung für Austauschbarkeit kryptografischer Algorithmen ab. Das Design soll durch modulare Infrastrukturkomponenten die Voraussetzungen für zukünftige Algorithmenupdates ohne grundlegende Systemumgestaltung schaffen.

\subsection{Anforderungsanalyse} \label{sec:Anforderungsanalyse}

\subsubsection{Funktionale Anforderungen} \label{sec:Funktionale Anforderungen}

Basierend auf der Analyse von \textcite[S. 130]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021} lassen sich für das SSI-System sechs zentrale funktionale Anforderungen identifizieren, die den den vollständigen Lebenszyklus digitaler Identitätsnachweise ab decken (\autoref{tab:functional_requirements}).

\begin{longtable}{L{1cm}L{4cm}L{9cm}}
    \caption{Funktionale Anforderungen an SSI-Systeme}
    \label{tab:functional_requirements} \\
    \toprule
    \textbf{Nr.} & \textbf{Funktionale Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Nr.} & \textbf{Funktionale Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung auf Basis der Auflistungen und des Sequenzdiagramms in Anlehnung an \textcite[S. 130-132]{nokhbehzaeem_BlockchainBasedSelfSovereignIdentitySurveyRequirementsUseCasesComparativeStudy_2021}.} \\
    \endlastfoot
    FR1 & Issuer Discovery &
    Das System muss die Auffindbarkeit von publizierten Credential Schemata des Issuers digitaler Identitätsnachweise ermöglichen. \\
    \midrule
    FR2 & Connection Creation &
    Das System muss Verbindungen zwischen den Akteuren des SSI-Ökosystems etablieren können. \\
    \midrule
    FR3 & Credential Creation &
    Das System muss Funktionalität zur Erstellung und Ausstellung digitaler Credentials bereitstellen. \\
    \midrule
    FR4 & Verification with Credentials &
    Das System muss einen Verifikationsprozess zwischen Identity Holder, Verifier und Blockchain-basierter \ac{VDR} durch Validierung eines Identitätsnachweises ermöglichen. \\
    \midrule
    FR5 & Credential Revocation &
    Das System muss die Funktionalität zum Widerruf von Credentials unterstützen. \\
    \midrule
    FR6 & Credential Deletion &
    Das System muss die Funktionalität zur Löschung von Credentials unterstützen. \\
\end{longtable}

\subsubsection{KRITIS-spezifische Compliance-Anforderungen} \label{sec:KRITIS-spezifische Compliance-Anforderungen}

Die in \autoref{tab:compliance_requirements} konsolidierten Anforderungen definieren den normativen Rahmen für die Gestaltung und Evaluierung des \ac{PQC}-\ac{SSI}-Prototypen im Kontext KRITIS.

Im Bereich der \textbf{kryptografischen Verfahren} (Nr. 1-4) basieren die Vorgaben primär auf den Technischen Richtlinien des BSI. Für die Migration auf Post-Quantum-Kryptografie ist insbesondere die Wahl spezifischer Parameter-Sets für ML-DSA (NIST Level 3/5) und ML-KEM (Level 3/5) sowie die zwingende Implementierung hybrider Schlüsseleinigung vorgeschrieben, um sowohl Integrität als auch langfristige Vertraulichkeit gegen Quantencomputer-Angriffe zu gewährleisten \parencite[Kap. 2.2, 2.4, 5.3.4.2]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. Ergänzend fordert die TR-02102-2 den Einsatz moderner Transportverschlüsselung via TLS 1.3, um durch Perfect Forward Secrecy (PFS) die Kommunikationskanäle abzusichern \parencite[Kap. 3.2]{bsi_TechnischeRichtlinieTR021022KryptographischeVerfahrenEmpfehlungenundSchlussellangenTeil2VerwendungTransport_2025}.

Hinsichtlich der \textbf{Betriebssicherheit} (Nr. 5-6) leiten sich die Anforderungen direkt aus dem IT-Sicherheitsgesetz 2.0 (BSIG) und internationalen Standards ab. Essenziell für KRITIS-Betreiber ist hierbei die Implementierung effektiver \gls{SzA} durch umfassende Protokollierung sicherheitsrelevanter Ereignisse gemäß § 8a BSIG \parencite[Nr. 101, 103]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024}. Flankierend schreibt die ISO/IEC 27001 eine strikte logische Netzsegmentierung vor, um die Ausbreitung potenzieller Sicherheitsvorfälle innerhalb der Infrastruktur zu begrenzen \parencite[Control A.8.22]{iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022}.

Die dritte Säule bildet der \textbf{Datenschutz} (Nr. 7-9) auf Basis der DSGVO. Hierbei stehen Prinzipien wie \textit{Privacy by Design} gemäß Art. 25 und Datenminimierung nach Art. 5 im Fokus. Zudem muss das Recht auf Löschung nach Art. 17 durch geeignete Architekturmuster, etwa die Trennung von Identifikatoren und Inhaltsdaten, technisch gewährleistet werden \parencite[Art. 5, 17, 25]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}.

\begin{longtable}{L{1cm}L{4cm}L{9cm}}
    \caption{Compliance Anforderungen an SSI-Systeme im KRITIS-Kontext}
    \label{tab:compliance_requirements} \\
    \toprule
    \textbf{Nr.} & \textbf{Compliance Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endfirsthead
    \multicolumn{3}{l}{\textit{Tabelle \thetable\ (Fortsetzung)}} \\
    \toprule
    \textbf{Nr.} & \textbf{Compliance Anforderung} & \textbf{Beschreibung} \\
    \midrule
    \endhead
    \midrule
    \multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
    \endfoot
    \bottomrule
    \multicolumn{3}{p{\linewidth}}{\textit{Anmerkung.} Eigene Darstellung auf Basis von \textcite{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025,bsi_TechnischeRichtlinieTR021022KryptographischeVerfahrenEmpfehlungenundSchlussellangenTeil2VerwendungTransport_2025,bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024,iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022,daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}.} \\
    \endlastfoot
    CR1 & Einhaltung spezifischer Parameter-Sets für ML-DSA &
    Zur Gewährleistung der vom BSI geforderten Sicherheitsniveaus dürfen für das Verfahren ML-DSA ausschließlich die Parameter-Sets verwendet werden, die den NIST Security Strength Categories 3 oder 5 entsprechen. Konkret sind dies ML-DSA-65 oder ML-DSA-87 \parencite[Kap. 5.3.4.2]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025} \\
    \midrule
    CR2 & Einhaltung spezifischer Parameter-Sets für ML-KEM &
    Für den langfristigen Schutz vertraulicher Informationen mittels des gitterbasierten Schlüsselkapselungsverfahrens ML-KEM dürfen gemäß BSI-Einschätzung ausschließlich Parametersätze verwendet werden, die den NIST Security Strength Categories 3 oder 5 entsprechen. Zulässig sind demnach ML-KEM-768 sowie ML-KEM-1024 \parencite[Kap. 2.4.3]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. \\
    \midrule
    CR3 & Implementierung hybrider Schlüsseleinigung &
    Um langfristige Vertraulichkeit (Schutz vor \textit{Store Now, Decrypt Later}) zu gewährleisten, muss für die Schlüsseleinigung zwingend ein hybrides Verfahren implementiert werden, das ein anerkanntes klassisches Verfahren mit einem empfohlenen PQC-KEM kombiniert \parencite[Kap. 2.2, 2.4]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. \\
    \midrule
    CR4 & Bevorzugte Verwendung von TLS 1.3 &
    Für die Absicherung der Transportebene wird gemäß \textcite[Kap. 3.2]{bsi_TechnischeRichtlinieTR021022KryptographischeVerfahrenEmpfehlungenundSchlussellangenTeil2VerwendungTransport_2025} vorrangig das Protokoll TLS 1.3 empfohlen, da es PFS erzwingt und auf unsichere Cipher-Suites verzichtet. \\
    \midrule
    CR5 & Protokollierung sicherheitsrelevanter Ereignisse &
    Sicherheitsrelevante Ereignisse müssen auf System- und Netzebene zentral protokolliert werden, um eine zeitnahe Erkennung von Angriffen zu ermöglichen \parencite[Nr. 101, 103]{bsi_KonkretisierungKRITISAnforderungen8aAbsatz1undAbsatz1aBSIG_2024}. \\
    \midrule
    CR6 & Logische Netzsegmentierung &
    Gruppen von Informationsdiensten, Benutzern und Informationssystemen sollten in den Netzwerken der Organisation getrennt werden \parencite[Control A.8.22]{iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022}. \\
    \midrule
    CR7 & Datenschutz durch Technikgestaltung (Privacy by Design) &
    Gemäß \textcite[Art. 25]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016} sind bereits bei der Entwicklung des Systems geeignete technische Maßnahmen zu treffen, die die Datenschutzgrundsätze addressieren. \\
    \midrule
    CR8 & Grundsatz der Datenminimierung &
    Personenbezogene Daten müssen dem Zweck angemessen und auf das notwendige Maß beschränkt sein. \parencite[Art. 5]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}. \\
    \midrule
    CR9 & Recht auf Löschung &
    Die betroffene Person hat das Recht, von dem Verantwortlichen die unverzügliche Löschung sie betreffender personenbezogener Daten zu verlangen. Der Verantwortliche ist verpflichtet, personenbezogene Daten unverzüglich zu löschen \parencite[Art. 17]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016}. \\
\end{longtable}

\subsection{Framework- und Technologie-Auswahl}

Wie von \textcite[S. 3]{ghosh_DecentralizedCrossNetworkIdentityManagementBlockchainInteroperation_2021} demonstriert, setzt auch die vorliegende Arbeit auf existierende Konzepte und Tools für dezentrale Identitätsverwaltung als Bausteine für die Entwicklung des \ac{PQC}-\ac{SSI}-Prototypen. Die systematische Auswahl der Frameworks und Technologien -- bestehend aus der \ac{DLT}-Plattform, dem SSI-Framework, der Kryptografiebibliothek, der Revocation-Infrastruktur und dem \gls{Sidecar Proxy} -- wird transparent in \ref{sec:Anhang_Framework- und Technologie-Auswahl} dokumentiert und begründet.

\subsection{Architekturentwurf}

\subsubsection{Gesamtarchitektur}
\label{sec:Gesamtarchitektur_Iteration1}

Der Architekturentwurf dieser Iteration operationalisiert die in Kapitel~\ref{sec:Designziele_Iteration_1} definierten Designziele durch eine dreischichtige, containerbasierte Systemarchitektur, die Post-Quantum-Kryptografie auf der Transportebene verankert. Abbildung~\ref{fig:Architektur_Iteration1} visualisiert die Zielarchitektur, bestehend aus der DLT-Schicht mit vier Hyperledger-Indy-Validator-Nodes samt Ledger Browser, der Revocation-Schicht mit dediziertem Tails-Server sowie der SSI-Agenten-Schicht mit drei ACA-Py-Instanzen in den Rollen Issuer, Holder und Verifier.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Architektur_Iteration1}
    \caption{Architekturentwurf der ersten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Architektur_Iteration1}
\end{figure}

Das zentrale Architekturprinzip bildet das Sidecar Proxy Pattern (\ref{sec:Anhang_Sidecar Proxy}). Jede extern erreichbare Komponente wird durch einen NGINX-basierten \ac{PQC} Sidecar Proxy geschützt, der TLS-1.3-Verbindungen mit \glslink{Hybride Schemata}{hybrider Schlüsseleinigung} terminiert und im Fallback \ac{ECC} (X25519MLKEM768:x25519) unterstützt. Die Authentifizierung erfolgt über ML-DSA-65-signierte X.509-Zertifikate. In \autoref{fig:Architektur_Iteration1} wird diese verschlüsselte Kommunikation durch die rot-gestrichelten Verbindungspfeile zwischen den Sidecar Proxies visualisiert.

Die Backend-Dienste (Indy-Nodes, Webserver, Tails-Server und ACA-Py-Agents) verbleiben innerhalb isolierter interner Docker-Netzwerke und kommunizieren ausschließlich über unverschlüsseltes HTTP. Externe Zugriffe erfolgen ausschließlich über das gemeinsame Netzwerk sidecar\_proxy, das als quantensichere Kommunikationsdomäne fungiert und eine strikte Netzsegmentierung gemäß der sechsten \ac{KRITIS}-Anforderung (\autoref{tab:compliance_requirements}) gewährleistet.

\subsubsection{ACA-Py Applikationsarchitektur}
\label{sec:ACA-Py Applikationsarchitektur_Iteration1}

Die Architektur von \ac{ACA-Py} folgt einem modularen Designansatz, der durch eine strikte Trennung zwischen der generischen Protokollebene und der anwendungsspezifischen Geschäftslogik gekennzeichnet ist. Dieses Architekturmuster entkoppelt die kryptografischen Kernfunktionen und das \gls{DIDComm}-Messaging (Agent) von der Steuerungslogik (Controller) \parencite{openwallet-foundation_AcapyREADMEmdMainopenwalletfoundationacapyGitHub_}. \autoref{fig:ACAPY_Application_Architecture_Iteration 1} visualisiert diese High-Level-Applikationsarchitektur und verdeutlicht die Interaktion der Schichten.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{ACAPY Application Architecture_Iteration 1}
    \caption{ACA-Py High Level Applikationsarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung auf Basis von \textcite{openwallet-foundation_AcapyREADMEmdMainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentAdminserverpymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentProtocolsout_of_bandv1_0routespymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentProtocolsissue_credentialv2_0routespymainopenwalletfoundationacapyGitHub_,decentralized-identity_AriesrfcsFeatures0434outofbandREADMEmdmaindecentralizedidentityariesrfcs_,decentralized-identity_AriesrfcsFeatures0023didexchangemaindecentralizedidentityariesrfcs_,decentralized-identity_AriesrfcsFeatures0453issuecredentialv2maindecentralizedidentityariesrfcsGitHub_,openwallet-foundation_AcapyAcapy_agentWalletaskarpymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentProtocolsout_of_bandv1_0managerpymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentAskarstorepymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentAskardidcommv1pymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentTransportinboundhttppymainopenwalletfoundationacapyGitHub_,openwallet-foundation_AcapyAcapy_agentTransportoutboundhttppymainopenwalletfoundationacapyGitHub_}.
    \end{flushleft}
    \label{fig:ACAPY_Application_Architecture_Iteration 1}
\end{figure}

Layer 1 bildet eine HTTP-REST-API (Admin API), die über \enquote{server.py} implementiert wird \parencite{openwallet-foundation_AcapyAcapy_agentAdminserverpymainopenwalletfoundationacapyGitHub_}. Sie ermöglicht es Controller-Anwendungen den Agent über standardisierte Endpoints wie \enquote{/out-of-band/create-invitation} \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsout_of_bandv1_0routespymainopenwalletfoundationacapyGitHub_} oder \enquote{/issue-credential-2.0/send} \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsissue_credentialv2_0routespymainopenwalletfoundationacapyGitHub_} zu steuern, ohne direkt mit der Python-Codebasis zu interagieren. Die Endpunkte werden hierbei durch mehrere \enquote{routes.py} umgesetzt.

Layer 2 implementiert die SSI-Geschäftslogik als Protocol Handler durch mehrere \enquote{manager.py}, die Aries \ac{RFC}s umsetzen. Das Out-of-Band Protocol (RFC 0434) \parencite{decentralized-identity_AriesrfcsFeatures0434outofbandREADMEmdmaindecentralizedidentityariesrfcs_} generiert Invitation-Nachrichten mit \enquote{did\:peer\:4-DIDs} \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsout_of_bandv1_0managerpymainopenwalletfoundationacapyGitHub_}, das DID Exchange Protocol (RFC 0023) \parencite{decentralized-identity_AriesrfcsFeatures0023didexchangemaindecentralizedidentityariesrfcs_} authentifiziert Agent-Verbindungen mittels ED25519-Signaturen \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsdidexchangev1_0managerpymainopenwalletfoundationacapyGitHub_}, und das Issue Credential Protocol (RFC 0453) \parencite{decentralized-identity_AriesrfcsFeatures0453issuecredentialv2maindecentralizedidentityariesrfcsGitHub_} erstellt AnonCreds-Credentials \parencite{openwallet-foundation_AcapyAcapy_agentProtocolsissue_credentialv2_0managerpymainopenwalletfoundationacapyGitHub_}.

Layer 3 abstrahiert die Schlüsselverwaltung durch das Aries-Askar-Wallet \parencite{openwallet-foundation_AcapyAcapy_agentWalletaskarpymainopenwalletfoundationacapyGitHub_}, das ED25519-Schlüsselpaare für Signaturen und X25519-Schlüsselpaare für Key Agreement generiert \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_}, diese mit Multicodec-Präfixen kodiert \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_} und verschlüsselt in einer SQLite-Datenbank ablegt \parencite{openwallet-foundation_AcapyAcapy_agentAskarstorepymainopenwalletfoundationacapyGitHub_}, wobei ChaCha20-Poly1305-Authenticated-Encryption verwendet wird \parencite{openwallet-foundation_AcapyAcapy_agentAskardidcommv1pymainopenwalletfoundationacapyGitHub_}.

Layer 4 realisiert das \gls{DIDComm}-Messaging über \enquote{pack\_message()} und \enquote{unpack\_message()} \parencite{openwallet-foundation_AcapyAcapy_agentAskardidcommv1pymainopenwalletfoundationacapyGitHub_}, welches anschließend mittels HTTP-basierter Transport-Mechanismen für Inbound- \parencite{openwallet-foundation_AcapyAcapy_agentTransportinboundhttppymainopenwalletfoundationacapyGitHub_} und Outbound-Kommunikation \parencite{openwallet-foundation_AcapyAcapy_agentTransportoutboundhttppymainopenwalletfoundationacapyGitHub_} übertragen wird, wobei in der klassischen Architektur kein quantensicheres TLS verwendet wird.

\subsection{Implementierung}

Die Implementierung realisiert die Zertifikatsinfrastruktur mit ML-DSA-Signaturen, PQC-Sidecar-Proxies mit TLS~1.3 und hybrider Schlüsseleinigung, die Hyperledger-Indy-DLT-Schicht, die Revocation Registry sowie drei ACA-Py-Agenten, die mittels Docker-Compose mit expliziter Netzsegmentierung orchestriert werden. Die hierfür genutzte Entwicklungsumgebung ist in \ref{sec:Anhang_Setup der Entwicklungsumgebung} dokumentiert.

\subsubsection{Zertifikatsstruktur}
\label{sec:Zertifikatsstruktur}

Die Zertifikatsinfrastruktur für die PQC-Sidecar-Proxies basiert auf einer selbstsignierten Root \ac{CA}, die mit dem Post-Quantum-Signaturalgorithmus ML-DSA-87 erstellt wurde. Die Root \ac{CA} dient als Trust Anchor für alle in der Architektur verwendeten TLS-Zertifikate und gewährleistet, dass sämtliche Zertifikatssignaturen quantenresistent nach der höchsten \ac{NIST} Sicherheitsstufe 5 sind \parencite[S. 15]{nationalinstituteofstandardsandtechnologyus_ModulelatticebasedDigitalSignaturestandard_2024} .

Das Zertifikatserstellungsverfahren folgt einem fünfschrittigen Workflow, wie in \autoref{fig:Zertifikatserstellungsworkflow} dargestellt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Zertifikatserstellungsworkflow}
    \caption{Zertifikatserstellungsworkflow für PQC-basierte Sidecar-Proxies}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Zertifikatserstellungsworkflow}
\end{figure}

Zunächst wird der Root-CA-Schlüssel generiert (Step 1), gefolgt von der Erstellung des selbstsignierten Root-CA-Zertifikats mit einer Gültigkeit von zehn Jahren (Step 2). Anschließend werden für jeden Sidecar-Proxy dedizierte Schlüssel mit ML-DSA-65 generiert (Step 3), die ein besseres Verhältnis zwischen Sicherheit und Speicherbedarf bieten \parencite[S. 16]{nationalinstituteofstandardsandtechnologyus_ModulelatticebasedDigitalSignaturestandard_2024}. Für jeden Proxy wird ein Certificate Signing Request erstellt, der die erforderlichen Subject Alternative Names enthält (Step 4), bevor die Zertifikate abschließend von der Root CA mit ML-DSA-65 und SHA3-256 signiert werden (Step 5). Die detaillierte Implementierung dieses Workflows ist in \ref{sec:Anhang_Zertfikatserstellungsworkflow} dokumentiert.

\subsubsection{Sidecar Proxy nginx}
\label{sec:Sidecar Proxy nginx}

Die Implementierung der post-quanten-kryptographischen Absicherung auf Transport-Layer-Ebene basiert auf einer modifizierten Version des NGINX-Dockerfiles von \textcite{open-quantum-safe_OpenquantumsafeOqsdemosNginxDockerfile_2025} sowie spezifischen NGINX-Konfigurationsdateien für jeden \gls{Sidecar Proxy}. Beide Komponenten realisieren ein konsistentes Konzept bestehend aus Hybrid-Key-Exchange mit \ac{ECC} als Fallback, welches auf Transport-Layer-Ebene Anwendung findet.

Das modifizierte Dockerfile folgt dem Multi-Stage-Build-Prinzip nach \textcite[S. 1]{rosa_MiningMeasuringImpactchangepatternsimprovingsizebuildtimedockerimages_2025} und integriert OpenSSL 3.5.4, liboqs und den oqs-provider. \autoref{fig:Sidecar_Proxy_nginx_Dockerfile} visualisiert die zwei zentralen Phasen (Build-Stage und Runtime-Stage) sowie die Modifikationen gegenüber dem Original-Dockerfile (rote Markierungen). Die Hybrid-Key-Exchange mit \ac{ECC}-Fallback wird durch die DEFAULT-GROUPS-Konfiguration X25519MLKEM768:X25519 realisiert, eine Konvention, die sich konsistent durch die gesamte Implementierung zieht und in \ref{sec:Anhang_Dockerfile Sidecar Proxy nginx} ausführlich erläutert wird.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{2 Stage Sidecarproxy Dockerfile}
    \caption{Sidecar Proxy NGINX Dockerfile Multi-Stage Build}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Sidecar_Proxy_nginx_Dockerfile}
\end{figure}

Die NGINX-Konfigurationsdateien implementieren ein standardisiertes \gls{Sidecar Proxy} Pattern, das diese Architektur operationalisiert. Sie folgen einem konsistenten Schichtenmodell aus globalen Parametern, internen Service-Abstraktionen über Upstream-Blöcke und externen HTTPS-Endpunkten über Server-Blöcke. TLS~1.3 wird durch die Direktive ssl\_ecdh\_curve X25519MLKEM768:X25519 konfiguriert (Listing~A-\ref{lst:nginx_holder.conf}), wodurch Schlüsselaustausch und Fallback auf klassische \ac{ECC}-basierte Kurven ermöglicht werden. Die aktivierte Direktive ssl\_protocols TLSv1.3 wird durch SSL-Zertifikate mit ML-DSA-65-Signaturalgorithmus ergänzt, sodass sowohl der Schlüsselaustausch als auch die Server-Authentifikation post-quantensicher erfolgen. Die gesamte Konfiguration wird in \ref{sec:Anhang_nginx_holder.conf} erläutert.

\subsubsection{DLT-Infrastruktur}

Für die \ac{PQC}-Integration Transport-Layer-Ebene wurde die von-network-Architektur um einen PQC Nginx Sidecar Proxy erweitert.
Diese Modifikation stellt die zentrale Anpassung gegenüber dem Original-Quellcode \parencite{bcgov_GitHubBcgovVonnetworkportabledevelopmentlevelIndyNodenetwork_} dar und betrifft primär die docker-compose.yml-Konfigurationsdatei (Listing \ref{lst:docker-compose.yml-DLT-Infrastruktur}), sowie die Hinzufügung eines neuen Verzeichnisses \enquote{pqc\_sidecarproxy\_nginx/}, welches die in Kapitel~\ref{sec:Sidecar Proxy nginx} und Kapitel~\ref{sec:Zertifikatsstruktur} vorgestellten Dockerfile-, Nginx-Konfigurationsdatei und Zertifikate für den quantensicheren \gls{Sidecar Proxy} enthält. Der Webserver-Container, der im Original-Setup direkt auf Port 9000 exponiert ist \parencite{bcgov_VonnetworkDockercomposeymlMainbcgovvonnetworkGitHub_}, verbleibt in der modifizierten Architektur ausschließlich im internen Docker-Netzwerk \enquote{von}. Stattdessen terminiert der neu hinzugefügte pqc-sidecarproxy-webserver-Container alle eingehenden \ac{TLS}-1.3-Verbindungen auf Port 8000 und leitet die Anfragen nach erfolgreicher \glslink{Hybride Schemata}{hybrider Schlüsselvereinbarung} und ML-DSA-65-Zertifikatsverifikation als unverschlüsseltes HTTP an den internen Webserver-Container weiter. Die unmodifizierte von-network-Implementierung wird in Kapitel~\ref{sec:Anhang_DLT-Infrastruktur} näher erläutert.

Die Integration des Sidecar Proxies erforderte die Definition eines zusätzlichen, extern zugänglichen Docker-Netzwerks \enquote{von\_sidecarproxy}, das als gemeinsame Kommunikationsebene für alle PQC-Proxies der Gesamtarchitektur dient. Dieses Netzwerk wird in der docker-compose.yml (Listing \ref{lst:docker-compose.yml-DLT-Infrastruktur}) als \enquote{external: true} deklariert. Der pqc-sidecarproxy-webserver-Container ist sowohl mit dem internen von-Netzwerk (für Backend-Kommunikation) als auch mit dem externen von\_sidecarproxy-Netzwerk (für Client-Zugriffe) verbunden, wodurch eine strikte Netzwerksegmentierung zwischen interner und externer Kommunikation gewährleistet wird.

\subsubsection{Revocation Registry}

Für die Integration in die Post-Quantum-gesicherte Gesamtarchitektur wurde der indy-tails-server analog zur DLT-Infrastruktur um einen PQC Nginx Sidecar Proxy erweitert. Diese Modifikation betrifft primär die Docker-Compose-Konfigurationsdatei (Listing \ref{lst:docker-compose.yml-Revocation-Registry}), in der ein zusätzlicher Service \enquote{pqc-sidecarproxy-tails-server} definiert wurde, sowie die Hinzufügung eines neuen Verzeichnisses \enquote{pqc\_sidecarproxy\_nginx/}, welches die in Kapitel~\ref{sec:Sidecar Proxy nginx} und Kapitel~\ref{sec:Zertifikatsstruktur} vorgestellten Dockerfile-, Nginx-Konfigurationsdatei und Zertifikate für den quantensicheren \gls{Sidecar Proxy} enthält. Der ursprüngliche Tails-Server-Container verbleibt im internen Docker-Netzwerk \enquote{tails-server} und exponiert Port 6543 ausschließlich innerhalb dieses Netzwerks. Der neu hinzugefügte PQC-Proxy-Container terminiert alle externen \ac{TLS}-1.3-Verbindungen auf Port 6543 und leitet die Anfragen nach erfolgreicher erfolgreicher \glslink{Hybride Schemata}{hybrider Schlüsselvereinbarung} und ML-DSA-65-Zertifikatsverifikation als unverschlüsseltes HTTP an den internen Tails-Server weiter. Die unmodifizierte indy-tails-server-Implementierung wird in Kapitel~\ref{sec:Anhang_Revocation Registry} näher erläutert.

Die Netzwerk-Integration folgt dem etablierten \gls{Sidecar Proxy} Pattern. Der \enquote{pqc-sidecarproxy-tails-server}-Container ist sowohl mit dem internen \enquote{tails-server}-Netzwerk (für Backend-Kommunikation) als auch mit dem externen, manuell erstellten \enquote{von\_sidecarproxy}-Netzwerk (für Client-Zugriffe) verbunden. Diese Dual-Network-Architektur erzwingt, dass alle externen Zugriffe auf den Tails-Server über den quantensicheren \gls{Sidecar Proxy} geleitet werden.

\subsubsection{SSI-Agenten} \label{SSI-Agenten}

Die SSI-Agent-Schicht bildet die Anwendungsebene der Gesamtarchitektur und implementiert die drei klassischen Rollen des SSI-Ökosystems Issuer, Holder und Verifier (Kapitel~\ref{sec:Self-Sovereign Identity}) samt ihrer dedizierten PQC Nginx Sidecar Proxies. Die Architektur folgt dem in Kapitel~\ref{sec:ACA-Py Applikationsarchitektur} beschriebenen Referenzmodell, alle drei Agenten basieren auf dem unmodifizierten \ac{ACA-Py} Base-Image (Listing \ref{lst:Dockerfile-acapy-base}) und werden ausschließlich über Kommandozeilen-Parameter konfiguriert, ohne Änderungen am ACA-Py-Quellcode vorzunehmen.

Listing \ref{lst:docker-compose.yml-SSI-Agenten} zeigt die Docker-Compose-Konfiguration der drei ACA-Py-Agenten innerhalb der Gesamtarchitektur. Die Agent-Konfiguration erfolgt hierbei vollständig deklarativ über Docker-Compose-Service-Definitionen, die jeweils den \enquote{start}-Befehl von \ac{ACA-Py} mit rollenspezifischen Parametern aufrufen. Jeder Agent wird in einem dedizierten Docker-Netzwerk isoliert betrieben und über einen PQC Nginx Sidecar Proxy mit quantensicherer TLS-1.3-Verschlüsselung nach außen exponiert. Die Wallet-Konfiguration nutzt persistente Docker-Volumes zur Speicherung von DIDs, Credentials und Connections über Container-Neustarts hinweg. Die Agents verbinden sich über PQC-gesicherte Proxies mit der DLT-Infrastruktur und der Revocation Registry. Auto-Response-Features ermöglichen vollständig scriptgesteuerte SSI-Workflows ohne manuelle Interaktion. Die Netzwerk-Architektur folgt einem strikten Isolation-Prinzip, sodass Agents nur über das externe \enquote{von\_sidecarproxy}-Netzwerk untereinander kommunizieren können. Health-Checks und Service-Dependencies orchestrieren deterministische Startup-Sequenzen und eliminieren Race-Conditions während des Deployments.
Eine ausführliche Darstellung der Agent-Konfigurationsparameter und der Sidecar-Proxy-Architektur findet sich in \ref{sec:Anhang_SSI-Agenten}.

\subsubsection{Docker Orchestrierung der Gesamtarchitektur} \label{sec:Docker Orchestrierung der Gesamtarchitektur}

Die in den vorangegangenen Abschnitten beschriebenen Einzelkomponenten -- Zertifikatsinfrastruktur, PQC-Sidecar-Proxies, DLT-Infrastruktur, Revocation Registry und SSI-Agenten -- werden mittels einer mehrstufigen Docker-Compose-Orchestrierung zu einem funktionsfähigen Gesamtsystem integriert. Der Startprozess der Gesamtarchitektur folgt einer deterministischen Sequenz, die in Listing~A-\ref{lst:Docker-Compose-Start-der-Gesamtarchitektur} dokumentiert ist und die korrekten Abhängigkeiten zwischen den Infrastrukturschichten gewährleistet.

Die Orchestrierung gliedert sich in drei sequenzielle Phasen, die jeweils durch separate Docker-Compose-Konfigurationen gesteuert werden. In der ersten Phase wird die DLT-Infrastruktur über das von-network-Management-Skript (Listing~A-\ref{lst:von-network-manage-script}) initialisiert, wodurch die vier Indy-Validator-Nodes, der Genesis-Webserver sowie der zugehörige PQC-Sidecar-Proxy gestartet werden. Diese Phase erzeugt das gemeinsame externe Docker-Netzwerk \enquote{von\_sidecarproxy}, das als zentrale Kommunikationsschicht für alle quantensicheren Verbindungen dient. Die zweite Phase umfasst die Initialisierung der Revocation Registry mittels des indy-tails-server-Management-Skripts (Listing~A-\ref{lst:indy-tails-server-manage-script}), wodurch der Tails-Server-Container sowie dessen PQC-Proxy-Frontend bereitgestellt werden. In der dritten Phase werden schließlich die SSI-Agenten gemeinsam mit ihren jeweiligen PQC-Sidecar-Proxies über die projektspezifische Docker-Compose-Konfiguration (Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten}) gestartet.

Die in \autoref{fig:Docker-Compose-Übersicht-Iteration-1} visualisierte Containerarchitektur verdeutlicht die resultierende Systemtopologie. Die Gesamtarchitektur umfasst insgesamt 14 Container, die sich auf die drei funktionalen Schichten verteilen. Die DLT-Schicht besteht aus insgesamt sechs Containern, den vier Validator-Nodes, einem Webserver und einem PQC Sidecar Proxy. Die Revocation-Schicht umfasst insgesamt zwei Container, einen Tails-Server und dessen PQC Sidecar Proxy. Die Agent-Schicht besteht aus insgesamt sechs Containern für die drei SSI-Agenten und ihre jeweiligen PQC Sidecar Proxies.

Die Netzwerktopologie nutzt sechs dedizierte Docker-Bridges, um die logische Separation der Schichten zu realisieren. Das hope\_hope-holder-, hope\_hope-issuer- und hope\_hope-verifier-Netzwerk verbinden jeweils die SSI-Agenten mit der DLT-Schicht. Das docker\_tails-server-Netzwerk isoliert die Revocation-Infrastruktur, während das von\_sidecarproxy-Netzwerk die PQC-Sidecar-Proxies konnektiviert. Das von\_von-Netzwerk integriert die Validator-Nodes untereinander und mit der Revocation-Schicht.

Die Datenpersistenz wird durch elf Docker Volumes realisiert. Während docker\_nginx-logs und von\_nginx-logs die Webserver-Logs aggregieren, speichern hope\_holder-data, hope\_issuer-data und hope\_verifier-data die lokalen Wallets und kryptografischen Materialien der SSI-Agenten. Die Validator-Node-Datenbank wird durch von\_node1-data bis von\_node4-data persistiert, während von\_webserver-cli und von\_webserver-ledger die Ledger-Zustandsdaten und CLI-Konfigurationen verwalten. Diese Volumenstruktur entkoppelt den Containern-Lebenszyklus vom Datenschicksal und ermöglicht die Wiederaufnahme der Systemzustände über Container-Neustarts hinweg.

Die \enquote{depends\_on}-Direktiven in den Docker-Compose-Konfigurationen (Listing~A-\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~A-\ref{lst:docker-compose.yml-Revocation-Registry} und Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten}) definieren explizite Startup-Abhängigkeiten, die Race-Conditions während des Deployment-Prozesses eliminieren. Die PQC Sidecar Proxies werden vor den ihnen zugeordneten Backend-Services gestartet, und die SSI-Agenten warten auf die vollständige Initialisierung der Infrastruktur-Services, bevor sie ihre Genesis-Transaktionsdatei abrufen. Diese Orchestrierung gewährleistet eine deterministische Startup-Sequenz und stellt sicher, dass alle Komponenten beim Erreichen ihres operativen Zustands auf vollständig verfügbare Abhängigkeiten zugreifen können.

Die \enquote{depends\_on}-Direktiven in den Docker-Compose-Konfigurationen (Listing~A-\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~A-\ref{lst:docker-compose.yml-Revocation-Registry} und Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten}) definieren explizite Startup-Abhängigkeiten, die über reine Ausführungsreihenfolgen hinausgehen. Ohne Synchronisation führen verfrühte Interaktionen abhängiger Services zu \enquote{faulty interactions} während der Boot-Phase \parencite[S. 25]{deiasio_FrameworkMicroservicesSynchronization_2021}. Die implementierte Konfiguration eliminiert diese Race-Conditions, indem sie sicherstellt, dass die PQC Sidecar Proxies nicht gestartet werden, bevor die ihnen zugeordneten Backend-Services den Status (\enquote{ready}) erreichen. Diese Orchestrierung erzwingt eine deterministische Startup-Sequenz, die verhindert, dass abhängige Komponenten auf Dienste zugreifen, die sich zwar im Status \textit{Running}, aber noch nicht im Status \textit{Ready} befinden \parencite[S. 29]{deiasio_FrameworkMicroservicesSynchronization_2021}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{docker_compose_übersicht.png}
    \caption{Docker-Compose-Übersicht der ersten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Docker-Compose-Übersicht-Iteration-1}
\end{figure}

\subsection{Formative Evaluation}
\label{sec:formative_evaluation_iteration1}

In Übereinstimmung mit dem in Kapitel~\ref{sec:Schritt4-Design der individuellen Evaluationsepisoden} entworfenen Evaluationsdesign setzt dieser Abschnitt die erste definierte Evaluationsepisode (\autoref{tab:eval_episodes}) um. Charakterisiert als formative und artifizielle Untersuchung, liegt der Fokus dieser Phase exklusiv auf der Validierung der Transport-Layer-Security sowie der korrekten Konfiguration der Infrastrukturkomponenten. Ziel ist es, gemäß den Prinzipien von \textcite[S. 6, 7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} Designfehler in der Sidecar-Architektur frühzeitig zu identifizieren.

Methodisch erfolgt dies primär durch White-Box-Tests. Da bei diesem Verfahren die internen Strukturen und Implementierungsdetails der Software bekannt sind und gezielt in die Prüfung einbezogen werden \parencite[S. 10]{myers_ArtSoftwareTesting_2012}, eignet es sich besonders gut, um die korrekte Konfiguration der kryptographischen Primitive innerhalb der Container-Architektur durch eine detaillierte Analyse der Handshake-Logs zu validieren.

Für die technische Durchführung dieser Analysen war die Bereitstellung eines \ac{PQC}-fähigen Browsers zwingend erforderlich, da aktuelle Produktivbrowser noch keine Post-Quanten-Kryptographie in ihren \ac{TLS}-Implementierungen unterstützen. Diese Limitation führt bei Verbindungsversuchen zu \ac{PQC}-fähigen Servern unweigerlich zu einem Cipher-Mismatch, wie in \autoref{fig:Cipher-Mismatch-Blockchain-Webserver} veranschaulicht. Um diese Inkompatibilität zu überwinden, wurde ein Chromium-basierter Browser mit integrierter \ac{PQC}-Unterstützung kompiliert (siehe \ref{sec:Anhang_Eigenkompilation eines Chromium-Browsers mit PQC-Unterstützung}). Dieser ermöglicht die Durchführung von TLS-Handshakes mit hybriden sowie rein \ac{PQC}-basierten Algorithmen und dient als fundamentale Testplattform für die experimentelle Analyse der implementierten Verfahren.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_blockchain_webserver_CIPHER_MISMATCH.png}
    \caption{Cipher Mismatch der TLS-1.3-Verbindung des Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Cipher-Mismatch-Blockchain-Webserver}
\end{figure}

\subsubsection{Validierung der Zertifikatskette und ML-DSA-Signaturen}

Zur Verifikation der kryptographischen Integrität der implementierten \ac{PKI} wurde die Zertifikatskette der Sidecar-Proxies mittels openssl-Diagnosewerkzeugen analysiert. Ziel war der Nachweis, dass die ausgelieferten X.509-Zertifikate korrekt auf den spezifizierten Post-Quanten-Signaturalgorithmen basieren. Die Inspektion des vom Issuer-Agenten-Proxy bereitgestellten Zertifikats (\autoref{fig:Successful-Validation-Issuer-MLDSA-Cert}) bestätigt, dass der öffentliche Schlüssel des Leaf-Zertifikats (\enquote{pqc reverseproxy issuer agent}) den Algorithmus \enquote{ML-DSA-65} verwendet. Des Weiteren belegt der Signaturalgorithmus \enquote{ML-DSA-87}, dass die Zertifikatskette valide durch die \enquote{Master Thesis PQC Root CA} signiert wurde, was die erfolgreiche Generierung und Einbindung der Dilithium-basierten Zertifikate in den TLS-Handshake beweist.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_issuer_mldsa_cert.png}
    \caption{Erfolgreiche Validierung des ML-DSA-Zertifikats des Issuer-Agenten}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-MLDSA-Cert}
\end{figure}

\subsubsection{Validierung der TLS 1.3 Algorithmen-Aushandlung}

Die erfolgreiche Integration der PQC-Algorithmen in das Transportprotokoll wurde durch einen Verbindungsaufbau mittels \enquote{openssl s\_client} verifiziert. Wie in \autoref{fig:Successful-Validation-Issuer-TLS1.3} dargestellt, konnte erfolgreich eine TLS-1.3-Sitzung etabliert werden. Die Analyse der Handshake-Parameter bestätigt die Verwendung der hybrid-post-quanten Schlüsselaustauschgruppe \enquote{X25519MLKEM768}, welche den klassischen elliptischen Kurvenalgorithmus X25519 mit dem KEM-Verfahren ML-KEM-768 kombiniert. Zudem wird für die Authentifizierung des Peer-Zertifikats der Signaturalgorithmus \enquote{mldsa65} ausgewiesen. Diese Ergebnisse validieren die korrekte Konfiguration der OQS-Provider-Bibliothek innerhalb der Proxy-Komponenten und belegen die praktische Funktionsfähigkeit des hybriden Schlüsselaustauschs im Zusammenspiel mit PQC-Signaturen.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_issuer_TLS1.3.png}
    \caption{Erfolgreiche Validierung der TLS-1.3-Verbindung des Issuer-Agenten}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-TLS1.3}
\end{figure}

\subsubsection{Validierung der Ledger-Initialisierung}

Die operative Funktionsfähigkeit des Hyperledger Indy Netzwerks wurde primär über das Web-Interface des Blockchain-Servers validiert. Wie in \autoref{fig:Successful-Validation-Blockchain-Webserver} dargestellt, zeigen die Statusindikatoren aller vier Validator-Nodes eine aktive Beteiligung am Konsensus-Protokoll (Status Node1-4), womit der Distributed Ledger erfolgreich initialisiert ist. Simultan belegt diese Abbildung die korrekte PQC-Absicherung der Webserver-Komponente. Der Zugriff erfolgt über den eigens kompilierten PQC-Chromium-Browser, dessen Security-Panel explizit eine authentifizierte \ac{TLS}-1.3-Verbindung unter Verwendung der hybriden Schlüsselaustauschgruppe \enquote{X25519MLKEM768} ausweist.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_blockchain_webserver.png}
    \caption{Erfolgreiche Validierung der TLS-1.3-Verbindung des Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Blockchain-Webserver}
\end{figure}

Als zweite notwendige Bedingung für die spätere Anbindung der SSI-Agenten wurde die Verfügbarkeit der Genesis-Datei verifiziert. \autoref{fig:Successful-Validation-Genesis-File-Blockchain-Webserver} dokumentiert den Abruf des Endpunkts \enquote{/genesis} mittels \enquote{curl}. Die erfolgreiche Rückgabe der JSON-formatierten Genesis-Transaktionen bestätigt, dass die für die Anbindung externer Clients erforderlichen Netzwerkinformationen korrekt publiziert werden.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_genesis.png}
    \caption{Erfolgreiche Validierung der Genesis-Datei des Webservers}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Genesis-File-Blockchain-Webserver}
\end{figure}

\subsubsection{Validierung der ACA-Py API-Verfügbarkeit}

Die funktionale Erreichbarkeit der SSI-Agenten wurde durch eine systematische Analyse der Initialisierungsphase und der anschließenden API-Verfügbarkeit validiert. Die Logging-Ausgabe des Issuer-Agenten (Listing~A-\ref{lst:Issuer-Agent-Boot-Logs}) dokumentiert den erfolgreichen Abruf der Genesis-Datei und die vollständige Ledger-Konfiguration. Die Erstellung eines neuen Wallet-Profils mit Askar-Backend und die erfolgreiche Initialisierung der Inbound- und Outbound-Transports demonstrieren die korrekte Konfiguration des ACA-Py-Agents. Die durchgeführten Health-Checks über den Endpunkt \enquote{/status/ready} bestätigen die vollständige Initialisierung und Bereitschaft des Agenten.

Die Visualisierung der Swagger-basierten Admin-Oberfläche (\autoref{fig:Successful-Validation-Issuer-Agent-ACA-Py-Swagger-API}) ergänzt diese technischen Log-Daten durch den Nachweis, dass die Admin-API über den PQC-Reverse-Proxy fehlerfrei erreichbar ist und alle administrativen Endpunkte zur Steuerung der Agenten-Komponente bereitstellt. Die Tatsache, dass die Swagger-Oberfläche unter dem PQC-gesicherten HTTPS-Endpoint vollständig funktionsfähig ist, belegt die korrekte TLS-Terminierung am Proxy sowie die fehlerfreie Weiterleitung der HTTP-Anfragen an den ACA-Py-Container.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_Issuer_Agent_Swagger_API.png}
    \caption{Erfolgreiche Validierung der Issuer Agent ACA-Py Swagger API}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Issuer-Agent-ACA-Py-Swagger-API}
\end{figure}

\subsubsection{Validierung der Netzwerkisolation}

Die integrale Sicherheitseigenschaft der Netzwerksegmentierung wurde durch eine Inspektion der Docker-Netzwerktopologie und systematische Erreichbarkeitstests validiert. \autoref{fig:Darstellung-Network-Isolation} belegt diese Topologie anhand des \enquote{docker network inspect}-Outputs: Der Issuer-Agent befindet sich exklusiv im Netzwerksegment \enquote{hope\_hope-issuer}, während der Holder-Agent im Segment \enquote{hope\_hope-holder} isoliert ist. In jedem dieser Segmente fungiert der zugehörige PQC-Sidecar-Proxy als einziger Ingress-Punkt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_network_isolation.png}
    \caption{Darstellung der Netzwerkisolation innerhalb der Gesamtarchitektur}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Darstellung-Network-Isolation}
\end{figure}

\autoref{fig:Successful-Validation-Network-Isolation-Through-Tests} demonstriert die Wirksamkeit dieser Isolation auf zwei Ebenen. Erstens zeigt die Prozessliste (\enquote{docker ps}), dass lediglich die Sidecar-Proxies externe Ports (8020, 8030, 8040) an das Host-System binden, während die Ports der ACA-Py-Container nicht exponiert sind. Zweitens beweisen die Inter-Container-Verbindungstests die logische Trennung. Ein direkter Zugriffsversuch aus dem \enquote{issuer-agent}-Container auf den \enquote{holder-agent} schlägt mit einem DNS-Auflösungsfehler (\enquote{Could not resolve host}) fehl, da keine Routing-Route zwischen den isolierten Netzwerkbrücken existiert. Im Gegensatz dazu ist der lokale Zugriff des \enquote{pqc-sidecarproxy-holder} auf seinen zugehörigen Agenten erfolgreich möglich.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{validate_network_isolation_through_tests.png}
    \caption{Erfolgreiche Validierung der Netzwerkisolation}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Successful-Validation-Network-Isolation-Through-Tests}
\end{figure}

\subsection{Erkenntnisse und Anpassungsbedarfe}
\label{subsec:findings_adaptation_needs}

Die erste Iteration bildet das fundamentale technologische Fundament der Forschungsarbeit. Die formative Evaluation (Kapitel~\ref{sec:formative_evaluation_iteration1}) validierte die operative Integrität der entwickelten Architektur. Die verteilten Micro-Services, der Hyperledger Indy Ledger und die PQC-Sidecar-Proxies interagieren funktional korrekt. Diese Initialphase generierte jedoch spezifische Erkenntnisse, die eine gezielte Weiterentwicklung in der zweiten Iteration motivieren. Diese werden nachfolgend in Bezug auf die Designziele analysiert.

\subsubsection{Abgleich mit den Designzielen und kritische Erkenntnisse}
\label{subsubsec:design_goals_critique}

Das primäre Designziel, die Absicherung der Transportebene in einem SSI-Ökosystem mittels Post-Quanten-Kryptographie, wurde vollständig erreicht. Die erfolgreiche Validierung des Sidecar-Musters belegt die Machbarkeit einer transparenten PQC-Migration für Legacy-Systeme (ACA-Py, Indy Node) ohne Eingriffe in deren Kerncode. Die implementierte Micro-Segmentation erfüllt zudem die architektonischen Anforderungen an logische Netzsegmentierung in \ac{KRITIS}-Umgebungen (\autoref{tab:compliance_requirements}).

Durch die strikte Entkopplung der kryptographischen Terminierung von der Business-Logik durch die Sidecar-Proxy-Architektur konnte eine PQC-Integration realisiert werden, die die Kernprozesse der Identitätsverwaltung funktional nicht beeinträchtigt. Diese architektonische Entscheidung ermöglicht es, sicherheitskritische Updates an der Krypto-Komponente vorzunehmen, ohne die Integrität der komplexen SSI-Logik zu gefährden. Die empirische Validierung der Zertifikatsketten und TLS-1.3-Handshake-Protokolle (\autoref{sec:formative_evaluation_iteration1}) bestätigt die technische Reife dieser Architekturentscheidung.

Bezüglich der Algorithmenauswahl und Sicherheitsbewertung operationalisiert die erste Iteration die in Tabelle~\ref{tab:compliance_requirements} definierten BSI-Vorgaben für Post-Quantum-Kryptografie durch die Implementierung der NIST-standardisierten Algorithmen ML-DSA-65 und ML-KEM-768, welche explizit die NIST Security Strength Categories 3/5 erfüllen \parencite[Kap.~2.4, 5.3.4.2]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}. Die formative Evaluation bestätigte die technische Machbarkeit dieser Algorithmen in der Sidecar-Proxy-Infrastruktur durch die erfolgreiche Validierung hybrider Zertifikatsketten und TLS-1.3-Handshake-Protokolle mit der Schlüsselaustauschgruppe \enquote{X25519MLKEM768}.

Bezüglich der kryptografischen Agilität zeigt die erste Iteration, dass das Designziel einer architektonischen Vorbereitung auf Algorithmenaustauschbarkeit erreicht wurde. Die containerbasierte Sidecar-Architektur ermglicht es, kryptografische Bibliotheken durch Rolling Updates der Proxy-Images auszutauschen, ohne ACA-Py oder die übrige Systemlogik anzupassen, was direkt die von \textcite[S. 102]{mehrez_CryptoAgilityProperties_2018} geforderte \enquote{Extensibility} kryptoagiler Systeme adressiert. Gleichzeitig nutzt die TLS-1.3-Integration eine konfigurationsbasierte Fallback-Kette (\enquote{DEFAULT\_GROUPS:X25519:ML-KEM-768:mlkem768x25519:mlkem1024}), sodass hybride und klassische Verfahren orthogonal ausgehandelt und bei Inkompatibilitäten automatisch gewechselt werden können \parencite[S. 26]{rescorla_TransportLayerSecurityTLSProtocolVersion13_2018}. Diese Protokoll- und Infrastrukturmechanismen realisieren damit zentrale Kryptoagilitäts-Eigenschaften wie \enquote{Fungibility} und \enquote{Updateability} \parencite[S. 102--103]{mehrez_CryptoAgilityProperties_2018} und entsprechen dem Erfordernis, kryptografische Komponenten ohne grundlegende Systemumgestaltung migrieren zu können \parencite[S. 670]{kreutzer_Kryptoagilitaet_2024a}.

Eine zentrale Limitation identifizierte jedoch die Analyse der Sicherheitsmodelle. Während die Transportebene durch die Sidecar-Proxies vollständig quantensicher abgesichert ist (\gls{Data-In-Motion}), verbleiben Verifiable Credentials und DID-Dokumente (\gls{Data-At-Rest}) mittels klassischer Kryptografie verschlüsselt. Diese Diskrepanz zwischen Transportschutz (PQC-gesichert) und Datenpersistierung (klassische Kryptografie) widerspricht dem mehrschichtigen Sicherheitsansatz \enquote{Defense in Depth} von \textcite[S. 242--243]{alsaqour_DefenseDepthMultilayersecurity_2021}, bei dem konsistente, sich gegenseitig verstärkende Kontrollen auf mehreren Ebenen implementiert werden, um Ressourcen und Assets umfassend zu schützen. Diese Erkenntnisse folgern eine Erweiterung des Sicherheitsmodells von der Transportebene auf die Applikationsschicht in der zweiten Iteration.

\subsubsection{Design-Refinements und Operationalisierung der zweiten Iteration}
\label{subsubsec:design_refinements_iteration2}

Die systematische Analyse der Evaluationsergebnisse führt zu zwei konvergenten Design-Refinements, die die identifizierten Sicherheitslücken adressieren und die zweite Iteration strukturieren.

\textbf{Refinement 1: Applikationsebenen-Integration der Post-Quanten-Kryptografie.} Dieses Refinement adressiert die identifizierte Sicherheitslücke durch technische Erweiterung der PQC-Integration von der Transportebene auf die Applikationsebene. Die direkte Einbindung der \emph{liboqs}-Bibliothek in die ACA-Py-Agenten ermöglicht ML-DSA-65-Signaturen für Verifiable Credentials und \gls{DIDComm}-Nachrichten, wodurch die kritische Diskrepanz zwischen quantensicherer Transportverschlüsselung und ungeschützter Datenpersistierung geschlossen wird. Die Implementierung als modulares Plugin-System folgt dem Stabilitätsprinzip nach \textcite[S. 1--2]{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005}, indem kryptografische Primitive in stabile Abstraktionsschichten (Kryptografie-Wrapper, DID-Verarbeitung, Integration-Patching) gekapselt werden, während instabile Algorithmen-spezifische Parameter (ML-DSA-65, ML-KEM-768) als austauschbare Konfigurationselemente behandelt werden. Dies realisiert das Open-Closed-Prinzip nach \textcite{martin_AgileSoftwareDevelopment_2003} und minimiert den Aufwand für zukünftige Re-Separation bei Algorithmen-Updates, da nur die Konfigurationsebene modifiziert werden muss, ohne die stabile Plugin-Architektur zu verändern.

\textbf{Refinement 2: Hybride Sicherheitsarchitektur mit redundanter Tiefenstaffelung.} Dieses Refinement etabliert ein übergeordnetes Defense-in-Depth-Modell durch beibehaltene Sidecar-Proxies als erste Verteidigungslinie (Transport Layer Security) bei gleichzeitiger Quantensicherung der Datenobjekte auf Anwendungsebene (Application Layer Security). Diese redundante Absicherung schafft eine tiefengestaffelte Sicherheitsarchitektur, bei der ein Bruch einzelner Schichten, nicht automatisch zum Kollaps der Gesamtsicherheit führt. Das Refinement implementiert damit die von \textcite[S. 242--243]{alsaqour_DefenseDepthMultilayersecurity_2021} geforderte Prinzipienkonsistenz über alle Architekturebenen hinweg und gewährleistet die Resilienz des Systems gegen hybride Angriffszenarien.



\newpage
\section{Zweite Iteration der Artefaktentwicklung}
\label{Zweite Iteration der Artefaktentwicklung}

\subsection{Designziele dieser Iteration}
\label{sec:Designziele_Iteration_2}

Die zweite Iteration der Artefaktentwicklung baut auf der in Iteration 1 erfolgreich validierten Basisarchitektur auf und korrespondiert erneut mit der DSRM-Phase 2 \textit{Objectives} nach \textcite[S. 54]{peffers_DesignScienceResearchmethodologyinformationsystemsresearch_2007}. Der Fokus dieser Iteration liegt auf der Erweiterung des Prototypen um eine tiefgreifende PQC-Integration auf der Anwendungsebene (Application Layer). Im Kontext des Drei-Zyklen-Modells nach \textcite[S. 88]{hevner_ThreeCycleViewDesignScienceResearch_2007} wird der Design Cycle intensiviert, um die kryptografische Sicherheit von der reinen Transportsicherung (TLS) auf die tatsächlichen Nutzdaten (Verifiable Credentials und DID-Dokumente) auszuweiten und somit eine Ende-zu-Ende-Sicherheit zu gewährleisten.

Die Designziele dieser Iteration leiten sich konsistent aus den in Kapitel~\ref{sec:Zielsetzung und Forschungsfragen} definierten Forschungsfragen ab, wobei eine inhaltliche Vertiefung der technischen Anforderungen erfolgt.

Bezüglich FF1 (Systemarchitektur \& Compliance) wird das Ziel verfolgt, die SSI-Kernprozesse so zu modifizieren, dass sie quantenresistente Signaturen und Schlüsselformate nativ unterstützen. Das Design muss sicherstellen, dass die Unveränderlichkeit und Authentizität von Identitätsnachweisen unabhängig vom Transportkanal auch langfristig gegenüber Quantencomputer-Angriffen gewährleistet bleibt, was eine zentrale Anforderung für den Einsatz in KRITIS-Umgebungen darstellt \parencite[.S 25]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025}.

Hinsichtlich FF2 (Algorithmenauswahl \& Sicherheitsbewertung) wird das Ziel verfolgt, die praktische Machbarkeit von NIST-standardisierten Post-Quantum-Algorithmen in den Kernkomponenten des SSI-Systems nachzuweisen. Der Fokus liegt auf der Integration quantenresistenter Signatur- und Verschlüsselungsverfahren auf der Applikationsebene, um die digitale Authentizität und Integrität von Identitätsnachweisen langfristig gegen Quantencomputer-Angriffe zu schützen.

Für FF3 (Kryptografische Agilität) zielt diese Iteration auf die Implementierung von Agilitätsmechanismen direkt in den Datenstrukturen ab. Das System soll so gestaltet werden, dass es hybride Szenarien unterstützt und eine Koexistenz sowie den nahtlosen Wechsel zwischen klassischen (z.\,B. Ed25519) und post-quanten Kryptografieverfahren innerhalb der DID-Methoden und Credential-Definitionen ermöglicht, ohne die Interoperabilität grundlegend zu gefährden.

\subsection{Architekturentwurf}

\subsubsection{Gesamtarchitektur}

Die Gesamtarchitektur der zweiten Iteration erweitert die in Kapitel~\ref{sec:Gesamtarchitektur_Iteration1} etablierte dreischichtige Containerarchitektur um eine zusätzliche Kryptoebene auf der Anwendungsschicht. Während die in der ersten Iteration implementierte Sidecar-Proxy-Architektur mit TLS~1.3 und hybrider Schlüsseleinigung (X25519 + ML-KEM-768) vollständig beibehalten wird und weiterhin die Transportverschlüsselung zwischen den Komponenten gewährleistet, wird in dieser Iteration die kryptografische Absicherung auf die SSI-Agenten-Schicht ausgeweitet.

\autoref{fig:Gesamtarchitektur_Iteration2} visualisiert diese Erweiterung durch die Integration von \enquote{PQC-PLUGIN}-Modulen in die drei ACA-Py-Instanzen (Issuer, Holder, Verifier). Diese Plugin-Module ermöglichen die Verwendung quantenresistenter Signaturalgorithmen (ML-DSA-65) innerhalb von Verifiable Credentials und Decentralized Identifiers sowie die Verwendung quantenresistenter Schlüsselkapselungsverfahren (ML-KEM-768) für die \gls{DIDComm}-Messaging-Verschlüsselung. Durch diese duale Architektur mit Sidecar-Proxies für die Transportebene und Plugin-Module für die Applikationsebene wird eine durchgängige Ende-zu-Ende-Quantenresistenz realisiert, die sowohl \gls{Data-In-Motion} als auch \gls{Data-At-Rest} schützt. Die DLT-Infrastruktur (vier Hyperledger-Indy-Validator-Nodes, Ledger-Browser, Webserver), die Revocation Registry (Tails-Server) sowie die zugrundeliegende Docker-Netzwerktopologie bleiben strukturell unverändert und gewährleisten die Kontinuität der in der ersten Iteration validierten Infrastrukturkomponenten.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Gesamtarchitektur_Iteration2}
    \caption{Gesamtarchitekturentwurf der zweiten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Gesamtarchitektur_Iteration2}
\end{figure}

\pagebreak
\subsubsection{ACA-Py Applikationsarchitektur}
\label{sec:ACA-Py Applikationsarchitektur}

Während Kapitel~\ref{sec:ACA-Py Applikationsarchitektur_Iteration1} die klassische Applikationsarchitektur als geschichtete, unveränderliche Referenzimplementierung vorstellt, demonstriert die zweite Iteration die transparente Applikationsschicht-Integration von PQC durch ein modulares Plugin-System, das bestehendes Kerncode-Design respektiert und durch gezieltes Patching erweitert. ACA-Py-Plugins ermöglichen hierbei eine standardisierte Erweiterbarkeit, ohne die ACA-Py-Codebasis zu überlasten \parencite{_ACAPyPluginsACAPyDocs_}.

\autoref{fig:ACAPY_Application_Architecture_Iteration2_PQC} visualisiert diese erweiterte Architektur und verdeutlicht die Integration des PQC-Plugins als zentrale Interceptions- und Delegationsschicht. Die roten Markierungen heben die Unterschiede zur klassischen ACA-Py Applikationsarchitektur (\autoref{fig:ACAPY_Application_Architecture_Iteration 1}) hervor. Das Plugin ist seitlich an alle vier klassischen Schichten (Protocol Handlers, Wallet Interface, Transport Layer, externe Business Logic) angebunden, woraus sich bidirektionale Pfeile ergeben. Diese Bidirektionalität symbolisiert die transparente Interception: wenn eine klassische Schicht eine Operation initiiert, wird diese zunächst vom Plugin abgefangen, eine PQC-äquivalente Operation durchgeführt und das Ergebnis zurückgegeben. Diese Interceptions-Delegation ermöglicht es dem Plugin, als Zwischenschicht zu fungieren, ohne die übergeordnete Geschäftslogik zu modifizieren.

Um langfristige Wartbarkeit und Kryptoagilität zu sichern, folgt das PQC-Plugin intern dem Ansatz der Separation of Concerns for Evolving Systems nach Hamza \parencite[S. 1--2]{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005}. Das Plugin ist nach dem Software Stability Model mit drei internen Schichten strukturiert, denen nachfolgend die konkreten Implementierungskomponenten zugeordnet werden.

Die stabile Kern-Ebene, das \ac{EBT}, kapselt die Enduring Business Knowledge der Kryptografie. Sie umfasst abstrakte Operationen wie Signaturerstellung, Schlüsselgenerierung, Schlüsselaustausch und Verschlüsselung. Diese Operationen sind unabhängig vom konkreten Algorithmus und stellen die stabile Kern-\ac{EBT} dar. Wenn zukünftig ML-DSA-87 statt ML-DSA-65 verwendet wird, bleibt diese Abstraktionsschicht unverändert, es ändert sich nur die konkrete Implementierung. Nach Hamza sind \ac{EBT}s die Basis für Stabilität, da ein System ohne \ac{EBT}s bei Änderungen neu separiert werden muss \parencite[S. 1--2]{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005}.

Konkret wird die Protocol Handlers-Schicht der ACA-Py-Architektur erweitert. Während die klassische Architektur DID Exchange, Credential Issuance und Presentation Proof nur mit klassischen Signaturen durchführt, delegiert das Plugin diese Operationen und nutzt ML-DSA-65 statt ed25519 \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_}. Die abstrakte Signatur-Operation \ac{EBT} bleibt gleich. Nur der Algorithmus (ML-DSA-65 statt ed25519) ändert sich.

Die semi-stabile Geschäfts-Objekt-Schicht, das \ac{BO}, konkretisiert die abstrakten \ac{EBT}-Operationen in praktische Strukturen. \ac{BO}s sind nach Hamza intern adaptierbar durch sogenannte hooks, aber extern stabil \parencite[S. 1083]{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005}. Im PQC-Plugin sind die \ac{BO}s die DID-Verarbeitung mit W3C-konformen Strukturen, die Multicodec-Identifikatoren und die Key-Type-Registry mit ML-DSA-65 und ML-KEM-768. Bei zukünftiger Migration zu ML-KEM-1024 können neue Multicodec-Präfixe hinzugefügt werden, ohne die DIDComm-Schnittstellen zu brechen.

Konkret wird die Wallet Interface-Schicht nicht ersetzt, sondern erweitert. Das Aries-Askar-Backend bleibt funktionsfähig und verwaltet weiterhin klassische Kryptografie \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_}. Das Plugin registriert zusätzlich neue Operationsmethoden wie ML-DSA-65-Signaturen, ML-KEM-768-Key-Encapsulation sowie Speicherfunktionen für größere Schlüssellängen in SQLite mit ChaCha20-Poly1305-Verschlüsselung. Die Key-Type-Registry und \gls{DIDComm}-Verschlüsselung werden ebenfalls dynamisch erweitert. Das Plugin registriert ML-DSA-65 und ML-KEM-768 als vollwertige Schlüsseltypen neben den klassischen Varianten ed25519 und x25519 \parencite{openwallet-foundation_AcapyAcapy_agentWalletkey_typepymainopenwalletfoundationacapyGitHub_}. Die \gls{DIDComm}-Verschlüsselung wird orthogonal erweitert, sodass PQC-Nachrichten ML-KEM-768-Key-Encapsulation nutzen. Diese Erweiterungen verdeutlichen die BO-Struktur, indem neue Algorithmen intern hinzugefügt werden, während die externen Schnittstellen stabil bleiben.

Die volatile Implementierungs-Ebene, das \ac{IO}, adressiert Framework-spezifische Implementierungsdetails, die sich bei \ac{ACA-Py}-Updates ändern. Nach \textcite[S. 1--2]{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005} sind \ac{IO}s konkrete Repräsentationen der \ac{BO}s und sind volatil. Diese Volatilität wird bewusst isoliert, sodass Framework-Changes nicht die stabilen \ac{EBT}- und \ac{BO}-Module beeinflussen.

Konkret realisiert die Integration-Patching-Schicht die transparente Einbettung durch \gls{Monkey-Patching}. Kritische \ac{ACA-Py}-Funktionen werden zur Laufzeit überschrieben, ohne Quellcode zu ändern. Dies ermöglicht PQC-Operationen wie Schlüsselgenerierung, Signatur und Key-Encapsulation in bestehende Workflows. Das Plugin erlaubt auch hybride Modi, bei denen Agenten je nach Plugin-Ladezustand klassische oder quantenresistente Schlüssel erzeugen. Das Monkey-Patching ist auf die volatile \ac{IO}-Ebene beschränkt, sodass Framework-Updates nicht die stabilen \ac{EBT}- und \ac{BO}-Schichten destabilisieren.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{ACA-Py Applikationsarchitektur mit PQC-Integration}
    \caption{ACA-Py High Level Applikationsarchitektur mit PQC-Integration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung auf Basis von \autoref{fig:ACAPY_Application_Architecture_Iteration 1}.
    \end{flushleft}
    \label{fig:ACAPY_Application_Architecture_Iteration2_PQC}
\end{figure}

\subsection{Implementierung}

Die Implementierung der PQC-Unterstützung auf Application-Ebene folgt einem zweistufigen Ansatz. In der ersten Stufe wird das pqc\_didpeer4\_fm-Plugin entwickelt, das sich in den ACA-Py Plugin-Mechanismus nach \textcite{_ACAPyPluginsACAPyDocs_,_ACAPyPluginsACAPyPlugins_,openwallet-foundation_OpenwalletfoundationAcapyplugins_2025} einfügt. Das Plugin ist als Python-Paket strukturiert und definiert einen setup-Entrypoint, der beim Agent-Start aufgerufen wird. Über den PluginContext erhält das Plugin unmittelbaren Zugriff auf zentrale Agent-Komponenten wie die Wallet, das \gls{DIDComm}-System und die Protocol Registry. Diese Architektur ermöglicht es Plugins, neue Protokolle zu registrieren oder bestehende Funktionen durch Monkey-Patching zu erweitern, ohne den ACA-Py Kern zu modifizieren. Die zweite Stufe integriert das entwickelte Plugin in die containerisierte Deployment-Infrastruktur. Dabei wird das Plugin als Abhängigkeit in dem Dockerfile definiert, sodass es während des Container-Builds installiert wird. Anschließend erfolgt die Konfiguration über docker-compose, indem der ACA-Py Service mit den erforderlichen Umgebungsvariablen und Plugin-Parametern initialisiert wird.

Der Aufbau des PQC-Plugins gliedert sich in drei funktionale Schichten, in die die in \autoref{fig:pqc_didpeer4_fm_directory_structure} dargestellten 15 Module eingeteilt sind. Diese Architektur garantiert vollständige PQC-Funktionalität ohne Änderungen am ACA-Py-Quellcode.

Die Kryptografische Abstraktionsschicht bildet die Grundlage und abstrahiert die Komplexität der liboqs-C-Bibliothek durch ein Python-Wrapper-Modul (liboqs\_wrapper.py). Sie stellt einheitliche Operationen für ML-DSA-65 (digitale Signaturen) und ML-KEM-768 (Schlüsselencapsulation) bereit und garantiert, dass kryptografisches Schlüsselmaterial als Byte-Sequenzen serialisiert wird.

Die DID-Verarbeitungsschicht orchestriert die vollständige Lebenszyklusbearbeitung von PQC-fähigen did:peer:4-Identifikatoren. Dazu zählen, die Erzeugung und Auflösung (pqc\_peer4\_creator.py, pqc\_peer4\_resolver.py), W3C-konforme Multicodecs (pqc\_multicodec.py, pqc\_multikey.py) und standardisierte \gls{DIDComm}-Nachrichtenverschlüsselung (pqc\_didcomm\_v1.py). Diese Schicht verbindet kryptografische Primitive mit Identity-Protokollen und ermöglicht hybrid-sichere Kommunikation zwischen PQC- und klassischen Agenten.

Die Integration-Patching-Schicht implementiert die transparente Einbettung in ACA-Py durch gezieltes \gls{Monkey-Patching} und Registry-Erweiterungen. Neun spezialisierte Module patchen Wallet-Operationen (askar\_pqc\_patch.py, wallet\_patch.py), Connection-Management (base\_manager\_patch.py, connection\_target\_patch.py), Schlüsseltyp-Infrastruktur (key\_types.py, key\_type\_patches.py), Validierungslogik (validator\_patch.py), Multicodec-Registries (multicodec\_patch.py) und koordinieren deren Installation (monkey\_patches.py).

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 liboqs\_wrapper.py.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

\subsubsection{Pluginentwicklung: Kryptografie-Abstraktionsschicht}

Die Kryptografie-Abstraktionsschicht bildet die unterste Ebene der PQC-Integration und wird durch das Modul liboqs\_wrapper.py (\autoref{fig:pqc_didpeer4_fm_directory_structure_Kryptografie-Abstraktionsschicht}) realisiert. Dieses Modul kapselt die nativen Operationen der C-basierten liboqs-Bibliothek und stellt eine Python-API für die NIST-standardisierten PQC-Algorithmen ML-DSA-65 und ML-KEM-768 bereit.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_Kryptografie-Abstraktionsschicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 \textbf{liboqs\_wrapper.py}.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Die Implementierung (Listing~A-\ref{lst:liboqs_wrapper.py}) definiert eine LibOQSWrapper-Klasse mit sechs Kernmethoden. Die ersten beiden Methoden generate\_ml\_dsa\_65\_keypair() und generate\_ml\_kem\_768\_keypair() erzeugen kryptografische Schlüsselpaare. Die Methoden sign\_ml\_dsa\_65() und verify\_ml\_dsa\_65() implementieren digitale Signaturen, während encapsulate\_ml\_kem\_768() und decapsulate\_ml\_kem\_768() die Key Encapsulation für sichere Schlüsselvereinbarung realisieren.

Die Wrapper-Architektur abstrahiert die komplexen \ac{FFI}-Aufrufe an die liboqs-C-Bibliothek und stellt sicher, dass Schlüsselmaterial ausschließlich als Byte-Arrays serialisiert wird, was eine Voraussetzung für die Persistierung in der Aries-Askar-Wallet \parencite{_EntryAries_askarEntryRust_} und die Kodierung in Multicodec-Formaten \parencite{multiformats_MultiformatsMulticodec_2025} darstellt. Das Singleton-Pattern (get\_liboqs()) gewährleistet eine einzige globale Instanz zur Vermeidung redundanter Initialisierungen. Diese Abstraktionsschicht ermöglicht es den höheren Modulen (\ac{DID}-Generierung, \gls{DIDComm}-Verschlüsselung), \ac{PQC}-Operationen durchzuführen, ohne direkte Abhängigkeiten zur liboqs-C-API zu haben.

\subsubsection{Pluginentwicklung: DID-Verarbeitungsschicht}

Die DID-Verarbeitungsschicht (siehe Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_DID-Verarbeitungsschicht}) orchestriert die Erzeugung, Auflösung und Kodierung von PQC-fähigen did:peer:4-Identifikatoren sowie die \gls{DIDComm}-Nachrichtenverschlüsselung. Diese Schicht umfasst sechs funktional gekoppelte Module, die gemeinsam eine standardkonforme Integration von Post-Quantum-Kryptografie in das did:peer:4-Ökosystem realisieren.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_DID-Verarbeitungsschicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 askar\_pqc\_patch.py.
.4 base\_manager\_patch.py.
.4 connection\_target\_patch.py.
.4 key\_type\_patches.py.
.4 key\_types.py.
.4 liboqs\_wrapper.py.
.4 monkey\_patches.py.
.4 multicodec\_patch.py.
.4 \textbf{pqc\_didcomm\_v1.py}.
.4 \textbf{pqc\_multicodec.py}.
.4 \textbf{pqc\_multikey.py}.
.4 \textbf{pqc\_peer4\_creator.py}.
.4 \textbf{pqc\_peer4\_resolver.py}.
.4 validator\_patch.py.
.4 wallet\_patch.py.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Das Modul pqc\_peer4\_creator.py (Listing~A-\ref{lst:pqc_peer4_creator.py}) implementiert die Funktion create\_pqc\_peer4\_did(), die aus zwei PQC-Schlüsselpaaren (ML-DSA-65 für authentication/assertionMethod, ML-KEM-768 für keyAgreement) einen did:peer:4-Long-Form-Identifier generiert. Die Schlüssel werden über die Wallet-API erzeugt, in Multikey-Format transformiert und als KeySpec-Objekte in einem did:peer:4-Input-Dokument strukturiert, wobei die Reihenfolge der Schlüssel deren Fragment-IDs determiniert (\#key-0 für Signaturen, \#key-1 für Verschlüsselung in recipientKeys). Das Gegenstück pqc\_peer4\_resolver.py (Listing~A-\ref{lst:pqc_peer4_resolver.py}) registriert einen DID-Resolver für die peer-Methode, der did:peer:4-Long-Form-DIDs in DID-Dokumente auflöst und dabei PQC-Multicodec-Präfixe korrekt dekodiert.

Die Multiformat-Kodierung nach \parencite[Kap. 5.6]{w3c_ControlledIdentifiersV11_2025} wird durch drei Module realisiert. Das Modul pqc\_multicodec.py (Listing~A-\ref{lst:pqc_multicodec.py}) definiert eine Multicodec-Registry mit provisorischen Präfixen (ML-DSA-65: 0xd065, ML-KEM-768: 0xe018) und stellt Wrapper-Funktionen (wrap\_pqc(), unwrap\_pqc()) für Präfix-Operationen bereit. Das Modul pqc\_multikey.py (Listing~A-\ref{lst:pqc_multikey.py}) transformiert Schlüsselinformationen in das Multikey-Format durch Verkettung von Multicodec-Präfix und Schlüsselmaterial sowie Base58-Kodierung mit Multibase-Präfix \enquote{z} (Base58btc), wodurch Multikeys wie \enquote{z6MNxxx...} (ML-DSA-65) oder \enquote{z6MK768xxx...} (ML-KEM-768) entstehen. Das Modul pqc\_didcomm\_v1.py (Listing~A-\ref{lst:pqc_didcomm_v1.py}) erweitert die \gls{DIDComm}-v1-Envelope-Verarbeitung um PQC-Unterstützung. Hier detektieren die beiden Methoden pack\_message\_pqc() und unpack\_message\_pqc() automatisch anhand der unterschiedlichen Schlüssellängen ob PQC- oder klassische Kryptografie verwendet werden muss, und generieren JWE-Envelopes mit angepassten Algorithmus-Headern. Die Content Encryption erfolgt weiterhin mit XChaCha20-Poly1305, während der Content Encryption Key mittels ML-KEM-768 Key Encapsulation für jeden Empfänger verschlüsselt wird. Diese Schicht ermöglicht eine hybride Betriebsweise, bei der PQC- und klassische Agenten koexistieren können, solange jeweils homogene Verschlüsselungsmodi verwendet werden.

\subsubsection{Pluginentwicklung: Integration-Patching-Schicht}

Die Integration-Patching-Schicht (Abbildung~\ref{fig:pqc_didpeer4_fm_directory_structure_Integration-Patching-Schicht}) implementiert die transparente Einbettung der PQC-Funktionalität in den ACA-Py-Kern durch gezieltes Monkey-Patching kritischer Funktionen und Erweiterung globaler Registries. Diese Schicht umfasst neun Module, die gemeinsam eine vollständig transparente PQC-Integration ohne Modifikation des ACA-Py-Quellcodes ermöglichen, sodass existierende Workflows und API-Aufrufe unverändert funktionsfähig bleiben.

\begin{figure}[H]
  \flushleft
  \caption{Verzeichnisstruktur des Projekts}
  \label{fig:pqc_didpeer4_fm_directory_structure_Integration-Patching-Schicht}
\dirtree{%
.1 pqc\_didpeer4\_fm/.
.2 pqc\_didpeer4\_fm/.
.3 v1\_0/.
.4 \textbf{askar\_pqc\_patch.py}.
.4 \textbf{base\_manager\_patch.py}.
.4 \textbf{connection\_target\_patch.py}.
.4 \textbf{key\_type\_patches.py}.
.4 \textbf{key\_types.py}.
.4 liboqs\_wrapper.py.
.4 \textbf{monkey\_patches.py}.
.4 \textbf{multicodec\_patch.py}.
.4 pqc\_didcomm\_v1.py.
.4 pqc\_multicodec.py.
.4 pqc\_multikey.py.
.4 pqc\_peer4\_creator.py.
.4 pqc\_peer4\_resolver.py.
.4 \textbf{validator\_patch.py}.
.4 \textbf{wallet\_patch.py}.
.3 \_\_init\_\_.py.
.2 README.md.
.2 setup.py.
}
\begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
\end{flushleft}
\end{figure}

Das zentrale Orchestrierungsmodul monkey\_patches.py (Listing~A-\ref{lst:monkey_patches.py}) koordiniert die Installation aller Patches durch die Funktion apply\_all\_patches(), die beim Plugin-Setup aufgerufen wird. Dieses Modul überschreibt Methoden der Klasse BaseConnectionManager (create\_did\_peer\_4(), \_extract\_key\_material\_in\_base58\_format(), long\_did\_peer\_4\_to\_short()) und delegiert deren Implementierung an spezialisierte Patch-Module, wobei die ursprünglichen Methoden als Fallback-Referenzen gespeichert werden. Das Modul base\_manager\_patch.py (Listing~A-\ref{lst:base_manager_patch.py}) stellt die PQC-Implementierungen dieser BaseConnectionManager-Methoden bereit. Die Methode create\_did\_peer\_4\_pqc\_complete() generiert did:peer:4-DIDs mit ML-DSA-65- und ML-KEM-768-Schlüsseln anstelle klassischer ED25519/X25519-Schlüssel, die Methode \_extract\_key\_material\_in\_base58\_format\_pqc() extrahiert PQC-Schlüsselmaterial aus DID-Dokumenten unter Berücksichtigung der größeren Schlüssellängen, und die Methode record\_keys\_for\_resolvable\_did\_pqc() persistiert beide PQC-Schlüssel (Signatur- und Verschlüsselungsschlüssel) in der Wallet-Datenbank.

Die Wallet-Integration erfolgt durch drei Module. Das Modul askar\_pqc\_patch.py (Listing~A-\ref{lst:askar_pqc_patch.py}) patcht die Aries-Askar-Funktionen create\_keypair() zur Unterstützung von PQC-Schlüsselgenerierung mittels liboqs sowie pack\_message() und unpack\_message() zur Integration der PQC-DIDComm-v1-Implementierung aus pqc\_didcomm\_v1.py. Das Modul wallet\_patch.py (Listing~A-\ref{lst:wallet_patch.py}) erweitert die Methode get\_local\_did\_for\_verkey() der AskarWallet-Klasse, um ML-KEM-768-Verkeys korrekt in der Datenbank zu lokalisieren. Dies stellt eine kritische Anpassung dar, da klassische Verkey-Lookups, wie in der Originalmethode get\_local\_did\_for\_verkey() \parencite{openwallet-foundation_AcapyAcapy_agentWalletaskarpymainopenwalletfoundationacapyGitHub_} demonstriert, nur für 32-Byte-ED25519-Schlüssel ausgelegt sind. Das Modul connection\_target\_patch.py (Listing~A-\ref{lst:connection_target_patch.py}) passt das Marshmallow-Schema der ConnectionTarget-Klasse an, indem die Validierungsregeln für recipient\_keys PQC-konforme Schlüssellängen akzeptieren.

Die Erweiterung der Schlüsseltyp-Infrastruktur erfolgt durch zwei Module. Das Modul key\_types.py (Listing~A-\ref{lst:key_types.py}) definiert neue KeyType-Konstanten (ML\_DSA\_65, ML\_KEM\_768) mit Metadaten wie NIST-FIPS-Referenzen, Schlüssellängen und Multicodec-Präfixen. Das Modul key\_type\_patches.py (Listing~A-\ref{lst:key_type_patches.py}) registriert diese KeyTypes in der globalen ACA-Py-Registry durch register\_pqc\_key\_types(), erweitert die Admin-API-Schemata (patch\_api\_key\_type\_schemas()) zur Akzeptanz von PQC-KeyType-Strings in JSON-Requests, und patcht Algorithmus-Mappings (patch\_alg\_mappings\_for\_pqc()) für JWS/JWE-Header-Generierung. Das Modul multicodec\_patch.py (Listing~A-\ref{lst:multicodec_patch.py}) erweitert die globale SupportedCodecs-Enumeration durch dynamisches Hinzufügen von ML-DSA-65- und ML-KEM-768-Multicodec-Einträgen, sodass Multicodec-Dekodierungsfunktionen aus multiformats-Bibliotheken PQC-Präfixe verarbeiten können.

Das Modul validator\_patch.py (Listing~A-\ref{lst:validator_patch.py}) patcht die JWSHeaderKid-Validierungsklasse, die standardmäßig nur klassische DID-Formate (did:key, did:sov) in JWS-Header-kid-Feldern akzeptiert, um did:peer:4-Identifier zu unterstützen. Dies ist eine Voraussetzung für ML-DSA-65-signierte DID-Exchange-AttachDecorators. 

Diese neun Module bilden gemeinsam eine Patch-Architektur, die durch sequenzielle Installation beim Plugin-Setup (orchestriert in \_\_init\_\_.py) eine vollständige PQC-Funktionalität in ACA-Py injiziert, ohne dass Änderungen an Controllern, Admin-API-Endpunkten oder externen Business-Logic-Schichten erforderlich sind.

\subsubsection{Dockerfile-Modifikation}

In der zweiten Iteration wurde das ACA-Py Docker-Base-Image (Listing~A-\ref{lst:Dockerfile-acapy-base}) aus der ersten Iteration (Kapitel~\ref{SSI-Agenten}) auf einen vier-stufigen Multi-Stage-Build erweitert (Listing~A-\ref{lst:Dockerfile-acapy-base-pqc} visualisiert dargestellt in \autoref{fig:Iteration2_Acapy_Multi_Stage_Build}).

Die ersten beiden Stufen widmen sich dem kryptografischen Fundament. Da aktuelle Distributionen die benötigten Verfahren noch nicht beinhalten, werden die Bibliotheken hier direkt aus dem Quellcode kompiliert. In der ersten Stufe wird OpenSSL in der Version 3.5.4 gebaut. Dabei werden gezielt Parameter gesetzt, die das Modul auf FIPS-Konformität vorbereiten, was für den späteren Einsatz in kritischen Infrastrukturen relevant ist. Parallel dazu wird in der zweiten Stufe die liboqs-Bibliothek erstellt. Sie fungiert als Backend für die PQC-Algorithmen und wird so konfiguriert, dass sie als dynamische Bibliothek vorliegt und später nahtlos von der Python-Umgebung eingebunden werden kann.

Die dritte Stufe konzentriert sich anschließend isoliert auf die Anwendungsebene. Hier wird der ACA-Py-Agent mithilfe des Tools Poetry  in ein installierbares Python-Paket verpackt. Diese methodische Trennung hat den Vorteil, dass reine Entwicklungswerkzeuge nicht in das finale Image übernommen werden müssen, was den Speicherbedarf reduziert und die Sicherheit erhöht.

Die dritte Stufe konzentriert sich anschließend isoliert auf die Anwendungsebene. Hier wird der ACA-Py-Agent mithilfe des Tools Poetry \parencite{_PoetryPythonDependencymanagementpackagingmadeeasy_} in ein installierbares Python-Paket verpackt. Diese methodische Trennung setzt die wissenschaftliche Forderung nach einer Minimierung des \ac{TCB} nach \textcite[S. 27]{jarkas_ContainerSecuritySurveyExploitsAttacksDefenses_2025} um, indem reine Entwicklungswerkzeuge nicht in das finale Image übernommen werden. Somit wird der Speicherbedarf reduziert und die Sicherheit des Artefakts durch eine verringerte Angriffsfläche erhöht.

In der finalen Stufe fließen alle vorbereiteten Komponenten zusammen. Der technisch wichtigste Schritt ist hierbei der Austausch der Standard-Kryptografie. Durch das gezielte Überschreiben von Systemverknüpfungen wird erzwungen, dass sowohl das Betriebssystem als auch die Python-Laufzeitumgebung automatisch auf die zuvor kompilierte, PQC-fähige OpenSSL-Version zugreifen. Zusätzlich wird das eigene Root-Zertifikat in den Vertrauensspeicher importiert, damit sichere TLS-Verbindungen korrekt validiert werden können. Den Abschluss bildet die Installation des spezifischen Plugins, das die erweiterte Logik für die Verarbeitung der dezentralen Identifikatoren bereitstellt.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{Iteration2_Acapy_Multi_Stage Build}
    \caption{ACA-Py Multi-Stage Build Dockerfile mit PQC-Integration (Iteration 2)}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Iteration2_Acapy_Multi_Stage_Build}
\end{figure}

% Stage~1 kompiliert OpenSSL~3.5.4 mit FIPS-Modul und nativer ML-KEM/ML-DSA-Unterstützung, Stage~2 baut liboqs~0.14.0 als Shared Library, Stage~3 bleibt identisch zur ersten Iteration (Poetry-basiertes ACA-Py-Wheel), und Stage~4 integriert alle Artefakte durch \enquote{COPY --from}-Direktiven aus den Builder-Stages. Die Runtime-Stage überschreibt System-OpenSSL-Symlinks mittels \enquote{ln -sf}, aktualisiert Shared-Library-Pfade via \enquote{ldconfig}, importiert das PQC-Root-CA-Zertifikat in den System-Trust-Store (\enquote{update-ca-certificates}), und installiert das pqc\_didpeer4\_fm-Plugin mithilfe von \enquote{pip} direkt in das Container-Image.

\subsubsection{Deployment in docker-compose.yml}

Das Deployment der PQC-fähigen SSI-Agenten erfolgt innerhalb der in der ersten Iteration (Kapitel~\ref{sec:Docker Orchestrierung der Gesamtarchitektur}) entwickelten docker-compose.yml-Orchestrierung, deren Evolution vom klassischen Setup (erste Iteration, Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten}) zur PQC-Integration (zweite Iteration, Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten-mit-acapy-base-pqc-und-plugin}) zwei zentrale Anpassungen umfasst. Während die Konfiguration der ersten Iteration noch das klassische ACA-Py-Base-Image ohne PQC-Unterstützung und Plugin-Aktivierung verwendet, wurde in der zweiten Iteration im Rahmen der ersten Anpassung die docker-compose.yml so modifiziert, dass alle drei Agent-Services (issuer, holder, verifier) das neue acapy-base-pqc-Image nutzen in welchem das pqc\_didpeer4\_fm-Plugin enthalten ist. Diese Änderung kann durch den Vergleich von \autoref{fig:Docker-Compose-Übersicht-Iteration-2} mit \autoref{fig:Docker-Compose-Übersicht-Iteration-1} nachvollzogen werden. Die zweite Anpassung erweitert die command-Direktive aller drei Agenten um den Parameter \enquote{--plugin pqc\_didpeer4\_fm}, der beim Agent start das pqc\_didpeer4\_fm-Plugin lädt.

\subsection{Formative Evaluation}
\label{sec:formative_evaluation_iteration2}

In Übereinstimmung mit dem in Kapitel~\ref{sec:Schritt4-Design der individuellen Evaluationsepisoden} entworfenen Evaluationsdesign setzt dieser Abschnitt die zweite definierte Evaluationsepisode (\autoref{tab:eval_episodes}) um. Charakterisiert als formative und artifizielle Untersuchung, liegt der Fokus dieser Phase exklusiv auf der Validierung der Plugin-Integrationsarchitektur sowie der korrekten Funktionalität der kryptographischen Abstraktionsschichten während der Agent-Laufzeit. Ziel ist es, gemäß den Prinzipien von \textcite[S. 6, 7]{venable_FEDSFrameworkEvaluationDesignScienceResearch_2016} Designfehler in der Monkey-Patching-Strategie und der DID-Verarbeitungskette frühzeitig zu identifizieren und die Integrationsfähigkeit der Post-Quantum-Kryptographie in die bestehende ACA-Py-Infrastruktur nachzuweisen.

Zentrale Evaluationsziele dieser Phase sind die Korrektheit des Plugin-Ladevorgangs bei der Agenten-Initialisierung sowie die Validierung der Post-Quantum-Funktionalität im Kontext von did:peer:4-basierter Identifiziererstellung. Methodisch erfolgt die Evaluation durch kontrollierten White-Box-Testing \parencite[S. 10]{myers_ArtSoftwareTesting_2012} und Log-Analyse der kritischen Initialisierungsphasen.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{docker_compose_übersicht_pqc_plugin.png}
    \caption{Docker-Compose-Übersicht der zweiten Iteration}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Docker-Compose-Übersicht-Iteration-2}
\end{figure}

\subsubsection{Validierung des Plugin-Ladevorgangs bei Agent-Start}

Die erste formative Evaluationsmaßnahme bestand in der Validierung des korrekten Plugin-Ladevorgangs beim Start eines ACA-Py-Agenten. Dieser Test diente der Sicherstellung, dass die PQC-Integration transparent und ohne Beeinträchtigung der Standard-ACA-Py-Funktionalität erfolgt.

Listing~A-\ref{lst:Issuer-Agent-Boot-Logs} zeigt den Boot-Prozess eines Standard-ACA-Py-Agenten ohne PQC-Plugin. Nach der Registrierung der Default- und Askar-Plugins wird direkt mit der Ledger-Konfiguration und Wallet-Initialisierung fortgefahren. Im Vergleich dazu zeigt Listing~A-\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin} den erweiterten Boot-Prozess mit geladenem pqc\_didpeer4\_fm-Plugin. Zwischen der Askar-Plugin-Registrierung und der Ledger-Konfiguration erfolgt nun die Plugin-Initialisierung mit mehreren charakteristischen Schritten.

\begin{enumerate}
\item Askar-Patching: Die \_create\_keypair-Funktion wird durch eine PQC-fähige Variante ersetzt, die ML-DSA-65 und ML-KEM-768 unterstützt. Zusätzlich werden Session-Methoden (insert\_key, fetch\_key, update\_key) und AskarWallet.assign\_kid\_to\_key() gepatcht.
\item KeyType-Registry-Erweiterung: Die neuen Schlüsseltypen ml-dsa-65 und ml-kem-768 werden in der ACA-Py KeyTypes-Registry registriert und die API-Schemas zur Laufzeit erweitert.
\item did:peer:4-Erweiterung: Die unterstützten Schlüsseltypen für did:peer:4 werden von ['ed25519', 'x25519'] auf ['ed25519', 'x25519', 'ml-dsa-65', 'ml-kem-768'] erweitert.
\item Multicodec-Patching: Die SupportedCodecs-Klasse wird für PQC-Multicodec-Präfixe erweitert (ML-DSA-65: 0xd065, ML-KEM-768: 0xe018).
\item \gls{DIDComm}-Patching: AskarWallet.pack\_message() und unpack\_message() werden für ML-KEM-768-basierte Verschlüsselung angepasst. Die AttachDecorator-Klasse wird für ML-DSA-65-JWS-Signaturen erweitert.
\item Monkey-Patches: Die BaseConnectionManager-Methoden (create\_did\_peer\_4, record\_keys\_for\_resolvable\_did, etc.) werden durch PQC-fähige Varianten ersetzt.
\end{enumerate}

\subsubsection{Validierung der Pluginfunktionalität}

Die zweite formative Evaluationsmaßnahme validierte die Kernfunktionalität des Plugins, die transparente Erstellung von PQC-fähigen did:peer:4-DIDs während des Out-of-Band-Invitation-Prozesses.

Listing~\ref{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-vor-OOB-Invitation} zeigt die initiale Wallet-Abfrage eines frisch gestarteten Issuer-Agenten. Das leere results-Array bestätigt, dass noch keine DIDs im Wallet vorhanden sind.

\refstepcounter{manualListingCounter}
\label{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-vor-OOB-Invitation}
\begin{lstlisting}[language=bash, caption={Zweite Iteration - Wallet DID Abfrage vor Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X GET https://host.docker.internal:8021/wallet/did | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    15  100    15    0     0   1083      0 --:--:-- --:--:-- --:--:--  1153
{
  "results": []
}
\end{lstlisting}

Anschließend wurde mittels \enquote{POST /out-of-band/create-invitation} mit dem Parameter \enquote{use\_did\_method: 'did:peer:4'} eine Einladung erstellt (Listing~\ref{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}). Die API-Response enthält eine vollständige did:peer:4-Langform-DID im services-Array der Invitation, erkennbar am charakteristischen Format \enquote{did:peer:4zQm...:z25g...}.

\refstepcounter{manualListingCounter}
\label{lst:Issuer-Agent-Boot-Logs-mit-PQC-Plugin}
\begin{lstlisting}[language=bash, caption={Zweite Iteration - Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X POST https://host.docker.internal:8021/out-of-band/create-invitation     -H "Content-Type: application/json"     -d '{
      "handshake_protocols": ["https://didcomm.org/didexchange/1.1"],
      "use_did_method": "did:peer:4",
      "my_label": "Issuer Test"
    }' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 16198  100 16051  100   147  91160    834 --:--:-- --:--:-- --:--:-- 91514
{
  "state": "initial",
  "trace": false,
  "invi_msg_id": "89e9cc87-318f-49aa-a61a-fc805706cd8d",
  "oob_id": "70998122-5a5b-4020-8b5f-ae5884af20b3",
  "invitation": {
    "@type": "https://didcomm.org/out-of-band/1.1/invitation",
    "@id": "89e9cc87-318f-49aa-a61a-fc805706cd8d",
    "label": "Issuer Test",
    "handshake_protocols": [
      "https://didcomm.org/didexchange/1.1"
    ],
    "services": [
      "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc..."
    ]
  },
  "invitation_url": "https://host.docker.internal:8020?oob=eyJAdHlwZSI6ICJodHR..."
}
\end{lstlisting}

Die entscheidende Validierung erfolgt in Listing~\ref{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-nach-OOB-Invitation} durch eine erneute Wallet-Abfrage nach der Invitation-Erstellung. Die Response zeigt nun die automatisch generierte PQC-DID mit folgenden charakteristischen Merkmalen:

\begin{itemize}
\item Dual-Key-Struktur: Das key\_type-Feld weist den Wert ml-dsa-65 auf, während die Metadata zusätzlich kem\_verkey (ML-KEM-768) enthält. Dies bestätigt die erfolgreiche Implementierung der Hybrid-Kryptografie mit getrennten Schlüsseln für digitale Signaturen und Schlüsselvereinbarung.
\item PQC-Metadata: Die Metadaten enthalten explizite Marker (pqc\_enabled: true, signature\_algorithm: "ml-dsa-65", key\_agreement\_algorithm: "ml-kem-768"), die eine eindeutige Identifikation PQC-fähiger DIDs zur Laufzeit ermöglichen.
\item Key Identifier: Das kem\_key\_kid-Feld referenziert den KEM-Schlüssel über den DID-URL-Fragment-Identifier \#key-1, was der did:peer:4-Spezifikation entspricht, bei der Verification-Methods sequenziell nummeriert werden (\#key-0 für Authentication, \#key-1 für Key Agreement).
\end{itemize}

\refstepcounter{manualListingCounter}
\label{lst:Iteration2_Validierung-der-Pluginfunktionalität-Wallet-DID-Abfrage-nach-OOB-Invitation}
\begin{lstlisting}[language=bash, caption={Zweite Iteration - Wallet DID Abfrage nach Out-of-Band Invitation}, numbers=left, frame=single]
ferris@blockchain-ssi-pqc:~$ curl -X GET https://host.docker.internal:8021/wallet/did | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 17778  100 17778    0     0  1655k      0 --:--:-- --:--:-- --:--:-- 1736k
{
  "results": [
    {
      "did": "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc...",
      "verkey": "2BvJSsMeLjejWKygFBC1qFPLqUvvTzfed7y2Btp...",
      "posture": "wallet_only",
      "key_type": "ml-dsa-65",
      "method": "did:peer:4",
      "metadata": {
        "invitation_reuse": "true",
        "pqc_enabled": true,
        "signature_algorithm": "ml-dsa-65",
        "key_agreement_algorithm": "ml-kem-768",
        "kem_key_kid": "did:peer:4zQmYFdntsqaiZcU9PMf4dVshmxyTu5yk3NnkA28VjHqaySm:z25gYmQoBS9XWQbLxdKXKizWUz5MxCWwLc...D6SUGP43VJWg#key-1",
        "kem_verkey": "h6ngVfG9n2qF1SY5gM3DaDhK9iiwhvnW555QtodD1sgvEcg5...",
        "plugin": "pqc_didpeer4_fm",
        "version": "0.1.0"
      }
    }
  ]
}
\end{lstlisting}

\subsection{Finales Artefakt}

Das finale Artefakt der zweiten Iteration repräsentiert einen durchgängig quantensicheren \ac{SSI}-Prototypen mit nativer \ac{PQC}-Integration auf der Anwendungsebene. Die Architektur vereint die in der ersten Iteration etablierte Transport-Layer-Sicherung mittels PQC-Sidecar-Proxies mit einer tiefgreifenden Applikationsschicht-Integration durch das entwickelte PQC-Plugin-System. Diese duale Strategie gewährleistet nicht nur die Absicherung von \gls{Data-In-Motion}, sondern auch die langfristige Authentizität und Integrität von \gls{Data-At-Rest}.

Die Kernkomponente bildet das ACA-Py-Plugin mit dreischichtiger Architektur nach dem in Kapitel~\ref{sec:ACA-Py Applikationsarchitektur} beschriebenen Software Stability Model. Zur Realisierung langfristiger Wartbarkeit folgt das Plugin intern dem Ansatz der Separation of Concerns for Evolving Systems nach Hamza, der Systeme entlang der Stabilitätsdimension dekomponiert, um die Notwendigkeit zur Neu-Separation bei System-Evolution zu minimieren \parencite[S. 1]{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005}.

Die stabile Kern-Ebene (\ac{EBT}) kapselt native liboqs~0.14.0-Operationen als abstrakte Kryptografie-Primitiva für ML-DSA-65 und ML-KEM-768. Diese Abstraktionsschicht ist unabhängig vom konkreten Algorithmus und bleibt stabil. Wenn zukünftig ML-DSA-87 verwendet wird, ändert sich nur die Implementierung, nicht die Schnittstelle. Nach Hamza sind \ac{EBT}s die Basis für Stabilität, da Systeme ohne \ac{EBT}s bei Änderungen neu separiert werden müssen \parencite[S. 1--2]{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005}.

Die semi-stabile Geschäfts-Objekt-Schicht (\ac{BO}) orchestriert die Generierung, Auflösung und Kodierung von PQC-fähigen did:peer:4-Identifikatoren sowie die DIDComm-Nachrichtenverschlüsselung. \ac{BO}s sind nach Hamza intern adaptierbar durch sogenannte hooks, aber extern stabil \parencite[S. 2]{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005}. Die \ac{BO}-Implementierung umfasst W3C-konforme DID-Verarbeitung, Multicodec-Identifikatoren und Key-Type-Registry-Erweiterungen. Bei Migration zu ML-KEM-1024 können neue Multicodec-Präfixe hinzugefügt werden, ohne die DIDComm-Schnittstellen zu brechen.

Die volatile Implementierungs-Ebene (\ac{IO}) realisiert transparentes Monkey-Patching kritischer ACA-Py-Kernfunktionen (Wallet, Key-Type-Registry, \gls{DIDComm}-Verschlüsselung) ohne Modifikation des Framework-Quellcodes. Dies ermöglicht eine hybride Betriebsweise, bei der Agenten je nach Plugin-Ladezustand klassische oder quantenresistente Schlüssel erzeugen. Nach Hamza sollten Änderungen an \ac{IO}-Modulen, wie beispielsweise der Austausch von Speichersystemen, nicht die stabileren Schichten \ac{EBT} und \ac{BO} beeinflussen \parencite[S. 4]{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005}.

Hinsichtlich der in Kapitel~\ref{sec:Designziele_Iteration_2} definierten Designziele erfüllt das finale Artefakt sämtliche Anforderungen der zweiten Iteration vollständig. Das Designziel zu FF1 (Systemarchitektur \& Compliance) wird durch die native Unterstützung quantenresistenter Signaturen in DID-Dokumenten und Verifiable Credentials adressiert. Das Designziel zu FF2 (Algorithmenauswahl \& Sicherheitsbewertung) manifestiert sich in der erfolgreichen Integration von ML-DSA-65 für digitale Signaturen und ML-KEM-768 für Key-Encapsulation innerhalb der did:peer:4-Strukturen. Das Designziel zu FF3 (Kryptografische Agilität) wird durch die dreischichtige Separation nach \parencite{hamza_SeparationConcernsEvolvingsystemsstabilitydrivenapproach_2005} realisiert. Neue Algorithmen können durch \ac{BO}-Erweiterung integriert werden, ohne \ac{EBT} zu ändern (Extensibility). Degradierte Algorithmen können durch Konfigurationsänderung deaktiviert werden, ohne dass die Kern-Architektur modifiziert wird (Reversibility). Die nahtlose Koexistenz und der hybride Betrieb zwischen klassischen Verfahren und \ac{PQC}-Verfahren erfolgen ohne Beeinträchtigung der Interoperabilität, da die abstrahierte Kryptografie-Schicht die unterschiedlichen Algorithmen transparent verwaltet. Das Plugin kann vollständig deaktiviert werden, ohne dass die zugrunde liegende \ac{ACA-Py}-Architektur destabilisiert wird.

Die formative Evaluation in Kapitel~\ref{sec:formative_evaluation_iteration2} validierte die funktionale Korrektheit durch die erfolgreiche Plugin-Registrierung und Boot-Logging bei der Agenten-Initialisierung, die korrekte Generierung von did:peer:4-Long-Form-DIDs mit ML-DSA-65-Signaturmaterial, die erfolgreiche Out-of-Band-Invitation mit anschließender Wallet-Persistierung von PQC-Metadaten und die fehlerfreie Integration des Monkey-Patching-Systems in alle vier klassischen Applikationsschichten.

\newpage
\section{Summative Evaluation} \label{sec:Summative Evaluation}
        
Die summative Evaluation validiert das finale Artefakt gegen die in Kapitel~\ref{sec:FEDS-Framework} definierten Evaluationsziele sowie die funktionalen und Compliance-Anforderungen aus Kapitel~\ref{sec:Anforderungsanalyse}. Im Gegensatz zu den formativen Evaluationsepisoden (Kapitel~\ref{sec:formative_evaluation_iteration1} und Kapitel~\ref{sec:formative_evaluation_iteration2}), die modulare Einzelkomponenten prüften, erfolgt die summative Evaluation als systematische Requirement-Tracing am integrierten Gesamtsystem. Das Ziel besteht im rigorosen Nachweis der Efficacy und Fidelity, um die technische Machbarkeit und regulatorische Konformität des \ac{PQC}-basierten \ac{SSI}-Prototypen für \ac{KRITIS} zu demonstrieren.

Die Evaluierung wird anhand eines domänenrealistischen \ac{KRITIS}-Szenarios durchgeführt (\ref{sec:Anhang_KRITIS Szenario}), das einen Notfall-Wartungszertifizierungsprozess in einem Stromversorgungsnetz abbildet und alle sechs funktionalen Anforderungen integriert. Die detaillierte technische Dokumentation ist in \ref{sec:Anhang_Summative Evaluation} aufgeführt und referenziert Jupyter-Notebook-Cells (Listing~A-\ref{lst:Jupyter-Notebook-Cell-1} bis Listing~A-\ref{lst:Jupyter-Notebook-Cell-23}).

Bevor die eigentliche Validierung der funktionalen Anforderungen beginnt, ist zunächst die Initialisierung des Artefakts erforderlich. Das technische Setup deklariert zentrale Variablen, Basis-URLs der Admin-APIs sowie Hilfsfunktionen zur HTTP-Kommunikation (Listing~A-\ref{lst:Jupyter-Notebook-Cell-1}). Auf dieser Grundlage wird die Infrastruktur überprüft und die erfolgreiche Ledger-Initialisierung durch Abruf der Genesis-Transaktionen und Validator-Node-Registrierungen nachgewiesen, womit alle benötigten Kernkomponenten (Indy-Ledger, Validator-Nodes, Tails-Server) in konsistentem Zustand vorliegen (Listing~A-\ref{lst:Jupyter-Notebook-Cell-2-output}).

Die domänenrelevante Identitätsinfrastruktur für den KRITIS-Issuer wird vorbereitet durch lokale Erzeugung einer neuen Indy-DID als kryptographische Identität des Energienetzbetreibers (Listing~A-\ref{lst:Jupyter-Notebook-Cell-3-output}). Diese DID wird via NYM-Transaktion als ENDORSER auf dem Ledger registriert, womit der Issuer als vertrauenswürdiger Teilnehmer verankert wird (Listing~A-\ref{lst:Jupyter-Notebook-Cell-4-output}). Die Wallet-Ansicht bestätigt das Ed25519-Schlüsselmaterial und Status \enquote{posted=true}, womit die On-Ledger-Publikation nachgewiesen wird (Listing~A-\ref{lst:Jupyter-Notebook-Cell-5-output}).

Die fachlichen Grundlagen für die Zertifikatsausstellung werden geschaffen durch ein spezifisches Schema für das KRITIS-Notfall-Wartungszertifikat mit neun Attributen (Identität, Berechtigung, Zeitgültigkeit) (Listing~A-\ref{lst:Jupyter-Notebook-Cell-6-output}). Eine issuer-spezifische Credential Definition mit zugehöriger Revocation Registry wird erzeugt, die kryptographische Parameter und Revokationsmechanismen festlegt (Listing~A-\ref{lst:Jupyter-Notebook-Cell-7-output}). Mit Abschluss dieser Initialisierungsschritte liegt ein vollständig instanziiertes Artefakt auf reproduzierbarem, domänenkonsistentem Fundament vor.

\subsection{Validierung der funktionalen Anforderungen}
\label{sec:Validierung der funktionalen Anforderungen}

\subsubsection{Issuer Discovery}

Die funktionale Anforderung FR1 fordert, dass das System die Auffindbarkeit von publizierten Credential-Schemata des Issuers digitaler Identitätsnachweise ermöglichen muss. Die Erfüllung dieser Anforderung an das finale Artefakt wird anhand eines dreiphasigen, Ledger-basierten Discovery-Mechanismus demonstriert (Listing~A-\ref{lst:Jupyter-Notebook-Cell-8} und Listing~A-\ref{lst:Jupyter-Notebook-Cell-8-output}). 

Phase 1 extrahiert alle TRUST\_ANCHOR-Identitäten (Role '101') aus NYM-Transaktionen des Domain Ledgers, wobei im KRITIS-Szenario der Issuer \enquote{Energienetzbetreiber} mit DID \enquote{9pbXiFBZZGwXKp61HQBz3J} identifiziert wird (Listing~A-\ref{lst:Jupyter-Notebook-Cell-8-output}). 

Phase 2 verifiziert sechs kryptographische Eigenschaften (DID-Identifier, Ed25519-Verkey, TRUST\_ANCHOR-Role, Endorser, On-Ledger-Aktivitäten, Registrierungszeitpunkt) mittels der Funktion verify\_issuer\_identity(), wobei für den identifizierten Issuer alle Eigenschaften erfolgreich validiert werden (Listing~A-\ref{lst:Jupyter-Notebook-Cell-8-output}). 

Phase 3 filtert SCHEMA-Transaktionen nach dem Schema-Namen \enquote{kritis\_emergency\_maintenance\_cert}, extrahiert den Issuer-DID aus dem Schema-Identifier-Format \enquote{<issuer\_did>:2:<schema\_name>:<version>} und führt eine Cross-Referenzierung mit den TRUST\_ANCHOR-Identitäten durch (Listing~A-\ref{lst:Jupyter-Notebook-Cell-8-output}).


\subsubsection{Connection Creation}

Die funktionale Anforderung FR2 verlangt die Etablierung von Verbindungen zwischen SSI-Akteuren. Dies wird mittels eines dreiphasigen Out-of-Band-Protokoll-Workflows mit did:peer:4-basierter Post-Quantum-Kryptographie demonstriert.

Phase~1 implementiert einen Pre-Check existierender Connections via \enquote{GET /connections} auf beiden Agenten, um redundante Connection-Erstellungen zu vermeiden. Im KRITIS-Szenario werden keine existierenden Connections gefunden, wodurch eine neue Etablierung ausgelöst wird (Listing~A-\ref{lst:Jupyter-Notebook-Cell-9-output}).

Phase~2 realisiert die Connection-Etablierung mittels Aries RFC~0434 Out-of-Band Protocol \parencite{decentralized-identity_AriesrfcsFeatures0434outofbandREADMEmdmaindecentralizedidentityariesrfcs_}. Der Inviter erstellt eine Invitation mit \enquote{use\_did\_method: 'did:peer:4'} und erhält eine invitation\_msg\_id als eindeutigen Identifier (Listing~A-\ref{lst:Jupyter-Notebook-Cell-9-output}). Der Invitee akzeptiert die Invitation, wodurch das DIDExchange-Protokoll did:peer:4-DIDs mit ML-DSA-65- sowie ML-KEM-768-Schlüsselmaterial generiert (Listing~A-\ref{lst:Jupyter-Notebook-Cell-10-output} und Listing~A-\ref{lst:Jupyter-Notebook-Cell-12-output}). Die resultierenden DID-Metadaten bestätigen \enquote{pqc\_enabled: true}, \enquote{signature\_algorithm: ml-dsa-65} und \enquote{key\_agreement\_algorithm: ml-kem-768}.

Phase~3 validiert die Connection-Konsistenz durch Vergleich der invitation\_msg\_id, komplementärer their\_role-Werte (inviter/invitee) und beidseitigen State active (Listing~A-\ref{lst:Jupyter-Notebook-Cell-9-output}). Die Connection-Übersicht (Listing~A-\ref{lst:Jupyter-Notebook-Cell-11-output}) zeigt zwei aktive Connection-Paare: Issuer\,$\leftrightarrow$\,Holder und Holder\,$\leftrightarrow$\,Verifier, womit die vollständige Konnektivität des SSI-Dreiecks nachgewiesen wird.

\subsubsection{Credential Creation}

Die funktionale Anforderung FR3 fordert, dass das System Funktionalität zur Erstellung und Ausstellung digitaler Credentials bereitstellen muss. Die Erfüllung wird anhand eines mehrstufigen Credential-Issuance-Workflows mit Revocation-Registry-Integration demonstriert.

Der Issuer initiiert die Credential-Ausstellung durch Versenden eines Credential Offers mit einer Credential Preview, die neun KRITIS-spezifische Attribute enthält (Identität: first\_name, name, organisation; Berechtigung: cert\_type, facility\_type, security\_clearance\_level; Zeitgültigkeit: epoch\_valid\_from, epoch\_valid\_until; Rolle: role), wobei die Ausstellung über die in FR2 etablierte connection\_id und die in FR1 identifizierte cred\_def\_id erfolgt (Listing~A-\ref{lst:Jupyter-Notebook-Cell-13-output}). Der Holder akzeptiert das Offer automatisch, wodurch das Aries RFC~0453 Issue Credential v2.0 Protocol \parencite{decentralized-identity_AriesrfcsFeatures0453issuecredentialv2maindecentralizedidentityariesrfcsGitHub_} den vollständigen State-Machine-Durchlauf (offer-sent --> request-sent --> credential-issued --> done) ausführt und das Credential im Holder Wallet persistiert (Listing~A-\ref{lst:Jupyter-Notebook-Cell-13-output}).

Die Revocation-Registry-Integration extrahiert zwei kritische Identifier aus der Issuer-Exchange-Response. Die Revocation Registry ID identifiziert die auf dem Indy Ledger publizierte Revocation Registry (Type~113), während die Credential Revocation ID \enquote{1} die Position im Revocation-Accumulator spezifiziert (Listing~A-\ref{lst:Jupyter-Notebook-Cell-13-output}). Die Holder-Credentials-Übersicht (Listing~A-\ref{lst:Jupyter-Notebook-Cell-14-output}) zeigt das vollständig ausgestellte KRITIS-Notfall-Wartungszertifikat mit allen Attributen, dem Schema-Identifier aus FR1 und dem initialen Revoked-Status false, womit die Gültigkeit bestätigt wird.

\subsubsection{Verification with Credentials}

Die funktionale Anforderung FR4 fordert, dass das System einen Verifikationsprozess zwischen Identity Holder, Verifier und Blockchain-basierter Verifiable Data Registry durch Validierung eines Identitätsnachweises ermöglichen muss. Die Erfüllung wird anhand eines vierstufigen Privacy-Preserving-Verification-Workflows mit Zero-Knowledge-Proofs, Revocation-Detection und Zeitgültigkeitsprüfung demonstriert.

Der Verifier initiiert den Verifikationsprozess durch Versenden eines Proof Requests mit einer Indy-Proof-Request-Struktur, die fünf offengelegte Attribute (cert\_type, facility\_type, epoch\_valid\_from, epoch\_valid\_until, role) und ein Zero-Knowledge-Predicate (security\_clearance\_level >= 2) fordert, während drei Identitätsattribute (first\_name, name, organisation) durch Selective Disclosure geschützt bleiben (Listing~A-\ref{lst:Jupyter-Notebook-Cell-15-Output}). Alle Attribute enthalten eine non\_revoked-Constraint mit Zeitintervall, die eine Ledger-basierte Echtzeit-Revocation-Prüfung gegen die Revocation Registry erzwingt.

Der Holder empfängt den Proof Request und konstruiert ein requested\_credentials-Objekt durch Mapping der fünf Attribute-Referents und des Predicate-Referents auf die Credential-ID, wobei Attribute mit revealed: true gekennzeichnet werden (Listing~A-\ref{lst:Jupyter-Notebook-Cell-16-Output}). Der Versand der Presentation erzeugt einen Zero-Knowledge-Proof, der kryptographisch beweist, dass der Holder ein Credential mit den geforderten Attributen besitzt, ohne die unrevealed Attribute offenzulegen (Listing~A-\ref{lst:Jupyter-Notebook-Cell-17-Output}).

Der Verifier empfängt die Presentation (State done, verified: true) und extrahiert die revealed Attributes durch dreistufiges Mapping, wodurch fünf offengelegte Attribute extrahiert werden (Listing~A-\ref{lst:Jupyter-Notebook-Cell-18-Output}). Die drei Identitätsattribute bleiben geschützt und werden als \enquote{NICHT offengelegt (Zero-Knowledge-Proof)} ausgewiesen, wodurch Privacy by Design gemäß \ac{DSGVO} Art.~25 realisiert wird. Die Blockchain-basierte Revocation-Prüfung validiert den Credential-Status durch Vergleich des Indy-Proof-Timestamps mit dem Revocation-Registry-Delta auf dem Ledger. Die Zeitgültigkeitsprüfung vergleicht einen aktuellen Epoch-Timestamp mit den extrahierten Zeitgrenzen, wobei die Bedingung epoch\_valid\_from <= current\_epoch <= epoch\_valid\_until die zeitliche Gültigkeit bestätigt. Die finale Zugriffsentscheidung kombiniert drei Validierungsergebnisse (not is\_revoked AND is\_time\_valid AND has\_required\_clearance) und führt im KRITIS-Szenario zum Ergebnis \enquote{ZUGANG GEWÄHRT}.

\subsubsection{Credential Revocation}

Die funktionale Anforderung FR5 fordert, dass das System die Ungültigkeitserklärung ausgestellter Credentials mit kryptographischer Verifikation durch Verifier ermöglichen muss. Die Erfüllung wird anhand eines dreiphasigen Revocation-Workflows demonstriert: Registry-Management, Two-Phase-Revocation sowie Non-Revocation-Proof Verification.

Phase~1 implementiert die Revocation-Registry-Verwaltung durch den Issuer. Der Abruf aktiver Registries (Listing~A-\ref{lst:Jupyter-Notebook-Cell-19-output}) zeigt zwei Registries mit 100 Credential-Kapazität. Jede Registry enthält die Metadaten rev\_reg\_id (eindeutiger Identifier), tails\_hash (kryptographischer Hash für Non-Revocation-Proofs) und tails\_local\_path (Speicherort der Tails-File für Accumulator-basierte Revocation nach CL-Signature-Schema).

Phase~2 realisiert die Two-Phase-Revocation durch Staging und Ledger-Publishing. Die Staging-Phase (Listing~A-\ref{lst:Jupyter-Notebook-Cell-20-output}) referenziert das Credential via rev\_reg\_id und cred\_rev\_id und bestätigt mit dem Status \enquote{Pending}, dass die Revocation ist lokal gestaged ist. Die Publishing-Phase (Listing~A-\ref{lst:Jupyter-Notebook-Cell-21-output}) führt die Ledger-Transaktion aus (Typ 114 REVOC\_REG\_ENTRY) mit Accumulator-Updates und revokierten Credential-IDs, authentifiziert via ED25519-Signatur und Byzantine Fault Tolerance konsistent repliziert.

Phase~3 validiert die Revocation-Enforcement. Das Holder-Wallet zeigt nach Revocation \enquote{Revoked Status: True} (Listing~A-\ref{lst:Jupyter-Notebook-Cell-14-output-revocation}). Der Holder wählt das revokierte Credential aus, versucht einen Non-Revocation-Proof zu generieren, scheitert jedoch, da der Accumulator das Credential als revoked markiert (Listing~A-\ref{lst:Jupyter-Notebook-Cell-15-output-revocation}, Listing~A-\ref{lst:Jupyter-Notebook-Cell-16-output-revocation}, Listing~A-\ref{lst:Jupyter-Notebook-Cell-17-output-revocation}). Die finale Verifier-Entscheidung (Listing~A-\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}) zeigt \enquote{Verified: false} und \enquote{ZUGANG VERWEIGERT}, da trotz zeitlicher Gültigkeit und erfülltem ZKP-Predicate die Revocation-Prüfung dominiert.

\subsubsection{Credential Deletion}

Die funktionale Anforderung FR6 fordert, dass Holder Credentials lokal aus ihrem Wallet entfernen können, wobei diese Operation nur die lokale Datenhaltung betrifft und vom Ledger-basierten Revocation-Mechanismus zu unterscheiden ist.

Phase~1 implementiert das Pre-Deletion Inventory. Der Abruf aller im Holder-Wallet gespeicherten Credentials (Listing~A-\ref{lst:Jupyter-Notebook-Cell-22-output}) zeigt ein Credential mit \enquote{Revoked: True}. Dieses wurde zuvor via Ledger-Revocation ungültig erklärt, persistiert jedoch weiterhin im lokalen Wallet. Die referent-Identifier werden für die nachfolgende Deletion-Phase erfasst.

Phase~2 realisiert die Credential Deletion durch iterative Entfernung aller erfassten Credentials (Listing~A-\ref{lst:Jupyter-Notebook-Cell-22-output}). Für jeden credential\_id wird via DELETE die lokale Wallet-Entfernung ausgeführt, mit erfolgreicher Deletion bestätigt: \enquote{Gelöscht: 1/1}. Diese Phase demonstriert die Holder-Autonomie über lokale Wallet-Daten ohne Issuer-Interaktion oder Ledger-Transaktion.

Phase~3 validiert die Deletion-Enforcement. Ein erneuter Abruf bestätigt das leere Wallet (Listing~A-\ref{lst:Jupyter-Notebook-Cell-23-output}). Die explizite Unterscheidung zwischen lokaler Deletion und Ledger-Revocation wird dokumentiert: \enquote{Credential ist LOKAL im Wallet gelöscht}, \enquote{NICHT auf dem Ledger revoked}, \enquote{Issuer kann das Credential weiterhin sehen}. Diese Differenzierung ist kritisch für das SSI-Sicherheitsmodell. Lokale Deletion entfernt das Credential aus Holder-Verfügungsgewalt, jedoch bleibt die Ledger-basierte Revocation-Historie intakt, womit KRITIS-konforme Audit-Trails mit Privacy-wahrenden Holder-Rechten vereinbart werden.

\subsection{Validierung der KRITIS-Compliance-Anforderungen}
\label{sec:Validierung der KRITIS-Compliance-Anforderungen}

\subsubsection{Einhaltung spezifischer Parameter-Sets für ML-DSA}

Die Compliance-Anforderung zur Einhaltung BSI-konformer ML-DSA Parameter-Sets (NIST Security Strength Category 3 oder 5) wird durch strategische Verwendung zweier Sicherheitsstufen erfüllt: ML-DSA-65 (Category 3) für operationale Signaturen sowie ML-DSA-87 (Category 5) für die Root CA. Das finale Artefakt implementiert ML-DSA in drei Schichten: (1)~TLS~1.3 Server-Zertifikate für alle fünf Nginx Sidecar Proxies (Issuer/Holder/Verifier, VON-Network Webserver, Tails Server) werden mittels ML-DSA-65 signiert (Listing~A-\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~A-\ref{lst:docker-compose.yml-Revocation-Registry}, Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten}), während die Root CA mit ML-DSA-87 geschützt ist (Listing~A-\ref{lst:Zertifikatserstellungsworkflow}). (2)~did:peer:4 Signing Keys werden mit ML-DSA-65 generiert (Listing~A-\ref{lst:key_types.py}). (3)~DIDComm~v1 Authcrypt Message-Signierung nutzt ML-DSA-65 via LibOQS (Listing~A-\ref{lst:liboqs_wrapper.py}) für Sender-Authentifizierung.

Die operationale Integration wird durch \autoref{fig:Successful-Validation-Issuer-TLS1.3} demonstriert, das die TLS~1.3 Verbindung mit ML-DSA-65 signiertem Server-Zertifikat validiert, sowie durch die Wallet-Übersicht (Listing~A-\ref{lst:Jupyter-Notebook-Cell-12-output}), in welcher alle drei SSI-Agenten key\_type \enquote{ml-dsa-65} für did:peer:4 DIDs nutzen.

\subsubsection{Einhaltung spezifischer Parameter-Sets für ML-KEM}

Diese Anforderung wird durch systemweite Implementierung von ML-KEM-768 (Category 3) erfüllt. Das finale Artefakt implementiert ML-KEM-768 in zwei Schichten: (1)~TLS~1.3 Key Exchange für alle fünf Nginx Sidecar Proxies nutzt ML-KEM-768 konfiguriert via DEFAULT\_GROUPS=X25519MLKEM768mlkem768x25519 in den Docker-Infrastruktur-Definitionen (Listing~A-\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~A-\ref{lst:docker-compose.yml-Revocation-Registry}, Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten}) sowie via ssl\_ecdh\_curve X25519MLKEM768 in den Nginx-Konfigurationen (Listing~A-\ref{lst:nginx-pqc-konfiguration}). (2)~did:peer:4 Key Agreement für Agent-to-Agent Verschlüsselung wird mit ML-KEM-768 realisiert (Listing~A-\ref{lst:key_types.py}), womit \gls{DIDComm}-Nachrichten Post-Quantum-resistent verschlüsselt werden.

Die operationale Integration wird durch \autoref{fig:Successful-Validation-Issuer-TLS1.3} demonstriert, das die TLS~1.3 Verbindung mit ML-DSA-65 signiertem Server-Zertifikat validiert, sowie durch die Wallet-Übersicht (Listing~A-\ref{lst:Jupyter-Notebook-Cell-12-output}), in welcher alle drei SSI-Agenten key\_agreement\_algorithm \enquote{ml-kem-768} für did:peer:4 DIDs nutzen.

\subsubsection{Implementierung hybrider Schlüsseleinigung}

Die BSI-Anforderung zur hybriden Schlüsseleinigung (Kombination klassisches Verfahren mit PQC-KEM) wird durch X25519+ML-KEM-768 Hybrid-Modus erfüllt. Das finale Artefakt implementiert hybride Schlüsseleinigung systemweit via \enquote{DEFAULT\_GROUPS=X25519MLKEM768:mlkem768:x25519} in allen Docker-Infrastruktur-Definitionen (Listing~A-\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~A-\ref{lst:docker-compose.yml-Revocation-Registry}, Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten}), wobei die Priorisierung X25519MLKEM768 als primären Hybrid-Modus sicherstellt. Die TLS~1.3 Verbindungen aller fünf Nginx Sidecar Proxies kombinieren elliptische Kurven-Kryptographie (X25519, klassisch) mit gitterbasiertem ML-KEM-768 (Post-Quantum) für Perfect Forward Secrecy, wobei OpenSSL~3.5.4 mit nativer PQC-Unterstützung die kryptographische Verknüpfung beider Shared Secrets via Key Derivation Function durchführt (Listing~A-\ref{lst:nginx-pqc-konfiguration}). Zusätzlich implementiert did:peer:4 hybride Key Agreement zwischen X25519- und ML-KEM-768-Keys aus DID Documents für \gls{DIDComm} Message Encryption (Listing~A-\ref{lst:key_types.py}). Die Fallback-Strategie mlkem768:x25519 gewährleistet Interoperabilität mit Peers ohne Hybrid-Unterstützung, wobei reine PQC-Verschlüsselung via ML-KEM-768 Vorrang vor klassischem X25519 hat. Diese Architektur entspricht \textcite[Kap. 2.2, 2.4]{bsi_BSITR021021KryptographischeVerfahrenEmpfehlungenundSchluessellaengenVersion202501_2025} zur Absicherung gegen kryptanalytische Angriffe sowohl im klassischen als auch im Quantum-Computing-Bereich.

\subsubsection{Bevorzugte Verwendung von TLS 1.3}
  
Die BSI-Empfehlung zur vorrangigen Verwendung von TLS~1.3 wird durch systemweite TLS~1.3-Enforcement erfüllt. Das finale Artefakt erzwingt TLS~1.3 in allen fünf Nginx Sidecar Proxies via \enquote{ssl\_protocols TLSv1.3;} in den Konfigurationsdateien (Listing~A-\ref{lst:nginx_holder.conf}). \autoref{fig:Summative_Evaluation_TLS1.2_Error} demonstriert das Fehlschlagen des TLS~1.2 Verbindungsversuchs zum Issuer-Agenten.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{summative_evaluation_TLS1.2_error.png}
    \caption{TLS 1.3 Enforcement blockiert Legacy-Verbindungsversuch}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Summative_Evaluation_TLS1.2_Error}
\end{figure}

\subsubsection{Protokollierung Sicherheitsrelevanter Ereignisse}

Das finale Artefakt implementiert Protokollierung auf drei integrierten Ebenen zur Gewährleistung eines unveränderlichen Audit-Trails. ACA-Py Agent-Level Logging protokolliert Authentifizierungsversuche, Zustandsübergänge und Fehlerzustände via --log-level info (Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten}), wobei kryptographische Events wie ML-DSA-65 Signature Verification und \gls{DIDComm}-Decryption dokumentiert werden (Listing~A-\ref{lst:issuer-acapy-agent-logs}). Nginx Access und Error Logs auf allen fünf Sidecar Proxies erfassen TLS-Handshakes und HTTP-Requests (Listing~A-\ref{lst:docker-compose.yml-DLT-Infrastruktur}, Listing~A-\ref{lst:docker-compose.yml-Revocation-Registry}), wobei Request-Body-Buffering für PQC-Schlüsselmaterialien protokolliert wird (Listing~A-\ref{lst:issuer-nginx-logs}). VON-Network Ledger Transaction Logs erfassen alle Blockchain-Operationen (NYM-, SCHEMA-, CRED\_DEF-, REVOC\_REG\_ENTRY-Transaktionen) mit Zeitstempeln und Sequence Numbers, womit ein kryptographisch verifizierter, unveränderlicher Audit-Trail für KRITIS-Compliance-Anforderungen realisiert wird (Listing~A-\ref{lst:Jupyter-Notebook-Cell-4-output}, Listing~A-\ref{lst:Jupyter-Notebook-Cell-21-output}).

\subsubsection{Logische Netzsegmentierung}

Das finale Artefakt implementiert strikte Netzwerk-Segmentierung mittels dedizierter Docker Networks zur Isolation kritischer Infrastruktur-Komponenten. hopE-Agenten nutzen isolierte Networks (hope-issuer, hope-holder, hope-verifier) pro Agent, wobei nur zugehörige Sidecar Proxies Zugriff haben (Listing~A-\ref{lst:docker-compose.yml-SSI-Agenten}). Das Shared Network von\_sidecarproxy verbindet ausschließlich die PQC Sidecar Proxies untereinander für Agent-to-Agent Kommunikation, während interne Agent-Container isoliert bleiben. VON-Network Blockchain-Nodes operieren im dedizierten von Network mit separatem sidecarproxy Network für Webserver-Zugriff (Listing~A-\ref{lst:docker-compose.yml-DLT-Infrastruktur}), und der Tails Server nutzt ein isoliertes tails-server Network mit kontrolliertem Zugang via von\_sidecarproxy (Listing~A-\ref{lst:docker-compose.yml-Revocation-Registry}). Diese mehrstufige Segmentierung, visualisiert in \autoref{fig:Docker-Compose-Übersicht-Iteration-1} und \autoref{fig:Darstellung-Network-Isolation}, realisiert strenge Netzwerk-Isolation gemäß \textcite[Control A.8.22]{iso/iec_ISOIEC270012022InformationsecuritycybersecurityprivacyprotectionInformationsecuritymanagement_2022}.

\subsubsection{Datenschutz durch Technikgestaltung (Privacy by Design)}

Die \ac{DSGVO}-Anforderung zu Privacy by Design \parencite[Art. 25]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016} wird durch architektonische Trennung von öffentlichen Identifikatoren und personenbezogenen Daten erfüllt. Das finale Artefakt realisiert eine konsequente Off-Chain-Architektur, in der personenbezogene Daten (Name, Organisation, Sicherheitsfreigabe) ausschließlich in verschlüsselten Verifiable Credentials lokal im Holder-Wallet persistiert werden (Listing~A-\ref{lst:Jupyter-Notebook-Cell-14-output}), während Ledger-Transaktionen nur kryptographische Identifikatoren (Schema-IDs, Credential-Definition-IDs, Revocation-Registry-IDs) und Public Keys enthalten (Listing~A-\ref{lst:Jupyter-Notebook-Cell-4-output}, Listing~A-\ref{lst:Jupyter-Notebook-Cell-21-output}). Zero-Knowledge Proofs ermöglichen selektive Offenlegung. Der Verifier erhält nur angeforderte Attribute, während sensible Daten geschützt bleiben, und Predicate-basierte Proofs (security\_clearance\_level >= 2) erfolgen ohne Offenlegung exakter Werte (Listing~A-\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}). Diese Architektur stellt Privacy by Default sicher, da personenbezogene Daten dezentral beim Holder verbleiben und nur kryptographisch verifizierbare Proofs ausgetauscht werden.

\subsubsection{Grundsatz der Datenminimierung}

Das finale Artefakt addressiert Datenminimierung durch drei komplementäre Mechanismen. Pairwise did:peer:4 DIDs eliminieren globale Identifikatoren. Für jede Agent-to-Agent Connection wird eine dedizierte DID generiert (Listing~A-\ref{lst:Jupyter-Notebook-Cell-12-output}), wodurch Transaktionskorrelation über verschiedene Verifier unterbunden wird und ein kompromittierter Verifier keine Aktivitäten des Holders bei anderen Verifiern nachverfolgen kann. Selective Disclosure in Proof Presentations offenbart ausschließlich angeforderte Attribute (cert\_type, facility\_type, epoch\_valid\_from/until, role), während Identitätsdaten (first\_name, name, organisation) unrevealed bleiben (Listing~A-\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}), wodurch nur zweckgebundene Minimaldaten übermittelt werden. Predicate-basierte Zero-Knowledge Proofs reduzieren Datenoffenlegung weiter. Der Holder beweist kryptographisch security\_clearance\_level >= 2 ohne Preisgabe der exakten Stufe (Listing~A-\ref{lst:Jupyter-Notebook-Cell-18-output-revocation}). Diese mehrstufige Datenminimierung verhindert Profilbildung und Datensammlung, womit DSGVO-konforme Zweckbindung technisch durchgesetzt wird.

\subsubsection{Recht auf Löschung}

Die \ac{DSGVO}-Anforderung zum Recht auf Löschung \parencite[Art. 17]{daseuropaeischeparlamentundderratdereuropaeischenunion_VerordnungEU2016679EuropaeischenParlamentsundRatesvom27April2016_2016} wird durch strikte Trennung von Ledger-Identifikatoren und Wallet-Daten erfüllt. Das finale Artefakt realisiert vollständige Löschbarkeit personenbezogener Daten durch lokale Credential-Deletion via DELETE /credential/{credential\_id}, wobei das Holder-Wallet vollständig geleert wird und alle personenbezogenen Attribute (Name, Organisation, Sicherheitsfreigabe) irreversibel gelöscht sind (Listing~A-\ref{lst:Jupyter-Notebook-Cell-22}). Crypto-Shredding durch Wallet-Destruction gewährleistet kryptographische Unlesbarkeit aller Credential-Daten. Die Vernichtung des Wallet-Keys führt zur Unmöglichkeit der Entschlüsselung, selbst wenn Backups existieren (Listing~A-\ref{lst:Jupyter-Notebook-Cell-22-output}). Während Blockchain-Transaktionen (Schema-IDs, Cred-Def-IDs, Revocation-Entries) unveränderlich auf dem Ledger verbleiben, enthalten diese per Design keine personenbezogenen Daten, sondern nur kryptographische Identifier (Listing~A-\ref{lst:Jupyter-Notebook-Cell-22-output}). Diese Architektur gewährleistet vollständige Löschung personenbezogener Daten bei gleichzeitiger Audit-Trail-Integrität.

\subsection{Validierung der Kryptoagilität}
\label{sec:Validierung der Kryptoagilität}

\subsubsection{Transportlayer}

TLS 1.3 realisiert Kryptoagilität durch orthogonale Aushandlung von Cipher Suite, Schlüsselaustauschverfahren und Signaturalgorithmen \parencite[S. 26]{rescorla_TransportLayerSecurityTLSProtocolVersion13_2018}, wodurch jeder Mechanismus unabhängig modifiziert werden kann. Die supported\_groups-Erweiterung ermöglicht es Endpunkten, Schlüsselaustauschverfahren unabhängig vom symmetrischen Verschlüsselungsverfahren auszuhandeln \parencite[S. 47]{rescorla_TransportLayerSecurityTLSProtocolVersion13_2018}. Diese Architektur adressiert die Kryptoagilitätseigenschaften Extensibility (effiziente Integration neuer Algorithmen) und Removability (elegante Außerbetriebnahme veralteter Verfahren) nach \textcite[S. 102]{mehrez_CryptoAgilityProperties_2018}.

Die Implementierung nutzt eine konfigurationsbasierte Algorithm-Fallback-Chain via DEFAULT\_GROUPS=X25519MLKEM768:mlkem768:x25519:mlkem1024 (Listing~A-\ref{lst:Dockerfile-Sidecar-Proxy-nginx}), die primär hybride Verfahren nutzt und automatisch auf rein klassische Verfahren (x25519) bei Inkompatibilität zurückfällt. Dies erfüllt die Fungibility-Anforderung nach \textcite[S. 102]{mehrez_CryptoAgilityProperties_2018} und ermöglicht Algorithmenauswahl in Echtzeit basierend auf Sicherheitsfunktion \parencite[S. 19]{cyberresilienceworkshopseriescommittee_CryptographicAgilityInteroperabilityProceedingsWorkshop_2017}. \autoref{fig:Summative_Evaluation_TLS1.3_Kryptoagilität} demonstriert den kryptoagilen Fallback-Prozess.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{summative_evaluation_TLS1.3_kryptoagilität.png}
    \caption{TLS 1.3 Kryptoagiler Fallback von X25519+ML-KEM-768 zu X25519}
    \begin{flushleft}
    \textit{Anmerkung.} Eigene Darstellung.
    \end{flushleft}
    \label{fig:Summative_Evaluation_TLS1.3_Kryptoagilität}
\end{figure}

\subsubsection{Applikationslayer}

Die Applikationsebene nutzt die Plugin-Architektur von ACA-Py zur Algorithmenauswahl ohne Modifikation des Kerncode, entsprechend dem Open-Closed-Prinzip nach \textcite[S. 99]{martin_AgileSoftwareDevelopmentprinciplespatternspractices_2003}. Das Plugin implementiert einen metadatengesteuerten Ansatz. Via Parameter \enquote{metadata: {key\_type: ed25519}} kann der Schlüsseltyp explizit spezifiziert werden (Listing~A-\ref{lst:Jupyter-Notebook-Cell-9-Demonstration-Kryptoagilität-ed25519}). Der OutOfBandManager evaluiert in create\_did\_peer\_4\_conditional\_pqc (Listing~A-\ref{lst:base_manager_patch.py}) den key\_type-Parameter. Wird \enquote{ed25519} erkannt, delegiert das Plugin zur ursprünglichen ACA-Py-Implementierung für vollständigen Fallback auf klassische Kryptographie, fehlt die Spezifikation, aktiviert das System standardmäßig ML-DSA-65 und ML-KEM-768.

Die erfolgreiche Validierung zeigt Listing~A-\ref{lst:Jupyter-Notebook-Cell-9-Demonstration-Kryptoagilität-ed25519-output}. Eine ED25519-basierte Verbindung etabliert sich mit Status \enquote{active}, was korrekte DID Exchange-Durchführung mit klassischen Algorithmen bestätigt. Listing~A-\ref{lst:Jupyter-Notebook-Cell-11-Demonstration-Kryptoagilität-ed25519-output} verifiziert persistierte Kryptographie. Wallet-DIDs zeigen konsistent \enquote{key\_type: ed25519}, wobei Abwesenheit von PQC-Metadaten (pqc\_enabled, signature\_algorithm, kem\_verkey) bestätigt, dass das Plugin keine Eingriffe im ED25519-Workflow vornahm.