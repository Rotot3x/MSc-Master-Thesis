\newpage
\section{Ergebnisse und Diskussion} 
\label{sec:Ergebnisse und Diskussion}

\subsection{Beantwortung der Forschungsfragen} 
\label{sec:Beantwortung der Forschungsfragen}

Die vorliegende Arbeit adressiert durch Design Science Research Methodologie drei zentrale Forschungsfragen an der Schnittstelle von Self-Sovereign Identity, Post-Quantum Cryptography und kritischen Infrastrukturen. Die in Kapitel 6 durchgeführte summative Evaluation unter Anwendung des FEDS-Frameworks demonstriert, dass das entwickelte Artefakt diese Fragen nicht nur theoretisch sondern empirisch durch kontrollierte Evaluation beantwortet.

\textbf{Forschungsfrage FF1}: \enquote{Wie kann ein blockchain-basiertes SSI-System unter Einsatz von Post-Quantum-Kryptografie gestaltet werden, um die regulatorischen und technischen Anforderungen von kritischen Infrastrukturen nachhaltig zu erfüllen?}

Diese Forschungsfrage wird durch die Konzeption und Implementierung einer zweischichtigen Architektur beantwortet, die quantenresistente Kryptografie orthogonal und nicht-invasiv in bestehende SSI-Infrastrukturen integriert. Die erste Schicht realisiert Quantensicherheit auf der Transportebene (Data-In-Motion) mittels eines Sidecar-Proxy-Patterns mit nginx, das TLS 1.3 als Protokoll-Standard durchsetzt und ein hybrides Schlüsseleinigungsverfahren (X25519 + ML-KEM-768) implementiert. Parallel dazu werden digitale Zertifikate mit ML-DSA-65-Signaturen ausgestellt und validiert, was die Post-Quantum-Authentifizierung von Netzwerk-Endpunkten sicherstellt. Diese nicht-invasive Architektur erfüllt die KRITIS-Anforderung nach Backward-Kompatibilität: SSI-Agenten (ACA-Py), Blockchain-Knoten (Hyperledger Indy) und Wallet-Applikationen benötigen keine Modifikation ihrer Anwendungslogik, da die Quantensicherung transparent auf der Netzwerk-Infrastruktur-Ebene erfolgt.

Die zweite Schicht erweitert die Quantensicherheit auf die Applikationsebene (Data-At-Rest und Credential-Verarbeitung) durch native PQC-Integration in Hyperledger Aries Cloud Agent Python. Mittels einer Monkey-Patching-Strategie werden kritische Komponenten überschrieben: die didpeer4-Verarbeitung ermöglicht es, Decentralized Identifiers mit ML-DSA-65-Signaturen zu erzeugen und zu validieren; die DIDComm-Envelope-Verarbeitung unterstützt ML-KEM-768-basierte Schlüsselkapseln für die Nachrichtenverschlüsselung. Diese duale Implementierung adressiert das zentrale KRITIS-Sicherheitsprinzip der Defense-in-Depth: falls eine Schicht kompromittiert wird, bietet die andere weiterhin Schutz.

Die Validierung aller neun Compliance-Anforderungen (CR1 bis CR9) in Kapitel 6.2 demonstriert empirisch, dass die Architektur sowohl die kryptografischen Parameter des Bundesamts für Sicherheit in der Informationstechnik (ML-DSA-65 und ML-KEM-768 gemäß TR-02102) als auch die organisatorischen Anforderungen der Datenschutz-Grundverordnung erfüllt. Insbesondere werden die Anforderungen zur strikten Netzsegmentierung (CR6), zur Protokollierung sicherheitsrelevanter Ereignisse (CR5) und zur Datenminimierung durch Privacy-by-Design (CR7) vollständig operationalisiert. Das Artefakt demonstriert somit, dass quantenresistente Kryptografie nicht nur ein technisches Problem, sondern ein systemisches Problem ist, das Compliance-, Architektur- und Governance-Aspekte simultan adressieren muss.

\textbf{Forschungsfrage FF2}: \enquote{Welche Post-Quantum-Cryptography-Algorithmen eignen sich für die Integration in Self-Sovereign-Identity-Systemen hinsichtlich Sicherheit, Praktikabilität und Interoperabilität im Kontext kritischer Infrastrukturen?}

Diese Forschungsfrage wird durch die empirische Validierung der NIST-standardisierten Algorithmen ML-DSA-65 (Crystals-Dilithium mit Security-Kategorie 3) und ML-KEM-768 (Crystals-Kyber mit Security-Kategorie 3) beantwortet. Die bewusste Auswahl dieser Parameter-Sets entspricht der NIST Security Strength Category 3, die vom Bundesamt für Sicherheit in der Informationstechnik für Zielvorgaben im KRITIS-Kontext akzeptiert ist und gleichzeitig moderate Schlüsselgrößen ermöglicht: ML-DSA-65 erzeugt Signaturen von 2944 Bytes, ML-KEM-768 Ciphertexte von 1088 Bytes. Diese Größen sind für die Kodierung in didpeer4-Strukturen und DIDComm-v1-Envelopes praktikabel, ohne die Netzwerk-Overhead problematisch zu erhöhen.

Die empirische Evaluation in Kapitel 6.1 und 6.2 zeigt, dass diese Algorithmen nicht primär durch intrinsische Sicherheitsdefizite limitiert sind --- beide Verfahren werden von NIST empfohlen und ihre Sicherheitsreduktionen auf gut-verstandene mathematische Probleme sind rigoros --- sondern durch technische Integrationschallenges in bestehende Aries-Infrastrukturen, die originär auf Elliptic-Curve-Cryptography ausgelegt sind. Diese Infrastruktur-Kompatibilität adressiert die Arbeit durch drei komplementäre Mechanismen:

Erstens ermöglicht TLS 1.3-Algorithmen-Aushandlung es Endpunkten, zwischen hybriden Cipher-Suites und rein klassischen Verfahren zu fallback-en, was die Schrittweise-Migration für heterogene Deployments vereinfacht. Zweitens detektiert die DIDComm-v1-Envelope-Verarbeitung anhand von Schlüssellängen automatisch, ob PQC oder klassische Algorithmen erforderlich sind, wodurch PQC-fähige Agenten mit Legacy-Agenten interagieren können. Drittens schafft die Multikey-Kodierung mittels Multicodec-Registry die kryptographische Identifikation neuer Algorithmen ohne Schema-Änderungen im DID-Dokument.

Die Hybrid-Strategie, die klassische und quantenresistente Algorithmen kombiniert, ist ein Best-Practice für die aktuelle Übergangswelt: Die Kombination von X25519 (ECC, etabliert sicher) mit ML-KEM-768 (PQC, mathematisch neu) garantiert, dass die Gesamtsicherheit mindestens so stark wie der stärkere der beiden Algorithmen ist.

\textbf{Forschungsfrage FF3}: \enquote{Welche kryptografischen Agilität-Mechanismen sind erforderlich und praktikabel, um zukünftige Post-Quantum-Cryptography-Algorithmenupdates ohne Systemunterbrechung zu ermöglichen?}

Diese Forschungsfrage wird durch zwei orthogonale, schichtenspezifische Agilität-Implementierungen beantwortet. Auf der Transportebene realisiert TLS 1.3 Kryptoagilität durch eine fundamentale Separation of Concerns: Cipher-Suite, Schlüsselaustauschverfahren und Signaturalgorithmen werden unabhängig voneinander gehandelt. Eine konfigurationsbasierte Fallback-Chain in der nginx-Konfiguration ermöglicht es, neue Algorithmen durch einfache Textdatei-Änderung auszurollen, ohne nginx neu zu kompilieren oder Systemkomponenten zu neustarten. Dies erfüllt die Extensibility- und Removability-Kriterien und ist in Kapitel 6.3.1 empirisch demonstriert.

Auf der Applikationsebene implementiert das PQC-Plugin-System Agilität durch mehrere ineinander verschachtelte Abstraktions-Ebenen: Die Kryptografie-Abstraktionsschicht kapselt liboqs-Operationen hinter einer Python-FFI, wodurch zukünftige Versionen von liboqs ohne Änderung des Plugin-Interfaces integriert werden können. Die DID-Verarbeitungsschicht nutzt Multicodec-Präfixe für Algorithmen-Identifikation, die W3C-Standard konform erweiterbar sind. Die Monkey-Patching-Integration wird durch generische Patch-Methoden realisiert, die kritische ACA-Py-Funktionen überschreiben, ohne das Framework-Quellcode zu modifizieren.

Die empirische Validation in Kapitel 6.3.2 demonstriert exemplarisch einen kryptoagilen Fallback-Mechanismus: wenn ein X25519+ML-KEM-768-Schlüsselaustausch fehlschlägt, fallback-t der Server automatisch auf rein X25519, ohne die Verbindung abzubrechen.

\subsection{Kritische Reflexion} 
\label{sec:Kritische Reflexion}

\textbf{Methodische Stärken und Gewährleistung von Rigor:} Die Wahl des Design Science Research Frameworks kombiniert mit dem Framework for Evaluation in Design Science (FEDS) ermöglicht es, technische Risiken isoliert in einer kontrollierten Laborumgebung zu reduzieren, bevor naturalistischeFieldtests erwogen werden. Dies ist im KRITIS-Kontext nicht nur wissenschaftlich, sondern ethisch essentiell: experimentelle kryptographische Prototypen dürfen nicht ohne Risikovalidierung in produktiven Infrastrukturen mit Gemeinwohlverantwortung deployiert werden.

Die iterative Artefakt-Entwicklung mit zwei Iterationen ermöglicht es, frühe Design-Fehler in der first-order-Iteration zu identifizieren, bevor die second-order-Iteration aufgebaut wird. Dies realisiert eine sukzessive Komplexitätsreduktion und schafft frühzeitige Lerngewinne, die in die Designrefinements der zweiten Iteration einfließen. Die explizite Dokumentation des Evaluationsprozesses durch detaillierte Jupyter-Notebooks und strukturierte Log-Analysen erfüllt hohe Anforderungen an Reproduzierbarkeit und wissenschaftliche Transparenz. Das FEDS-Framework hat dabei insbesondere die bewusste Priorisierung auf Technical Risk erlaubt, wodurch die Evaluation nicht durch soziale oder organisatorische Konfounding-Faktoren überlagert wurde, die für diese frühe Forschungsphase noch verfrüht wären.

\textbf{Limitationen und deren Bedeutung für Generalisierbarkeit:} Der zentrale Limitation dieser Arbeit liegt in der bewussten Abgrenzung zwischen artificialem und naturalistischem Evaluationssetting. Die Evaluation erfolgt in einer isolierten docker-compose-Umgebung, die keine Netzwerk-Latenzen, Paketverluste oder asynchrone Fehlerszenarien simuliert, die in produktiven KRITIS-Netzen auftreten. Dies bedeutet, dass die gemessene Efficacy für das laborhafte Setup validiert ist, aber nicht notwendigerweise für dezentralisierte, geographisch verteilte KRITIS-Netzwerke mit WAN-Latenzen.

Die Blockchain-Infrastruktur wird mit vier lokalen Validator-Nodes betrieben, nicht mit dem typischen Produktions-Setting von zehn bis zwanzig geographisch verteilten Nodes. Dies beeinflusst die Konsensus-Latenz nicht fundamental, erlaubt aber nicht, realistische Blockierungszeiten oder Timeout-Szenarien zu evaluieren. Die SSI-Agenten laufen allesamt im selben Docker-Network mit lokal auflösbarem DNS, was die Netzwerk-Segmentierung-Evaluation vereinfacht. Ferner wurde die Evaluation ohne Last-Tests durchgeführt, weshalb Fragen zur Performance-Degradation unter Hochlast bewusst ausgegrenzt werden. Diese Limitationen sind Boundaries of the Evaluation, nicht Fehler.

\textbf{Trade-offs bei kritischen Design-Entscheidungen:} Die Wahl des Monkey-Patching-Ansatzes stellt einen bewussten Trade-off zwischen kurzfristiger Wartbarkeit und langfristiger Maintenance-Sicherheit dar. Monkey-Patching erlaubt es, das originale ACA-Py-Framework unverändert zu belassen, reduziert aber die Versionskompabilität mit zukünftigen ACA-Py-Releases. Ein offizieller Fork hätte langfristige Maintenance-Sicherheit geboten, erfordert aber erhebliche organisatorische Koordination. Für einen Research-Prototypen ist Monkey-Patching pragmatisch; für produktive Deployments wäre ein Upstream-Merge mittelfristig erstrebenswert.

Die Hybrid-Cryptography-Strategie erhöht die Komplexität des Vertrauensmodells erheblich. Ein Verifier muss entscheiden, welche Algorithmus-Kombinationen akzeptabel sind, was nicht-trivialen Governance-Overhead in KRITIS-Betreiberverbänden erzeugt.

Die Verwendung provisorischer Multicodec-Präfixe ist funktional, aber nicht W3C-standardisiert. Eine formale Registrierung würde eine sauberere, zukunftsfeste Lösung darstellen, benötigt aber externe Koordination mit der W3C Decentralized Identifiers Community Group.

Ein weiterer Trade-off betrifft die Signaturverifikation von Credentials: die Revocation Registry nutzt noch klassische ED25519-Signatures für CL-Accumulator-Operationen, um Abhängigkeiten zu minimieren. Eine vollständige PQC-Revocation-Registry hätte zusätzliche Entwicklung in Indy-Tails-Server erfordert.

\textbf{Einordnung in den Standardisierungs- und Technologie-Kontext:} Der zeitliche Kontext dieser Arbeit fällt in eine kritische Übergangsphase der Post-Quantum-Cryptography-Standardisierung. Die verwendeten Algorithmen wurden von NIST 2022 ausgewählt, 2024 formalisiert und als FIPS-Standards akzeptiert, sind aber noch nicht in allen industriellen Systemen vollständig integriert. Die in dieser Arbeit gewählten Versionen sind State-of-the-Art (Stand Dezember 2025), werden sich aber in kommenden Monaten ändern. Die Evaluation ist daher am Snapshot der Technologie-Maturität gültig; für Releases 2026 und darüber hinaus wird eine Wiederholung wertvoll sein.

Ferner befinden sich zentrale SSI-Standards noch in aktiver Entwicklung. Die Arbeit implementiert bewusst den stabilen DIDComm v1.0 Standard, was keine Breaking-Changes zu erwarten sind. Eine Migration zu DIDComm v2.0 wird bei dessen Finalisierung erforderlich sein.

\subsection{Wissenschaftliche und praktische Beiträge}
\label{sec:Wissenschaftliche und praktische Beiträge}

\textbf{Theoretischer Beitrag --- Konzeptuelle Integration dreier Forschungsdomänen:} Diese Arbeit leistet einen ersten umfassenden Beitrag zur Integration von drei bislang isoliert betrachteten Forschungsdomänen --- Self-Sovereign Identity, Post-Quantum Cryptography und kritische Infrastrukturen --- in einem kohärenten und empirisch validierten Systemdesign. Die existierende Literatur adressiert typischerweise zwei der drei Domänen; die Formulierung einer ganzheitlichen, quanten-sicheren SSI-Architektur speziell für KRITIS-Kontexte war bislang nicht konsistent durchgeführt.

Ein kernales Erkenntnisergebnis ist die Einsicht, dass quantenresistente Kryptografie nicht als eine bloße Cryptography-Substitution verstanden werden darf, sondern als ein Architektur-Problem, das fundamentale Fragen aufwirft: Wie integriert man größere Schlüssel ohne Netzwerk-Overhead? Wie gewährleistet man Interoperabilität zwischen PQC-fähigen und Legacy-Systemen? Wie realisiert man Kryptoagilität? Wie wahrt man Privacy-by-Design bei veränderten Signatur-Algorithmen? Diese Fragen erfordern spezifische technische Lösungsmuster: Sidecar Proxies für transparente Transport-Layer-Sicherung, Monkey-Patching oder Upstream-Integration für Applikations-Layer-Agilität, Multicodec-Extensibilität und sorgfältige Governance-Modelle.

Ein weiterer theoretischer Beitrag ist die Formulierung von schichtenspezifischer Kryptoagilität. Während Transport-Layer-Agilität durch TLS 1.3 relativ trivial ist, erfordert Applikations-Layer-Agilität komplexe Rückwärtskompatibilität in DIDComm-Envelope-Verarbeitung, Credential-Verifikation und Revocation-Mechanismen. Dies ist in klassischen Kryptosystemen nicht in diesem Ausmaß erforderlich.

\textbf{Praktischer Beitrag --- Reproduzierbarer Prototyp mit Migrations-Roadmap:} Das entwickelte Artefakt besteht aus Sidecar-Proxy-Templates, ACA-Py-Plugin-Code, vollständiger Docker-Compose-Orchestrierung und ausführlichen Jupyter-Notebooks und ist vollständig open-source zugänglich. Die Dokumentation basierend auf realistischen KRITIS-Szenarios ermöglicht es, die Technologie-Anwendbarkeit unabhängig zu bewerten.

Die modular aufgebaute Architektur erlaubt Partial-Adoptions: eine Organisation könnte nur die Sidecar-Proxy-Layer deployieren, um sofort ihre bestehende SSI-Infrastruktur quantensicher zu machen, und später zur Applikations-Layer-Integration übergehen. Dies adressiert eine zentrale Praktiker-Anforderung: die Vermeidung von Big-Bang-Deployments und die Ermöglichung gradueller, reversibel-testbarer Übergänge.

\textbf{Methodischer Beitrag --- DSR-Anwendung auf Cybersecurity-Probleme:} Die systematische Anwendung von Design Science Research auf komplexe Cybersecurity-Probleme ist noch nicht vollständig im deutschsprachigen Raum verankert. Diese Arbeit demonstriert durch konkrete Operationalisierung, dass DSR mit FEDS-Framework zu neuartigen, empirisch validierten Erkenntnissen führt, die durch reine theoretische Analyse oder ad-hoc-Prototyping nicht erreichbar sind.

Die Zwei-Iterationen-Zyklik illustriert, wie formative Evaluationen zu identifizierten Design-Defiziten und notwendigen Refinements führen, die dann summativ validiert werden --- ein evidenzbasiertes Designprinzip für kritische Infrastrukturen. Die iterative Entwicklung erfolgt nicht linear nach Wasserfall, sondern als epistemische Spirale mit Rücksprängen: formative Evaluationen der ersten Iteration identifizierten Inkompatibilitäten in der CL-Accumulator-Verarbeitung, die zur Design-Entscheidung für Monkey-Patching führte, was wiederum neue Evaluationsfragen aufwarf. Diese Zirkularität ist ein strukturelles Feature, das sicherstellt, dass Design und Evaluation sich gegenseitig kontinuierlich informieren.

\textbf{Konsequenzen für Standardisierung und Governance:} Die Erkenntnisse haben unmittelbare Implikationen für laufende Standardisierungsprozesse bei W3C Decentralized Identifiers und BSI-Richtlinien. Insbesondere wie Multicodec-Präfixe registriert werden, wie KRITIS-Governance-Modelle mit Hybrid-Algorithmen-Anforderungen umgehen, und wie Liability bei PQC-Zertifikaten organisiert wird, erfordert expliziter Industrie-Konsens, den diese Arbeit durch empirische Demonstrationen informiert.
